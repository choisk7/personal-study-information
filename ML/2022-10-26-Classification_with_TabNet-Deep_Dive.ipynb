{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7e7b1bbf",
   "metadata": {
    "id": "7e7b1bbf"
   },
   "source": [
    "# TabNet으로 하는 Classification: Deep Dive\n",
    "\n",
    "출처: [https://syslog.ravelin.com/classification-with-tabnet-deep-dive-49a0dcc8f7e8](https://syslog.ravelin.com/classification-with-tabnet-deep-dive-49a0dcc8f7e8)\n",
    "\n",
    "# Classification with TabNet: Deep Dive\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "여기서는 해석 가능하고 테이블 형식 데이터와 잘 작동하도록 설계된 TabNet ([Arik & Pfister(2019)](https://arxiv.org/abs/1908.07442))이라는 neural architecture에 대해 자세히 알아볼 것입니다. 핵심 building block과 그 이면의 아이디어를 설명한 후, TensorFlow에서 구현하는 방법과 사기 탐지 데이터 세트에 적용하는 방법을 알 수 있습니다. 대부분의 코드는 [여기](https://github.com/aruberts/blogs/blob/main/TabNet%20Classification%20Example.ipynb)에서 가져왔습니다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABEwAAAEfCAIAAADUQcQTAAAgAElEQVR4nOy9d5ccx5UveCPSlPdd7T28BwiCBvTeiaIkelKk3Ejz9uyXmM+we/ac2T1686Q3MiRFT5CASNHCO8IRHmhX1V1tyrv0cfePzKrKMg2AMkfSTP50xEZmZcQ1ce+NG5ERkQQRwYEDBw4cOHDgwIEDBw7+q4D/ezPgwIEDBw7+HLRMURECAOTvxIsDBw4cOHDwjwVnkOPAgQMHfwW0vxUn5G845EBEhkxVlKpcIYQEfEGeF/6WBB04cODAgYN/JjiDHAcOHDj466BSLc8uJERBHOgZEgTxb0oLEZcyC5/u+/Dc5dN9vYPPPPZKT1ff35SiAwcOHDhw8E8E+vdmwIEDBw7+i2B69up/vP5/7f787apc/ctrQ0RFlWdmJ2fnZ3Rda3lTpGnq0VP7dn/+TqVajoXiLtF1g9VqmjI3n0ikpmRVdvZkOnDgwIGD/6pw3uQ4cODAwV8HmdzSVOJKf8+QwPOMMXO5GgIjQAGAEGIfVCx3v/EA4vzS3Bsf/CoaiT3z+KsBX6j+MCJWpPK5y6fdbs8PHnt524YdXo8PERENBEKAAACllDFmEkIESixauWLu3U9eM3Tt6cdf7Y33X3ecg4CkttUHAQGQALVEQwRAhkgJASCEEuJsCnLgwIEDB/8YcAY5Dhw4cPBXgGHo+WJW1dSuSDcAnL100jB0jucX0/MBf3D12PqgP7ywNDe3mPR5/cVSvljOx8Lx8eE1wUCoKlWuTl1wuT1jQysZY1cmLxhM93oCx88c+Prs4b74wPjw4fWrNnfH+gAAEdOZhRPnjl6ePI+IpXJBUVXK8bPz03PzM4ZhDPSNjg6MuVweWZGSqem5hYSiKd3RnpWjayW5evTU/iMn97oE99jwqs1rtzPG0rnF8eFV4WB0biE5vzg72DficnmmZ69SQhljpUph1fg6j8uXmJuYX0pxlBsbXtXfPcRxXCa/ODF9qVDOR4LRFSNrI6Eoodzfux0cOHDgwIEDAGeQ48CBAwd/Fei6nitkOUojoWg2n3lnz28XM/NutzedXXSL7qceef7uWx4+/s3Bj7963+P2VarlcrXk8/ofuvPJh+56Yn5p7vVdvx4bXtXXPVgs5d/Z8zuOo4P9Y5/t/yiTXVJVZfdnbwf9IXOQwxi7OHn2/T+9nkxNC4J44NjnXbGeTHZx39E/lSslWZXj0Z5nv/OjdSs3n7t8cvfn72YL6Wq14hJd3334eY5yH332dmph1iW6P/zTW4TQXD575uLXrzz9C78vdOjEVwePffHM4694vN7X3/9fkiwBgMfjfcR4aiE9d/zMoapUUVRl5cjqHzz+SsAXfPePvz957ihjht8bePKBZ2+/+T63yxnkOHDgwIGDfwg4e3IcOHDg4K8ATVdzhbQguELBSK6QmUxcyZfyG1Zt2bB6y9xC4sz5ExWpnJibvjJ1UVaq99728F077s8Xsp/u/3B+aS5XyEzMXDJ0jeeFbH5penZCZ/rqsXUrx9a5XZ7bb7rnsft/MNQ3ZhIihAz2jW1avdXj9m5cs/W+nY+mFhJv7/4tx/Pff/SlndvvnZi5fPzMQVWV3S7f2lWbn3zw2Z0335vOLZ46d6y7q3f9qs1ej2/zuu1PPvzcQM/w9NzVUiVPCdUNfTp5ZW4xyfN8Np+5OnNpIZ1aNbb2jh0PXJo8t+fL9wb7Rp554kdb1t106vzxM+ePn710ct/RT/1e/3fuf/qWbXf29w3xnDPCceDAgQMH/yhwBjkOHDhw8JcCEVVNzRWybpcnFIgWSnlVU3ds3vndh57fuf1enzdAKJFlqVDKRsOxpx975cmHnv/OA8+uX7mlUMyXKsVMfknXtXAwKgpivpitSuWeWP+K0XX98UG/L3DL1jvv3PFAV7TbpEUpHe4fHRoYd4muzWu3b1q3fWL60txislqtnL10KpGaNphRrpTMl0W5fObk2WOXJs7Likw52t8zPNQ/5vF4t67fcd/tj0bCsVwhHfCFfd6AJFWy+azH7fF6A8VSgTH2wJ2Pv/z9f9285qapxJVMdjGdXfzmwvHF9LxuaOVqGZGJgmsps3Bx4pzX7Y+G4tRZq+bAgQMHDv5h4AxyHDhw4OAvBSJWquViueD1eAO+YKGUMwxjuH/U7wtomgoEwsGorErFUtHvC3Z39VJKZUVWNNnv8/OckM0tASFut0fT1NTirKxIsWg3ASyUcm63x+cLUEIJIfUP7yBgvpDVDT0W7tINPVtI8xxPKZfOLUlydfXY+pWjayYTV37/3v88efawrqvlalHT1Gg4TgktlPPAMByMcJRTFKlYLLhdboEX0tnFTG4pGIiIgpgrZFyCa9XouqA/JMnVQikvCi5D19K5RU1XN67eNj60cvX4hkfveWp0aOWJbw6/s+d3566eMZjx920FBw4cOHDgoA5nT44DBw4c/BVQKOWkaqUr1sMLQq6QpZSEQzFKaDq3yAwjHumWFalQzM4vzn6yd9dk8uqFy2cmZy7fseO+rmi3puuqppy9dFLT1QPHPmeI0XAXIpSlkiRLF6+ciQZjQ/1jHMeZQx1N0zL5NMfx4VDM7w3Eoz0et2d8ePVA3/BU4mrA59+wetuBY59PJq7cfesDm9bclC/nOY7vifUSQiS5KinS1ZlLPfEBQkA3tLmF5JeHPk4tzs4tzGzffBvP89n8ksvtCQXChBC/LxiLdJWqhXWrt/i8gYmpCyPDK8eHV00krhBKb9t2t6apk4krqiIBOAdSO3DgwIGDfxQ4gxwHDhw4+EuBiLIqu9zugd5hjnKqqvR09UeDMSBEUdVgINzd1SfJ1VK16PX4z5z/+vT54wYzNq7Zdt/tj0UjsRXDq7tjfecunZ5fmpNkqa97IBbuEkWxJ9Z37vLprw79KRbuHugd5mqbXlRNZobe190fCkT8vsDOHffNp+dOnT1y4coZANyx9U6/19/T1RePdl+dupgv5ArFfCwSj8f6BEGMReJet+/wia/cLs/dtzy4ZsXGE98c/uLQH92ix+f198aHXKLbYEY82hsKRAEgGonddcuD5c+Lh45/SSnH8/y61ZsR4OLE2WOn9nu9flmubt9026qx9Rx1OhQHDhw4cPCPgs7fZ3DgwIEDBzcOxlg6uzCVvBoNd/X1DM3OTZWqpRUjq/3e4FTy8lJ2ccXwmlPnjv7P1//vu299aNPabblCJhqKjQ2v7u7q4zm+Ui2du3R6MbcQC8ddomgYxqrRdT5fIDk3ff7KGd3QNq+9abh/jHIcIgIQRZWuTl+UFWX12Dq/L6BqSmJuaipxRVbl3njf2NDqUDBaqRTOXTmTzS1Fwl0et0dV1dXj64OB8EI69c2FE1WpvHJs7YrhNXMLyctT50VBjEW6K9ViT6y/r2fwyvQFQzdWj6/3uL0ApCqXZ5JXZ+YmEUh/z+DY4EqP2zu3kLgyfbFULkbC0RXDa3rj/RzH1xfUOXDgwIEDB39fOIMcBw4cOPhLUfvsZtu3MIm1hktVlXc/fu2DP73x0vf+5aG7vgNAOMoRSuubbBgyhgYlXH2cYH730zB0BOA5jhDbJzjN/wEAAKUEERCRMQMBKeUoUCBgfjOUMYPSRp0mP4ZhICLHcZQQBDCYQQAo5UwJiG3Zmbk6jiECYuMxAgQIIjJkzGCUo5RSAsRk2BnnOHDgwIGDfwQ4qwscOHDg4C8CIlK6/CEuBAAAAQ1Dj0d7uiI9PCc0PY8AFDjgOGg9nYwQQqnYXiOhQGrjKXNcQQhpqZNQAgBc+7HOBOxPEoB25luGKZQQaKnf5A2onWVnhOPAgQMHDv5x4LzJceDAgYO/OTRdm0pczhVyK0bXREMxZzDgwIEDBw4c/E3hDHIcOHDg4G8OxhgiIoB1FLQzyHHgwIEDBw7+lvjHXa5WH3052cB18d9KV/+thP1bw1Hmt8Wfp7HW9Wz/TDNLjXkwx0j+bPzTOdo/HcPXhn0y959Uov9iLfIXwtGGgxvEjQ5yahECiXVBrAus3exQxPrZMkIEAIJgK98B1gMEAJEZBqOUUkrN3bJNRRp7YxtF6gSbuO1QxOKtqYjFZI23ekmsP99CpVYKr00FALBJA8RGpV6kiVCLfkhnPddKIQBjjDFmLr4nTUVq2wGaqHTUT61hrQts3G7WgI03Yl0sqwFb09ipdNRAcxFobH9utTRENAzDNAzSKGIntIxxdmiauqQNxq5pmTdAxYZOZmPquc0FrqmBZQ3A3jQ1E+5gscvyhoZhAIC5a7zemnDNprm+C3TUwLWDgM0Fmtqp9vO1PbqjnluVdn2PJo0fO2nALGKaHyGE4zhyfRewhRpssbRmcdqKQNMJAMvYANiLtPx6Y2ZzPXtGQMawHl7aQnEjcnai0txwLR7d/ESbpYFlNh3jc2dZmorUxFm2u2kyzmsU6ciYXdRakY4wqZghuha1mszdXpONUFsv0IH0MvHZrvwbjM9tLtAUZq9lnNfvbds8+lu6QE2sPyPY1osAgBnrOI7WKryxuNHM27JF4LrG2TlydizSVIqAvZe3dXx1XVoPQHMRG5UbEKfVBZqL2FuhxmCTC9Qc58aNE4gp/Z+ZPNS1wXH0GsZpL3JjHl13gTYNtFNpLbJsP9gmzjJ6tqGjC9SKOvgWuOE3OcgA6+kUIDBA004JmgfqAAIhBAGJ6XFmCyEBggyAmCNvBAIEzYN5SL3J0DRCs7MARoAgoGEYhULR7Xb7fD5AaKECBBjWw0vNWdAkxIAAQQoEGABBk1GLrZqpofmLFR0IA2ZNCSBYMgAAIcAAavbVoGI5O6JJ3+TY5L9GBRulTQ0AIMGas5Gaihq2j1h3FlNBNioAgBQJIhACFi1sRG+UZaVSLYdDIUEQWE0fNQ0wUtMTmq1ACKmp3Mo1TMZMLVm8YU0aS34CNY5M3ohFnzBTtdZTDQ0gEkKwpgGzBS0qWNezWV2tFS1jYBYV1qACDAihZgFmsHw+7/F4fD4vs5TJTFNCS5k14zRlqVGxlGvx2dCAZQBgmSezNGyJw2r/BotKrUEIs4zkmi5gj+Q2FwAgpNbiVtRiNheworSpcWQNKmYx0wUavFkeyUz9W62MBEmTCyCpmY1lnIxhuVxmjIVCIUYsKg0XIFagtYy35qkMLQe0qLCaFSDUidaazTKbpiBAsK4nK8w3eXS9dM2qGmZDGxqozd/VHrWKWgZQp2IPAuaWeNKktGaPZiYv0FBRLfjV4wQgQywUChzHBYNBQgkgNPQMtdZEe0xjWHeBOpVa5KwHgZoLWE2DdRewYoQlTj0I2CMnIQD1UGNTmukCAMha4kZb5DRrt1ygrrRaKyiKLElyIBAQeN5qZnvT1CIfQ2jE55o9N7mAPW401N5QGmvIVfNoyy9ZnUrNo2tUrPaxmYvJoGkzzJZMNBlnx/hc82ggLS5gFiENldsiZ4Nv0uoCDXsGVVXL5bI/4He73AxYPfwTM4jXpqNrnVqtg2h1AXsQaIpppC5ULfxCPbARUgsC7VSYlZqirVsngEhUVS0Wi4FA0O0WGyZo/ljzaFtr1qnULmwuQG0u0J481HM9U3/tLtBIHsBunE0uAFY/XHOBmq8RJJZxMVauVJhhhIJBylHE+gRFs3FiZyot9txCpSl5sHXrnUNNvZdvXFogyycPQEBRlFLZ7OVFy2ss86h7NFrOwIiNij15aI/Py7iAqQG06fm6yQMjy1OxJQ+sVc+4rAt0Sh5qPY2pjVAwZJ7LgoAE6PLJg+lnrV3ncslD3ddq7dIxebCF9JoELcmDLQiAldk2uQBcI39uUGnOnwGdtc7fDje+XI3UmqpmkPWew3LexvRBs9taoaiWlVh+Y58qtBWwrAoRGENVUXmeN4O6lb3VqWAToVrAh1r0xAblejYEtX6yVg4bF/U+wvLn2i27LA0qxFZXjQoQaMzVdtBAQ4PY0KRNhvYiDSo1PdsUVKuTADIwdF2WZBYIYKNp0K77ZioWlzZJbQxZUz+kTgVbNNAoUBfYag1Sc2m0EWoqQpoaAm2uira/bVTAitfmE4iKrIii0IgenfUMJgWLir2xav9s0oBl2XUDaIjT0EWNvw6tWTdOy9qbldbkAjXt2F2ggXqr1dVK6lRMkYitbIMOqbFX74nqZlzXQEMc61pVVd3QgxikQDu4QKOaOpdW3Q1xGlRqF80NYxepVgTtRRqOY9NZJz1jXQNtSrM1TVOoaQQBO5W6BuzObvO1mqptVBpFkCmKwvN8jbeGH5u6anYBq97lPNouRMci0GScjSBArE63ieWOLmB3xbamqWvAbj02RQIggKbpsiL7/D5sZ6yuVgLE7gKWFHXlkIaj1bVq56RDL9CiAWwUIS0NV4fNREijzoZxmjepmfpDByrNHm3qBetik06R08ZEE5VmzgzDkGXZ6/U2ek9bkTbjtHJz1tKatiDQLnxD0qZQcw0XsEV8gAZjCACo67okST6fz16k3m5N8Rmgs0c3sdecCdhdwCyC9cpbqXT26KZIbnvephZ7VEdEXdM0TWeItOmpZuMknai0BQGA5rjRiJzWvEV7fG5NHtpcoD7TYVOb3TiBMSZLEvMHQMA2R2uUM+83U2lKjux+0UalWQOkSQN2m2lygdawWbc9sKMtE7CotLqAzdc6JA81QzAMQ65KAb/fRukayUNr3Gjx6GWDQIumOkTOehC4tgsgBWsEZnOBtuRhOSo2j8ZmrTq4Lr71nhwCTY5r/iHQeqfjDYT6cN2W7pFad9rUBTestnZJmmqzihCs1dZMqM4SthNo4c261xCiUdYKZ7Zkx15NozKsxzkAM6Q0JltbPL1Rvc3+W/v4ugdYVJp4rsnCWmtvzvraxMG2upo1UHt3Y0/VABipUyHt4rTLUg8M9uaxS2UbATbayiaLnYqNMdJCxy5tB8Zs140Wq8Vn0uEpe1thwwhbshioTfg0OGr6Y1dCwx5qBtqkZztjHVygxdHqJWz6q7lAO/fQ/FxTL9RmA3U0JtM6eEutN7Dx0VJ6eU9uagl7Na1mUyvaxPNyGiDWo42XoC2ZX1P1xJzQa1Za4/GGRxO74Gj18wBACDZoNknRcm1zgcbtBpX6WnKsGUaTCzS3JtqrbgspNSrNDtWAZYH2ITcx5zCtt0+tpVo10xwuW1O99sjZFNNIp3pbXACWUdo1Qk0LFdtPN+wCrEORNkLtdtzq4gCtCmpxtDY/q4eERsFOLkBs3Z6ViLXYfYOQ1f+RlrjRFjlt7mmj0hRsSRMnTYLaImejM27W2rIaQGy8CraXbAo1AASQ1ali7bVrEwuk3Qbq3T9iuzW26bdZkvbkoZkjqCvSJkv9mSYDaBRBYnURLS3dfJOQ5VzAxkAn47QVaVTYKaa1O1qTOI0O9xou0MbbdZOHlhqX6dZbqLS6QO2n2puURpKPyzsWsUJax1DTZpx1KrX1da01NoJAfVxl3WjWZwd9dAwCaGe70fCdiQM0HA3aPBoA6q/vHdwI/vyDBzp1gMvqHcGcKG66197qzX/ba7NRaS3SoMKabpImTtuqxM5MN24zxpgsK7ksJ7rESIRwPJDWIoioV0pKriAE/GIoBLRDlW0asDHWFmOWSUWvI0vn3qeutGUap3l4BQzRqJS1YpH3+wV/gHA36Es1KvXkHoEAMGYwSQaOoy6X+YHCzuK0By2AThowf8NOt5cT6hpUGg83mw1Zzi4Qkaka01QquijPk6Zxk90FkCHT8gWtXBIjEcEXqGUh7fWBLbto7QawFoJtXel1xOlE5dpmg1CzG2y936FLW+5yOSrt7tlGBVrEqV1gXSEtHm3fQ4yIqGlM06goUkEgTdm7HezbKK1J68tprnUM0EmWFhAAZEwtFPRKRYxEeJ+PtFCpZS6EADJkqsZ0nXO7CMfZ5807M2QXBwEBDakqZ7K8xyNGIpRyAMCQMUUBxqjLTTmupYa2kG5PP0gL+Y72fCMa6Mjv9X5rqeOv6wLX7wVuTJzrxueOuIYLQHtMaCW0jKN92yIdLoltwE+Wf+wakZMAADLGmKIAIHW565++xaZs0eovUNPlzBIguLu6aG1FFnSOGw3yiAgMmaoyXacuF+V4UhtCtNlzax0dO8vOLkAAEZmuM0WhglBnrxaWm6pEZFq5pOcLQigoBIKmqExVlEyGUOqKRokgdF5wdCN9dH0IjKArsprNUEFwRaKU5ztPBDRuXMc4bzA+L8tYO/4yKohoKLKSzXKCIEaiwPO2WayGEgBIfXnYNRkjALZvKBNAwzBkhRDCuVyE0mXSjeu483WSh+sFg9bzMJZxtOYkzRnhfDtw//Zv//Zty3Qa0JDGDWxtaOhwo9NwvLk6gxlStSoIosvtqr//ua5PLWPc1ynSSZz6CJ4VLlyY+u3/lhfm/WMreI8bCGkpgpqePnJ46ve/AcZ8Y2OU7zB07ESoM2NY89pOD3Xun1VNlWXZ5/PxHN8WK25IafUiaOjZY0emXv8d0w3fyCgV+AYZm3Y7yWJ2icg0Ta+WwWDA8dVkYuatN6SFRe/gEHW5rieOnQrpRAUAgCGrlCuiS3S5XC0TassUuU5f1slsOmuMqWrmyKHUng+B49zxuC5JqGmE54l1NkajlC7Lc3/cnXz3TSEU9g4MEI5rNwBEMBRFr1QIIYTnbPOk5mwTAmN6pWLIMuU4WxT+8+y5AxBRkqoM0efzEUpvpEijbIfnrlNkGRdYrpRlAO0ejYhMUYxKBTgODSN9cP/cno84l8vd3UMoIW3ueV3evq3SKpUKpdTr9bbN612370FDklJ7Pkx+8L6rK+7p6yPNn9dkyHRJMiSJcBxTlIUvP1/46nMxFBJjMdI6yri2OAiI+bNnJ371S71cDIyvpKJIgKjFQmrPR5mjR9zd3UIw1JJpLie+qqqqpnq8Xo7jiG1i6tu0ZoNKc5EOzWv3yG/VNMszdqNFoFWca8FepMZ0e6dmCaJpmixLHo9XEPjmD6YupzS0x8A2bv5aSmuNnPXnNE2rViWv1ysK/HJ9dSf3bLpCBC2fn9u9K3fyhDveQ10urVIBAGozJEsDhEgL85P/+evcyWOBFav4UMj+87WTaV2SFvd9tfDZJ7zP7+7qqgcBe0EElGWZMeb1eCklHSW6jiyGUTj7TfK9d5iqenp7DVlhskx4npDW2lDTlvbunX79N4RyvtExyvOAUE0mJ3/z6+L5c/7RUSEQ+Fa7KuotIkmS1+fjeZ4QgojlK5cn//NX1ZmEf8UK3uuF1oHjt3AB+LM8ehlLa0GHjLAtPexUAWJ5YmLyN7+qJhP+8RWC12MXUNW0qiT5fD6BF6Cl61zeBZhh6JUy6jqhnJRKJd59q3z1indwkPd463ndjYnTpIEbyzc6eDQyZlSrpiGZX1y+BpWapggQ+Fb2898cN/gmx9Q4w/Z3u+bPiMgYGgYgEEoIzwEQYADMQMYAAAgxszQEgswAxpBSQmn79yLsbYutRJaZELcVJE0FzBeSCAwRGQEAjiJDZMz8PDggImOEo0AIMkTDAADCcVYxxoAQpmnK0mL+5HEmS4YksUAAgBCOEHNzq2EAIczQ5NRs7uvD3v5+1HVkBtMNACSEI5x5bhWiYQAyIBTMIRBjzDCAEErp8rMI14/v9v6ZACw7kd2qSQDGkDFAJJSCySQiGsxQlUoykTl22BXvZprKBCuII2MAaOZkyAxgSChF89IwrC2JlAJCZWZ64fNPvQOD8TvuUjKZ9JGDwdVru++8CwJ+0BljNSVTioxZexvNxQY1k7iOBlpf5SBAa5e2rNhms5rpCDOAUmKKhggcB2bGyRgzGAACoZSjQAAN8zQHNCSpdPXK0sH97r4+T1/fwuefUVHoe+gRVzQGCMwwEBghlHIc6npl4kr2+OHYzbdCbRkGQUSz3QEIxzFDz359PHP0cHznHZEt2wjPIUNgDAAoxwEhWrk898fdWj7b+/BjvsFh0yoJ5QAswyOUmkdfmUXqhkTqu6SxZf1VB9QNxtKhua/5el+ub04gTBNHxgwwnYujQCgAooHALFYJpYAMDYaIppeZnJueyBgz9/FbFTMGhBKOEgJoWDICRwnhmCynjxwunPum+577fENDpcuX0gf3+UdGI5u2IKWoG9ZOe4uEYa53sLye5wihTfJ2iBtIbkQFTUXMmAEAaHkWIciYKTUyBowBIYTjmKaVJq7mvj7afcddwBhDQNMjKCWU6uXK4t4vq4mZvoceEUKhwoVz+dMnwxs2BVauQmrpgRBKOMtQzTlwZFZxU0wwDKCUUKqkl3LHj/BujyFJ1OUiHMckKXfmlLI4H7v5Fk//AGFWRwuEEMrBMslfk3Kam/7Ge1p7kWtOKRO7R9efQHObJjJrewCl1sbNRtygiGj1OIQQjiKhgIiGDmgFnA5vwzrKuKwLNCVOTYIsG4Bsdy2x7CnLcp0adqCCgMisYEs5SikQ65ApQCTmsIEZaIZ0StBgWOvObKGgMxW4gaZEEwYjyIjpXwDIDMaQEGL1mwwRDUsyRMJTvVLOnTqpl4qRbdvl9NLSvi8jW26K7biFc7nBFMdsQY4zKpX8mZNM17TvPeOtEzUrNMxFloRQCpQCQ8Z0RKSEEo5jmlq8eCF79GBw9VpcvQYRgVBz9RuhHFJC2tKWRsZSC7aICIaOAEA5c07KVCwAmKEDkVVnE+lD+zmvN7By9eK+L/Vyuf/RJ7x9fUCI2S6EEkI4xrCamMkeO+wfG0dDBxABQC8V86dPcF5ff/kJj9lpmvVTzvRcM24gAUI5Yp6uYugAANQMg9RsJHt+q2YzuRPHtNFxrVQSgiFCOcoRQEs6QERKCcdZeY7ZjyMCY4RSszc07cu6ZAYQSigFar3jtTKcmu2Req7CGDIz2aPAUUBgBjO7JySEWs8gMgMIActVDassIkNGiOmeDA0D670DmPZs1swBoJrP5k59rRXGDKnKjDAgEo4njTBF7K1ZzyUsd6AEEZhhWOcNcBwQUJaWZnfvEoKhnvvuV7Lp7NHDQigc33mnEAwTSoAjYCAyBqaZIUoe6f4AACAASURBVDKDQU3w2mjW1DCDWs9LeA6JlQgBY2h2W2ZcBSAcRQQ0DEKtgyWAABgMCAHKacVi6tOP9WKh75EnPL09ZoZiigSEUFN7VogGQijUeXBww7jBQQ5pHNzRAcg0TUqlqskZQ5LFWNQ/OiYEgrokVWdmlKVFoBx1iZ7+Pm9Pn1YqlaentEJBjEZ9o6NCIHiNjgdguZHtDXJtcaxVy+Wpac7l8g0Na5VSNZFwRaLu3l4lnVaWljwDA7zXK82npNQcMHT39Xn7+rVySVlcBErUbFaaTTJDB8b0aqV46SIzDP/oGCcIlblZaW6WUM7bP8A0DRgDxpiiVNJLleQMU1RXrCswOsYHAko+V56a1AsFV7TLv3IFoVxlZlqaT1GXKzC+0t0VJxT+Oq8gm7WEnV70IwNm6MriYmVmmqmqu6fXOzzEuVxavlCavKqVytW5WVRV1NTKzAwy3Ts8wglidWYGAX2DQ0xVyzPTWiHvjnf7hkf0SqUyM62VSoLf5x0e5T2ezPGjiTdf869azQeCrlhX/M57Pf191O3WK1VpdlaanyOEuPsHPD29aj6vpNOcx6PkskAgMDLmiseJdVLtNcRrMZjGzA1pfRha1GHIcmVmBhCZoWvZjBCNieGwNDfHVMU3POru60PDkFNzlWSSqaqrK+4fHaVuV3VmRpcl1HRDkty9fd333O/pHyqcPZt85w+cx+WKxiJbtqKulxMzRqUihML+sXEi8FgbRlqcIBiaJqXmqjPTiOAdGQFk8599nNrzoVGt8oGgu6tLXliQFhYIpd6BAU9ff2ni6uwH78gLc5w/gLfuBF03VNU/OkoIKU9PE1Fwx2LS4qKcSlGXKzA25u7uJhzfpIgbGiW33fiWvkYQEVEtFMoz01ouw3l9/sEhMd7NVLU6m5BT85zb7R9fIQSDSjptWp13aEgMh6uzs7zf7+nr1woFKTUrRKKo63q1QimvZNKc1+MfXcF7PdXUnDSbZLpumpycXkp9sidzYC8i6733Af/KVT3I/GPjAKjkspWZGS2fF/w+7/AI5/NLyQTTdKCgZrNiOOofH+O9vm8xgLu+vpqLMJSzWWlulhCql0uunl5XNFqdTSrpNOf1+kfHKMeZKQJjhl6tSvNzUiplhZ3BoerM9NxHH5QunuU87titO0MbNoqhsKevHxiTM+lKYkYvlcRw2Dc8QgSxMjNDKEFdVwsFdzzuGxphmlqenlIzGT4UDIyvQMaYoWuFfP6b01QUPQNDYjAY3b5Dy+fFaESaTWrFAhVFJZ0mohAYHXfFYh0nXHB5uf8MkGX7EfsjrWC6UZ1NaPk8Moa67u7v18tleX4ekHl6+7zDo7zHrVcqlcSMvLjI+33BFSs5r1daXKomZ1DXvX39noFBzu2+oVkgAubeijZOli95LZuxeSPanm05wq+5SOsIHJEZhrQwX52ZMWTJ0z/gGxkFSpWFhUpimpkC9vQp+ZyyuODu7RNDoUpimhDOOzIqeN2tmzOuK44N9SEaImrFYjUxo2QyYjjsGx1Dw6jMTKnZHOd2+UdGXT29WqFQTc1xgqgW8kxVvEPDvNcXvfkWJsmEowtffJ74w+/l+ZQQDHkHB5VMWp5PIWOunl7/8AgyBGaAwaxVvAgE0FDkSjIhp1IASAXRFY97+gfUbKY6M61LkhiJ+sZGOdEV3riJ83g8A0NyOi0vLXJuj1bII2O+4RF3T48VFWsiIwDTNHlhvppIoGF4h4ddXXFpYV6aTaKquuJx3+gY53JVZ+f0SoVQomQynN/vHxnxDo1033N/YMWq8uRk8v231WxWCIe7b7+TcLScmNELBc7v94+M8cEgIqvF/0bTo2GYo1BDUeSF+Uoyibru7un1DQ4BJdVEQkrNci6Xf2xcjMaU9FJ5aoqpimdg0DcywosuyyygcSIYMkRD10qlwvnz1WTS29/vHRwEINLCvJRMGqriinf7BoeYplbn5sRo1NMVlzMZeWnRFesypKohSahpyJinf0DJZtX0Eh8MBMZXipEwAQqIRqVSmp4ilGOaquWyYlfcNzLCiS55abE6M8003dPX5x0YZJpemZ4EAF2ShFAwMLaCCIJeKpZnpnmv19s/oBaL0mzS3dPj7opLCwtqIecbHqUcV0kklKVFzuP2DY+6urqQMXlhoZJMgKa5+/o8ff3AEA2GBtMrldKVy4as+EZHXaFQvdOv2ShqxUJ1Zoa6XIYka5WSt2/A09+vVyrV6Skll+O8Ht/wiBAKZ0+fTLz9hisaFUJhd19ffOdd1OvVJTl/9rSru9fdHdeLpcrMlBiNmflJZXpKq1Y8Xd3ekRHBZ3UcZgtKs7PV1CzleN/4uCsaU/O5aiKhFQtCKOgdGuVdrkoyCZT6R4YNWalMT/H+IOWpViwSl0vLZIDjvAODlWRibte78tKiEApFt+0wVIUpCtM0o1qlLrcrEvYND6PBylNTwFH/yCjvdi8fNBx0xo3vyWnMBLUEc0SoziYnf/Pr4sVzTFEI5foe/U7/o48vHTqQ+uh9rVgwJImK4sB3vx+/4+7U7l3po4eYqlJB6L3vocGnfiBGovZql+ss0H5iVCe0JbjE7KqAoZSan/rN/yKUrvjZvxbOnZ1+7TfR7TuGnn5u9sP3cye/Hn76BabKc3s+lJcWwGCu7u7+x540qtW53R+grjNd9/YPoabrsry498ulA/t8Q8Mjz79cnU0k332zOpfkRLFr5z2EUgRAxPLUVPK9t0pXLzNZ4jyegSe/H7/zrrmPdi18/ikQ4h0cHn3pFTWfm/7d/1YLeSEUGXjiu30PP8q5XKQ2HUygfYuzJVKbmNdRA6mfLGurBQ2jeP789Ju/L1+5jIYuRmJDTz8XWrs++cE7C599wgzDqFT0ckmvVGd3vVedmRx79Weurq6J3/wKDGPgye9ljh9JH9zHVNU3ODzw1A+KF85ljhzUq1VgRuzWnV2337W098tqalYtFQjPx2+/K3vscGDVmvCGTbkTX89++J6azSCip6e3/4nvyvPzC1/8iXN51HyO6VrvfQ+OvfwjVyyGtX2UpFUPpC5FxxlgaJpR7ZCrSYsLU7/739WZKQRQs2k+GHZ3dVXn54xyJXLTzSt+8nO9XJ75w2vlicu6LPMez+BTT0dvvmX6D68VzpxCNIRA2N3bJ80lEaEycbkyMwGEzrz5upLLVqamCudOG7JMAHoeeLjvkcehmQcELF48P/Gf/1GZnha8vtjtdwqBYObQfiWbXvjiEyIInv6B9P6v1EzG0BRP/8DQ958tnj9XvnJJK5eS776l5gvK4ryay676xf9JBX7i17/kvD7/ihVLe7/UCgUxHO575PH+R5/gvLxdbgK14zzbVFFXV4uhkRvwNXsN5pStvLgw/dYb6YP7DEkilIQ3bhn8/rPVmenk+2+r6TTn9fU//mRgzZrke28Vz50DwNDGLbFbb0/t3uVfsWrk2ReyXx9LvP1GdMdthlTNHT9CRJeWzwLH9d7/SHDd+oVPPy5PXDVkiff5B578PgBkTxyVllJzH71vlKuc2507/bVvcJjzehPvvpU9foSpKuFo9KYd8Z13ze3eVZmZoqKoZjJiNDr26s+677qH8jxpOn+r5a1O7RjgGw44VlYMwBjLnfh66ne/MhSVENJ1x92c25M+8JVerRCA6I7b+x58xJqrM4zcqROJd9+S51OGJImRyODTz6npdP7caWVpMfHe21q5whSlfOVScO1apmszb75e+OYU03UqCvGdd0e2bJt5+w9qLkOAqLmMu39w5NmX5Pm5uT27mGZ4+nqHn3sZDIa6nj1+pDw9yVQlvHHzwJPfL5w9oywuBtesy50+ufTVZ9TlUnNZANL74MMjz73gisY7vlkn9QTr+kPgDi81rvfmp1Gk/YWP+V9Dqs7t3rX4xacAIISjka3bSxfPyQvzhqq4Yl2jL70a3bJ1/vNPkx+8qxXyQig89L1nPP39iXferExNoqG74j0jL7wcv/V24HlSy3RJGwfNrdluGstKWDeAa+ulqYuzSHRWZ8vkHiJWZ2enfvvr3KkTVBBCmzaPPPeyms1Mv/ladXoKdU2MdQ0++X1dlmY/eDe0fmNo7YbUnl3+1WtGX3qV97qvNZHYSQMNThuDLFDz+dn335n/9GO9UhZjXYNPPa3l8gtf/kkvlZiuhTdsGvvhjyuJxNTv/xMMXZeqeqUcXLeh76HHCmdO6+USMj391WdKZnHpwF4iisE16zNHD8mpWUNRxWhk+JkXff2DzWaChqanDx+a/sPv1EzGUGQwjJ77H+p96LHZXe8WzpzUFYVyfP8jj/c8+EjpyuXsscO+kdHC2TPJ99+mgqCXS4aixHfeNfbqTz29vfVWAgA0WPH8uanf/6Z4+TylfOzW26O33J7a82FleoIpCufxDn7v6a5bbku882buxFHKi0o+S0Wh/7HvCsFQ5ugh1DS1kC9fvWzI1eS7bxqSpBcK2eNH9EqFMSO247bhp5+3jvewWUf92lDk9JGDyXffqiYTyJgYDvc9+h3O7Znd9a5eKAihSM8DD4XWrk++/1b+m9OcKIY2bRt98YfcwEC9ZZitW0TDKF44e/WX/w/T9MDKVaM//ImhKsm3Xq9MT6Fh8P5A74OPiJHo3Ee7um7b2f/o4wtffLrw2Sfdd99XSUwXvjkNyMRIl29svPDNGdQ1V7xn6Jnn47fv5ASKhFTnZif+4/9TMkuIqOayrq7u4WdecHfFkx+8U756GQ3DFYsPP/sC7w9e/Y//V81lALDrtrvcL78qRmOVZGLiV78UAsGR519OHz2U+uiD7vse7H/4scR7b5avXB195cdyam5213t6pQIEo1tuGn7uJa1cmvmDmZYYYiw2+NQznNsNgIaipA8dXDq0z9UVX/HjfxFDobbkiJQuXrzyy39nhs40TSsUQmvXDf7g2cLZs+l9X+iSxDQtvHlz30OPzX/6cXV2Rl5Mzbz5Wtdtd+ROHOf9fq1UzOzfG7v19sHv/SBz7OjMG7/rffCR6Labk7vezZ8+iYbO+wMDjz3Z+/Ajoj8AQJiqpA8dnHnrdWkuyblcPfc/HLv19tQfP8x+fYypKuW4yM23xrbfmvpkN+d2rfjJL6T51NVf/ntwzTre7186sJcKgprPA7DI1puZqpUuX9TKpcQfXpMXl+SF+eKFc8AYAuFE0dPfv+Kn/2oo0tVf/ru7t3/lz/8H53Y7A5xvC3r9RyzUUpr6f+xAFMOR6M23hjdtkVKzS3u/qExNpg/ulVKzwbXrCcepuazgCxQvnE99spsACW/comaz85/sriYTtmNGa5U3OtYGIQItdywfb+EHoenaZJp3uw1Jyp36unDubP7MqfyZE7mTXxcvXsx9fUxZmFcLuflP9pSvXo5u3R7etKV04dz8J3uKly8WL5xTM0uh9RvdvX0AUJ2enNv9gbIwF1yzFgjMf/LHwrkzofUbY7fuFALB+nsuBBQjsdjNtwbXbagmE+nDB8uTU0sH98tL88G1G0IbN1FRyJ/9Jn/6pKsrHr3pZne8u7Yu/5ppQL23uTFgs+oaWiNgSNLivq/Se790dcX94ytKl84v7f0ie+J46o8f6dVKeOMmIRQCxkDXpdRceeKqVigwSZISM+XpqeyJr1N7PgSG8Tvu9o2OAaHU4w1v3BK7+TZDlpf271WyWd/ImOD3e/oHI5u3EkGoTk/K87OV6am5Pbsq05PRm28NrV1XOHtm/k+fFC9dLJ4/q2SWvGNjeqmQPrhfmk+Zu+3tfXxzk9qzc7Dm+5oM8lrTxEySqompwvlvOK/PFe8pfnOqcOGsd3AEmZE5sK8yNYmMibGu2C23hzdsqs5Mp48cUtJpaTZRPP8N4YTg2vWGolQmrzJZ8o+tEIJhVywW3rLV3d0rBEPRbTfHbtqh5nPpA/uk+XlgzZwwVrx8KXPoABXFyE03+4aHvYND3qER3uXyr1gZXLuO9/m8w6PxO+/09PYVTp8sXrro7ukVojHe5wtv3OTp7ZVTc9XpCb1SNiSpMj1Zvnolc+RI/swpV7w7etMOd09vzZCanIC06se0gsYDje7XPtsJxGY0WNNzUyWNP4i5M6fndr2LjMXvuJsPBBe++Cz1x49md39QmbgS2rI1su0mIvDpA/sXv/rS1dMdv+Nud3e3Ua1Upyfl1CxTFTWbKU9ckVNz1dlE8eJ5QBZYu0FNL81/sruaTLq6e7tu2xlYuap89VL2+BHe5/P2D3Aeb2Dt+sCaNWqxUJm8Ki8tZr8+ntqzi/J8/M67qehe+PxPmaNHylevFC9d4DxeT/9A8cK5zOGDRrXaZiV2wetKa/m1XQOkNh1vK8tQy+dKly5Ic7O+sXE0jPk9u9R8NrRhM1Cy+MWfihcvmOvTEAAI9fYPxHfe6R0eLpw9nT95QozE3N09vM8X3rDJNzyqpBcr0xPK0lL64L6Fzz4RI9H4nfegps/t2ZU9caJ85VLp0gUhFBQi0cLpk0sH9i7s+6oyNekfGw9v2iqEQtYkB6W+4VHKC5kjB/PfnKkmpqszk3qpqMyniue/0SUpuH6jUSktfPFpNZEA66scLaivVrdPoLaE4vq/7YMUbHugo38S+7/qId1GiIBhSPOp4sVzaBjBNevESMTTNxC77Q7fyGjxwrnciePlqam5PR9K83Oxm2+JbN6KiIv7vkwf2u/u6fUOjuRPn0jv/0qvVOtc2F2gXZwm0rV/L+cCzUWWRy2uNdY22iVuVFiPaTYmEaXUXPrYIUOWwlu2BVauQV1b2vdl5sgBT/+Ab3S8cPbU0oG9nNvDNHX+k4+mXv/P8tRVd7yH93ptfTd2otIuTu2quV+tTE7M7v5AK+S7btsZWL2W8jwR+MDqtV2330EFIX3oQPHiRTWXKV06X51LBlas5P3+9IGv0gf3V6Ynq8lpzu31jo5zbo9vZDS8fiMfCHr6B+K33+UfGy9eOJf9+pherbZ03EyW0kcPli6eD6xcLfiDSi4rhsNU4MVgKHrTjsimrcrSwuLeL+SFlLK4UJ6c1PJ5ZWmpdPGsvLjgHR1DVU0f2i/NzdYimCWwIUuLB/Zmjh70Dgx13XGnGI0Bohjrit1yW3Ddhur0ZObgfiWXk+aSxQvniMAHVq2WZpMLn31SuHi+PHlVKxS8gyOuaFTwB8Mbt3gHBjmfP7Rxc9dtO8EwMocPVJMzYC2KbrcBoqYzqd0f5s+cDq7bEL1pR2V6em7X+wuffpw/fcIV745s3+GO91TnkpnDB1DXI1tv9q9cSUWxpZmwYU1AKPEODPF+X/bYkcyRQ6ld72ePHfaPr4juuFVeTM1++H7+mzOVyavywjzTVHVpsTxxRV6YlxIzpUvnqcvtH1tRunKpfPWCd3gkvGWbGInQ2mIws6Mpnj8rRqL+0RWlSxfmP9kz+9H7S/u+csd7vMOjxQtnF/d9Jc+nKhOXK1MT7u4+39g4FUVKCXW59Uo5d+pE/uyZ/Mnj+W9O5k99Xbx4IX/6pFbMqdnM3IfvyalkcO06KgjzX3yaO/n10r69mcMHXPFu78ho/pvT85/u0UpFQJSSM7MfvVeZmgyuWuOKxTo5GmrFYunqpfLEFXd3N+/zZE8cK54/TygJrF3fddvthJLMoQPywmJgfIUQCLpi3ZHNW3mvt5qYkuaSBEBZWsgeP1KZns4cPliZmQIguVPHFz/7hPf5Qus2VmcT8599rCwtmZ+IU/L5+U8/Ll08G1q7Ibbjdiq6cieOL3z6seD3x++8BymZ/2R3+tD+yuSVaiLBZFkvFiuTV6S5pJyaK144qxULgVWrtEI+9/VR6hLFSFQIBMObt3l6++X5VPHiWeJyRbbeRAQ+d+J44fzZ3JnThXPfEEo4l8tcq+aMc74VbnSQU0/irZlOQHsaLQSC3sFBJslqOoOaqpcKWrnMVBV1AwEox3mHRr0jo9JsQlqc14oFKTVnKLKaz6n5XNP5EmYHcP1Jp0bfQ5qjcf1TZY2HCREjkcDKVXqplD58sHzpIhCQF+Yyxw5Ls0nP0BChXHU24R9fOfLMi0NPP+fpG6gmE1q+QF3unnsfHv/JL8JbtgKB0tXLpcsXQ+s3xe+6h2laeeqqp39g6JkXVvz45/2PPSEGAgAABF2RiGdoUJeqaibDVEUrFgDAE+9mqlqZngBE3utzRaOc1yvNJbVSgfP66tuSTOZtaQJa34bq0BqdU3kCgM0aaJuERK1cKk9cVgs5JZeR02mmKvLiQunyJSWzFLv5lhU//nnP/Q9x/gDW16BaeTCioVemp7RiPn7HXeOv/GT8Rz+LbNrsHxkBSuX0oqHIerlMeRrZuk2MxoJr1vY9/Jint89cnmuuZgyu3TD64g8Hn3pa7O6pzs5ohTwRxe677x9/6dXAmvV6taKXy9ZaBcvi6hogTUI2hkGk/lGketKwjNIACJpLWj2DwyPPvdj/8ON8OBzZctPYqz+NbL3JUGStWBLDEU9fv16uKEtLhqrqpSJTFAAQu+Ijz708/NyL3v4BQokQDEW373D39HoGhvoefiyyZatvZJRpmrS4yFRVKxeNSqXeTqbykBAxFBHDUWVpQZ6f572+wJo1oY2bOW8gdvNtPffcF1y1SoxGlXRGK+QNVWGKHFq/wds/IIYjPfc9EN64mQh8bb0uEiCE51yxLt7rrSZnlFyO8/oIpQQt9+wwdWsunGsdLdYt6jqzvXXjrF02goChaeWrl9VCvufu+8ZefrX3vgeBGbmTJyqTE97RsZHnXlz5s3+N37qzOpugPB14/KkVP/n5yHMvubt7zPEV1rkhhAARwpG+h58Ye/lHwbUb1GyaEuLp6dFKZSWXY7qul8uegcHg6vViMNxz173dd97N+7xACJPl0sQVo1rpufeB0Rdf6bnnAdS0SjJhruQZfvqFgSeeEkJheWmRqUqLX9SSzqaY1hC6Md5DgMbHnbCRhjaVAADCC9HtO8Ze+al3cFBemNPLJTk1Z1SrWqmoZtOoGwAAhLjj3a6ubjWf0/I5put6peIfH/ePjYuhSM+9D8a230wFEYBolXLx0kUg0P/4d0dfeDl2206tkJfmEoDMNzw68vwPex94lHO79XLZFQ4DIdXEFNM0zuMBQijPRbZtH3vlp7FbbgcD1WwWGLOamgDn8fY99NjYD38S2rxNy2XldNra+9QkD9rCf33xZUNpndJ709KsQaB9MwguF9NsejZ7AbtHm+UIEj4c6X/iqbGXX4lt3+Hu7dUKeS2XZaqi5LKVRKKamA6tXT/y4ivjP/6X8MZNlekprZBTsxklk2aKLC8u6lKljcumuLGMOHZrsMfn5Yq0jA+axjC1yLbsEQU1QlA/Utssz/t8rkhULRWqiRkqCkzTypNXtWJRSS+p2QzTdDWb8fT1R7ffomQz+VNf+0bGYtt3cB5308ujVir2zdat3brFlfl2jWF1NqksLoS33jT20o9W/exfu265zT82zrs98tKiXq0Y1YqWzwFDThQjW7ePvvzjnvseRsaqqVmmawDgHRiI3rSDD4TCm2/quf+h0Jq17q64ms+puayhKHoxz3S15lrWuZKIDDWV6bq5ddY7MBBav8kV6/IMDhqqqmSWDFXRi0W9UmmcokwIEcSu23aOvfKT8JZtTJa1UglqB0yb0VErlcqXL/E+38B3fzD+k58Pfe/pwPgK7+CQXqkqmYyhKlqxyBSZALhi8YEnvzf64iu+kTF5aUHL5QgA9Xii27Z5+gZd0VjvAw9Ht+/wj40DofLSvCFJRrWiVyr1I0YtcWzqVNJLpcsXPf39I8++MPLsC4GVq+T5WUTkPd5qYlrNZni/TwiFhWiXmstUkzOcy9UY5JCmvwhACA2sXjfy4qvdd99POFqauFI4d0aMxAa/98zocy8H122U52flhfn6V3PRsgMCQNx9gyPPvzLywsuhNesIx1dnppki8eb+/rqjE+IdHBl5/odDP3hWjHeXrlzKnzltJg9qNmMoipJe1KtVoDS4dsP4j3/ed/+Dgt+PAO5YNLByjV4qZI4erkxNEo5Wk9PpY4eVpSX/itVMkUuTV/RqVV5I6eWyXi5VpieLl86b9qBmMqipyuKiXq0iM8qTV4rnzwZWrOq5934xFG7xyfpJ4ITjgqvXjv3wJ/GddwOAXq14B4c4j0daWjKqVV2SgJDYjttcsbhvZLT3kUd9o2PmBlrfyKh3dKyanEkfOVS8cM4d7/YODVemp+T0olrIS/NzTJHVTEYvlRARkam5TGnyqmdgePj5l8Z/+oue+x+QF+aZpvc++Ojoyz+K77xbr1YqyRmm6VbEQCvxQAK8x9dz30OjL/0osGINMCMwvtIzMOTqivc+8lhkyxbCc+7u3uGnXxj/0U/jd91jaGr60P7ssSNUEMKbt/I+f23Wo3P656Ajbni5mq2vJy35EGLpyqWZN19jiuKO94K50Q2RUKpm09nDB8RwpOe+Bz29fRndIAicx+uOd3u6u8WuuGdgsKWDsE2mdmxIM4mo573m/wlAnbcOQyTO4wmsXE1FIXvkIBAIrlynFvOZg/u1UjG4aq0QCDDdAI4DniO6dVIWIYQKgruvz93VVRbdhFLOHyDApNSsvLgIgMzQqeiilAOOA2p1Fcww8mfPJP7we2AoRKPAcchQDIcHnvoBdYnpw4dm3vitK94TvfkWNZtd/PLT2V3vEqC+kWExFDLjTnPiudxwb/lktNMOJ/s7OACCjKGhA6WCz+8dGPIPj/jGV+mlIjAkvEBFkQqieQo2IZTpul4ta6WioSjAGNM0ACA8DxwHHJXnU8n33q5MTHgGBwnlUdcBCRV4Qiig/VufiIaOzCA8T3geKGftBCWU8oIYjYrRGO/1mc/V5eicqddlsVmH/bUPabrRrAfLRKjg87m64oYscaJbDEXcsS7e5wdApqrZMydn3nqNcrwQjth2ZwLvC3gGBsRwmAqCuSWQE0XzoAVAVp6aTLzzhprNePoHzY2egMzMZ5ChIUlqLkdFEw5BigAAIABJREFUMbRu/eiLr85/+sfFvV/o1cqKX/wfVBDMVb56tbqw98vZ99729Pdb5x8gUp43dyhZ2zkpRU3Xy2UiCoai8KFwfOcd7p6exS8/m/voPSDoHxl1RaPQYbjSwWvqPyw7qdBwxXpWROpKxsYlAiLqGgEgvEA4HigHlKCho2EQyhHKEY5DQFRVAGIaDzX3LgMYsqSXy3q5bJ7HAACEckQUCS8AJUzXs6dPVKYmqCByHo+5Q5dSSsxD/xoJGyIy0HWo8UA4CrWtopzX5+qKa0WeE11Q20xcl6+e/SxjNA2lNftRu5oa/FCOc3fF3d3d5csiAnKixxWLeXr7eJ8vsHqNNJ8CAKaq6SMHEu+8IcZiYO4oRUY4rnY2IzZIMoa6BgSoKBCOo5S3xiiE431+VyyupNOE53mPO37Pg3wgmDm0L/HWa2I4wnu9QDkxFHZ1dfGBgLU92hzFmEteKKWCQOvHA97Alla70qCD0urzM3VXbHqNsPzG/6apjDaPtu7ybo+nt5fz+ha/+iLx1utCOEJ43jxegukqGjrlOMJxhOOAoXmGEu/ze/r6/ePjoY2bzSBTp9By5EYn2UnLP5oXoC4nDmm+qF2yZZ4wrxpfgqzz1hgOISHewaHBHzw3/8me/MnjajY99MwLTNMIpYI/4Onp9Y2MBVavEYLB2uIGZLrODMMKlQ1RW6g0xF9WHEs7DHUNmGF2eYTjlGxm9sP3sscO+4ZHCTUPIagdMsTzhBcoz5s9qSkj4TgqCqZcTFUyRw6aLUhdIqXmgUC1uQREtZjXKxUEAOCMSjlz7JAYDHXf84B3aKgyPTXz1ut6uezp7qUcb9v3YglEOV6MRF2RGO/zIwBYXNWEQUDDYLoGhFCOo4QzgOXPnk688VsiiEI4Qihn7qoH81wgXiS8YIlhdYuECALlOUAARDmVSn7wdvnyRe/wKHAc6jrYZgoMRdXKZcJxTNdNBphhoGEQjie8ABxnhruu23YG16xf/Oqz1O73ma6PPPfCyLMvpj7+KHv8iJLLePsGxC1bO9gOAaCU9/tdXXExGARKUVXRPEpbsCo3D+EABEOuauWSVimDwYAgIUQIBDz9/e7e3t6HHmWMpfd/lXj7Dd7rc8XiTJaJwDMronJUEMAwzONY0NAJpYIv4Okf8I+OBdZuEPx+QqkYjXp6ezmPRy0UDFnmfd7g2nWpTz7KHj8MCKE1G5XsUubgfqbIwTVrOZcLDYMT3WIk5u0fpC5XYNWa8uQE4Tje7/f0DfhGRn1j40IwSAjhfQFEJi+mpPmUt3+A1E+vrZuvZWFECAbFWIwPBAil0sJC8cK5ysRl78gY4XnT3KnAE2p+HofUpw/EWFdo7Yb8/8/eewXHkWWHgtekz8qyQDl4QwIgAHrvbbOdpnumR60xmtkZaUdvX8Tb92Ij9mf/9PF2P9772N0XsYpdhRQhjdTT076bzW52k81m04CeIEEDQ5AESHhb3mbmvfuRWVVZDgRnpd19Ut8xLFTlzXv8OdedM3B7/tszqblp/5HjYjBopGpgZVkKBKVgvVhXz7pc2aUloml6KgV0DfAcxBhiCAAkWhYAilgW4Vw+LYQgBHo2oyUSaixqzPMBAIhlebeHc7kZWTYEzOBO/vQqI8tiICB4va7eDTO13qVrlykhSvtapX1t7rrySpHR9628rXqSk7ONeYNYWAfV9dT0dHLimaN7g9LZFXs0TAHVEvFsOIxFSWpokhqbpUAQYSzUelmbnXW5XJu2QIwxx/FO53PdasUHKh6ZN1w0KfkSQoCx3NwseP3Ld25JdfU1e/Yv918P3bklev32zi7R7+eczuTY47lz3+ipVGp2VlnbyTocxh1cM1JCjKOjE4ty5P7A7JmvfAcP856a2OjozJmvBK8PsqwajQIIgKYnJyaS0xPujdulxqbEk8cAAi0e12JxR++mbDgS6r+enplmnQ4xWOfavC116vPU7DTJZFdE2+KDnt8oKJxrL9sAAQAAwEgy7/ViQRL9QdfW7VRVBa8/szTPyHL43sDkyROh/htaIgExZhS7mkjMX7rIiGJyakKsbxC8tZBhlm9eYxQ7yWQgZuKPRxnZ5ljXmw0tZRcXIQSI5QBCibHHS1cuI16gAACIObebc7hio8Ozp7/OhJayS0uO3vWYE4GZKgXmMjsVbkqUJZ2womO4oMpXg+mKxMpHtEaimkIEDyHRtMzEXGp6qnb3fjFYFxsZzHcyEwGCXDcIIctAlk3PzS5c7iOalhh7bGtd4+zdkJx4mpNE06FHRoZnz56xtbTZWtqQIHq270rNzqSmJvRkEvE81bXw/XucpzZ6/54Wj9o7j6mRcHzsMQAAYIx4To3Flm9cAZu3Y0nORkJz576hgKbnZjiXO7O0JNY31OzYNfHpB+mZaZLNFJv9SshXIs4fYDCtuoZYlvcHIGaWb1zFkrx0/SqE2N61LvZwODE+NnP6FKs4sM3GOhx6Kjn/3TeZxXmgEa62FgtC/MmjqS8+jzwY0NMpA5BsaGn+/NnE+OP4o1FWsWuRSHpuxrv3IJZtsZEhACDAmOF5omaXb11nHU49nQYAYl7gvT4A0fKNq4hhl65fhRiLgUBqagICiGClgNzScrUOCupTsG/FpqY07C0hSm4CBSFEGPEeD+t0Y1m2r+tlnU5IqJlaAwKSycTHx7KRUM3OPXo6HRl5AAGAGEOO15KJpetXIcJUVQEAWJQEX4BksnPnv8uEQqG7txm7XQwEo8ODeawgBVoypUYi9s51Wiwyf/7b9MKc3NCUF0MIkaFilrxEUEvG5y+eyy4tRIcesA4H73LDSjW+AKggUs9RtErUgQUKVbJplV5UJqgQAEgymfjYWGZ50blpK2LY+KOHECLO7WEdrujD4emvvsC8wCgOzuXGoiTW1bs3b9XTGamxCYviysCu0sjme5W7mxWaOb+ovqZQNjrMj0IJzUYjCLOebbvSc7PpuTmSyfI1PixKQn2Da+NmPZMRar3p2ZnQnX7e48U8H380unzrhq2pCVlOrOVHqWYErHJuyI75J8JcTS2W5fDg3alTJwEhiGWjQ/cBpfaubqLr2eUlowPJZiP3B6Y+/yw6dA8iJHj9ycwzXVUBgljgKdVjw4MLVy6H7w1klhZdW7ZjnosODxmkMQbW06m589+F7txybd6aWVqEDCsF6qTGZqmhkVKanp5KPhtT1nbb13XHx59YFDI3Rzf8iKHyRfmdjWk2YCSJ9/rDA7dnz51NTk9RTUvOTCenJmr3HBTq6+Ojw+b9ckDTSwuz357mPTXJqQmxroGzO4y3IYaFHJ+NhhevXuHd7vijh1iUnb0b1XAkvTifJyagNDHxbPbs16zdqbSvMcjJORx8rTfxbGz27BnMcYmnY3xtLQBAqgt6duyaPvlpaupZanoaYsazc096bjY9O6tGIgW9sXKK5nkEAUQAItZm573++KORuXNnOZc7/uih6PXbmlpiI0ORoQeTJz4J9d8gmmpxY5Ck09loVGlfo0YjC+e/Tc3NJp6Oz575inO55ZZWQGly4un0l59TXcsuLdp71iOEMksLQiDo2rKNqKoUrNfisfxsVk3Ep776MvZwpPFHP5YbG3lXTfjuLVtLW+3BI3PffBUZGXR0rLM1t2KOEzy1RNftHV2C10c1VW5qEQNBLEqCv86zdYeezfBujzEbVNZ0sHZH6G7/zNdfyg1NUiCQo26B9QWEAIQAAQDVcCj+eBRi5Oher2fMMzWA4SDLpqYnF6/0sXaXQU9GlpWOLixJ0eF7jN3h6O4VvX6h1sfIMldT69qynVLK2mxEVSdOfJxdWvbs2MV5auIPh2e+/oL3+o2VFKppC1cuadls6PYtLIq2llaSTCQmns6cPpV4Nq5GoyaUIG+QIQAQsizieDUSXrx8yd65jhJiLHhBiOSGRntX98TIAwiQ0tEp+vym96aoVHW/byu2Fy4GCsvuskOEpMZGpX1tcuqZFo9gQRRqfYhhIKG6ms0uL6dmZiL37zb/4leOdT01e/aF7955+t4/QoztHd32zi7OU0OLXwhAya55BddTcYazgtMV/UHnxi3p+VmlY51n+06iqen5WUdHt31tF+dy+Y8cn/ris6nPPwUAyM0twVdez4ZDwkiAtSkUQCyKgs9na2lzrN9INDU2+tCzfZf/4DEtEp375mvECzW793I1XsEX4DweqbHJ1rIm8Wwss7yIREmoqdXSmbmL3yXHn2ippL17va21NTYyMnfuNEmnRZ/ftWkLI8vl6FhPEaze+eY2oysTDQAAKWBssnff4eTEROhOf/TRCGJ536Gjnq3ba/cfXuw7P3Pqc8TzUrBe8PlFvz86Ohy5188qDt5TI/oDni3b9GQidPvms/d/J/qD/mMvO7p6IkP3F69c0rOq4Aswsk30+e3rekL9N2bPnq7de0Dw+jiP29bS5jvy0vSXn098+gEAwNa2JnDsleTEs/j4Y0ZRIMtwLg/v9SFeyMdtVSlASe6J0iSvxcJZLlYAsSzvqSW6jngeS5Lo9bPGIW+ni/cFOKeDc7tsLa2x0eHk1DOj6gIWRN5TQ1UV8zxAkFUcgs/PKHbO7XF2r5/99vT8d2ddW3cqazpS01Pzl84bfh2LIuN0Cj4/lqRsaCn2cBCxDCVk7uzXejqJeN6zfbfoD+qplNzcFh16wNqdUkNj4tn40vUrCGHBU8PaHaxNcfZuio0+XLx8ia/1OzduiT4cWrx+mbXZBZ+fdbqioyOJsUcknRG9hiDZiIUUlSWk5CeaW2Ov/nBFRbO+CiLs3rjVe+BIaKD/2fvvAEBr9x+of+Ot8ED/1IlPZr46iWWb//irNXsOpKanQ3f6Iw/u27t6Gn70tnvrtrlvTi9cPIdFUQjUsQ67lohRXY8+uBd/OII53n/0Fd7v15LxyPADLIisy815PIwk29rXisH65Vs3sSAhnhd8Ac7tlhpbYqPDsaEHyckJAKHvwJGa7btTU1NU1yDHYV7kvX7OUwOK0/cV240KulZhel2EfqmYMTaZ9/uNJWFbW3vg2Ktz352d/OR9xAtSsL7u9TdYh1PwBji32852Re4NLPffQCzHe2pYt4eVbfa1XeH+mwtXLmFRwjZF8Pn5mhqprj7xdDxy93Zs+D7ETPDl153rN0WGHnAOJ+RYLMu8L4B4Yenm1eTTJ3o6bVvT6ehcBzEWfH7W4YIsy9rtgtfPuVxavBYgiAQBAAAIjY0OJ5+NI4y9Bw7LTc1G4u8qc5SiBfOVFa1C9+fRuWIrvBpjzukSfD5GErEg2Ds6JH8gev8uEgTW6eTcHltzi//Yy9Nfnpj67CPW7qx740fe/YfS87PLt65Hhh4glg2++oarp7viHMNiair8VBHWEhVYCfISCqy4AVTRC1AAKCWZ+fmZ06fSczN6Munass3Z08t7a1MzE8vXL0ce3EUsV7NjN0SIalr9G29xHs/kR+/HHj3MhEJYlKxIr6DRoFjOC2E1AABCZc0a38FjCxfPTX78Hud0+4+/6uzdtHT98tLVPqJpgi+AFQXoOqAgMz8/c+YLQIhn686a3fvmvzurx2NYkqSGJqW9I/50bOnqZcHnEwPB8N3bWBB5l4tze7Ag8LVeoqkQweTUs+jIkNTQRIlONU2NRiL37oTv39FiMWXNWmVtV3pmcikRRywr1PqwKHJOp+DzYdnGZDK8L8Da7YBhOadL8PqwKFArhgCyis23/2Bi7PHyjSuRgdvOTVvsnV22tvb449HU3AyWJL6mFjIMgICqaujOLYgZ1uH0HX6JtSmRwQesw8EqirNnffzRw4W+72p27VfWdEVHBucvnNPTKcHnw5LMKA7BF2Dsdi0Wi42O8J5apb2dr/UyoiQ1NgVefn3y0w9mT38JIOQ9Nf6jr2TCoemvv6CZDOepcW/aqiWTM19/kV1e1LNZ95ZtUn09yJUCsEodEkXe5+c8HsSxjM0meP1SY6Nr85bJz7LzF85CxDCyXPfam46e9en52aXrVxb7LmCBF4P1rMPFuWsgyyKe1zOZ5ZvXl29dp5m03NLqWr+BZDLRhyOCzycEgsC493/5gpGqrv6V17EgUVUN9d+MPhxCHB84+rLU2Cj4fKzbgxiGZLKJ8bHYyGA2EravXevcsCG7vODo2VCzfWd6bkaNhp09G6SGRkaWg6/+0fSpz6e/+BQJAl/jbfn5L737DyaejYdv34yPDkOEa/cdtHd18V6fFAy6t+2iAMTHHsXHxwSfz3L7lAIIIKFYFHmvn3N7EMsydrvoD9iaW7AkRu8PLF6+qKtZwe9nZJl3OZ3d6+cvfjf37ZmaXft5by3vdDOCoLS1OXs3kXRKblvrWNfLypJnx67ow+HYw+H09BRkWPfmbYxiTzx5nFmY8x085D9y7NnS4uw3pxlRrN1/2L11R3JiIjo8FB99CCAMHH0l8NLLjM2Wmp+dP3+WtTuk+gbO7WFkm+ALMDYbZBnWXSP4YnxNrWNdT/zhyOx331BKWbuTUmpGGg6nc8PGuXNnIGacvRsZWS5W1u8nOqttL1YnJ7+2VNQQcnR2tf3ZX8THxxhZZgQR8jxJZ7KRkFTXULN7f3ToQeTe7eSzp759B1t+8evI4IPM4gIWBGVNB+/2mFnMXwTo3Ep/aav4EuNhVlHqX/+BfW2H4PXbOzs5l9PR0Sn4gqLfj3kh+MprclNzcvIZYlhbW7uyZm1mYUHw+e3taxHL2lpam376C87pkhqbhJrabGjZ1tLq6OkRg8HE06dY4B3reiDLScGgrbGR9/oYQUw8G2dtdiQIrN1ha21lOCb2aBRgrKzpcHR0iMF6VhK1ZFKsq3f1bmBEEYBSCpQv6a2KLoX3VO2CWNa9eQtrs0UfDmnxBOtwOHvWyw2NzT/9hbO7l2gqX+ulmi7V1Qm1tazdkZqe5mtqIGYQzzk6umzNreEt27R4XKpvcHR12zs6IkODECFWsUOGUdas4Z2u5j/5uWvDJtamKO1rBK+Xd7vl+vq6196wNbWkpqexwNva19pa21Iz07amZmPfLHjs5WwkLDc0gsoIwCqfS9tKK8MQ8LW19W/8iFIq1HoZWW75xa+EQIBVFO++g7aWNmdPD5ZsmOeTExOMYsOiyDmcclNT3Ws/UBMJIViHOcGzbYfgrVXaO3i3p/6Nt2xt7RBjR2d37fbtsUcPEScwioIF0bjgqLS22Tu6IMs0/+mv+BovZ7ezipxZWuLcbtf6jaLXy8hS+2/+bWp2Wm5sEbxee1e3Gg5xLhfEjNzUzNodgeOvCF6vnkw512/g3C7O5couLfK1XogQEkRG4GOPH+uJuBioc65fz8gyqL6TXVFrqNX7VyHm8xUNArmxqfVXfx5+sEMLhzm3276uW65vkIJBqb4xNT3FKIpr/Ua+1su73dGHw4AQZc1ae0cX73YprWsAoFyNV0+nWJsy9cVnnMvtO3xcqq8XampdGzYjgRN9vtTkBOt0QpbjnC6+psaoppeam7W1tGJRcq3foKztEP2Btj/7N9GhQS0e4z01jnU9rNMJEAS6Lvj9nNvd/LNfsHY7I9lWRKdC1rUVW/GMCCFHd2/rL/9crm9EPM9LUuOP3rav7UjOTCGE5eYWZc1a1m63d3Q6urohgzmnM7Mwz7ndEEAhEOTcbu/+g5zdng2HlTVrIcKebTuUtR28w4F/829jD0f0VFLwBx3dPZjnm3/yc8TxfE0t4riWX/6ac3morsYejQJK5ZY2Z3evnkq0/vLPBX+Atds923cItV6xvkGLxfRUSqyrhwAwss138JittZVzuJwbNvJOl5mSshLLaekXVcUh38qD6Wp/rby9ACjFguA7dMTZ3aO0dzCiWLN7L+aF9MIC53RCjMVgnejz173+ptzYnJ6f411u16bNrN3Bud3x0VEtleRcTtf6TYhhi68IPQ+B6rOxlaUij07FTtVmTSuNgrGtpSX4ymupqQksyc7uHqW9XW5s4uyO6KNRPRHnnG5lzVo9nZYaGh1d67AoCW43ZFhGlqy5sKvJ88pTNQAAoFSs9TW9/TPHuu5saJmv9Tm7e7Xtuxzrukk2y7ncECFba1v47gDiOHtXt3vbdk6x27u6xfoGzq6QTEYK1EGObfuzv0iMjwn+oNTQ4OjuzSzMsw4nYlm+1mtrbGr48dtUJ3JjE+Z5paWNAjh39jTvqfHs2peZn128fCH+5JH/yNG2X/0m/ngUizIjSkgUbc0tjCjZ16xVOrpIJs25XbaWdk5RvPsP2js75ZZWaCYIMfdBEGbdm7YgXow/HoUQ2ju7xLo60R9ITk4wNhvDCYzLZRwgF2q8/pdeFvxBwet19m7UM2nO6ZQam1inM/Dya4IvQFTV0bWO6np0eIgCyjmckGXsHR1SQwPvccstrZzT1fz2z5Ekyg2NjX/8E8QwtsYmuaFB8PuSY+MAQVtLi7KmM7O0KNTUaom46A84ezZAhkEMTk1PMrLN0dMr1TcWFgcsLJObmpp/9kvWpnBut6t3A+J4ubFZCPilumB87AmgVGpocnb3MpLU9NM/dW7YhFmO89ToqYRU1+DsXU+yGdHnZyTJd/Cw6PVRXZObW5w9vZTQ5p/+KZZkqhOAkFTfFHzldcZmk5uanb3rEcvxHk90dFhPJFiny9GzgbPZmn/237AOJ6MoAIDg8Vc9W7ba16zlne761990dveKdfVK+9rGN3/s2bRFbmrha2oQx9W9/obc2JyamQIAiPVNcksrwwtYlGKjI3oiwTqd9q4ezuls/pOfMzbF1tom1PrSczNSIFAUIeQW6Wyt7S2//DXnqWEddtfGTZxiF+vria7FhoYo0Y3D547OLs7taXjrT5SOLsRySlu70t6GeYF1uRHGTW//tGbnLqHWZ2tuhpgxYtrI8AM1FGYVu72zU6prqPujN/VUUmlbY2tr5z21qWdPoSi6ejdIdfWc2x0dGtQTcd7rc6zrEf1+zuGUgvV6KiEG6vV0mnO7Ecs6urrsHZ2sYg8efyUbjTg6O+WmJsHr19MpZc1amsno6YxUVw8AhAzm7E5GlkVfUGlpgzhfk7eSCfu+VW/QeiluhUYpqLwzb1wRJJQSQjUdYAghAkQP3RkY+av/LT07I9Y3ZEMhzLKtf/YXvoOHEcMQXaeaBhEyqgVDiEq9KgUUAjWrLi4uyLJst9tXKBhaAk3FXygAgFAACDVrMBm1tyiAECFs3gTVdaJpCELAMAAh8+w+QqavMrYREQCEAgqMhNGA6FTXjD1HswQVhBBBohOi6xBB46QyQBDolGgqBAiyZmk2oqqUEMgwCGMIUU5fq60kVkYVGP6S0ng8Hg6HvbVenudXdr80l6LaKDdBdQIxMs61A0KobtSVM+qOQYRQ7gAxNi92IggIILpOCUEMBkbRj3y5PWAU5oNEJ1TTjLuAxtKlWUWUEqJpRuU4hBDJVyOFgBIKzCJ3IIdZ5aap2uzcnKLYygVjZcwBMMvZGcgZ4BgFtqhxi8aoDarrVNMhhrmNY2hWXTRqtBGzOhgFEBilBoGBOyWqBhE2zt8ZaYgBoQCaNfsMOae6nrs5wJjL4YRQXYdGmUuiU0KQsdUAEUKIUkJ0jRKCGBZCSHQdEAIwhsCczxpF5SDDoFw5yGqBWflXhJDFxSVd173eWrxSeaLn0BUCACghhBp1VBHGORECVDfPcBvlC4lxvQQAhBmIIAGAqhqAwJCB7HLo4V/9l9DA7fZ/8+98e/ciToAYUwiBphqFNYvOn+g6IToyTD8FAEEEISEU6DoxhBMhAAA0eWdWmjNOAkBYbSZYGTsr6YhOZudmGYapqalBCJU+bdYQJOZZEIgIpYDoRNUAhMiwLTQn9gAQXac6QRgDCEzTRCnQdaoTyDLQMLwImbUVdR1QAhEGDGPUJjJsFACFoxtE1SAAgMGmZSOkQDFC8nUetETi0f/1V3PffdP+3/33gaMvQYaFDFPxUB+lNBaLxeNxj6eG49hValxVKfxDn6eE5PE1bbJOaK6er0E6s9iupiOMAGYgpJRQqmmUEogxxAyCqGJG9X/yVo5OIpFYXg55PG5JlCqOvyIFcsZL04hOjDshhpUhhhkn1LyJBCigFCFEAAREBwAAhJBRY9fCuOfyhVKaTCaXlpZqamokUTR28QxyAsPgYAyRUeVQo5QaJovq+vTpU4//5v+s3b2/5Ze/Fjwes8KyURXRsLS6Rkxzh8yakgjBUkuLAAWUkNjj0dH/43+PDN2XG5u0VJpk0o0/+dOG13+AOJ7oOoTIPF1paA0FwMC0YJ9NJ44g1AkJh0OqqtXU1DAYm55A0wCAkGEgBEaZ5nzNx/TC/Mh/+V/jjx52/Lv/wb11G+I4hBABlBIKkXG0mupa3vgDavmctzZm/U0z1YeR6AEgiI3KyWYXxgxeqapSSg3RBRACTSOaDjHCDEMBgggkEoml5WVvbS1vZNki1LiMlldwSgk0KEIp0XQAAGSweSbNCM+MaqrGpNdYXIYIQkB0YvgRxLLGvSOjYGj4wf3B//QfsSB1/Y//k62pCTKMUWWY6oTqmlnsmGGAIWww5+UJMREBhlsnRo1Ro14nRBAYcZFRSkjTKADIvKhJKQDECEsYjBADEKA6ARAYFWANH40QopQmEonlpaXa2lpRFIEZ3xEj0KCEmgVhITBO/Ob5YnpwXaMUQIYpEAEAQo1yohAimL+OSzSV6gRijPLly41K1kZlXlUDCObvCFFNM+0zxqaE5EMjmls9oxQiTAHICycEgOg60AlkzWpOBgBqIvHso/fHf/fbwNGX2379G97tzu2bU7h6B/Z9W+VOjuE7njMdghCwrOlsEZbXrGn51V9ERgb1VJKRbfa1Hc6e9RRhYvCV44C5C09B7q45KA0mdEqoblSIL/KsRWtk+Vg/t1pTGTjzQWtAACEEUCe50SGELJuLFMwLlIW8KBBSQCEBRvBKae4BhjXoAwAAENHc3MmQe3NSaBSEZlmQd1YAAOMmHACkOgVWoHUJBQhwkuw6AAAgAElEQVQhhBJCSAGdFZs5CsYIM2b2DwMFwzDlRtGNCIlh8udMKKEQAIARxIjmCYWZXC+jbjQFABR6QQgBJLnUtAZlKAC6SWTDmoAcwc375ytwU9d1QyDzgpEnWqXV0woUAwAQSnLzBJpjnxlJAggBy+Sfpvl1k1y1dXNSZLzQ8HDGtywLcmBTQC12DUCIiPENQhBxFBQky0JharqQHMQmNxE2zCI1IlqEgJU42LjWD4z4ozL2lShgTnQpAZTqesXEwaXt+cKJcL5glNGBQgAZhlrRyamGKXIMzqODRMGzZ7/U0ia3tgKOpwhRSgyigRxZgNkRWmlFIYCU6pRCAGleOI00fSbvciwGwHjn6uxGhWZYQkoo0aubxNxcwkikASFEHGfqWM50mH1NLHLcMZTCwmVqaJ3xWowBwIbememMLTbKYA3KiS7J26gC+ojmRBWwrHPHTsZTo6ztgCwHEKSU6BWwgYaqUUoJ0XWCn6dopT9adHMV9rm0F7SkWgbF+EKAIEB5ywMoMTUaGhTIa2vO0lIKdCMdSBls/6zNBI9SSomuE51ozx3WytCihrB5xT9fLxNYEDS38pFu5mYzWa9X4utKowAAADCEmxCiFyfcozm9M/mAcZ55FEK5bW3dj96Wm1sZRaG4kI0A5vQu7xzNyQzKexxosbRGFAGl+oamX/wqcu9uNhrFgmhrbXVv2AhZjpovyUmUqekA5hawiCU5GKBUp5QQQ1+pruuFiTrD5O0UtQIGAJak2v0H7et6hMYmyHEUQj1nTyilRjk7i/E3zZr5OWdtTB7lFuAhhBRQPe/u810Mg8YwMP8npRQhyCEIIKGUAh3owHTyOiF5jtAiBTfX3cyXm7AVnLv5TX4fpGAMAQSQydmWPPCUcjU1gdfeRCzLeTzAiI4oJbpeGjzkhK2QmxEikq+gABEFABpigBABFFiCLsCyuXVkqudcquHRdEBgfl3dEpLpug4AILqxbk01Q/GBudimm0EaMBWimC85oc19mSeC0cwZosWTYgZiAHLLkQYMJD8iywCrK8cFGpqSiXJcgLm9cAgLw+WtmengjPVnEwACgNTU3PDHP/Vs3opkKR/aQQQrpZf6vlVtq9rJoZSmUqlEopB/09rHevs7bzcNc0IyGUIIZjBkucJuQOGhQnCb1y2QS5ypaVoymWRZVhAEaJ4Hp8WJ1HIOEBbdtS8CzDpQTjBoZbALT0Pzg+VXWjRK6UDFZMn7VGNoWAZYYfRKgOUpYOlVMGZ5tKwUyGTS6XTaZpMZhs3hUoAflgCWH6UUFws3LACbYNIcUOW8BqCcNaDA0TLWlOSUtVIgbxgrscb4TtdJLB7jOU4QBJNdxawphs3kZikFqOWNhVFy8lnMmuq8LgBGy4WzchcLNAanKbRyFxQTLUeVAlPymgCsrCkR2VK6FtEk/yclJJlMUkpk2QYtmxKQ0hI9qMi7CmQpGtXI2wpLuhSkMQdQ/l9KgZ7JUl1DPI9xoappEd3yAV2BAkUqY+liwlI0aB7MYrGxImilWhE3KQAQUEJisRjGWJZl0y5ZZalcnsveZoUFlvxt7oyXKxq12kZQio75T/kuC7XkIaa5DoZ9Jpks0TQs8MicZxZaXp4Nl5vJZrOZjCRJmGHKBKAUsBKilVC+8KtFPQpmPE+BShpdwvly1pSNklOsFzC2eY0uvTtDLe9ZSQVKoTUfUtVsKpUURYll2Xz/VXqB3BdF8gxK6JxPZV3mbmAxPEWAVVAB861qNptIJmyyzLBc/q00l4WjRNJyMFOiaSSbhZjBHAuRZcnsRfxgHjwIACU6yWaJqgKMEccZZXyLBi1IUGU5zP1BkskUIUSSZZwHrLJ6AkABpYRkM4BQxPFGppAVTXqBFRWEs7hL7mkKctOgvBcosRsldM5kM6lEUrYpbC63ZLGxLWWNBbaKwUMFw1ms0ZRQnaQyACLM8xBX4GYJkQvvsehjIXgoE+YcBQpeAFjls5hoIC8VEFBAs5lsKpmSbTKTmyaVqIAFHVDR2K7kBSzAVADMavCLwauq0cVdik1NBTtJKQCU6Nks0HXE88g40QAARshms7EsW3qI4PtWvb1A4gFiJsYFwOBBQe/NCvWUUgtXIYAICiJj6hGgxtQewkKXvN+leVGCIP+deR7D2Nk1VyOMJIZFo+RaId4oKHVOtyig+WXEQmWLQorjvE4CCvPf5/UZlIwH813yvooWRintlTMYBbIA8wujC6iATt5a5wAz7I5BNFjoYj5baCS/apfDIac8lFYnWoERxigg912pLYcF2HJG2fzVXDqBVnSgNY4tsBsCYK7kw/xKhjk/KDbBVgnJYQqNVWySR7hglyxmLAdbTtKK1rqL3miaRgv6ICeccEXWWN8JKwxEC6GFOUqhi2UUo3pB3sKVCye1/EFLiVbEmvxakcG8EnkuZw00zxUY64ZU10s12kr8qhSwuGXziB4tBawC0XI6ASEgRSoAWQaxLAWAEL2Um6Cg0QUjYLyO5nKjFWS3IAy50CM3gy4xNUVGwBTOSiqQ/2TsQlGSLzhjImWu1pXQOc9Di92wsgbmoKWwAGKBcBWE0xisqEspa0yEc9yszBqWMbZ9CMlvbRW4Cc0iOBCYJxGBsXlVoGmpPAOrcEIIcuY+78ytpgYWiFaqAmUUAABQaDFfK2l0EWz5fdSCySrX6PycslR5cxQoH6WkSxHRjL7lxpZQSsxNMQJIXgWAmSo/36W4V2Fxz9QDs4AJzO8E5nrBnIcrZU2OpOamdSWiFblOkwKAEOO0I6XGp/x7chDnFajI2GKEBZECai7Yl3sBK9EKBq2gAoV35rpAnsMcZ3QilAJCcgYt92BFjS68ERRcJKGE6CV+pUCBYvuMWA5ASCmgNJeJu6KYFcmFITYQWFxv/okyP2gVzucYWwCguWlCibkZVRo8WOAoGQVUCh6eZ58N1iBBBBZuWjS64KFydq7A2rJR8mwpQdY8BwlosTyXUyBv0EDOaVJiOdBhEKhivJFnTUUVKGJPGQXyPKweCeS/gZajA8VBWilgpaYG5DQaFBk3ACDLQpYFEBBa2JhfzbbE983aVjvJEQSBKyq7+8/bKKWqqhKdSLKkKMoLJib419WM86mEEIfDyfH8v3BKUaBpmqaqNsWm2O3/wpH9Z22UEkqXl5cJIS6XG+PvV4ZW1YhOVFVjGMbtdv9rWE6jlMYT8UQ84XA5eZYD36vcH9AoSKaSRNcdDodxxeX/a4Ce0ygFqVRS1zWHwyFWybv9X1cjhIRCYV3X3C43ZvB/jcd9EomEpulOp5PnnnPz9l9Bo4lEUtN1p8MpCPz//xXqn7Ch3K2k76PiVbZVTXIMamKMwD+NbllXP6p8QSkhxCiAiLFRO5JW62L9gRZKXpSMCMs/VgevwhPP71f2CDVXX1foRws4gJUHsCyyFaFNKQHIoBTC2Lg3+dx3VIK2GCRavOZgdFytVllWZVbXJY9TYbiqg1FK89jmVs9L6VyV6EXEWwVLQXXWFO0AwdKnSri0mrZqcIqUYaVelX6z9IfGbX5CMEYY4+eOvxoAc1IJACgisXX9CeZXA1c0As9vzycyBeZBfZDfaVnFKHkagYpikhM/XGmSU2pqViRaZbtU3sVyN7AKQ8v6lb+v8BJgXe6uJNmFdUtIKUUQQQQxQgivaF5K+j+HOytxojrlqor0ajS6CLCc/lYxNWWvsoxCcxtPqzG2xosQQggijLD1HCaoSIUSKIt+rES0Yszz91Oqu8Dna7JhY6FZghgZ+wYvbNDKYHvOg6vy0tVtWtVHKQAQAogQIgRijBnMrBqdKnHGini8KJGqv6joPRhjBCGCCDOoSMOe79arBA8UFPznqmGqPkrZgy/A0OLfnyc2lAIEEQIIYYgZDHJbZyumHTNPfZcgsfJQhbPgoIx4FFQ0AqWKBlbJmtIvqsFknGr6foaz+vZCdXKg9ROt8lDBdxhP5rfhLF1yZ2sqXSawCBYsGqT4IVjhI60AWJmoFLuMkruwJWG5eSrGyMBRjCasMJUqFTsrblVEFpb8W4wHtIxShhnM/5MPgMo8m+WVBUxpEZpFEU3hhRBSQClVNTWdTjMMw/M8MtJbPa9RSjVNU1WV41jGSL1ShlsJmqbtoFQnJJvJYIxZlsvV3qw4ZbVgD/Lhm0mx3NvyT5ostBCtAmtKI0EATPNVjaKUqpqq6zrPcQjjirynhReavClBp8iGrsp351WjaKCSLrlRrIylRUgXxqRwBaEp/sUUtQJh8z/k31+q0ca/hFJN1dLpFMZYEARcUZCqqEAZKLT07QaV839bD9lTACjJZFUAKMdxEFVGtZoKVAKsCrwVvy6zbcbBeVNMjWNdefmvZNDyvXIKxTG5m42Vnq5Iq8JLdF1XsyrLMTh3Vb2KblbGDFZ82GJY8jayRDfNhy2/kmIuVbWcle1zZZOe/78iFSiayRSE0zi5lFWzAACO4ytFDMUSYRmAAkgIyWYzGCGW4yx9KymaFVbLJDNvBCrQ2mrYC4fQYJGhzFtpWDQapZQQms2kMWbYolR4xSVtq8tuwUdDUMTPKtpQbNDKAtZKo1lHKT57U9mqVSZryRuLW7GI5NCw3jurgs4K4ULhxHv+p8IpLQvZrCe+c8dVab5L/rjp8/aSrMjSYtLQEm9WaqQLn54TPMDqo5S2krO+wMIWkM8pkvO+FeK66tpeSQ8KvUunDDlJoEXIQ8v/LE8WC6f5whKHW0GoLKlciiyDpZ+xCp/NZjHGLMua30O4oqJVpG7Zl5Uk0+qhniM337eyhv/yL//yRfvQCtNPAIB58DWdSs/Nz83OzqZSKZZlGcwQSmKx2OzMzNLSEgDAuDVlFnyt9H5DCnWip5JJluN4vqITqtixHLCqroRSSgkJR8Lzs3ORSCSdSWOMMcMA01CZ5zQmpyYRQoIglMQO5RbBSEBkzrLLAK4EW+WWW28oOOzn4pJVs+l0WpZlnMtmWA5bPBGfnZ0NhULJZBJCyJj5uysuqpuWOZVO3759+7vvvotEIj6vz8qIargYMjA9PX3z5k1JlhXFXr1LBXSikcjly5eTyaTXW4uMlGJlo+iUJOIJjud4gTcS6lBKY7HY4uIiAIRlWIgQoIAQPRaLLS4uUAA4joXQuuhe4jWKjEgqlZqZmdF1IgpCJcEz5lNQ07Xh4eHR0VFvbS3H86WPIABMwKJz83MMw3Asa55ALnq0ZIAih15dnqs2WEE4V1KBVCpJKJVlGaLyWveVuhASj8fm5udNQQKQyWUpXWGUTDp9587tb8+eXQ6F/H6/YFSifA4eABTn2KgGFaEkEonMz8+zHMuwLLLsqlEKstnswMCdqakpn9eHMNLzB7hhqQCsPIoVnUQigRCSZOmFMpgbZjAWixoGUNf1SCSSTCV5jl/52BuldHx87NatfqfTaWQ7WHmoYh8LQS4EmZ6eun7juk1RFJtSvhJYKcQxv8hms1k1K0pSblM9PwrNZrML8/PJVIrnOYxhcURCAQWxWHxmZgohbFiPco2udIndxIAQEolE5ufmQuFwKp3CCBsArEwBqwoQStPpdCi0jBBimKL815l05vbt29PT015vLZvPq1kx2ioJ3SmNxWI3blxPJJIejwcjXBxsVqarqqrpdMpIPLC6JNYUUKBq2tLSUiwaZRjGwJ0Qoun60tJSJBJhGbb4mAMFAITD4WvXrqXS6dqiFOdV1dMKqFULNE1NpVKyJLMsU21ta/WmpnwUw1VkMpmFhfn5+Xk1q3IcV3GrEFYWzpVaeRdKSTqdJoRIkoQsE7gS2KqNQgnRdD0cDk9PT4dCIYSQmU4dQkpINBpdmF+glPI8BwDUdT0cCoXCyxzHY8zour68vDw/Px8OhyKRKKGU47kXOulqQKWqaiqVkmSZsWRfqNb+ANZUC1EMn55JZ+bn52dnZ5PJJMdxyWRyfm42FA6Hw6FQKJROp3mez0ljRRVYwamtgIQZBZXgQA1qpJOyLLMMa4mVikZZHQWKltIApalk0mAxw1bMmG8+Hw6Hb926papZjPDc3CzH8Wzh+ZUoUMXUVIUKFBMNGts4L6QP/7rbC+3kFASoYoMQJJPJc+e+O3/hQjQcEWXx+EvH9+/bF46EP//85ODgoKqqbW1tb775ZnNLC1O++F1pvBdtL8T6VCp96stTFy9e5DhOEIVt27YfPnTI5XJBc6GVPnny5OOPP375lVd27txpfXnFUZLJ5Pj4uMPhCAQCFauOrB62FzPr1Eqpyg5UJ9q1a9c//ugjxGCe4zo6Ol966VhjQ4NRe6SivaeUPnv29B//4R8SycThw0cy2YwClNXgQgh58uTJZ5995nA4g4Fg6fruCnhQEAqFTnz22YYNG7q71zEMU23hvbCqBAEAVM2q58+fP3Xq1LZt29544w232w0AiMfjJ0+evHLlytGjR4+/fFwUVjpZbh1menr6008/3bRp04EDBxhUriBm9Kiq6vXr14eHhzs6OhS7vfQ6IAUAAl3TBwcHL1+5/PLxl9etW7eKsHIlwFbZ/jDrt8peqqr29fV9+eWXAAKWYdesWXP8+PHGpiamepkdCODTp0//9m//Np1OHzp0MJPJ/NNCpev63bt3b928+Uc/+EFbW1uJPGcy6YsXL2Uyme513YlE4umz8ebmFqfTBYpl6w8h2gtGXqqqXrlyZXx87Ac/+EEwUJdKpb7++rSqZt944w2Hw7FCR6Lrw8Mjn332WV1dndfrXc1YpXBRQCh5/Ojxe++973A4A4FgOeCrizmK/6b0yZMnv/3tb+125Wc/+3ljY2OJKSGUPH786MSJE6+8/PK2bdtBmT6vTMJkKnn6zOkL5y8ghHhB2Lh+w9GXjnhrfauZ5lkh/Pbbs/v37+/t7c2bZQpoKp28cP6Cruvd69aJovj86K/wUhAJhz8/8Xnnuq61a9ewZZvVK0JGq5noiqMuLS3/9rd/PzEx8cM339yzbx/PcgCAiYmJd955Jx6P/+QnP1m/fn1RJwoWFxdPnvxi48YNXZ2dL1T6qiy0BWbenxU8/ou8v6SLsZx04cKF7747F4vFPR7PK6+8smXLFo7nyunzT2AGV/GKFR6hlD4df/r5yc9HRkbUrNrb2/vWW2/V19cDSqPR6MmTJy9evHj8+PFXXnkVQDo8NPzlF1/GE/Hf/OY3La0ty6HQe7///YMHDziOEwRh7949R48ekyTpxXEqWxP7g3B54V4URCKRCxfOX758JZFI+Hy+V199dWlp6Ztvvkln0oSQRDzR1NT0Z7/+dUNj4wovL9vme37Lb8hU/pWW26Tn4bJigwAQQh4+fPjd+fPHjh3rKnPZ1rEXFxdPnjy5ZcsWv99/+cqVH7/1Vmdn5ypH+QMarPDp+7aqtvpJDqwuUJRSBCGhFGazWiQSbaiv59paz5755sSJE62trf23bp0+fXrnzp0Y40uXLjmdzp8G/IxsqyjwuUXwqqNU18QKZhrCir+YX2Wymfv378/PL+zbt3dsbOx377xjk+Vdu3bpmq7pmqZpLMM2NDTIshSNRAghiqJghFLpdCqVMhYzUqkUz/MulwtjPDY29tu//21HZ8fLr7xc46mBEMXjsUQ8zvO8w+HgrNsg1MxRWvXaSRVCV23Pk3tdI48ejY4+Gj127KVoNPLZZ58Sor/99tvGrmsmm3E6nBzHxePxRCLBMKzDoQAAH448nJicPHbs2O7du+12ex44QkkymQyFQhBAl9spSRLRaTwRj0ajGGFFsWWz2Wg0Gg6HpqemWY51OhwszxNdj8fjsVgcY2RXFEmWAQCZTCYSiWSzWVmWFUVRNS0ai6VSKUAAoCVbv5WxhRCqmjo0NHzqq1NTU1Pd67q3btuKIBwbG/v000/v3LkTDAYPHTqka3okEtE0TVEUu92OEEomk5l0OquqAABZkjLZrJnugpBgMOhwOgEAmqbFYrF4Is4xrMPp5DmOUppIpaLRaCadDi2HotEoIXqOp5RSoJtoxhiGURRFUZS6YB3H86FwGCOk2GwAwGQqoaqazaYwZsFHqqpqNBpJJJKiJDkdDkBpIpkEABjbbg6HUxRFAEgikYxEIoBSxW6XZVnV1FQyJUsSy/HpVDKdTit2u6qpkVBY03S7w64oNgBgKpWKRCKEULtdkWXZsvYMrE7EdEImIpUjSU3ThoeHRkdHjxw5HIvFT506RQj54x//GDMMISSTydjtdkEQ4vF4PB5nWMZhdyCEhoeHx8fHX3/ttf37DzjsdpBLz0sISSaT4XCYUuByOUVJTCVT2WxW1/V0Ki3Jkt1hZxDOqmokEslkMpIk2e12jBljmy4Wi7EsqyiK3WEPBusEXiCExOPxPIlsik0nJJFIZDLZdDo9cHfgvffee/vttzdv3owQ4jjOJssAgEQyqeu6oijGDrOBfEUSVPPQz9VoAIGuk7GxsYGBgcOHj1AAstns8PBQOp0+cuSIrhNJEjmOy2Qy6XRKkmRKSCgcVlXVbreLopDNZiORSCgUmpqa5FjO4XQyDJtOpcKRsKZpsiw7HA6McSqZymQzlNJUKiWKot1uZxgmr2KLy8vLoVA2m/3DZnTQKiQAAECzmezNmze/+uoru6KsX78hEAiyLKOqaigUyqTTks1myFtDQ4NNUQjVU/F0JBJRVVVRFIfDYehgNpslhKbTeYDZ/JHTTDozeH9wfn5+z549MzMz73/wPsdzr776aiaTicfjDMM4HA5JkiCEhsFJp1KSKClOO5vbtKGULC4u9Pf3d3Z2GooZjUQwwzhdTl0niURcJ4QQms1mI5FwIpHiOdbhdIkir6pqIp6ECKaSKQCB0+nkBYHoeiwWS8QT8/Pzy6HlVDJFCM2kM+FIWFVV2SYrih0AGI/HNU3NZrMcxzmdTqZwCcea/hCY9TUprLC/m2uxaOTSpb579+5yLLuuu9vv92Uz2avXrn7yySc8x+3bt6+rsyucDMcTcYyw0+kUBVHX9Xgink6lAKW6psXj8Vg8xjCM3e4UhOfsGf4/ac9XgeJGCBkcHPzggw8URenp7bl549ZHH33U0NhQX1dPVwzmV3brlW7kGm2FaPn5o1BKI5GIrpHent7R0YeffPJJQ2NDIBAghN69e/fEiRMDAwOtrS3Hjh6bnpk+ceJEX1+fTsjbb78NAEjE4/fv3aMA9Pb2chwfCARXWBIqQacMQwrBi9H5DxmluKmaevPGjQ8++LCxsXHPnj2CIMiyjDHu7u7OZrOh5dAXX36hqmpJPSVLMzc3ivYyVgU8zMOXy1+bf1e1VZrC99Y51YrCWfQVoXR+fv7WrVubNm1Kp9OpZApjlEwmEUJOp5PjOF3Xo9FoMplcWFgIhUKpdFqx2xvq60VR1HU9kUhEIhFKqd1uzzuU6ptIJqSVjEBl15P7//83Khr/i2mrKwYKAAQ0bzsqBJ3m3IPaZPmll45hjKPR2NiTsZnp6UgkMjwy4nQ6f/jDH7Is+3T86fDwUCKRkGVbyWvys3ZS8Aaw0ijVILR+NKOoFWY4FAAjkl6zZs1bb/14fHz8P//n/zQ0NGSzyYODQ/FYjGHYDRs36JqWTmdu3ry5vLx88OABp8N59+7d0dHR2traJ4+fzC/MC4Kwb9++9rb269evX7h0YWzsCcb40KFDiUTi6tVrMzPTsizv3LFzw8YNQv74U0HmK2iitbLH81c+Snflqwg/BJRSv9//+uuvA0CfPn06NDQ0PDw8ODgYi8cy6czhw4dlWb5y5cr09LQgCBs3bgwEApcvX3767OnIyMimzZsb6usBAMZx1Wg02tfXd/fuXYTQ3r17t27Zsri4dOHihUejj3iB37FjRyabTSQSfX19t2/f5jju4MGD3d09MzPTfZcujT99xjC4q7Nz9+49nMDdvHHzzp07iXg8EAzu3r3b9MEQltYqWrlRAADw1nrj8fiDwQc9vT0MwwwODkYiEZ/PRwGIRaP37t8fGBhIp9ONTY1HDx/1+rx37twZGBiIx+OKonR2dg4ODmazWV3Xurt7dE2nhBBCJicnL126NDk5KQj8tm3bN2/enE6nL1++PDAwACF8+PAhwzA5UaUAAELI9NT0xYsXHj95IsnSrp27JEkihCQTicH79yFChw8fRghdvXotFosdOHDA5XYDSjVNf/Lkyfnz5+fm5uob6o8dfQkAevHixWQisbC0RHR9y9atu3buSiYTfX2XRh4+JDppb2/fs2dPLB6/c+fO7p276hvqHzwYHHk4cvDgwcePHl+7fk3X9S2bt+zeu1vNqlevXr1//76mae3t7fv37fN6fdbbW5WWPMvKlFiarhOf1/vaa69jjBcWFkZGRoaHR0YejqRSqWQyuWf3HqfLef3G9anJKZ7ne3t7g8HgtWvXZmZmRh4+3Dg11dDQYPKMglgs1tfXd3dgAGJ8YP/+np6eO3fuDA8PZ7PZhfkFr8975OiR+rr6Bw/uX716LRKJeL3e/fv3t7S0zMzMXLhwYWxszGaz7dmzB2FkFKxcXl7u67s0NDSsquqatWsPHTrEcxwAEEI6Mzt74cKFK1euiKK4tLSkqZo/4N+zZw+EsO/yZaLr+/fvl2XZED8ASi+p5rWr8gLEShpd6K7ruqqq6XQ6k0lnMhljOjc9Pf3o0aMtW7a0trY+efLk3r17W7duXVhY6Ovry2Syvb09e/bsAQDEYrFz585dvHhBsSn79h9oaWnpv3Wr/3Z/MpkMBoOHDx9uaGh4MPjgzu07hNL5+Tmv1/fSS8f8fv+9e/cuXbqUSqWWlpaSyaQF3lykbVGjMpbTko95RCmF4XD4wYMHjY2Nuq7fu3dv9+49Nps8PDz83bnvItFIW3v7kcOHjRNWlNJ4LH712rWBgYFEIlFXX3/0yJFAIHB34O7g0KCmafPz84FA4OjRo42NTRiZy1wUUAppa2vrD3/4w+Xl0P/yP//H4eHhNWvWDAwMPHv2DGO8edOmPXv38jw/ODh06dKl5eWlYCB4+MjhluaW/JLuca0AACAASURBVP0r4zISIfrS0lJfX9/IyIgky4cPHfb7vUaspGna6KPRSxcvzczMiKK4Y9eObVu2LS4tXrpwSdO12dk5SsmePXs2b968uLj47bffTkxM6Lo+MzO7cQNNp1JDw8O3bt2Kx+P19fUHDhxwOp2XLl0aGx+Px2Jtbe3Hjx935JaHcvQzwy3jP4V01GWNAkAIxRgFg8En4+Pj4+O13trl5eX+W/2yLMuSrOv6s4lnfX19ExMTCKFNmzYZomIMpRMyMzvb19c3Pj7OceyWLVu3bdsmSXKFc6kVuQ9zpqBK4Fja0RD+MnSo6c2LVlIAAFlV7e/vj0Qiv/zlLzdu3CDwwsmTJ2emZ+qC9blkwwBUEk5ovc1b/CusOsMpWva3BMzVVaBYlyFCa9rb6+sbZFm6euXq3bv3ZmdmNU0LLYf6+vowZoLBoJGQn2XZjRs3Mpi5duM6BcBIjsywbGdn56uvvCpJkiSJLMeV6VrpiSZYidQwhwqEJV0KYTxYdfCw8j5JviUTyavXrjEM8/rrr7e2toqCKMoiArCzs1PT9Js3b1zqu7Rly5Yaj7viRCIPQzFtq4FTBDgE5ZdQcyQoflH5KKXCXHXc0mameidkcmLi0qWLEOK5uVkG4/0HDvT09ExMTn537tzs7KymaXNzc8BYetd1SqlhYYaGhtRstq29/dDhwwG/3zJ9Kct8kAeustYUE62A+vd51V6srS67GgDF1C5y9vn5BICQYRhCyPXr1wcHB4eGhrZu3WrsciSTyfn5eUVRdKKHQolMJlt9tMqRRGGUsq/zum2Bl+b+gRbgSwWGGlWlsplwODQ3PwchVBRleHjkd+++297Wum3b9sXFpW/Pnav1+lKp5JkzZ4LB4Jr29m/OnJmbn9+wYYOma36//8qVK3Nzc3/+3/65KIo8J0iyrChKaDl04vMTs7OzPd09DwYfjIyM/Hvnf+js7LDCV0lOS+X5+ZYKWuMQusLDlAJVVaPRaDKZMFbcZ2dnP/jgA5ts27lr5/LS8kcffbSwsLB+/XrjOMTLL7/McRzP8YqiiIIAACRGGWAIRx8+/Pjjj+vr65uaGrPZbCweP/PNmXPnznV2dCKEJiYneZYLhZYfPXq0fv36W7duhUIhQRC++urUvXv3N27cGFpefvf3v09n0oIgfvDBh42NDV6v99KlS+Pj48ePH88hYjX0Ffyv1QhACDBGzc0timK7f//+oUOHGMzcu3evtbU1kUhAAOLx+MzMrGJTKCVnTp+RJfnYsWO3b99+7733e3t7tm3bNjY29u6779bX1+/cuTMWi/Vd7uMFvrG+4cSJE/fv39+wfv3Y+Njdu/cEQVhcXPz9u78PBAKCKDx+/Li5udmMoihBAMZjsS++/PLKlcvr1q0jGhkbHxMF8fLly7W1tU/GxgYfDLa2tsqy9PXXp2tra/bu2atrGgQwkYh//fXXt27d2r59O8dw2UwmHAl/8sknlNJtW7dOTk+PvPMOg/HTp0/Pnj27fn0vgujEiRORSMTj8Xxz5kxzU3MgGBgeGf7mm2/qgsH3P/iAZdne3l6d6Jl05tq1a79/773Ojk6M0CeffAIhfO2118XcrRhqkrdAZ1hZ14o8lKpp0Ugkq6rJZLKhoWFufu79999XFGXXrl3LoeWvvv5qZmZ6w4aNU1NT77zzztGjR43bmTabIooiMKs5UwDh+Pj4xx9/7PF42tvbVVXNqtk7d+58/PHHGzZs8Hg8p0+fXl5ePnDgwGeffQYAaGhouHz58sL8/I/eeuvMmTO3b99et26druuTk5OqqvZd7uvs6pRleW5+3uFwLC4ufnHypMPh2LZ1mzE1Z1lGFEWOZRVFEUXx5v2bt27dam1tpZR+cfJkV2fX/n37C5618jopLLYy0PLZKqNWnYRmwZjcj8+ePTtx4oTf70/EE4ODgy0tLbMzM2fPnvX7fM1NTeNj499++60kSefPn08mk5s3bwYA6LoOKFhcXBobG1u3bt3NW7emZ2Z/+tOfTE1PiaKAEDp//ryu62//8R8PDg6+87t3uru7vV7vV1+d0nVt7959v/vdu7FY1JhBRSMRE0VTb0Cxpa1oPWDxf82mE/3Ro0fT09MvvfTS3NzcyMjIzPS0z+/78MMPnz19tn3HdgZjVVXnZufOnTvX0NDgcrnm5maNNeDTp08jCN98801jb23Tpk12xf7ll18ihH7yJz8xrmzBfHqAbDYSiczNzeo6URRleXk5Fo/5/f7h4eEPP/rI6/PZ7Y5//MffxmOJrnVd4Uh4dna2vr6eYRjj0DGgZhm3/v7+Dz/8sLu722G3q9lsviK7pmvzc/OZTCbgD9y9e3d6Zro+UBcKhz/+5GOE0Pr1G548eTw1NSVJ0pXLV86d+7ant9e4nKBq6r379999912Px1NbU/vtt9/G4/Hjx4+fP3/+xo0b27Zt6+kputRXiLJzUWkVY11YhaOA8jy/efPmcDjc39/f0dExODg4Nze3bdvWyYkpXdcXFxdjsZjP53v06NFHH35YW1sr22zGOyORyKlTp/r7+3u6e6Znpv/+7/9ekqStW7cCgPOjFLvOYs9LS4WjongU243VBF/UuEipZrPT09M2m62pqdHhcDY0NOi6HlpeJkTHmMmBV3n0knXAEngqj1r56/LgwRJeWwCAECqKXVFANptdWlpiGCYQCKiqeu3atcnJyQMH9p0/f9F4XUNDQ21tbTwWv9V/y+hrHJK8ceNGIpH0+bzbd2xf276WZdmVY+4/eLcm12VVa6QlcV2FhymIJ+KPHj1aXg6dPXv2woULTU1N+/btCwaDPMNmMpH+/n6e53ft2iXJNlDGsxJ0VgF7ieU05Co/py1MAvOY5qcQ5fiWObUSDCtEj3mrTgGdnJx8//0P3G53R0fng0ejy6EQy7JffvnlwMBAT0/P1PT09My0rukTk5Pnz1/oXb/ebrfPz8+73e6FhYWTJ0/Ksu21V1/leC6HTv5Ee3n8XEZ0y2Q1j4vZ9/sZzgu21R5Xs273QQCJGRgVzUAhAATQWCz24MGDgYGBxYUFVVUxxhs3brx3797f/d3fiYLY39/f1tZW0eLkoytLUFsID1Y2XpZfoXU1pzjsMN9pXcTWNO32nTv63/xNKBRas6Z906ZN/f39DrvjjTfe3LFjx+DgYDKZggi2tLRks9mhoSGGYR6Ojm7ZsmXXrp3hUHg5FLIpyuTUhK7pPT09LS3Nm7ds2b9/35MnYwN37vj8fofTIYnS7Tu3J5496+hYW3ZBxQoYNMtcFZnyilszJTpuQR7m8pyU9aKUPHny5B/+4beZTMZms+3buzerqgzGBw8d/OEPf2js6rz5xhuv/9EfDQ8P//Vf//XMzEzXuq7B4cG9e/e2tLQMDw8/m5xA/zd7b/Yd13Ee+lbVHntEj+hGAyBmgJgBkuJkURZlTdYUWbYlW7bXOsdZJzkrD+ch/0Mezn3IQ26yzr1r2TdZcrKsRLEsyY5tidYsURRnABxAEiAxAw2gG42e9rzrPhTQaDRGTiJIfr8HEtj4atg17frqq/oKodq6uryi5HI50zDq6xtaWlry+fyFCxerq6pfffVVp8upG8bAwIC3rOzpp58+evQozwuXL1+6evXqxYuXurq6X3vttXh85p/+6Z9OnzlrGgbB+JXvvVK1q4oQ8sUXX3R2dlK7eNlveWNT8TuuKgSEEPMDh3w+X0dH+4kTJwYHBymlU9PThw8dGhgYwBj7fL79+/fF47OjIyOKcnJiYsI0TV3XI5Hwqz98ta297dNPPyWEPP30U8899/z4+Pif/vQnXdfjc7OnT5/med5bVuZ0uU+ePMVmGDzPf/8H3/f5fLlcLpFMjo2PD165ks/no9Go1+Pt7++vq6v78Y9/LAiCpml9fX35fF4QhKampk8//ez8+b5IJDwzM93QUH/69Bnd0L1eT1VVlaZpuVzO7XL39PSUl5cnkgnTNA8ePPjjH//40qVLv/jFL06cODE6OlpTU/Paaz+yLCuRSAwMDLS2tiqKYlsmosjQDUVRDNPM5/KiJFZWVra1txFCzpw5Mz01deCR/ZjgZDJ54cKFJ598km1+KzQzhJBd1NK2/EyOjIz86l//VdM0DpNDhw/blk0pffzxx7//yiuDVwaHh4cf//a3v/fKK0PXhv7P//N/5ubm6uvrY7HYo0e+1dzcfO3atZHREYRoTU2toqq5XK6szNfQUN/Y2MgRTtd1f8D/4osvMgX13LlzPMdfvHiRLZcQQi5eutTR2dl3/nxLc/Nrr73G8ZxpWie++kpVFdu2y8vLD+w/MD8/jxA6efLk9PQU20yIEIpEIt3d3V98/vmRI0cOHDioqMp777w3dG1I07WZmZnvPvddWZaLh7I13XOLj3RRkGLXWXZxKOYh49q1a4lkQlHUZCJRU1NjWRarOIoQc2ZommY+n1dVNVJe3tHR7nK5KKKBgP/5558/fPhb77zz288++zybze7du3d2dnZyclLXjdHREVVVDcNwezzPPfdcQ0PD9PT0lStXysvLJycnXn755SNHjvj9/t/+9reoyPX5qrxtuOxSPNtdmVGoeaW/v980zdbWVo/H3dfXd+XqFX/AryhKLp8L+P1dXV0+n98whxQlb5mm1+vdu3ff7Gx8anJKU7WR0RHWB30+/8vf+17Q75+JzwwPDw9cvJCcT1iWVVVdFQ6Hbdvu7+//5S9/mU6nK2IVhw4dqq6udrlcCwsL01NT165cicfjc3PzN26MvvrqD7/zxBOKqmq6fuLEicXFRafT2dLSUsi6YRi5XI5g3NraWlNbS5cvtmZ9U5KkZDI5fH14ZGRkIZUyTdOyrEePHPmLl/7iz3/+80cffnj16rUzZ8/UNzT89Gc/Hb0xOjk5RSk9e/bs4ODgM8884/P7DMPo6+v71uFvGYbR2Nj4+uuvNzQ0rDp6we49xdReb3wupmjQw4SQ2trafD7fP9Df29t75sxpv9/X3t4xMxPnOK62tpYjXHJhIZlMXr58eW5uzuV2swpOJBKnT582TcPrK8tkM1999dWVq1f27NlTdDAJFdd5yWd9bcte/rF4r8Gq8XndVyrxhctSwQhblqVpGs/zzJGmKIqEEMM0ly9rpKv63lb7czaYxZb8WpxPjIrsHusJrxoEMMKUUMuwhoaGPv/i88bGxo6OjpmZmc+//CIajba2tn3xxZemaRqm6eZ5SZIJR9DyqoDXW3b06NGRkZFsNvf++++PjIz81f/4q1hlbM2pwFXTnvU8D5WoaiWTh1Wz+e1MHta4KV5n8kARMk0znU7rhk44Lp1Ov/XWW7Zl/eCHPxQEYXx8vK+vr6O9vbGhgXAcpYUL1otTQSWD5wZTlFUzt+KVTbxexlChfJdlSkprbeNcxyqynMmSvLGfTNOklB45cuSpp5/+r9///syZM1evXh0YGOjo6PjZz3524cKFxPw8Jtg0jLyiWJYViUT279+fSCQRpblcbmpy0rIttKTgrXqddefPJW+2SaGBnnNT3MSZnMIt6mjjMRpjXFlZ+frrPzl69Og777zT19c3PDx8+PBhp9M5MjKSz+cnpyZ9Pp+47HSvNHhhfN94oCpNcM1QtVmzKYoSIYQpxRgLPM9aZ29vT1VldV9fXyQSaWlpCYVCoigSggnhamtrY7HYxYsXVU3Vda25ufnKlaufffaZpmkjIyM8zyNEZVkWBNHhcDidLkVR5pNJVVUJ4TRVbW5u9pZ5SzxQrpex0utWNtx8turnIm1/UwfqPC/4fL66+vqO9vbdra0nvvqqzOdradkdjUbPnTtn21ZdfX0wFKysqiwrK8tms4IgSKLodLowxn0D/V98/gVH8BPf+c7evXuPHn38ww8/Gp+YeOWVV+obGrLZzK5du8qjEZfTaVnWlSuDXo+3oaGhoqIiGo1cvnxxYSGl63ptbU0oHCaEhMPh+flEJpOOVcSqqqvCodCuXdUI4Xw+v+KRdqNaX+VZfHlwx1QQhPb29nPnzh0/flxRFIcst7a2MoUntZj++ONPLl68qOt6fHZW13VKKcdxsVhlU3NTwB/gBd63XBRzc3Ms6lw+Pz8/Z9v05NcnDdNobm72eD3Xrl3z+XzV1dVlZWU1NbtSqdTY2OiZM2eTyUR3d8/ePXuy2UxnZ0c4HHY4nLqmXbp0ifmya21tDQT8p06djMVioigGAoEvvvx8amq6urrqlVdeeeyxx6anp999793rN67/6Ec/opQ6HI7a2tpIJLK4uOh2u+PxeHJhoXdPbyQaMQ2zoqLi0qVLqqpSSpl/OUZ5eflzzz/3u9/97le/+tUzzz7z2JHH5hPzifnE+b7zoiiGw+HKykpCuGWT99Y9ehV06R+O48rKyurq6tra2tra2k6dOuXxeFrbWiPRaP/AAEKotq4uEAjGKpVAIKAoCs9zoii6XW5CyKXLlz766COmFB0+fPiJJ5746MMP33jjje+/8v0DBw9igsPhcE1tbUVFRSwWGxgYmJqampudu3r16kJqASHU0NDAjtlEKypC4bAsS4Zu8BzPzLKJROL999+/ceMG251l6MbS22HM87zT6RBEweVye8u8HR2dH/75wzNnTqua5vV6mhobCcetVwbFig9FCBc+PBtPvFZN6Qo9GiOMMW5sbPz5z39e11CfWlj45S9/yRGOHYEqhh3C/s1vfvOv//ZvR48efekvXkIIecvK6uvro9FIZWUlQnRubm5gYICpGdPTU5WVMZtSjHEoGKyvq6uoqPD7fQsLC4upFCFk165dFRWx+vp6th+PTfJoaaa3WPSly/+y2W0ymTx37tzQ0NC7776TTmdGRkb6+/sPHjz4/PPPv/nmm//x1lsjo6Ovvfbaclo4nU5/+sknFy5eNAxjdjZu6AbzQxmNRhrq60VJ9Pv9+bwyeHnw5MmvDcM4dOjQY489hhAWBCEQDPb29nZ3dzc0NFy4cOG9995LpVJzc3PpbFbXdU3TCME1NbuCoRCldHR09MsvvxwaGgqHw95ljyCU0u7u7scff/z48ePjExOvvfaj5uYmhBBF2DTNK1eu/OEPf8jnc5OTU7Zts6mJ0+lsaWmurIpFoxHCkUwmnc5kent7K2OViKJQKEgpnZ2dTSQSg5cHp6enJUmqqanhBUEUxbq6utq6Oo/Hs1zSGCGE6ZJtafv3jbFS93g8DQ0N58+fP3bs2LWha49+69FoNMr2AY6MjLz77rvpxXRyIZnJZEzTwmjpLnp2bCCfz538+mub2vX19aFgqMQj7ppp/Xpz4tUWheIv1LY9KKxKiIXiOE4URV3XNVWzbVvVNIyxJMmEsEIqiaI0oeLP3nK+Sps0RSXGsiJDGkKoaHF9+XU26gIYYUQtOj0z/fY7v03Mz/+3//7fKyoqPv7oo/7+/s6OjpMnT46Ojtq2ffny5b179xGCl/3QUISR1+t99rvPmoaZTmf+9d9+de7suZn4TEUstp4buULGNjA9bRhk1VCzkuktolh7EGR9pcjhcHR2dv7spz9NLS7+X//7f1+4cOHFF1+0bXtgYCCXyx04cJAdYS1q2KXxrG0AW77eLbS0zVNZGwVencraP7tc7ubm5srKWHl5OaVocTGtKGpNza6Kiop8LhcOhYudZc/Ozf7p/ffHRkfz+XwymTRMoxAR3m4JrLBBF6AIPfg3UN9ZbsK72vqHwIuhVFXVRCLhdDgbGhqamprOnTuXzWYdsrRv376e7u6Lly6dOX1md0uLy+XceDgp+WEDO3NRiJvUavHK6EYRz/Pd3d0//clPohUVAs9ruo4xZncjFicQCAS6urreeuuta9euNTc1+crK3nnnHY7jXnrppa+++urSpUsF7SKTyaiqIklSOBzq7ux+9rvPSqJEOFJVWUXwFq3zbqrnFBNSV1f72muvNTc18YLI7J6YYJ7jMMZulwtRND4xsZhanJmeyWazoVCI53mmQTqdzmefeebwoUMIobKyMkEQnnzyqfr6hl//+tfvf/DB6z/+sSRJs7PxZCKh5POqquq6gQkhmCCECSEIYbavZnJyMrWQmp2dTSSSgWBAkqT5RCI+M8Pz/OTkJM9zHo9n6xnABi2CEFRZWdne3v72229jjH/yk59EIhGMEKX08uVLfz527PGjR2traxVFJYRDCGGM2X2OGC9NQAseclkOHLIcCocrY5Uv/8XLbo/btm2v13tl8OrExMRsfFbT9ImJSdu2u7q6Dx06bBiGy+XKZDKiKM3OziaTSUHI5JW8YbCRDkej0c7Ozvfefe/69esHDhw4dOjQgQMH2OnksjKfpqk///nPP/30s//6w381NDTW19erqjo+Pj4/Pz81OZnP5xsbG9Pp9NTkdDKRNAxjdnbW6/UGAgFd02fnZuOz8bHxMUPXOI47dOhQVVXV22+//cnHnzQ1NvnKfHX1da9875Wq6irLtIKh4LavMMdr/l2ipqbmxz/6UWNjoyiKaPnGQJ7jMcZOl8u27cmJiXQ6HZ+ZWVxcbGxqEkQRIcQ0tyeOHmW7sLxeryRJT37nO3V1dW+++es/f/hhfUMDslFiPjE5MSHw/NTUlNvjjlZEq6qrnnzyyf37H6GUOhzOTCYjSFI8Hk8tLHAcp6ka+5yYlnny5MkvvvjixRdfZFp6SVvCmJimtbiYMnSjqrJy9+7dn3zyiWEY3/3udyOR6AZHFYqL41Y66KppCMZOpzMajVZXVbscTq/Hm8/nRVGwLGtubm5+fn50dDSfVwghPb09kUj0v37/+08//ayzs9O27Uw6PTo6WlVVNT09zXFcPD7zpz/9cf/+g93dXZZpFcarpQscMcaYIISdLqdlWTMzM8lkYmxsbPlMzroriJu+3cqKKaKU2pY1PDw8Pz+/Z8+emto60zA0TRscHJycnGxsbPyrv/qrDz744Kuvvuro6GAbIym1h4eHP/n000ceeaS9vT2TySx1NAbBGGFCiCSJhw8ffvTIo9SmXq+HrUR0dHT87Kc/jcVigiCwg0nj4+OvvvrDiYnJDz74AGPscroMw5iYmGxpSeWVvCgKP/nJT3RdFwTB5/OdPXuW5dzj8bz44ot1dXX//u///sknH1dURNk7LaYXP/zzn9Pp9Pe+9/LAwMCZM0vyBBOCCV4awZAgCA5ZnpmZmZ+bn5qaXlhYQAj5/f6qqqpnv/tsR0cHpbbL5WaehTmOY6N9iafyrcuZ1eHq33meZ8tk7777bl19XW9vbzaXRQjlcrmPPv5odHT01VdfTSTmf/e73xcPjrIkhcvD/rKml7/3Pa/Xa9t2rCLGhr5CNm7+03nbvQAtTSJEUYzFYn19fUPDQy636/rQsMPhiEYjS+W2jVRWS2xwFL1oPrFijlw51YALM0e8tF1lfWzbnonPvPXWW33nzz///PNdXV2U2h6vt6uzg9p0eHg4lUo5HI65uTnd0BBFmq5ZlqUoS0fvVFWVZVkQBUEQBIFf1/nqpm+3/HCt6WGrILeQSgmyLIdCocV02jRM1sAkWcaETE9Pf/3117W1tW3tbVu90U1P0rZYbsFL/9OlhYBltfUmU9k0yNKSceFWXIyRJEm8wE9NTScSiYnJiUQiQZdX/kzTPHP6zImvvnrhxRf8Pv+bb75Z+vW56Yzdzfngw8TNXga6MobSokeFlZFEIvGbt982dF2SpPPnz1dUVFRWVl4evHL+/Hld065cvSo7HY/s3+9wOLcwLK9nSVxDsXl3abloY+cqawNSRDDHc4IguNxuURKZA3KO41YmuxjzPEcwFkWpra0NYzw2NvaD7/8gFAoJgpBKpS5fvnz9+nVqU4SJw+Eo83pOnToZiZQ3NzU3NjRev3H91KlToii6nK6AP1BWVrbVUunNNuv1g6z7lCPE4XC43W5JkhHGtm0RQgReIIRghGpqa+sbGv587INkYn5ifEIUxd7e3sXFtCAImGCe58Phcua+lh0yPnHiBOv5Ho87GAq2tLR8/MnHb7zxhiiK5ZFyl9PFcxwmBGPEcZzAC7GKWH19/VdfHdd1PZVK5XK5Z555xjCM//iP//j1m2+Wl5f39fW1tLRUVlaKosixNfXNh5+Vd2WqFMdxvMvl6u3tffvtt91u9969e2VZ5ngGhzCemprK5XKJxHxhUrVU0RgXnOJTStnPHMeVl5e3tbZdvHjx1OlTbreb47jDhw/v3t1y+vSpN//9TY/H09/fX1VV5fOVVVVVszV4WZZbW1u//vrEG2+8gRCKRCJut5vnBUKILDt6urvffffdxPx8W1tbeXm5JEkIIUrpwsLCF198MTs7m04vspOpBONcLnvsgw80TRsbG3M6nYcOHfJ4vZ99+imLeWJy8umnnmppafn444//+Mc/Dl6+fPLU1xzhZ2ZmvvzyS0KIZZput9vtdnd3d1+8ePHrk1/PxGdM09zTuycSiSyVIivI4l35JT16vVbFcZxDdrjdblmWMSaWbWGMOZ7DBGNMqquqqqurPv7kk0w2Ozk5iQnu6uzMZDKspXGEC4ZCoXAYIWTZ1uDlwc8//5xSGyHsdrsFnrepPTw8/Otf/7q8vPzSxUuPHnl0//79ExMT/f39GCGb0srKyuam5rbdu8+fP89c3O6qrrYtmxd4ggnP85TS8fHxiYmJxcVFjuMwQhzPc5aFEPJ4PDzPHzt2zOV07du3r7Oz8ze/+Y3ACz09PS6nc2kCv7Ivd51iWG3N3pLSGApNjl2QzI4qhUIhv99/7Nix0dHRM2fO6LoxNzd35cqgbVNN190elyRKHMdls9nf/va3bFtpfX19VXU1x/Gzs/GLFy/GZ+PBUBAjzHEcz/MYE4Qxx3GiINbU1AYCgT/96U8jIyPnzp3TdZ0QglfGS7xOLreBqmnXhoYCgcDPf/7zzq4uyzQ//PDDN954o6+v7+zZs7Zt53I5l8slyzLhOJ7nCSHsCpSZmWl2kqShoR5jRAjheZ5N3djAGwwGg8EAQohSlEjM8zzndDhcLhfrLBgjXhA0IYCDmAAAIABJREFUVRseGr4xMqKqKtuyFYlE/vCHP4yNjem6fujQocOHD4uiiBAyLZPdcE8p7evru3jxIkKI53nWnQnH89gihON4PpfLDg5eGbo2ZBomwdjGiOM55hsJEyLwfCgU6ujoOH78+Bu/eiOZTE5PT4ui2NbWNjAwcPbsWUVRbNtubGioq6/nCFekS6wUsL2NT1pJs8EYcxzPc1wkEuns6Dx96nRTY1NtTe3lwUGeZ/e68aqqDg0NzcxMq6rKJmQCx3McCYXCba1t586dO3XyVJmvjBDidruCoeDqVEp7fPH+p82zV9xsNm5CpZaUwrxSEITePb1fffXV22+/zdyNdHV1VVRUILzardn6MZdke3vfwfXyss0psm3b58+fe/fdd0VRHBsbe+s//7Outnbv3r0NDQ3Md0gqlWpoaNi3b99CcuHL418e//L41NTU+++/b+iGLMsnT53kOE5R8n3n+3bv3h2JRAjB2zxzU1LOG7ztqgK5mR5dGmRVcpRijL0eT2dX1+9+97tf/euvNE2zLGvPnj08zw8ODk5NTb388suhUIgQQjd7n9IGtlUO16mqdeqJlt4msX747aVSiJv1K0ww4ThB4NmASQjH83x5JNzc3HTq1CmK6NTU1NzcLMGEEMLElr4+Y+OTE5OpVGqL28+27mKrCm1pZksxJTZboN76/QCE0DYvA13dAVa2h+E1XcK27dm52dHR0VQqVRmLvfjCCx2dnfPzib7+8/Nz89GKihdfeKGrq0uUJLJ8aW3xEuFyTJhSZNtWXsmLwsploGu6B5uUFFTelb3CaDMrZJGeRqmhG5WVlU1NTZIosXfTdb2srKy1dbfL6TJNk3Cko7MjWh5xOByCINTV1T3z7DOxWMzj9eZzOUVRGhoaOjo6Ojs7g8GgQ5ZTqRTP8WxnhWEYMzMzmUwmFAo1NjW5trg9sHSOtY6rmvWCIITYWpHL5eI4fv0VAIp0Xff5fO3t7S6ni1lPTdMUBbG1rTUQDLrd7lhFLK8oc3PzgUDg2Wef7enpIYQTRbG1rS0YCLBdBIhiSlEmk75y9er09HQ0Gn322Wd3t+yORCKU0ng8znFcZ0dnVVWVy+VqbW0LBPy6rnvcnr379tXX15umGY/PyrL85FNPHnn0SF1dXZnXOz+fyOVznR0dL7zwQkVFhW3bzc3NNTU1ZNnTccnr2LaVy+dEUVq6XpAiRKmh6+FweVtrWzAUlGX5wIEDBw4ckCTJNM3a2tqOjg6Hw5lKLTgcjubm5t6entq6Wtuyg6FgS3OLLMmGYciy3NXV5fP5TNNECDU3NdXV10ciEcuy4vGZxcVFv9/f2tq6a9cuWZaTyaTT6ezp6W1ra21rb1s+Ko1FQSgvD9u2HY/HRVHs6empjMVcbtfu3bv9fh9TDFpaWh5//PFAIFA4+G1Z1sTE+LVr1zRdP3Tw4JEjR/L5/KmTp8oj5RzH+3y+F154Yf/+/TW7dhFC4vE4Quhb3/rWE088UVVV5XF7Uospnufb2tvb29t3t7SMT0yMj4+X+Xzf+c53Ojs7Kysr3W733NxcIpHgOb6xqTEcDhPCsYPdSl6hlDpdLjYib/z5WW6MFOm6HgoF29ranU4nJhghZJimIIidHZ3BYMDlckXKo5qmzc3Neb3e7z773Uf2PcLznCBJrI+wIMyOmslkBgcHp6enK2IVzzz9THV1dX9/fzw+U1VVbZrmvn37XnrppabGpmAwmEotxOOzmqZVVVW1NDdXVVcbhh6Pz0qi2N3THY1GPR5PW1tbVXUVx3GpVKqsrKylpaW3tzdWWWmZZqyioqmx0e1y8RyfzqT9AX9jYyPG+OTJk3X1dT/4wQ+8Xi/GmJ3qLBpSSlZhEEaY3atLCGHOizfrncXTDrrkKNzv97e2trlcLvZrLBbr7u4OBkOpVIpS2t7e3t7e3tLSwqw6siw/fvRod0832x/o9/sXFxcbGhtffOGF1tbdLpdzIZkSBL6pqbmnu6e5uRlRVFZWxqpG07TKysr9+/eHQqF0Om2ZZmtra3t7e09PTzAYRGjlBCteb7SkRc91XTd03elauQzUMIzkQrKurm7f3n0et0cQBZfLRQiJRCK6ro+NjRFCjjz66MEDByRJ4jm+o7OjunoXz3OpVEqSpObm5u7u7sbGRtu2A4FAa2urJEmmYVbGKpuamph+gjGybdswjFhlZVNjkyRLbAXK4/FomraYXoxGo21t7T09PfV19eXl4XQ6nUwmw+FwT09PMBRi5iGEkGmavMC3trZijK9cubKwsNDU1PTUU09VVsYsy4rFYm2trT6fP5fL5XO5qqqqjo6Ozq4u9jptbW3BUMg0DEmSent7W1p2s/tJmcW4t7d3z5494XCYXfVoWRbb1Uwp3bWruq6ubsn5AVoqMVVRHU6HIAirPO6t0+kKpymwZVm2bbe0tNTU1Hi9XuZdsKGhgdo2z/MdHR0NDQ3M9Ut5eXl7e0d3d3cwGEAUNTQ1NjY2RqNR27an4zOLqZTX621ubvZ6ywrVvqyx48Knp7gNLF096XQWXXG4qpmsOxNY9xtdPDuly2ljjP1+fyAQWFxczOfz7e3tzz//XDQa5QhHMS1yjboqY8s5KCmz0ia8Tnu2kaYtXQbK9ogWTx7W7QLFUErn5+dM0wqFQsxbptvt7ujoKA+X+/w+t9uNMe7o6Gjd3ZpKpQYGBmzbrq6ulkTRH/CHwqGJiYmxsTFVVbu7u59/7oXKqkqO4zYePIomQkUlyGrEtf5loBuU80YprCS0FHCdEsRLdkiO50OhICFkdm7OIctPPfXUo48+KksSc/Fy5MiRcDjMLLIbFt7ymtG6Gs66XWDt65SoYsul4V5unyvZp+uVwMYdrVDOtNBVJVFsa2tzezyiIHS0d/gDAbZTo7e3t7mp2TCMTCZTU1vT1dnV2dVZXl7udDrZp5ZgklpIeTye1tbW7u7u2poaZuMq6R1oixIofuNVHnfZHzHcBnozFDaPbgVFCFEbbebaly1mq5qay+YM02QrcDzH64aeTqdN03Q6nU6ni+c5zCyBRXHj0piwYejziXmn01XG5h9FkmvXkOimGUPrNS+WW0VVMUWyQ2aTPHYHs2EYDoeD4zjTMBVVkSSJ53mEkKIolmUxB0G6rmcyGdu2ZVkmGMuyzHG8pmvZTIYQzuP1YIzzipLL5gjBbpdbdjjYJpLtlDRet0tuJE9pNptNpVLl5eWiKK1NgSKEbKpqqmVZskPmCc+q3TBNTVVlSeYFHiHEvLwrqiqJosvlEnjeME1d0yRZYpeFU8S+C8g0zWw2p6iKLEset4e51Mvn89lMlud5b5kHY6xpuizLPM9rmm4YhsMhY4xz+bySz/M87/a4BUHACGuqms3l2LfH4XBQhNR8nuN5WZbRBnvXTcOIz8Y9bo/X613yJ4oou82anR3P5fOEIw7ZgShSVAVjLEmSqqi5XJYXBZ7jBUGQJEnXdMu2ZFkmmOiGrmmaw+HgeZ4dBGcytm0rSj6XzSGMXS6Xw+HACKuams/leZ7nRQFR6nA6OLI0kCFKWVHkcnlR5N1uN6JINwxRkgSepzbNK/mlD+3SRw4v3yetZrJZSqnb7ZYk8dy58//3P/zD0888c/Txo7JD9ng8giDYtq2qai6bxYS4XS5JkjHBmq5nMxmMsSiJiFJZdih5JZfPsQtkRFGkiOqqns1lWate+kaipWtqEomEZVnhcHg7OygQQnS5ITkcjsKtMoZhaKoqybIoCBQh27JYRYuS6HK5BV4wTENVNVmWBYFfXrCgiCLTMnOZnKoooix53G5N0/6/f/7nS5cu/c+//p/RWIXb5XI6nIhg0zRy2ZyqqmwNXpIkatNcPpfP5QVR8Hg8bLVClmVCSC6Xyyt5UZQ4joiiKAqiqqmUUocsU4RVNZ/L5WTZ4XA4Tp48+Q//8A9PP/3066//RJbldRvb2n5oW/ZMfIbn+dCqG+XXD4gKExaKEKWappmWyYqOUqqoCqJIlmXTNLOZLEVUlmWKkCSImq7lcjnC8V63W5REwzB0XWcNQJIkt8vNcURR1Ew2I/A8Lwg8z8myQ9d1w2DxY0VVqE2dTudS5JRKskQplSWpcJP3Rk5KVr07pdlMJpvNBoMhQRTY6gu7igdjzLoPxdSyLCWvEEKYGYcQ4na7ZVliVx5JkszzvKIquVxuybTKcQ7ZoemabVmyw4ExVhQVIyo7HBgTliPbtjVVRQjJyye5KaWmaWazWdZbCSGSKAqiWHjodDiZMrY8b6OmaaqaKokSQiiTyei67nQ4XG43IVhVVUqRQ3aYlpXNZEzLZMZJWZYQQqqqiqIoiKJh6Lqqyw6JEI45hJAkCWEs8oIoLSetaqIkutxugeNVTSUYyw4HQqjgQDaXyyWTC4FAwOl0rv6arT/KsymhaZmKooiCKIiCZVmqqoqSJAqCaZiqprJVnmwup2saa/yiJHGEsJ6yPHwpuVyOLWS4HE5mTytOBa336aSU5pV8Yj4ZCgUdDseagXizKfRam0CR9KrFaUSppmu5TNZaHv/Z3uZlj6jFGdvwU7j6DyvqQYmYZVmpVMowjVAwVHRzUSFvW3xwKaW6pqmaRm3K1vp4QXCy8qTUsu18XuE5TpZl0zTYvVsEE4yxIAqCIKqqksvlOI5zuVwO2YHXmwmU5GBt1TA/N+XhsFR059565bHO628kupzimlJcmWBRipYuNMtmc4LAs88KolRRNTap41Y3qo2zVXidbRleVr8JLW5BlNJcLpdMJsOhsMPhKHa+tsnLb5zKSjlTSg3D1DRNliVKqaqqDtnB87xu6LqhMzezuVxO13VJljDCTMUqDEf5fD6fz0uCyPE8LwiyJOLlb8Tmk7m1f13TAJYrimw4YgPrsi0lh5lo2GxsO5EW3PYVP0Lo5m4wMg1zMZOWZdl1a3cDb5N11Gq63LKWGn0+n5+cnAgGQ8FgcKWv0SULIi7EsrRagSmyi5rm8uHGu9ksVVXNZrPstMyGQtsYSNiXZ2XhbJOvMPtGFZb4KFVV9fr16xXRikAwULxIVpwKK7Ti644oZY5rEN7sZu1VWKaVWlxwOJwbXhq96kj4ck5WxoyigYOuHUSXs7vShOnySlfpx3T1AsvaLKC1f9tkFF5ZVaJ0aGjod++9d+DgwQP7D3ACX5wwpQihgh10/YiWXrLgQJ29wdo6pDSdTtuWzXazbBDd+vGvGZJL0yj9dm5UUJQijAnCFFFFVY59cOzs2bNPPPHEgYMHZFFe2Y5AEcKIUGoX3JIwPanUS8mqjwNaXgFBRae9WZyWaR0/fvz48ePPPfdcZ2fn9q3/tm2nFhY4jveWebcfqpC31SNjSeNcO2yyWlwucrr8eoVpIKHLDWHdyUBRsnQ52M0PREo+r6gq07SL36U4WfY2FC+N8kUXnZXOn5b0qmUVauV1SnO9QSqFUlx3dFq/mS2VM6UIow2umSjpNUuihWaz2VyaUoQwJRSxxrl22w7GWFXVTCbj8XjYvrubYHVFrizRFdVmqQ+MYq2CLneBtT1lUzRNu8UM3wxjY2OKojDPinf1E2lTO5vJ2pbtLfPelRtRl6sGY5xIJKanpxvq6+WS0483oYCsA2tCPp9vs6/83YFSmkql4vF4VVWV2+1efooQursTm01QFCWbzZZ5y0RRuCVX25tRuImIrTVsGP/yTGGlay0PMWjjQLfFypFL0HO2y7a2qyGEtq/hIITw2vrFGy8YbpAcIUSSJNaf72KN4jW9lJ3SKHo6OTn51ltvuVyuqqoqvHw8mUlgFhwvv/GKdlQU6dok7jSEELaSt1lBrfuXkrytvFJxkPVC4tJamZub+8UvfsH8d5WaU5ejxGucJjLBdfWBDd8DY0mSN2sYq9NeiR4X/bPmzUqzW+QoprRCi2LbKNfrBFkJt3UQr9fb1dW1a9euNa+5vC9gk9IqvCQuDrO+rCAIkixt0XK28w5r0iit040KqkhP5jhu165dCwsLJ0+e7OnucbqcRWKstIva1UZW+6I6xsWCqCgcwhjjSCSyZ8+eWCx2c6+PkCRJoiRuukNjA0pHxpLGuf6wufJ/8VCDCkHWjDar/l9OdstmszEcx0nSmkay0ciJV2V5bcdZNQjgkpdevzbXPCvW1tZ0zHUoNJ+NvyUlvWZJFBf9eU2uVvrXUlWspLIGNkSzHQE312zWLZ7VtVnaC1bnbcOesiksw4UNincDSum777578uTJ/fv3s90EdxVmnF/al3vHX2o5PkJIX1/fW2+91dHZ6V2+B3ZF5jaSJYQU7Oe3HsstQSm9dOnSe++9V1NTs7zR+puY2GySH47j2HYbXDqG3AGW48PrjspFckUD2krIu5Gj4rzhW/n0PMRs7zLQZQdKdzs3OxB29k7TNNu2i3YnA6tgSik7ffvNrzM9eAiCsG0faA8U7MU1TWNeMba/sHJrad29yAEA2BJ2soLtYLzXebkzYIzZLkF2Ev1eZ+fOwDbyKIqCYNjcAcAs9KbYViekG1j4HypYCUA5bAcoJeB2KKxUQUMCgAcVtoTx4PV0tuT3QC63P3iVBTzwbMs4A20aAIBvDBhwAAC4T2GLwjCIAcBO4GHcgQYAAAAAAHDHsW0bNBwA2CGAkgMAAAAAAHAHKGxXu9cZAQAAlBwAAAAAAIDbht23AUoOAOwQQMkBAAAAAAC4A4CjJgDYOYCSAwAAAAAAcAewLAssOQCwQ3hA/LgDAAAAwA7Htm3TNC3LAgdclFLLsmzbvtcZuZOwa9Mf8poFgJ0DKDkAAAAA8E1gGMaXX3559uxZl8vldDof5tkwpbS/vz8Wiz1ghQBncgBg5wBKDgAAAAB8E2ia9oc//OHtt98+cODA7t27H/KpcFVV1RNPPCEIwr3OyB2jYMl5yGsWAHYIoOQAAAAAwDcBpTSXy1FKn3zyyZdffpnjuHudo3sJx3GyLD9g+gC7J+cBeykAuE8BJQcAAAAAvjkIIU6n0+fzPeRKDkKIUooeII9kzJJDCLh0AoAdASg5AAAAAPBNw+b3DzkPhm5TDFhyAGDnAOsNAAAAAAAAdwBwPAAAOwdQcgAAAAAAAG4XSimz5NzrjAAAgBAoOQAAAAAAAHcEdiYH9BwA2AmAkgMAAAAAAHAHYNvV7nUuAABACJQcAAAAAACA2wfuyQGAHQUoOQAAAAAAALdL4UwOKDkAsBMAJQcAAAAAAOAOAN7VAGDnAEoOAAAAAADAHQC8qwHAzgGUHAAAAAAAgDsAnMkBgJ0Df68zAAAPAnB5+R2BFSMUJgAA9yPsTA54VwOAHQIoOQBwB2DftkQikc1mRVHkeehZt0gqlTIMA/QcAADuO8C7GgDsKGAqBgB3hsXFxX/5l3/5+uuvq6urfT7fvc7O/cro6GhZWdm9zgUAAMCtAI4HAGDnAEoOANwZVFU9d+7c2bNne3t7Ozs773V27le6urrC4bDH47nXGQGAhxSwo94yhe1qoOQAwE4AlBwAuGNQSt1u98GDB48ePXqv83K/wjZ7wKZ2ALhXsD1XlmXBTP1mMQzDNM17nQsAAJYAJQcA7iQYY47jOI6D+cFtwrSde50LAHi4sG07k8kMDAyMjo6CReJm0XX96tWrXV1dHMfd67wAAABKDgAAOxKYXQHANw+l9MKFC3/3d3+nKMqBAwdEUbzXObqfsG07HA739PQIgnCv8wIAACg5AAAAAAAsMzs729/f/+1vf/uv//qvvV7vvc7OfQbP8y6XCzbcAsBOAJQcAAAAAACWYGdyHA5HIBAAR5G3DGy4BYB7Dig5wB2DFvHNpAjXEQAAANwNwMfabQLfJgC454CSA9wxKKXxePzGjRvfwOAuCILP53O5XAi+JQAAAAAAAMBqQMkB7gwul6uqqurTTz/t7++/21qHYRiKouzbt+/5558PBoN3NS0AAAAAAADgvgOUHOB2YbsavF7v66+/fuPGDdu273Zy09PT//iP/9jf379nzx5QcgAAAAAAAIASQMkBbheMMaWU47i6urra2tq7nRyldGho6I033kilUpZl3e3kAAAAAAAAgPsOUHKAO0Bhf9o3czyGpQJHcQAAAAAAAIB1AVfuAAAAAAAAAAA8UICSAwAAAAAAAADAAwUoOQAAAAAAAAAAPFCAkgMAAAAAAAAAwAMFOB4AgPsASiml1Lbth+EacnApcWeB8vxm2E45s46Minr03c/XzUGLsG17B+YQ+IYpNFoAuO8AJQcA7g8URTl79uzo6Cj73hTPqCilm0+wtpx+bSRwB6NdV/iWM3Y3or1Lmdm+wDdcTXcptzdVtncj57cZivWmTYQ36m5blichJJvNxuNxVVWvXbt24sQJQlY2U9xyNd2C8CZitm1fu3ZN1/X5+flz58653e67kYF7GOr2o9oJ7/iN5QFjbNv22NgYIYTjOFgxAe4vQMkBgPsAjPHIyMjf//3fj4+PHzp0yO1232aEN7Uyt33h7Uiyz+RGkre2ZHhnFxrXjW1LTbIQit0chZbnBxuFuoU833LhrJuHbywDtxPwDka7UbWyH7acvd2Rlqlp2tWrV7PZ7Oeffz41NVWs5NxOcpsIF3e3Qsss+blY2LbtkZERpob96le/kmV5+9m442zebtd9hZJQW9bv2jWjtaG27PvFAUu05bU/r83t2trZkuJQaL0GsFH9Fmdmm+9FKTUMY+/evaFQaPtFAQA7AVByAOD+IJVKDQ8P+/3+v/zLv6yurr6FGO6SYrMd4W9SdbnbobYjeft52HImsYn6tM0kbk3gloVvOcjtBNxcsfnmM5DNZlVVTafTzz///LPPPstx3B1J7k5VK9ui9tFHH50/f761tfVv/uZvtrmeclerdROZb6Y5fWMNZocs/awNyHFcRUVFWVnZrUUIAPcKUHIA4P6AzWh5nvf5fIFA4F5nBwCAmwNjvLi4WFZWJopiNBptamraRMm5V9i2ffXqVZ7n/X5/U1OT3++/q+cxim0ddy8V4KZYu3oCtQPcp4CSsy1s29Y0TVEUMNRuAsdxgiBsvp0duH1gwwAAPBjs5I5cGMm/mUzu5KIAbnbbHgDsEEDJ2RpBEEzTPHbs2PDwMPTwdWHeV2Kx2COPPBKLxXbg8iQAAACwfWDxHigB5j/AfQcoOVsTDoeffvrpCxcuaJoGnXxdbNu+ePHiP//zP7/88st/+7d/63K57nWOAAAAAAAAgIcXUHI2gxlnHQ7H0aNHjxw5AitbG2Ga5n/+538eO3bs+vXrcK8CAAAAAAAAcG8BJWczmBNGjDHHcTwPZbUhpmmKoghmLgAAAAAAAGAnABP3LYCJOwAAAAAAAADcX2x4ExkAAAAAAAAAAMD9CCg5AAAAAAAAAAA8UICSAwAAAAAAAADAAwUoOQAAAAAAAAAAPFCAkgMAAAAAAAAAwAMFeFcDAAC4aSillkUtuDrrlsAI8RwiBFbZAAAAgLsFKDkAAAC3wrUp86MBTTXudT7uN2yK6su5Z/bKbvleZwUAAAB4cAElBwAA4FaYz9Djg3pGoQgu07oZLBvlm4Qne0HFAQAAAO4ioOQAAADcChgjQhAhcGXwzUIJFBgAAABwlwElBwAAYGdBKcKI1pZzNeUrQ7Sq0wtjRlaloFMBAAAAwJaAkgMAALDToISgnnrhQJM0mbRsihBCi3l7eMbMqtvydUAplQUsCjir2LCdDgAAAHgIASUHAABgB4IFDg9OGL85oRoWRQhRGxnWdgPbFDXF+KYK7o9nwTUCAAAA8DACSg4AAMBOhCJkUWRY1DARQohSZFPKEVzuI7tCHM+hmQVrbN42TCqLeFeIC3uJTdHonDWTsneFud56oa6cm16wR2ZNm2KHiMbmbJtSjwNHfNz4vOVzEoeERB67ZHxl0qQU1YS5sJcoBr0Rt5JZm8LOOAAAAOC+BZQcAACAnQjGKBbg9jeKpo0QQvNp63rcrCvnnt4jYYQJRpKA3j+rDYwZNWHu2x2SZVGfi/TW07eOKxEfVxngvC6usYLPKDTsJbEAmUqqqoEq/NwTXdJbXygtVfzBFjGTp/Npa2Le6q0XumrFnGp7HDi+y37va3UhZyPY6gYAAADcn4CSAwAAsBPBCAfdpCnGs1M11zk6u4gfa5cQRX86p1o2OtIuHm4Vh+Pm1IL15/OqRVHYyz3bK+0K8eeu6x4H7tzF/+GMmlFoLCA5JcLMMjyH3TIhBPMEBd3k96dywzNWfYQ72CJ+NahfnjQjZeTZXrmjhv/ysg6XnQIAAAD3KaDkPGhQSimllmVZloUQwhgLgoAxtm3bMJb25nMcx3EcQqhYjOd5QsjmYgghQRDWirF/nU6nIAiapomiyPM82+liGAaltBAbxtg0zbWxWZZl2/ZGifI8z3EcpZSFNQxDFEVJkjDG7NeCGLtD3TRNFhshhOXEsizTNAuJsryViCGEbNsuiBUnuklsLFFW5oIgOBwOSqlt24SQtWLFiRaqpliM4zie54sTZWKEEIyx0+mUZdk0TcMwWCmViLEGUFw168bG2oNpmoWqYWLrtodisXWbDcaYJVFS0bDV6TahlF6eMN75WmVHcQyLeh046iMYo8O7RUpRmYNwBIk89siot170OYnAI6+TuCVkWcgwqWUh1UCmhShFBXWFw4iw6BEan7cm5i3VoOVlJODm6iJ8NMARjClGbplgjCloOQAAAMD9CSg5DyC2bc/MzKRSKYSQLMuxWMzpdObz+ampKTb9DYVC4XAYITQ3N5dIJErEpqenNU3DGAcCgfLyciaWTCYRQjzPV1VVud1uVVUnJiZ0XSeE+Hy+UCjU1NT06quvBgKBsbExl8tVUVHh8XgURZmcnFRVFWPs8/mi0SghJJlMzs3NsdhisZjH41FVdXp6WlEUjLHX662oqGBi8/PzlFKO4yoqKsrKyjRNm5ycVBRlcXHxsccek2U5GAwmk8l4PM5ii0QiZWVluq5PTk7m83mMscfjqaioEAQhlUrNzMwghAghsVjM6/VI5YPwAAAgAElEQVQahjE1NZXNZjHGbrc7FovxPJ9KpWZnZ5mKEolE/H6/YRgsNoSQ0+msrKwURTGdTk9PT1NKCSHl5eV+v9+yrEwm09PTU1NTI4qiruuSJGWz2enpacuyMMaRSCQQCFiWNTMzs7i4iDF2OByVlZVMbGZmxjRNjHEoFAqFQkwsnU6zqqmsrHQ4HH6//5lnnhEEIZFIeL3eUChEKS3EJstyRUWF0+nM5XKTk5NMawqHw0xsdnaWtQdBEKqrqx0ORy6Xm56e1nW9uKKZGKVUFMXiGmRifr+/vLyc47hCexBFMRqNFsRYs2FiTCsDVed2oAgZFsppVDeXVA1dwKpB0wo9cUW3KJIFpJvIMOnTPU7Tph8OaA4RhcsIJhghRCkiZCkq06YijwQOq4iGyohTRkx7yaqUaVCKjvI6HZwwJpI2h5Es4tmUZVMK29UAAACA+xRQch5AVFVVVdXlchFCRFFkq+88z7tcLjb3lSSJSUqS5PF4EEKCIBSLiaKIMWamkoIYpbRgjuA4zuVyMQFZlnmeb29vj0aj+Xye53lBEJhhhBDCzDsIIVmW18bGxJgViP3scDiKxWzb5jiOGR9YbDzPezye119/vaysjM3pWWxMrJAoex2Hw8EyLIqi1+tl2gszPjA1g6VVEBMEwe12M7HiRNlfZVkuiJXkDWMcDAZfeuklhJDb7WamDJ7n3W43U3JEUUQIseJiRhVJklhsrMwtyyKEsCIlhDCLENM3mKmksrLyZz/7mW3bkiStja1Q0axqCokWXtCyLEopMwoVEi3UIEtClmW3283EClVTLMbCSpLkdrtZOTATEBNjycmyTCmNx+NOp7OsrOwuN/aHAlaJlKKsSi9PGO3Vgt9NVJ3WlHM34pZlI4FHpo54gqI+zuMgGCOMkWrQgIfrrOFH4tbMgnWgWXy0VZzP2F01QonuiREambWmEmZ1iE9mDa+TBD14OmlRikBFBQAAAO5TQMl50KCUZrNZRVEaGhpkWUYIFSboFRUVBTH20Ofz+Xy+4ieyLEej0c3FKKWSJJXEJknS2oDrPvR6vUyzQsuzN0mSIpFIiZjH4ymIsURFUSyIFUwEJWIIIUEQmF2i+KHb7Xa5XMWJCoLAzFklYmz6XhDjeb4gVkjU5XI5nc7ih0ysIMliczqdDoejWIzjuGAwGAwGtxQLBAKBQKBYzOVy1dXVleRkbWzMKFcsxqwrhRpkAYvbQyG2zSt6IzG0bNIpiOm6PjMzEwqFCmLATYIppTNJS+CRvbxhDGNkU/r5ZZ1S9EijQClKZulC1tBM+vGAtr9JeLxTnM/YX1/VF/M2xmhi3ppMWPsaRcPUL08YZ4eN9mo+rdKRWXMygXUTJTIWh7FlU4TwXNr641ntSJv4eKdoWujKpJnXHtKdamzVAC33FKb/0+V9e6xfsA2fhSDsIUKoIFboLMWxlVg1C0FKYmOSWyZayN7aJDYXK+R2bYaLE11bIJskuvb1t5noumJg/gUA4I4ASs4DCDvjwQwCaPlDgpbnowz2sPjJug83enI7YsU/7OREN09iO7HtHLF1H97VRJnhCAG3CkXoq6sGRogpIUsPKc7k6bE+/cvLBsJI1alhUUrR1SlrZM6SeKwYlNpLx2/m0vavP8+LPM5r1DDpRwPaiau6bVPVQAQjw0IXx6zLxDKtpZivx82JhOUQsW5SzUCW/TDacSzL0nW9cLpMEAR23ozZwDHGzOjNjgIWjhEyG3JBDC1bVtnZxWIxjLEsy16vFyHEtneWxMbM7yy2wuE6FluJGLPKGoZREGOW1eJEi8UKp+YKBljDMNjhuuJEdV1HCHm9XmboZrEVxNbGxkz3xbFhjEVRJISwVygkWjhGyEqpEFuxGDPvg5IDAMAdAZScB5C16k3h+VrJdYPflFjx4t92wt6RREFsx4qxxsBmOWvDAtuBKaHW8lp5yXPTRmmFFn7FGFGEVB2peuHhUqi8hvIaRRhhjE0LpfNLAsyhh02RvTQpXQqiGUgzlmQetokmG8ey2ezk5CTb7en1emOxGMa4cD5QEAR2Vk1V1ampKXbacO0xQp7nKyoqvF6vrusTExPFYoIgHD58mG21HRsbY+cDdV2fmppiB//cbndVVRXHcYXzgRzHRaNRn8+n6/r09HRBrHDasHCMMBqN+v1+0zQLhxKdTmcsFhNFMZPJzMzMsD2x7HwgO5SYy+UopU6ns6qqShAEJiaK4g9/+MOOjg5RFE3TnJmZyWQyTKyiokKW5UwmE4/HTdMkhLCDf5ZlTU9PZ7NZSqnD4YjFYrIs5/N5dj6QEMJOG9q2XTj4x04byrLMzgcahoGXzwcyY07BMAUAAHBrgJLzAMI2XLG1urv9kWCexNi3k501v6vJbYlt2+vaFh5OiveH3CmVo9g+s1EJcxxXVVUlSRLsPLkbYITWugNYt5hXHbzZRj085HVFKV1cXDRN0+fzEULYWTWMsSRJbOMlMz4ghDiO83g8bJcps3gwE01BjBlGisVYbJIkPf300wcPHmS6UHFsrL8Un130+XysBxVic7vd7OfCib5iMXbYsiS2wobSsrKyYjFCiNvtZkaYQmxMrKurq6ury+v1SpJk27bL5WJ+JgsH/9gRRzYUsE3RGGOXy8U+OsUnPAtirJTYEUdW2sx9JUJIEAR2YJKJGYaRTqcL5QYAAHDLYNhS8iBRqE22sIc2noayZUvDMDRNY6HY95udHd/mxNSyrIWFhbGxMUVRqqqqKisr2Wn1m8qwZVmKovA8X/jQ3jKU0lQqNTExwZZgd862hxJLF9sSY1kWc3hwlzJJKdV1fXx8XNO0mpoal8u1NqFNTHAbxZnNZkdGRhwOR01NzdoSZrOo7ShC9zuU0i8v6//v+9mMAorczWHZ9JFG4X+96Clz7iBbH9uWNjw8TAipr69n8+/iv26nlovFSjrCLce2pXCx2CaJ3lTS2+QWimVLycXFxfHx8crKykAgAD0LAIDbASw5DxTsC2fbNtNhNv9C2LY9Ojo6ODjIDvAIghAMBhsaGoLB4JYzb/YdVRTlzJkzg4ODkiSxLQo3m2HmhuvChQuRSKStra1wg82tQSmdnp7+/PPPm5ubI5HIzWpcdwlWF6xSOI4jhCiKcuHChWw2u3fv3rt6ND+fz586dUrTtGAwWPC7UJwx27aZ7YsZ4raMkFI6Pz//xRdfxGKxqqqqtSWMl88uq6rKcRxbdQa+WSjBGGNk2QiBf7SbhI1saxd6tjkubTPUTcW2pXCJ2Obyd1ZtuLVi2QRW/my0vPVsAQAAIIRAyXnwYCthi4uLbCv2JpK2bU9MTFy8eNHj8bCN0ZcvX04kEo899ljBX9nmzM3NXbt2LRAI7Nu3j1lObiHDzBZUcIV8O1BKM5lMJpORJGmHaDgMwzAGBwcXFhY6OzsDgQC7ZUjTNHb/zF1KlFKqKEoqlXI4HAWn4SXMzs5euXKlvLy8qalpm0pOOp1mjsKZm+x1xUzTHBkZ8fl8t6D3PthQigihbplIwspDjJBNUUahmnG7KgmlyO/C+xolWUTHB/VkFmaKN0dhqxVwr8DL1x/f64wAAHDfs4MmgsCdgk1to9Ho5hNo0zSz2awoigcPHty1a9eNGzc+++yz2dnZbDbL8zw7ZmOaJlMYdF1nTodEUWSbsFVVjcfj+Xy+oaEhGo263W7TNFVVNU2T4ziHw8HmCrquq6paCEgpLUzuHQ4H87y8b98+dojWtm1VVZmzIFEU2fUslmVpmoaW97YJgsC2rdu2zXJl2zaL3LbtXC6HMXa73Wx3OCoypLCY2dZ59hFlG1RUVbUsi+M4duEPS84wDLYpn+M4VVXZz7Zts5xIksQ8AhFCLMuybVsQBLbdjm0SY7vReJ5n190kk8lLly7Nz8+z+zodDsfu3btFUfT5fMx5EcsDezXmlElV1UI1FcqzUKEsJ+xEb0Gg8C6sNAghuVzOMIxgMMgyzN6LbcoXBEHX9bGxsbNnz+7evTsajXq9XhZboUBYBbFSKoRdXFxECHk8nk1mIbZt5/P5wuZ7oAgq8fhgs9BYIRCMHBLWTWqYyLDoxwPatSnz9iyZCGO6t1HqqeP7RwzTBkPOzcGO+MN59xKKTb6bLG3ccpyFi4MRQuy7EI1GYfQAAOD2ASXngWVLc7+u6/l8nh1mLcz7RVFUVfX06dPMHpLJZHbv3u3xeK5fv86c85SXl7MnFy5cuHjxoqZp4+PjgUCgsbExHo/fuHEjnU47nc6Wlpa6ujpd1wcHB0dHRw3DiEQiHR0duq5fvnx5fn5eEISmpqbGxsbp6enp6eny8nLmn2doaGhubg5jXFFR0draGgwG5+fn+/r6MMaGYWQymVAo1Nvb6/f75+bmrl69Ojc3p2laOBzu6uryeDzZbFYQBPaBZF9NpnVMTk4ODQ0lk0me56urq9krKIoyOjp6/fr1TCbjdDrb2toqKiqmp6eHh4cXFhYkSWpubg4EAhcvXvT7/V1dXYqi9PX1CYKwe/fuiYmJsbExp9O5uLioaVogEOjo6IhEIouLi1evXp2amlIUxePxdHR0cBx3/vz56elpXdfPnj2rqmogEBgfH2fTqXQ6PTw8zM41eTyepqam2traXC537tw5to0wmUyyo8AVFRWFNWbTNK9cuTIxMSHLcjabLS8vb2xsHBsbm5yczOVyfr+f3c2ay+Usy/J4PJZlTU1NsffCGO/atau+vn5sbGxgYCCXy42NjfE839vbK8vyyMjIyMhINpt1uVytra01NTWWZY2MjAwNDaXTabfbzTwjMR+4G7HNbTYPJVg36eCkOZ2yXSJ+bp98cdy8MGoiiubS9m0XGJV4XBXkLowZx/p124bDQjcBK6vioaMYtlbCTjCy8/cPT9kWTuK5XK6amhrmLOH2yeVyN27ccLvd1dXVxXGKoli4IgwAAOB2ACXnAUQURafTueWtapqm5XK5fD5/+vRpnucTiQTP8/X19bZtDw4OJpPJYDDo8/nm5ubOnz+fSCR8Pp9hGOfPn89kMnv27Mnn89lsluM4SZIMw+jv77969SrTlyYmJlKplMvlmp2dPX78OLs6M5VKzc3NXbp0aWJiIhKJMHOToig3btyYmppqaWkZGxv78ssvM5mMz+dTFIV5QX300Ufn5+f7+/slSQoGg8lkcnx83Ofzud3uubm5ubk5QRDYERdRFDs6OnK5nCRJhVVAZoW4evXq119/bZqm1+tNJBJjY2O6rnd1dV26dKmvr4/5PJifn4/H48lksr+/n1LqcrmSySRzkzo4ONjY2IgQSqfTg4ODoVCovr5+aGhocHDQ6/X6/f58Pj8+Pp7P5x9//PGFhYWpqSlCCMdx165dsyyrubk5n8/n8/mC96H5+fkrV65IkpTNZk+dOnXt2jWn0ykIwtDQ0PT0NFvXHBwcVFU1Eolks9nR0VFZlsPhcOGslK7rN27cuHTpks/nYxk4derU+Ph4MBgUBGFwcFDTtMceeyybzVqW5fV6mVfZTCbjcDji8fjp06dZueXz+YInKE3TLl++fPny5bKyMkEQRkdHc7mcw+GYnZ09ceIEpdTn883MzMzPzzudTq/Xu0nTYq5gnU4neFcrAWNk2Xh0zkJzltdBvtVqj8atvhuGwCGnhGURO0RsWiir2LKI3Q6M/3/23vO5jizLEzs3febzHsCD94agN6CtIqtIVnVVr4nR/hXSTsTqgzYUG9J0dMwXjTQz/UWKkD5IipG2d1czOzvVXY7eexa9BwlvHh7wDJ5Ln1cfDpD1CBAgynR3Nfv9oiIKzHfy3Jv3XHfuPQZIUXM0HQihikgsG2SRcCyUVKqZFChhGOqTGZ4lRc2xLBLyMj6JpIB4RFLSKCHUKzEyT0yHFlVq2RQAFIHYDgg8MISoBuVYcBzwSMS2oahRgQOvxJgWLaiO7RAAYBnwyQST8JQ0h1LgWcJzQB2QRVLSqG6+C1LGuwU38vLqL1JV9ebNm6VSaWhoqDqP8I9VOsYjwUQxP66xFn4a3p9/p9AyLubm5i5fvtzS0oKRplcwBwBM1yOK4gbVP0ppOp2+dOlSa2trMpms/gnv0gVB+EmZHNdQQw1/jKhNIu8g/H4/3sysT6breqVS4Xle0zSe52OxWHNzc09Pz9zcnKZpoVBoaGgoGAw+evQolUr19/cPDg6Wy+VLly7hpURfX9/09HShUNi+fbskSefPny+Xy62trT6fr1gs5nK5XC63sLBQqVSi0WhTU1M0GhVFMZPJOI4TDAbD4XBTUxN60YiiaNv28PBwNpvdsWNHd3d3Npu9ePHixMREoVDAnXpbW9uWLVsePXr06NEjVVXxMqGurg6XWDScU1VVVVVJktztNSGkVCo9fPiwUqns3bu3ubl5amrq0qVLU1NTsVjs2bNnHMft3bs3HA6XSiVCyM2bN03THBoaSiaT5XJZUZTJyUnHcXDTU6lUNE1Daz28Mtq0aVNPT08mk8FmwVfq6+styyqXy6lUqlKphMPh7u7uqamp5ubmgwcPiqL4+PFjzCYxNzf3/PnzSCSyZ88eRVFu3779+PHjmZkZv99vmmYymRwaGpqenr569Sp+MgoOLdxQnduyZUtra+vMzMy1a9dEUYzH4wzDzM3NZTKZQqGASTB8Ph/P89FoFDcfpVKpUChQSru7u6enpx3H2blzZ3NzM9rU6bre2dkpimKhUECF7cWLF5ZlDQ0NtbS0oCIqiuLqMAYIbHaO4xobG9+Bje/vAoQAAQIADAEgmJEGJIEc6BdYhiSCzPNp68mkubdHbIqwAk+mMva5R7plwcF+0XJozM9EvOxo2r7wWNdMuqVF6GviFIGMzFlPJq3d3UJrglNkpqw5d16ZzXFuRzvvkYjtwLNp684rw7Jhd7cgchD0MIsV+nLWGmjmDAvqQyxD4OGEGfIwrXHWduDiY/35jM2xsKmZ29rGeyRSUunV58bwjJWMsFtaOcsmYR85+0Cfyth/6Eb9cYA7b5Zlm5qaVvxECMETGTQTheXNvRuoYCPMV1BWxzbEoCnDw8PJZLKjowOqLqKrady/38hkdXHui4VC4dGjR4qi9PX1oQ2ty9+tWHUNV7AtFouapmHyK/cV91fbtkdGRiYmJvr7+5PJpPtrNdmK4tB3FJeeaicoSmmlUkmn07FYbP3r4hpqqKGGt6Km5LxTwKWL53kMU7bO0ote6YZhtLS07NmzBxMm4Dnc2NiYZVl9fX2dnZ2GYaDneldXF94q+Hw+TNSNeeIURYlEIplMplgs2rY9OTlJCDEMw+v1iqLY1NQ0Ozu7sLCQyWRaW1u3bNmCdyAvXrxAf494PF6pVHw+n2ma6XTa5/P19vZGo1GWZRVFwRqiFtTS0lJfXz8yMsIwDF683L17d35+XhAEVVVN0+R5Xtd1XddDoRDqIYhisZjNZqPRaFdXVzAY1HUddapsNlsoFLq7u9vb22VZtm17fHwcfZna29sDgQAAmKb54sULx3G8Xi/qY5ZleTwe9KIJBoO9vb3xeBzdVyqVCgY/Resvy7JUVcW4cwDAMEw4HI5EIoZhoOOQJEnpdFrX9ba2tpaWFkIIxrWzbRtz6rW2tjY0NBQKBdfhxxUoqluxWAzt7l69elWpVCilL1++hOUMGKho8Twvy/L4+Pjdu3dVVeV5PpfLYfPyPG/btqIo8Xjc6/Wi2R7DMKOjo64QK5VKJpPByATBYLBSqUiS5PF40F1qdb9yH/5YNi1/IuAYMtjCizw5eU8bnbMZhhRVeuWZIfBwZLO0WHHujpj9TTzPwYk7msjbR7eK8wV7ZM46PCg+nTIfZuyAwugmfTxpdtZxI3PWixmrPsx+ulN8NmXdGLZiAWZftwCU3hkx2+Jcc5w9dVcdm3dCXnKgT7zzyrj6zNjRyf2r/fLFR/qFx/p7A+LhQXE0XemsY49tFe+8Mqdz9mAz/9E2KVOo+CRyoF+8NWzcfGFkiz80XshPB2jaulbgAU3TcLLieR693TiOQ985n8/HsmylUsGsMjj8MWsnHgfgEQxmsMGhYZpmqVRCp0ec60ZGRu7du2fbdjQalWXZMAzUKHDKkmXZPcRBjzhKqcsERyXDMOgDiV6UOD/LsoypSx88eBCNRhOJRDQaxfscvOEpl8uYclTXdVmWMVNNNVsAwGSgeH+Lv+KlEz7J5/PPnz8fHh4OBoOBQAAj46OlAM4w7pkIOoLqus5xXD6fx6ZbsVThBPg7DTtZQw01/ImgpuS8U8B1S9M0Xddx3X3jThTXNjzOD4fDdXV17pqHO2O0TULfdFyucrmc3++fnJxMp9OhUMjv9+OSH4lE3JRt8Xi8v7/fNE1UFWKxWKlU2r59ez6ff/jw4cTEREdHRzKZjMViGLoaXUpUVU0kErhp1jQtk8kQQl6+fJnP55uamgRBKBQKkiR5vV40JgEARVFGR0dHR0c7OjpaW1ufPXtWLBY9Ho+qqpZl4YdXtwmewmYyGcMwhoeHVVXt6OhwF+9MJsOyrG3bmOa8VCrlcjn0s/f7/bqu27ZdqVTm5+fHx8cppV6vV9M0zGK+sLDAsizWNplMLi4uPn36NBaLDQwMTE1NZbNZRVE4jnPvYTAwQ7lcZlnW4/GgMpPP57PZbLlcHhkZURQlHA6jVxJGAnA/udqCpVKpGIYRjUbdTHzoa9TS0lKpVIrFYkdHB+pdsiw7jvPkyZP5+fkdO3YoinLz5k1kaBiGqqq4a0FBo9rZ3d2Nym1zczO2XrlczmQyuq6/evVqcXExkUhgDsF1etf8/Lwsy6gr1rAROA68mrVuvzQdB2SBLBTtRICVeFBEqA+x94lp2XQ8bT8Yt1gGtrTxMT/zdIrmK04ixBYqdGLBypWdigG5sjObs2fzzuYW3jDhwmM9X6bDMxD2MFva+CeTlkNhbM66/crSTBqQOdWgd0bNh2MWz9HuBv7uqDmWtgMKs7dH8IikO8kFFIYChDyMbtJEgIkFGApQ0eg3L83nMxbL/Kk4X+HJQn19PaX03r17MzMzPM8XCgUA6Ovra2tre/DgQT6fHxoaSiQSs7Ozd+7ciUQi/f396BCIJwjt7e1btmzBIfnq1Std1wOBQFdXVyaTefz4cblcfvHiBSa2GhkZsSwLL2GCwWBdXV0qlcrlcqFQaNeuXQ0NDfPz88+ePZuZmdE0LRAIbN26tampaXR0FG13Ua1qbGzcsmXL5OTk/fv3cVq7evXqnj178KoKD25u3LhRKBTwtAjDPz5//nx2dlbTNL/fv2XLloaGhnK5DABer7dYLD59+nRqaqpcLguC0N/fH4vF7ty58+rVK1VV7927p2natm3bcCZEc99wOLx169ZkMqmq6tOnT/FERpblQqFACEElp7qdazauNdRQw4+FmpLzrgEXxfn5+a6urnVioaIvKcMweP7nLip4/4DRCPDOJJlMTk9PX7t27cmTJ4uLiyzL9vb2BgKBXC6HdlyiKEaj0Xg8nsvlpqamUPlJJpOVSuXmzZt4IYBb9tnZ2YmJiVAoZBgG7uY1TUMmkUikoaHh/v3758+f93q9uVxOluW+vj6e50ulElqgmaaJdyOSJGH4snK5PDY2Njs7i/cVqqo6juP3+6s/HK3aRkZGzp07x/N8Pp+PRqMY3CwSiUxMTKBS5/f7t27dmkgkXr16dfbsWXTUGRoawqBqDx48GB0dTafTHMcpioJKjmVZly5dQncjURT7+/tVVUWD8snJyampKQDAZsR9//Pnz1mWbW5u1jRNFEUMAefz+Z49e4bhE8rlcl9fXyKRGB8fx/AJqGC4fFzZYaQ4PDPmOC6RSPj9ftS4cNfV39+PSiNqWaZpOo6TzWZnZ2eLxWIkElEUBTPGZjKZGzdu4OYmFArlcjmMXoBXTNFoNBaLjY2NnT17VpIkVHXw3m+djYhlWTMzM9FotHYcu3FoJp3N2QCEIbS7gftgiziXt/Ml9IEBADBtmM7aDqUsEM0EhpDFMv3ytrqtXdjaxu/o5P/+iporUwJACLAEBJ6Udce0gCHEobSkUYlnGAKU0lTOMSxMp0NyZWex5DAMmBbkSk5FB4aAqlPbAZ4FkSMcS2J+xnKAIXB/3CxrNOwl2ZKzWHHeMQ3HPVlY/ROedOC9BKUUA5bEYjGO49LpNKU0FostLi6+evWqpaXF5/M9f/4cCSYmJq5fv46hFNEdLhqNmqZ569YtjuOCwWC5XMa7aLxEwgGL8Ugsy8KjopmZmcnJyUAgoGnakydPcPzeunVrbGwsHo/joQ/DMMFgEG3eFEUJBoO5XC6fzycSCTdAJUaTr75lLRaLY2Nj8/PzkUgkFovpun779u3R0dFEIuGyxeMSjuM8Hk+lUpmbm2NZNhAIjI+P27a9fft2jL6IvqAsy2az2Vu3bs3OztbV1QEA+h8GAoEXL15cvXoV381ms9ls1ufz4epQ3dQ8z+MM8zuWdg011PDuo6bkvIOwbRs3tevvP9Daqq6urnpRR6Op/v5+jG8jCMLAwADDMNPT05Zltba2dnZ2Njc3ow7Q1dWVTCbR32Pfvn14oyIIQnNzM7pkxGKxubk5VVVbW1u7urrQ3hrXy+3bt/f29uZyud7e3ubmZp/Pt23bNlEUU6kUuot0dnY2Njbqut7Y2CgIAqbuqa+vR38eQRB0XcfIB319fQAQj8eLxWJXV1dDQ0O1PuDz+fbu3RsMBhcWFgghTU1N3d3d9fX1juPs27fv+fPn+XwefUhisdiuXbt8Pl8mk2EYpr6+3ufzdXZ2lsvlfD7v9/vj8TghJBQKTUxM2Lbd0tKC10ft7e2dnZ1tbW3FYnHz5s3ZbNZxnI6ODvSrwQbJZrOlUgmDTTc0NCDzcDh88OBBPNr0+Xxbt27t7u5GpcXn86FJeiQS6enpcT1qEB6Pp6urq6mpieM4/Kj9+/e/evUKD19bWlpwv9Lc3Oz3+2Ox2KZNmzA+RCgU8ng8fr8fDfB6e3vHx8fxIiiRSOzbt294eLhUKgDuDREAACAASURBVMmy3NnZWV9f7/V6h4aG/H5/sViUJKmurk5VVbfctc5cydvSrtewGpSC7QAAcCzpamBVnZ66pws82dLGk2UC015qV3wiC+CVyc2XxstZ67/aJ7cm2MVRC7k5FKYz9mAL31nPjaUtn8x2N3AT85ZhUQpgU+pGl3YcsKtkRar+Z9kwnbV7Gp2H49Z01o76GUUg6UUn7GUcB5x3TsIMw+C+fLWeY9v24uIiIcTj8aApWjgcPnz4MM/zJ0+exDDu9fX1L1++TKVSoiiOjo42NDTEYrEbN26USqWurq5oNIoJsjKZDABomhaJROrq6kKhUEdHByoPxWLx0KFDiUTi0aNHjuP09vbu2rXryZMnt2/fbmxs3LNnz+jo6OXLlyuVysTEBCoz8XgcAObn53O53OLiYrlc5jhux44dnZ2dN2/eRPvV/v7+TCajadr27dsHBgaqs2bhcUZDQ8PBgwcjkcjLly9dto7jpNNp954Zz7MEQcA7GTSiM00TYz/OzMx4vd6jR48qivLgwYOxsbFwOJxIJPAOPJfLpVKphw8fchx36NChpqamsbGx8+fPy7K8IsYDRn14Y6LhGmqooYbvito88g7CzTywDg3Hcf39/T09PehL6j5HCwRKqXtUHwwGd+zYMTAwYNs2mobjc1zC3aSQLS0tiURC13V0UMFzuD179uDtiiRJaFjV0NDg0giCEAgEkskkMolGo0NDQ9X06Pmzb98+NwLYjh07MIRrMBhE/xYM5woAbuwEjIXtbsEZhmloaMBbIwDAcgkhLMu2tbXV1dVpmubWGVUCNOJCrxVK6YEDBzBwEN7JAADuJLq7u3t6evAnNEPH2uKJLLYAutUmk8lgMGgYhiRJsiyHw2E3zFFvb29LS4thGHgZheHXtm3bhp9JCEExVe9LGIZpamqqq6tzfXYx8Q7ywSQ5mKLnwIEDWBMMBo0NSynFqhJCtm3b1tPTgz48PM+3t7cnk0n0BnZjV7S0tMTjcTTBx1xGbt9Yp4/V0vm9FZSCqlPTXvLD1gxq2gAAtgMT83ZThDs8KFIkMyiloJnUcgAAKIBmUt2iXok50CcShjAEyjpNZR2HgmZS0waGkJez1vCMdWSzuFDg/TJjWs6VZ7pugW6CaVFUY2yHqgZ1KIZ9A82gqLpYNmgGpQCPJsy2BHd4UMiWnKCHGUvbL2Ysy6aqSd9JPRYnjRXaO4Y+KxaLaGWK96ixWKy+vh6j8OOgQ7NbvCw1DKO7u5sQks1mKaWZTCafz+u6HolEPB6P1+ttbW3F4PixWAyDsuD9diAQEEURc3M1NjZivESe55PJZCQSmZqawtkSlRae58fGxiilHMeFQiE06PV4PG1tbRgjkeM4nA1whgkGg6hU4NehQw6e1zQ3N6P1GrIdHx93HAfvmvAWy+/327b9+PHj4eFhjuPQ4LmhoQFNjvEyPBAIWJaFhsGapo2MjNi2LcsyBsxcXFysq6tramoKBAI44Xg8ntUZq/HM5V26Iayhhhr+UKgpOe8gPB4PesOvc9AOANX7ZjcWGTrEr6AXBAH3u9Ueorj0ujQMw6CTK1Sdg+LJn0uAdXMzUbgxEtw6uKYUbkGobLilVNdNURT3FNCtlVvcis2KJEn4vSuurdDRFp/jps2lxDqgEw7+hO+Wy2VMour3+30+n1sE0mMjrHClRYdjt9DqQ0o0AkEHIeS/QgTVYoLXY0tUP3f5uJVB0xe38bECKyrmKp/4HF9ZIUT3o1a03jqm86jXoUJV26yshYrhfH5bWyxTlgHVhJP39bJGAahD4f6YNb/oRP1sQXWuPjMch5Y0euqetlhxAMC26YVHmmmTbIl++Y2ejDAsS6YWrFTOAQJnHugVnQKlZQ2+/EZrirJhH1PW6NSCna84hMDFx7pmon5CJxfsL7/RCxXKEJjO2F98oxVVBwDG0vZiRSuq1HTof7mutcRYr0RyZXM642gGHZ+3C6peVMG9+Hk3gOHdCSHRaHTFT5ikC61VK5WKZVlobooOkMFgEHWJcDg8MTGxsLDQ0dHR0tKCelEgEBgYGOA4LpVKxWKxxsZGVVW7u7tbW1vRtwfj9aPfP2pNeIzixjsBAHTxx7trjP7C83xjY2NrayuGoMSjEFVVcbTidZObjxiDImiapqqqe1DlKjmhUMj1wHS9+0qlUrFY7OzsRGs0WZZLpdKTJ08EQdi6dWsul8tkMpIkoTOPbdsAgImk8WClra2tvr4+m82aptnX14dOjMViMZVKlUql58+fFwqFZDIpimL1LIGBFgqFgs/nc709a6ihhhq+H2pKzjsFXC28Xi962mz8xfV3otU74/UVJ7IcJ7R63+++CKs22Ss44CXDRir8VsoVyo9b7ooFtdqwrZp4Bavqd9GSzev1RiIReNO+f3VB63z1WnVY/7veymedX9d5+EYhwhqt98aauE1US+f3Vlg2GU/bhAAhxHboVMYmANiuhkVH0/bY/Ld2ZATIZMbGoNMOhZmcg60/k7NncjYBoLAUmXo6a6MUAUA16PNpixD8FQAIpYD0BAgFKOu0pFsEgBBS1mlp3sa/S5pT1AD/LqrOwwmHAKCFGyGkpNGitvTW77/dfndwHAdjD65WcnRdR1c6j8eTSqVc3z9UHtzolHV1dZg0s6enx+/3C4LQ3t4+PDz87NkzQgiaqFmWdffu3bm5ObwUSiQSkUgETy7S6fSFCxcGBgbQmw4DnWGgf4/HQylF5SccDnMcNzIyMjMzg7nOPB4Peg9iEZjTGZngKQbHcZiVy3GcwcFBHPi2bWPERTwc4Xm+ubl5dHQUvfKQLcYwwLMevGcul8tomYyJht3L/PHx8StXruzcubOlpWVqampsbAzt3CKRCLogJpPJkZGRM2fOCIJQLpcxSIwb88btS5qmofdjTcmpoYYafiDYX/ziF3/oOtTwo2GFKrLO3vqHF/FdaTZSmY3X9nt/V/WLa/29Dj2lFPdAjY2N6DL7XRlusD7fFevzWUcv3QjDDb4CVd44hmEAwFvNJv+oMbVg3xszbRsY8n3+YxlgGcIyhCFLf7AMYRl4/Z/fPl8iZr598U00Sz8RcBhCOYZZi2AFn+pC1/r7jb9+j/8IIY0RZne3KPE/rb6BwTlQRV+h/xuGgSm/WltbLcsihLS3t4dCITSvbWpqQttdAMCfenp60AI2FAoRQtAvv6urq6enx+PxoMpk23ZdXd327dsbGho4jrNtm1Iqy3J9fT1qMuj8Vi6X/X5/e3s7RmHxer2dnZ3RaNTn81mWheHLNm3alEwmLcvSNK2xsbGhoQEVmHg83tjYiHeqaG9cX18fjUZdJadUKnk8ntbWVtRz0GHPMAzTNMPhMOa9waAFGNEeA1EKgoA2wGjLKgiCaZqEEHQIxJD0uq47jhOPxwcGBhKJBBqt4QlIKBRqbm4OBoNtbW2YVnXFTQ4G83xjStYaaqihho2j5h/8rsFxnHw+XygU6uvrV5s711DD7wGmab569SoYDNbX1/+h6/K7AqX01az1eNI0f2qZMCnk87nU9GgsFo/EG3+CBmWUQjzA7OwUPNJPyGsLA+iPj49jCMQVGSodx3EcB5btWjEyIcMw+JxhGKR3HAcj0bvh+5Et6gCuE51t24ZhoHtbdfh+dMVxLVTxjAAtwdwX8ZwFX8Egk+gsh5VxS8dKVr+o6zqlFM3qXHM1l6Gr1GGuYcw8hrc0tm2731v9LXgVzLKs4zioF2FAGqwJ1s1N2oac8XVk675erck4jrO4uDg1NZVMJlE//N1LvoYaanhnUVNy3jU4jpNKpSYmJlpaWjCrpmEYGNeLLDtXoJ03nrVjFGP0TC0Wi0iGQW/QMgH99d00dsgN111ZltGZBG0b0FHV7/fzPI8J41wydA7BSD64piI30zQLhQIuxph4jhCCGR6QzOv14jEhJqdDMjeIM67o6DcviqJlWZivEwDQsATzzCC3N5IJgoDRmTVNw1jSGFYbE4aWSiXTNN9IRgjxer2SJKFHMpJhuWgQ75K5liQuGc/zmMxH0zRMlYNkmNMGk+WtIEPTeYwcgFHXXAlixFWO4zDc3AoJutw2KOhqMleC6P60Vn9wuaFoAACzZDQ2Nra0tPz+uv7vF5RS2wGH/rSUCF3Xp6anR0ZGQgFff3+/4vH9oWu0BgiwBBjmJ9R4lFLs4ThPrrjJeetC6ao06zxxn694uPrJW7E+k7cydC3EVryy/otv/HUjn7NWU1SXi/9E7ahcLq+TcbiGGmqoYYOo+eS8g8Czumw26/f70ZN1ZmYGTSwSiQRuuLPZbD6fR+sIURTRg3Z6ehrVhng8jhtu9C51yXieV1V1dnYWt9exWMzj8di2nc1mMepOQ0PDhx9+GAwGNU2rJsNQafl8fmFhAeOGtbS08Dyv6/rs7Cxu/TGvKMMwi4uL6XTacRxRFDEfqK7rGIqaUhqJRFRV/c1vflMsFrdt2xYIBNBTVhRFlwwAgsEg+tcWCoV0Oo1nio2NjajkuGSBQAA3NMVicWZmBs9Wkcw0zfn5eVRC3KhEmLMCzzXRDsSyrHQ6jSrHo0ePyuXyJ598EgqFsDE5jsMARLZtu9y8Xq8syyzLqqo6PT2N6cbr6+uR28LCwuLiIpJJkoR2/zMzMwsLC0+fPvX5fJ9++inGuUYyRVFaWlo4jkMy0zQZhkH7ENu2MawTkmHANFfQAFBXV4cJc1xBY6BYTGA6OzuLChKSUUpdMnQ4Rm6pVErXdUJILBZDM/pCoYDB4t7hwAOEEG7NNFR/AFBKC4XC48ePc7lcf39/Y2PjOglba3gjCCEYn+ONW/kNctjIixsk+yFlbdA2ePUrP4oV63cydq22VWMYxo2GUjuBraGGGn4gajc57xRQmmj2gCfraGCA5tGEEEEQ0IYNo6ACAMuyuJPGNKBu8C4MemMYBioq1WSYwRMABEFAy4pKpfLZZ5/99V//9f79+//yL//S7/djoagyuYXquu66aqAm5nJzCwUAwzBwb11NhtwAgOf56enpP//zPy8UCn/7t3/b29uLX4pG7Xi9g2R4EIifgMsn6mmO47jhgDBWMgCYpom3TNVkmPETADASK8MwWDe6HIVZEAQkQ43ol7/85dOnT//qr/5q//79SEYIwRBz1dwwYjXDMKZpapq2gkzXdRQN2n6wLIuJAm/fvv0Xf/EXoVDoV7/6FWYUXSFB/ARsTPwENHBfR9CrRbOaG1RFyUNu+Pmop6HpvytBtL3Rdd2yrGrDmBp+d8BxOjY2Njo6GovF2tvb0fmhpuF8J+BNDp594PD8Q9foTxFotmdZFqY5rnXgGmqo4YegdpPzTgF3Nhh71H24Itww0rihk12gndIKbu6hWjVZNXMEKifz8/PFYhHtyHGJWlHoxrmtiJtczQ0VOdz3i6Lo9/vduG2YxeKt3NAgbQWZu913K4xBsdcng+XY2Rik1VXPNshtdSRoVB5WiAaVB57nc7kcBjgiVcGv3SK+t6ChKpb0OnV7IxmaFK4mq65DbafyOwLuy/P5/LNnz0qlUmdnZ2trK/YQeOdCn/0egLa+DMNg0pg/dHX+FIF6ZiqVSiQSaJdbQw011PC9UVNy3jW8dWfzu9h0unYOLucfxR7jO5X+437Xd+WG283Vtfp+3N6I9W1RVhfxU9Aufgp1eIdhGMbo6OjY2FgoFBoaGvL5fDWt8ocAbz4Nw1BVFQ1xC4UC3nCKoujz+dArr1gsYiP7/X60RHXJMKGw626HN5xer1dRFHTewxtpTJ4jSZKmaYuLiwCAZGjhWSgUXK885KbrOnq+AQAmkKHLiTsBAD0h0SvPJcOsWeiVh9fFrsOkruto6QrLicsIIcViEW+x8NYar3/xDtzlBgClUsl1cQwEAoIgoFce3lErioJ+lS4ZOu+h9e/i4qLrpYkujqVSqVwuw7KPH9oS53K5xcVFDNBfQw011PBDUFNy/uTwrm6Aftzv+ilz22ARPwVB/xTq8E7CcZyFhYWRkZFCodDd3d3c3Fy7wPnhYBjG7/dnMhnMMIMOcsVikRDiOu+Vy+XZ2VnXPtP1fCsUCmQ5Rxn60aVSKcuyWJatq6tDXSiTyWQymQcPHqTT6ePHj2/btg3J0CsPydBBLpfLuWoPqkxzc3MY1gxvcW3bRjJYjsWCfpXpdBpzesbjcdfdLpfL4aWu65U3NzdnWRbDMK4f3eLi4vz8PN7eZzKZzz77rK2tbc+ePWi253JbXFxEv0qe5xVFQYfJdDqtqirDMOhXSQhxydDSFR0m0+k0Km+RSAQbs1AopFIptJtFA2PLskqlErqA/mE7Qw011PAOoKbk1FBDDTX80QA9cKampp49e4YXOK5VT029+YHAiB3RaBS9QTA+ihvBGUMhB4NBr9eL+qQgCLjdb25uRjJ01UOlCC9S0HaXYRie55uamnw+369//evz5893dnZu3bo1EAigjuGSMQyTTCbr6uqQGxbq8/k6OzuxUHyCEU0SicQKso6ODpcMLYeRDO9e0ADV6/V2dXWtIKurq3NToD558uTXv/71sWPH/uzP/gx7l1sopi7FCqNFrsfjaW9vx+sjNzEoNiMWipbGiqK0t7djoUgGALFYLBQK4ScgmSiKHR0dqED+HiVfQw01vJuoKTk11FBDDX8cwLiIjx8/Nk1zcHCwvr4e94I1E7UfDmzAalc0DOCxgmy1r9p3IpNl2Y3pD697G7pYzW012RsLfSPZ6mxpbyzUdSPE0JGwHPdlhSfhaqdElmWrcwq5ZCueYLSVtQpdn1sNNdRQw/fD91FyXPcDx7Ftx2YZjmEY27ZUvYKnWQIvyJICBHRd03QN0J1aVHiOtxxL1VTbtpBMEmVCiG5omqEDpYQQRfLwPG/bdkUt244NADwnyJJMCDEMXTM0SilDGEmSeU5wHFvVKpZtAQDP8bKkVJMRQmRRFnjRfp1MEmWGYQ1T1/SlGFOSKIuCaDuOqpaRjOM4RfIQwpiWoWkVZ5lM4AWHOpqmmpYJABzLK7JMCGtahqpVKKUEQBRlSZAc6qiaaloGAHAsJ0sKwyCZSqkDhEiCJAoipVTVVdM0KADHsIrsYVnWtExVrTjUIYSIy2SarhmmTgE4llMkhWFYyzJVvbIU/0qQJFEGoKqmGqYOACzDypLCsZxpm6r2LZkoSISApqu6qQMFhmEUycNxnGVbqlq2v+UmAYCua7qpOXSJG89y1muCFmVJBgBVq1TUsuPYpmmYpkEdx3JsVSu7ZJIoEUJ0Q9cMFSgQhlFEheN4x7ErWtm2bQogLEmQMQxdMyoOBZYQSVJWCJpjeewYlmUWS4u5QpYAyJIi8ILt2Kq6qj+YhitoWZR5XqCUVrSyZVkUQOA4WfIwDGOYyxJcFjSlFCVIAXiOVySFEMY0DdWoUIcSAEmURVFyHEfVKqZpFEp5w9ABgFLHMPW1BA0ALMspklItaCAgCbIraNPUHQCOZRXJsxQfz9CKpUUcOADUcWwUNHabZUFbFa1MHQcIiPySBFVdxVoxDKtICocS1FxBi5IoA4Cma4ahOQAcw0iSwrG8bVuqVrEcmwHglwWt65pmakCBIYwsKzzHW7alqhWUSJWglwb+sqA5x3EqWtmybbI08BUk03XVAWAJkSUP9gdVU03bJFUDXzd0zdCAUoYQCQVt26pWMW2riowxTF3VK0DBFbRDqapWkBvH8YqkYHw8Va9U9QeRUkfVKksjemngE9M0Nb1iU8oQkARFFESnmuy1EV2hlK4QtGEaBIBlOVlSOIY1LVPVyg6lgN1GkCilmr40VDmWlSUPi2R6xXYchiwNVUrBJQMKqdn0xMS4z+9r62jx+b0ltSha4pKgNVUzdFI18F8X9FJ/QEFTAJZhZMnDspxtW6qmWo5FUIKSTJDM1CgFhmFkSeE53rKW+gOpFrSuaca3M7w7opcFLUqSRIDohq7rKgUghFFkhWNR0MsS5Hl5qT/o+tIMTyRREYQlQVePaIYwuqmrWgUwMgrOyY5T1W2Wp5GqGV4WFZ4X1hC0oemqQykQIguyKAq2Uz3Dc7KksCz72vwgSAIKWqsYlklcsuX+gIKWRVlYGtGqYS4tBOi74jhOuVLKF7Isx4mCKC31B800depKkONM01Q1nB+IyH8r6OoZHiVY0crOGoL+doa3LFWr2I4NBAQORzTVdN0lk0WF53nTMjRddRzHMPWKWvb7fQBE01V9WdCSqPBLgq4sL+XfzvD68uKrfDuiV87JVWSMLMpvFjTDYO9aJpNQghXVHfi8JMkMYVbN8KJDHe3bocorsoIjWtVVSh1CiCRKAi8tL+XGa4Kumh/cxbda0JIkswxnLQv69TV6SdAswyry0tS9tEYvz8nuUg6o+InLgl4iqxZ0xeVWJeiK49grBO2KRvl2RH87J+PUvbR/oJRhWFmUeZ7Huq1YozVd03GGZ1hZlN2pe/VSrhsqpcC8NnW7EhQUWQGA6v4gi4ogCJZta6sEjZ/g9geMC1pWy/a3ezaFYZjX92yKwPOOQzW9YlomBeBfE7QrQVkURIfamqYtC5qXJZllWcPQVV2jr++yVs/wlmVWtPKKgf+toJfW6G83YwRAECRJlCl1vhU0w8mSjILW9Iq9TCaKEsERbelAvx34lvXaiBZFiVDQjI0KWjd1wAioorIkaG3lGr1C0DzH2863u+7X9my6CgAMYWRJqRY0BRCqBI1rNCFElhSBE17fdQuyJDMM0XR3hmekpTX62103z/GSpDCEMU1d1VVKKcswkqhwHL+Os/db8T2VHE1X5+ZnUgvThWJuU/dAfawuNTd56vLX85m0Q+lA18Dx9z5hCLlx5/Kt+9dtx/Z5/B/sP9rd1jOXnj116av0whwQ0tfRf3jvB6Ig3rx79daDG5ZlKrLn2MGPutt68/nMb079Yzo7Twjpbu/+cN9xSZIfPLl9+dZFwzI8ivfI3qO9Hb2ZXOb0lRNTsxOO43S2dP/s/U9EUXrw5PaVby7phi6J0nt7jmzp25rPZ09e+npydpwCtDe1f7jvuN8XePT0zuXbFzRdEwXpvT2HN/duLVYKX577fGp2glLa3ND68Xuf+H2B4VePT18+oRmaKEoHdx7a2r+9WC6eu3p6ePwFdWhTfdPHh38e8AWfDz86f+NMRS2zDLd/58GhbXsrldLJyydfjj2nlDYkkscOfhQLJ16OPjl79XS5UuI5fmjb/l2bd+umcfryiRejzxzHSUTrPjnyzxKRxNT0yOdnP6uoZY7j9mzZu2fbXsM0Lt48//DZA8dxEtHEx+9/mojWjU8Mn7l2Ml/IU4Bdg7vfH/rAtIyL188+eHafUhoOhj869LPG+uap6ZGTl77OF3Isw23btH3/joMA5NLNc/ef3HOoHQyEPz70s+aG1rn09Odn/ilfyDEMs6Vv23t7DhMgN+5cufXghu3YQX/o+KGPW5NtqbnJU1dOphdSADDYveWD/ccIQ27du3j+2lfFcnFqdmR69nkosGl+fuar81/MZ+cYwvR3Dby354goSLfuXb1577plm17F9+GB491t3ZncwpdnfjOXSQGQ3o6+oweOi4J0/+ntSzfOWbalyN4PDxzrbe/LZNOnL5+cnB0HCp1tPR313QTs+Wzq7z//Py/fSwi88MGBY1t6txQWs1+e+3wqNUEIaWvq+HD/Mb838PjZ3Qs3zhumJkvKe7sPD/ZsLpQWv7745fj0GKW0tbHtZ+9/6vcGhkcenbz0tWHokiAd2nN4S9/WYql45uqp4bHnlEJzsuWj9z4J+oLPXz68cPNcuVJiGe7g7kO7Nw9V1PLJS18Njw0XFkuvxp8BZahTeTV699SVk6paFnhhaNv+HZt3Gbp++urJ56+eUgoN8YaP3vskHo1PTo18ee63ZbXEstzebfuHtu01DOPC9TMPnz9wKK2L1X383qfxaGJs8sXZq6fv3XuUWZyPxyLULmrawoVrZx69eOA4TjgY/fj9TxrrmqZmRr46/0WxtMix3LZNO/ZtP0goXLp59t6TuwA0EoweO/RRc31Lam7qi3O/zReyQMiOgZ3v7TkMQK7fuXjr3nUKNOgPffTeJy0NLam5yVOXTsxl5xggg31bD+89wgBz/c7lbx7esmzLI3s/PvxpZ0vXwsLMF2c/W8gtMAy7LGjx1t0r1+9dcxzb7w18sO9oV1v3Qjb91bnP5xZSANDftemDfUclUb7/+MblWxcs2/LInqMHP+pp681m509e/mpyZoIQprut5+jB45Ig3X98+9rdK7quiaL84b6jm3oG8/nMVxe+mEpNMoRpa+o4dvCYz+N/9OSbCzfPmZapyJ5Du9/f1D1YLBe/Pv/F2PQoIaS9qfPogeMBf+DZqwdnLp82TE3gxSP7Ptzcu6VYKpy6dOLV+DAQaE62fnzoE7/P/+zlw4s3zpfVEsfxB3e9t3NwV6lSOnXpxKuJYUqhIdHws/c+jYSjL0cen7r8taZroiAObdu3Y9MuwzROXvrq+cgzQkgy0Xj04PFEpG5scvjExa/KlSLDsAd3vbd78x7DMs5eOfX4+QMgkIjW/ezwz2Ph2Ojk8NnLpxZLeZZhd20Z2r/jgGEa566ffTL8yNAsnni6m7u2b9tsOMZvT/8/xXKR4/htAzv2bd9PAM5fO/vg2T0AGg3HP9x/rLmheWZ28usLn+cKOYYwOwZ37995kCFw7fbF2w9vUeoE/aGfHf55U11Tam7yxKWv5zNzDMNt7tv8/u4jQMj1O5fvPv7GtEyf13/80M86mjvn0lNfX/hiITfPMGxf58CRvUcEXrpx5+KN+9cpdQK+4OG9H3a1dS9k5r48/8Xc/CzDMANdg+/tOSJJ8t2H169+c9myTUX2fPzeJx2tXbns/FcXvpiem2YY0tXWc/TAR5Ig3Ht0+/rdq7qhyZJ8eO/RTV2bcvnM1xe/nE5NEQJtzR3HD37s9/gfPLpx4eZ527E8sufg7vc3dW8ulBa/PPf55Ow4wzAdzZ1H9h0N+ILP5DpwWgAAIABJREFUXtw/f/2MZmg4Pwx2bS6Vi19f/HJk4hVDSFND88/e/7nX6306/OjijXMVrcxzwoFdh3Zs2lUsF05fOTky8QoorU8kP37vZ9FQ/MXL+2eunsL1Ymjbvp2Du3RD++rCly/HXjCESdY1fbD/aCKaGBl/furyiXKlxLHc/h2Hdm7eZZjGmaunnw4/ogCJaOLQziOEGqXy4plLv5mvvOB4ftfmPfu2H9BN7cKNc0+HH9uOEw3Fjh/6qLG+aXxy+NTlE4VSgeO4bQPb9+84RADOXTnx6MUDABKLxD7cf6ypvmV6dvzrC1/kCzmWYXds2rV3+37CMFdvXrj75BvbcQK+wKcf/ItkIpmam/rqwhfZ/ALDMAPdm4/s/RCAXv/m8p0ndyzL8vv8Rw8c72zpSs1N3Lp/QVVLL0YeX7n11ScffCrw4rXbZ28/vEUpDfgDh4c+7GrtzmTTvz37m4VsmmGYgc7Bg3vel0Tp7sPr1+5cMy1TkZWP3vuks6Urk0l/ffHL2fQ0IaSztfujgz/jBf7uo1vX71w1TEOWlMNDhzd1b17Izp+6/PXM3BQAtDd3Hj1w3O/x3310/eo3l0zLUmTl4K73B3s2F8uF357+bHpuimFIR1PX4f0fBLzBp8/vn795Vtd1URCP7P1goGdzsVQ4efnrsckRSqGpvvnnH/wLRZafDj+6cOOsqqk8z+/fcXDn4O5iafH01VMjE68AaEOi8djBj2Kh2LPhB+eXyfZu279r8x7D1D8/89no5AjDkGRd44f7j8XCdSPjz05eOlFRSzwn7Nu+f/umXYapn7t+5tnLJw51ouH4vzz2Z0F/eGzi+cnLJ0vlIssyOwZ3H9h5SNe1CzfOPX352HGcaDh27OBHyfqm0YnnZ6+eXiwusiy7fWDHgZ2HAMiZy18+HX4MANFI7IN9x5obWmZmJ748/9vFYp5lue0DO/Zu308Ic/X2xbtPvrFtO+ALfvrBP0smmmZSEycufZXNZQiBge7Bo/uPO9S5dufynUff2Lbt9wWO7j/a0dI9kxo/ffnUQi5NCNPf2f/+0IeCIFy7ff6bR7cdx/H7Ah/sPdrZ2pXJzv/mzD9lcvMMw/R3DBwaOiIJ4p37N6/fu2JaplfxHjv4cUdL10ImffLyV7PpGUppR0v3p0d+zjLs3Ye3rt9FQcvvDx0Z7N6cyaZPXzk5nZpEQX+4/7jf47v78Mb1u1cM05Ak+fDQkU3dm0vlwj+e+M9zC7M4dX+w/2jAF3j64v7562dxa/f+niMDPYPFUuH0lZOjk68cx2mqb/nnR/+lLMlPhx9euH5O1VWe4/bvOrRrcE+hmD979fSriZcANFnXdOzA8Ug49nT4/sWb5ytqheeFfdv37xjcZRj6F+d+OzY5QgFwzxYPJ0Ynnp+4+GVFVXme37dt/47BXbqhn79x5unwE4c68Uji5x/883AwOjr+/PTV08VSgSFkx5bd7+06rOrqhRvnngw/dBwaC8eOHfoomWgaHX9+9trpxeIix3HbB3bs3XEAKD135dTj4UeUOpFw7PiBjxvrm1JzU78581+KpSL2h307DgCFq99cuvv4G9uxQ/7wx4c/baxrmp4dP335xEJugVI62Lvl+MGPbce6dvvSncff2Lbl9waOHjze2dw1m5o4dfnEfHaeZZj+zk3v7T0scMK12xeQzOcNHDtwrLOlO5tb+KeT/5DNZwkh/V2bDu85Iori3Yc3r965ZFmWz+M7euCjjpbO+Uz61OUTs3PTDnW623p/dvjnLMvee3jz2t2rhqnLknxk79GB7sGFTPrU5a9nUlOEkPaWzg/3HfN6vPcf37x654ph6IrseW/PkU3dg4Vi/rdn/imVngWAtubOoweO+b2Bp8P3z149bVqmx+N7f/fR3q7NAMQwTY7lXYVn49rOd1ByKKWUOgBg2/qLV3eu3zkPYNZHYowdo6bjkypbu5vKagQoxCIR1k4DIc0JhdvSSykVBCHitak55xPLW7qbyo1hICQWDPOQJTbXEpe5zT2O4/AsH/HaYKZkVt3a01JWowAkGgzxJEssrj7M79nc4zg2z/FRvwNWWuHKm9rrm+Me3NNzkAGLrw/zezZ1247NsWxdkKFmSua0Te11TXEFAEL+kMguEkutD3G7N3XbtsWybF2IJfacSIwlbgBBX0Bk82CpUT/dPdht2xbHsnVhHqy0yBi9rbFYkKUUAj6/yCyCpcUDsHug07RMhpDGmEjNFA9mb0s0HmAAwOvxefgyWKmoD3b1d5qWwTBsY0xk7Hke7N7maNTfBwCKrChcyTGdoKIvc2OSMZmx0zx1OpNBv9jnAPXKiocvgZkKec3tfW3oytkQ94E1xzp2RzLgE/soUFmSfZIKZiqoGDv62jS9nhBSH/OxzgIAtDf4PUIvpVQSJb+sUWvWJ5ZdskTEzzjzBEhzwoMSlEQpIOvUTPlEdWtXU7kxTAESkRBD54lNmuJKZ3OdJPBBnxKQDWrOeoXy1p7mihohQKLhME+yjM01x2V2c49DHZ4XUNAeTt3S01SuhAEgGopwNEMsNhnmhzb3UurwHB/1OtScVTh1U0d9c8JDKUSCYWouUkf3yPLW3o7OziaOZeMBcIxZidE2dda31HkBIBQISewisbS6EDs02G07Fsfy8SAD1pzI6gPtdY0xBQUtkDw11ZifDm3qth2bZdlEkAFrTmCM3tZYPMhSgKDPLzGLYGrxINk10GGaJiFMMiJSCwUdjwXYTGbx2plbC6k8WNmIL7IHJYiCttI82D3N0aivHwC8ilfhi9R0goqxe1OnYRoMYRpjElhzLLU7GkM+uQ8AvLLHw5fApGGPtbO/zSmXTokiARPsBc7hOpJBn9QHKGhRBXM2KBu7+tt0w2AIUxfzsc48AOloCHiEPgCQJTkg6dRK+SR1R1+rptcBQH3cR+w0ALQmPPzWPgCQRCkga9RM+SRta09TWY0AQCIaYO0FIKQl4RGYXsdxBJ4PKQY1Zj1CeWtPi6rFAUg8EuYhy1hsU0Ihm3sBqMiLYa9NzTkPV97S1VRuDANALBzmaBYsNhkV9m7udajDc3zE5zjmrMypgx0NzQkfAYjg/GBxDRF+z6Yu27Y5losFgJqzMqcNdjS01vlQ0ALJg6nWRfihwV6H2hzHJ4IErDmRMQba65NxhQCE/EGRzVNTS/jJ3s3dlm0xDJsIEGqmRKL3tcUTIZ4QCHj9IpMHqxIPkF2bOjCzakOEB3NOAKOvNZYIcQDg8/gkrkBNK+qny9MIl4yKjD3PgdXTGov6GUKIz+Pz8GVqpcIec/dAu2GahJBkRABrjnWsrsZQQO4nBDyKR+FK1LQjHntHf5tu6ISQWIg3KtMsxzRGlNSkUrHMzrbGndvaoxExX6js6u/QTYMhTF3cyzoZAOhsxP4AiqQEJA3MOb+sbe9t0wwc+B7WnicE2up8ItNHgUqi5BM1x5z1ieq27uaKFgUgiWiApQtASWudV2R7HMcRBTGkGBTJeporWowQEguFWZolNttc52GhD4CKgoQjWuErW7uaSo1hAhCPhHiSIRbXGBP3bulxHIfj+KDHAiMlc+XBrsbWhsCyoDPEYpNRYc9gF6bQjQeAWnMyVxnsaGit8wPQUCAkQI6alfqosHdLL6UOz/M4VEVGH+xsaE54CCGhQEhiFsHSEkGyZ7Dbsi2WYeN+Qq2UQIz+tkR9RCQAAV9AZPJgVhJBsnvT0lBNRnhizYmM3tcarwsJANTv8clckZp2LED2bOq2bItl2WREIFaaA6uvNZ4I8oSAz+v38GVqzoW99u6BDsM0GYZJRgVipTlq9zSFQ55+AOpRPDJfok5FFPju1uS+rX0syzUkFOKkeWp3NYaCSi+lVJEVn6RRMxXyWDv723VDZximLupj7Hkg0NkU8sv9hIAie/ySRs1UQNJ29LYuCTruZekC2NDW4JP4XkqpKIg+sQxmyidWtve2qFqcEBILB1k6DxRa630ityTooGLhDN+cCPE8Fwv52xsCLF0gNtdW7xWYXgAQRSm8LOjtPc1lNYrcBMgyFtcYlYY2dzuOw3N82GMh2eauZHtDAICEAyEOMsRiGqPi0GC37dg8x8cDhFopD18Z7Ey21vkASCgQFEmeWpXGqLh3c4/tODzHJ4IERbO5K9na4CdAwoGgxBSIrSdCzNCmLsu2WZaNBRhizomMPtCaaAiLAOD3+nmSJRafCJA9m7pMy2QZtiEqrBa0wpWo5cSDZPemLssyWZZtjInEnmOpM9Be1xCVCIDP61f4MlipiNfePdBhWibDMMmYyDjzPFg9TeGwt49SqkiyyCyCZYQ99q7+DsPUCSENcQ9jp3mwuhpDQc+SoL2SSs1U2GPt6GvTDZ0hTF3MyzjzANDdFA55ljYGAVkDM+WXtZ19bRqSxb0czQCFtjqvxLmC1sBM+SVte0/r8pwcYpx5QmlrnVdieh3qiIIY9NjUTPklfWtPU0WNEEJi4TAPGcZmW+t9IovcpLDXAmtO4cvbeppVLUYIiYbCAmSJwzXGl0XD8yGPBVbKI1Q2dza21QcAIBwIsU6GAeIKmlsS9JzClwc76lsSXgIkGAiJTA6sSmNUqCYDMyUwxpbuxnJjCABCgaDILIKpJYLM0vzAcvEQQ6w5iTH62xL1YZEC9Xt9PKCgmd2DnRhXIxkWwEpJjN7XGqsL85RSv9cvc0Uw7USQ7BrotCyTZdhkVGDsNAd2f3uiISLiDK/wJbBo2GPtHljqNsmYSOx5HqyuxkjI00cp9cgemS2CaYW9zq7+dt3QCZCGhJfYczy1uhqDQaVvaUQLKrVSYa+9o69dNzSGYepiXtaeByBdjaGgp49SKkuKX1JxqO7sazdMgxCmPubFPVtbvQ8FLYmSX1TBTAVkbWtPi6rFKKWJaJDYacZx2uq8IttLqSMKYshjLS3l3c0VDYdqiKdZYjNt9ctk/BKZwqnbelo1PYFkHMkSm23ENdpxBF4IeS1qzXn48ubOZFu9n1IaCUVYZ56hTDIqDm3udtdoMFNI9u2IZnJglRtQ0DYOfAAzJbL6lq7G9oYgLuUikwdTjQeWpm5CmJDXAHM2Vyhdv38HGKmztb+poRUv4TeouWwoGSjap5XKhYXsXDToUQSYWxgrlvLhQNCneASBJ4QBjCCMPIG6cX6wInQpvQkBoK8/hOonAOBQSghQuvpdIG6w4KpcyG8otErJc1aSvYHbcqFLoVdXcAMApiofM12j0NfJgALdANnSp76R7A0VXo9sdZu7T9Zv8x+hUEqpaVr/3z98/e9+8asjh/b87f/y3/v9HnRmXYPbG0XzBgmuFjQFsC37xcux/+bf/OXiYvH/+N9+uW1LH8rubdwIAHVWNshGBI01eQuZbTszs3P/7X/3Pz17NvI3f/VvD78/xHEsAYJfsE5/2GCbA8Dlq3f+6z//ZSwW+t//11+2tSZZhsFx930lSLAvbIAM1h7R65Ot7oSvk605VFeQfdtv1iYjBOhGuFVLcINkG+gPZGmaXKN5X2u61/rDm8gIMQzz+q0nBKCrs2lkZHqxWB7oa21oiLlVWkPQ1dyq23y1oN8owe9Kttwcb+W2nqA3QvZtEbg6rC3B1xrzu5KtmuHfXOjagn59sl3FzaE0m1/8d//Dr06dufrL//Ff/6s/+0gQeFirUAC6ZptXPSEA9HtL8A1kjuN89ttz//rf/PL40YN/8z//24Df9z24vU3Qa43o19ocv+sHCHplhX8sQa/coqzB7U2L7xvanLy291iTDF7bLaxD5vaH9QtdY5e1wU9YlsybuK25GVuz0I3NDysFvfb2qVqCsEahG+kPbyJbc//w2rtA4U0N8sYivh/Zmm2+HtkPFfRabb5hQb994Fe1OQEASh2H0rJaefDsydPRUctmh3Z8MNi7i2V5WF5GYV2wv/jFL9anoJQ6tj2bnjp//cSrkW8aop6Awvk8cjgY8igKz3HL6/JrJa3xZKV3LCErq0gIeX2qrOJW9ZCQtQv9XmSwqrHe8O7a3F4nW+vzV3GD1Q2y8cb83m3+YxYKAPnF4sVLt786cfHBg+cMSzxe2etRQkF/dcrw7/YJa0iQUmqa1p27j7/8+uLFS7dK5YpXkUVRiMcjLMtsmNsGPn+jgl6CaVmPHr84cfLSufM3FjI5j0cWBD4Rj/A8B7Dh/rBGKwGAqmo3bz348sSFazfuG4bp9SmyLEUiIZZlviu3PxDZm9t8w0N1I4XSDXIj353su/aHt5G9pTEppU+fT/ynfzj75NlYsag2Nsa2be6MRoJLBwc/sM3Xr9t3I8OlcQPcfrype8XqsEEJbpBsLQmuXJLWbpC1yCilDqXDL8dPnr5y5uy1yalZRZEFgY/FwoIgoGRXFvrmImDlk7WWy/W/9E1kAKDr+uzcwjd3Hp27cCORiG4e7JFlSRR4fOE7cVtX0G8nw3GyEW6/f0FvuD+8eVOxituGyMhGyTYkmjV3WRv8hBUbmbW4vS6aDZJtVNAb27OtVejGJLiabAOFLs/xbyfbSKE/TIIbFvRaa/SKr1+rP2xQ0Bv60lUSBIEXGuJ17U3NQZ/i98gBX4ACQ9/UzqvBrP8zYrGUu3L7ZC43srm7PRLwAaGEEJyV6apvXhcbp/wTwe+hQVYX8SMXaprW5Su3P//qfH6xeO/B8//wn77KZPM/bhEuCIGR0cm/+/f/NDo2NT099+//4+dPn79ytf8N8vjxawVkZib9d//+N4+fvpxLZ/7+H0/cvfcUPTV/FDiOc//Bs7//h6/T6czI6OT/++vfjE9M/1jMfy/4g/TzP0pQSqdn5k+euTmXzs4v5LP5QmtTwutVvss0i6i1+e8fb2mQXG7x1//x89t3HuXyhc8+P3vl6h3L+tFmiR8F+Xzx1//ht//33/1joVC+cfPB3/zq/3ry9OV3m19rqKGGPz78pCdzQgjLsuFAcKCru6UuAtbC6PjdB09uVtSy49D1d4DrKTkUARSo1hQPHN9/cFN3jySKhBBK3R9X4nt8wCoe35/bW193f3Jc1KbwH4ZQyL9lSx/mw6bU6e5q6Wxv+e57sg2BZdntW/sbG+sc27H/f/beM0iOI0sTdPfQEZkZqVVVltYSBa0BQpOgAFVzmuzp6R25N2tnZ3d2Zvd3ft3fs7vZm9vemdke1dOCTQVKgNAaKMhCFUprmVpnhnS/H1kogiDYDZBVJMDBZzAYEBnh8VzE86f8PRMHAp6OtkaaplbodQ9NFWprq6+sDBq6iTF2OeWuVc08zy9X+6IodLQ3ut1OQjDGJBDwtDbVLbqJnuKHhUJBOXXmZm//BMexwYDbIgn6YyYHP8U3QMk8WV9X1dpaZ5qYECCJQmdns2yzfL+86z5IFpFm6PHJWU3TI9FEOpN12K33hB4/xVM8xROAZRSqf3+D376dP/gIvMfbiSCCEBCipVNTJy98eOtO92Lq0a/H7w1XI0TRFVPLiUwh6LbLVmvJq17SEHRd1w3DMM3Sn9Kxlq+6nx4SqqZNz88WigWGYcKxSCKdFASB+ooT/2FQVIozC/PFYlESxXsjpu7pFskXC5NzM+MzU5qu2SzWb0z2f3AQQiCECCGbzTo6OjUwOFZTHfpf/stPWlrrEEL3RlQvFyCEFouka/rlq7c5lv2zn72yb+9WjmO/9+kTRRECcOVqD8H4j14/+MqhfZIkLAtVpUZk2RZPJK/fuGO3W//zX7yxfdvaUqWL773jT7G8SCQz41Phrva6HVs6d2zvWr+2WbZZEHo6y082SqyS51lRFC5396TT2RcO7vzJmy847DK8eyTj+6YRAABYlhF47lbP4PTMvMfj+qs/f2P71nWllL6PCYVP8RRP8QdBCNEN414R3cAmBPCrkbEP2RohJJFOzS7MUwjphjGzMGeapsh/EyFHN41wLBJPJTiW+2YWagShbLESot0cuOWwe1x27++R4b/WGEwIUTTl5p0rIqO01JTTNHXvT7Fk/EZ/b65QKDm5IABOWe5sbrNbbY9KcckZFI5H//GdX1UGy3du2PzRyc+LivLnr7/lcTgfqakSpubn/u3D31WVhd56/lXhQWXFFFW5cOPqZ2dPqqq6Y/2mMm+AYp9WH7sfGN97DOz3gAAAfB7n/j1br167vXPbus6OFkAgNsnSr8sLmqG3bV23dnVrUVG3bVknCnyJ1GV/0SMBQbh5U9fWLWtGRqd3PbPRapWWlyqrVXpm56aPPznj87l2bt9AMwzG32SEv4Uh4g+AYIIJId/3RDzRgADYZevB/RtFgWcY6q6lixjLF/r4qPR8G9PV947F4QOPyaokAIC2lvpdOzdCCPfu2eLxuO7hEo8FiQCA2trK/Xu39N4Z7mxv3LZlDcexpokBAI8PhQAA+KCDbd8eZDH1wlM+9oPCk87HHhWEEFXXuntuhuOxu10mDM10NjVXBkPfzGCBCT5/vfvYxbNvPPsiSzO/O/Lh5jXrD+7Y80BHwu9HLp9/79hn6Uz6rRdfrQiU3RcotxhpRQjBGFEIwQedVwRAFIS1bZ0UxUKiEIB/T1Ta1yo5GOOxqaFL145t7WpH8EvjQggZn5n+9ceH84W8IAgIQgBhQ2VNXWW13Wp71A6XtJxoIj41Pxdwe3P5/OTMjM1qo77RcsQERxPxmYWFcl8ZgA/mUwux6MnLF/LFwu5NW1c1tj2tr/xVlJx1qXRR1cyHmQdCSH1Dw/79uzeu61R0uBDNrhwvIQCwvHXXrh2qotrsrnAk9zhEkxIAAOSf2bmtumbO5y+LxPPLSxQhwOP27dmz0+txspwlHM09avuEAIpCdhvHccxKBOBiQmLxTDpTeMyje58QZL9vAgAAAEHgclntsvR9E/LNYZo4lSlqugkeg3VJADBMsmXzRkG0VlfXJZIKhMr3TdSXUNoyV3V1req4umXzBpazzoezj5VkSACgKWSz8jy3IvG6poGjiUw2+3jNy1N8GyAEPW6r1bI8sRWPOUp2nWQ6dfjE0eHJMZvFQiGKAGCVJK/LXRkMfYM2IYSapk/Pz4VjUYzxQjwyF41gE38zllooFsemJylEMTQNHjQjpmlOzE5HEvG6qmqP3fl1sybywsaOTkhZIDAAoMjXhA59LZtQ1WLv4HWf01pfWXWfBowJTqRTuXx+bXvnxlWraYqGEMgWm8vuJIQUFaWUPJ5jOZqiAAAEANM0VU0tlddgGLaUks/EWNM1XdcRoiKJGDZNp91RUIq5Qr46FCKAZPM5hmY4li0pixhjTdd1QwcQ8CxHUzSEkABgGoaqa6VM3gjBVDZtGIbb7kAAqZpqGCZN0wzDQAAIIZquT8/PhmORtoambWs2uux2TdeRaWBCMMY8y0EINUPXdR0ixDMsRVEQQt0wDNOgIDJMExPMsSyEUNU0TAjPsiVKfkjfD4RA1YyJ6RRBAs/xD9MxVvS/8OJrkiimc+xKDwQm1IaNz5gm1kxbPPO4jDsBdGv7xtoGjSA5mX5k88YfhInlfQdepCkqWxRg8VGfhpqhq4V0bbXs4Zhlpw0AYJrm0MhcNKE5nd/EAfsUjxcgICaJxcL1NR57+5Oq5BACFFWfmslgyPMc9zgwCgzoytoOb6CeE+Vk5rG0r0Ho8ta+9cc/Kwv684pQUB+HYVtESZZQlGx1CPCcZSVeoRlG/+B0oUhZrLbHynn1FN8MpmGk0smWRl9DrfB90/JdAYJUJpNMJ0P+4MGdu20WKyGAZZiaUCUAwDBNTdNKVao4hoUIgruysaZrEEKe5SiaggASQEzDVDQVAJAvFhLppCSIkihMzExDAK2SVCgUIIQcyzJ3a3SapqlommkaNE1zLEshCgCACdGXGue4XCGXLxTK/X6BF0zDKBo6gohlGIqiCCEmNjP53KkrF/tGBn/8/CGbKHEsVyJb1VWCCcuwLMOUDkoghDSjODZ202ot93vLwIMC+L9WyTGx6bCJ5Z4Wi3j/DmcYZjKTBhA21dSt7+iiEAUhQBBhjCfnZ/uGB+aiEZHnOxtbG6trWYbJ5XP9YyND42MFtVDhL1vd2uG2O0yMp+Znbg30ReJxp2yfmp81semw2orFYr5QyBeLxy+dS6bTXqdrdUtHKBAEEMwszN0eGpiPRBCELQ2NXY2tHMdl8tmB0dGhydGiolQGy9sbmtOZDMbYIcvpfO7WQG8ml22vb64JVVIUpelaz8CdM1cvx1PJ+Wj09nB/dVmof3SEZRhFVUyMt63dkC8Ue4cH5mMRnuWaa+rb6htYlhuZHBuaGBcFIZpMaJraUFXDc/zg+Gi+WGhvaOpsbONY5oek5AAAMCaGCQP+crfb/dAPwae7wgoPwjdtHMJ8Ljc+NmSaK0UbIUAzsNcXamtr/YF9C/8xYZjmxQvnFFX7vgn5VsCYEEAHAhV2h+NxWpSPNaskhDQ2tn2z8P2VhqIo46MDKxfASTApFs2yUH1NTc0KveIpvksUCsWeW9dVzXycv7hlRyqbyStKQ3XtmtZOu9VGAKAQQgjl8vnBydHB8bFcPhf0+ta2dvrcHkzwQjRye2hgJjzP0HRbfVNLXQPPcrlC/s7o0MDYiG4YssU6F1mwiCLP8slsWjeM8dnpqYU50zTrK2u6mlttVluhWBgYGxkcH81ksw67vK5tVVVZCBO8EI3eHuqfiSxwNNPR2JwvFjRDt1tlwzSu3+mdnJsJBYIdDc2SKAIA4qnUmauXrvXeCidi565dIYSsamorFIv9Y0PDk+Oqpof8ga6Wdp/TBRCCEGJTv9Zz1mKrOLDzFYZ+gAH3wUoOIUTkmS2ruhikfpXT6boeSyUUTbl48+pMeA4AKAnC1tXr84XC745+nM5lJUFYiEXvjAz97NAbXpfr0zMnzl67Igmiruvnr3UnM+kXn9k7Oj35q4/enw0vCDyv6VoinZYEUbba5mORoqrc7O+bXpjTVC2bzw9Pjv/s5TdEQTh56UL/2DDLsHORhev9vbYfWwJe36enj5+6cglCYpjmnZG31/HXAAAgAElEQVQhlmES6TTLMKqu/e6zD6/23upqaVvfvrrkC1I1rX98pG9kSNO0WCI2PTer6/pvP/uQYGyRpJpQpd1qO37x3Fw0zLFcvpA/2335xy+8tKF99bU7tw8fP2qzWGmKiiUTkiDYbbJq6LFEvHdo0Gmz11VWr8BC/Z6BKCQIgih+g/S1T/F4AUJIMKaZlVXFKURZLKIsy08XzJMOCKFhGDzPP27xVI8MAiiaEgTBIj2p/qinuBcQQnqFE0siBCVpkY9942xUT/E4AELIMAzP8wgZ3zct3x0IAKlMOlfIj05N/PKj9xiapim6q7m1vrLm5OXzp65cZDnGMIyzVy9H4rHX9j8/F428e/Sj+UjEIkmxROJmf99PX3qtrrLms3OnPj19ggDC0kyumE+kUl0tbRRFpTKZZCZ17lq3JPDpbPb89e5c/uCezdsn52YPnzyqa7phGjNX5xeikZ8e+lEkHv31J4fHZ6ZYmlF1LZlJB70+TdNYhj13rfvz86dlq62uqqqULRZCmEgnr/X1zIQXIATDE+NVZaHKYPmHJz+/ePMahShsmidVZXhy7K0XXnXZHQAAhqYrAv6rfXdiiS0Bb/lXR+MBzIIQYpp6sZDiKExT999AANFMI55MYoyn5+ci8TgBxG13VpWFrvfdHp2e2Ld5R3Wo4tLN673DA2OzUwuxyJFzp512+97N2/NK8fCJIwOjw+s7uk5evjA5P7N30/au1vah8dG3P/uQ51iBF9K5DECoraFx/9adqqa9e/ST/rGR2chCU3VdQ3WN2+lkGfbK7Rt9Q0PhWDSeTp68fMHv8R7YuhMipGpqwOs7f61b1bWTl87PLMyvbm0/uGNP0OsrSV0CL2zqXDMxMz08OXZoz7NdLW3dt29ls9nW+sbdm7fbJOnI2VNTC7P7t+5sb2i6PTR4+Phn569311fUxJNJwzA2dHa11jb89rMPR6Ym1nes7mxuOXz8yFwkkkivVFmYxwRPZdYfBFZ8Epde8HTBPMVjiKfL8geA73gSn66Zp3jiYBhGMpMyDTOZyfQM9AEAOZYN+YMQjh09d0oQxGfWbwGAfHDsSO/w0IbOufPXu28NDDyzflNLXcOtof7z166MTk/qpvn5+TMiL7y4Z7/TKn967uSlG1ftVtk0zUwua7fJezZt7Wxq6R0ePHzi6K3B/vWdXQ6bvK61k2GZbC6XymTmo5FEOnni0vnBsZFdm7Z1NbVGU4mAxzMwOpovFvrHhq/cvumQ5UN79rfVNpacMISQkC+wb9O2cDTidjpf3/d8RbCsZ2jgTPeluoqqfVt3apr6ztFPbtzp3bpmQ0nJQQjVVlTdGZuMJcJ+T9lDhatBAFOZxPWeM601gaDXe//PBGiqmsykQr7AS7sPeF1uAADHsblCfmhyrKgoNwf6+sdGMrksQ9OKqkzNzcSScYjgsYtnS4mnKYqOJeJDE2OVwdCeLdsr/EGbxXrqykWOZViGTqbTNotl35ad69u7soVcz2B/9+2biqrOhudvDw1MzE4bhhGOxwghFEUNjo9qhrFr45b1nasZiiaQTM3NpnOZdCaTTKeDPt++LTsqguXo7oEZhqYdsh0hZJNsTdW1brszk8uKgrBzw+btazcMjo+MzkzWllft37LT43QJnHD6yoVcvpDOZdPZbMDr27Z2Q8DtdV46585mtq3bUBksP3f1SiQRZxh2BRbqUzzFUzzFUzzFUzzFUzzFQwECqOlaIpUSBOG57bvbG5oAABRFed3uc1cvz0UjDlk+ffkiAaSoqQ7ZHk0mhibGikrhzujQ+Ox0vlhgKBoTPDg+ks5mDu05sGPtBgjhdHi+b3jA7XQWVSVXyLfWNe7Zss3v8vIsf+FGt6qruXx+ZmHu1uCddDajaGo4EfN7vJlcrn90uNwf2L9le3mgDJumpuvdt28pqjo4PirywqG9B7qa22iaXiqGI4mSXbYDAMu9gYbqOpqieocGEIV2bdq6vn1VQSneGrjT3XurqHwRYmC32jatWuOQHQ8ckK84aggBBCzEFobG+mrL7V/9lQCSyefyhWIoEFzT1uFxukrhxT1DdwzT9Hu8HQ3NFE3Fkgmf21NfUT27ME/TdENVTUWgLJPPhgLBzqYWjmVVVTUFMVfIR5OJ/tHhZCbVWFWHEJXMpA3DKBaLqUx6an5uam5Wtlg5lv307Mnu2zc3rVrjtNtPXb5AIWSzWnXDME2jqCrpXEbTNEmU8sViOputCVXSND0bXhgcH62tqJIEsUQ8BFDR1FQmLQmCzWo1TCOWStgsVp/bQ1OUqqmGYRimmSvkAAB9wwOKqlaVlWOM07msx+GUrbaiquQLBYdNdsqyaRjpXIbnONlqXb4l+kPHg9z/i6r342kzI4QAYCqKWSjQFgvFso9O5z35SB/PPj7eIATcG079A7atErDY2xJ+wD190vF1UUyP85QRQoxCHusGI0nwrlTxaM8DAB5zdv0Yg/yH+bSf8rHvExBouhZLJqyi1NHUtLq5gwAAINANXdN1hqFrKypryiuzhXzQ62utb7QIoqZpTtnR3tjMsWw8mZSt1tbaxiu3b5QShqWz2XyxMDwxZprY63QVioVMPuczjFw+H6MS/ePD2Vy+pbZhNrLwu6MfQwA3d62NJhOz4QWbxUohStM1hmGy+Xw8mVB1jaHoeCrlcboCHu/4zPTQ2Mi6tk6v072UwJkAkC8UCkqRZVnTNAEkiqZiEyuKksplpufmJudnHTbZ63Qt9Zhj2aaaOsR4IYSE3M+ZHuDJMQnOZlMsgyT+gckoYCqT1nTNbrNxLAcRggAQApw2e8gXmAnPmxhjHSczmZa6hsqy8qqyCqtkUVQFE5zJ5ViaqQyGeI4NeL0DY6O/O/Kx3WobHBtJZbI2qxUTnM8XUpnMp2dP9o+PzMzPzUciuzZuli3WuUgYY8yxbDqTzeRyHqdbtlqrysouXIdHzp0em57MFwqrW9pFQVB1rbOppaai6peH3zl5+UJNqKKzqY2h6VJ8bSmrQdDrFThB0/VkKiWJokUUIYQ+l6ciEBydnvjNp4dFXuwbGXLbnRtXrSEEZ/PZMp9f5PlYIpnL5z0uJ8fymUIuXyjYJItFFJdzjf5wQQgxlWJufEzPZO7ulYQWRWttPSWKD8MIv/t9ggAAIMwMD8UunA0eOChVVj3UW78sBBn5nLIwzzrdrMPxlOM/OkgmV5ydjwd9Tpv126YBvU88fbymgxBV02cXkiLPet0yRT1OtD3FXRBC9HQ6NzFuKsUlPsbaHZaaWop9KK/+9yLvEtNMXLtanJv17d3POb42MeuXn/nS16KnU0osznu9tMWCHqsP50kAISSRyoVjmcoytyRyP2w+punmQiRJUcjvkUt1q5/iuwHGWFHVVDYt8rzNYgMQIAgJIRREoUDQbpU1VcOEZHM5TMzKspDdag0Fgr3Dg6ZpmqaZyKQrg2XlgeB8LMKyzLlrVzK5XKFYuNnfBwBxyPZ0JqNq2tDE2DtHPhYFoW94yCKJq5rbcoVCPJks9/kBhNFkAmPssMkuu72yrPzGnb53Pv/YKlkggBs7V6cyKb/LvWfz9hMXz165fbOqrOLZ7bsEnl/sACGGYWi6Pjg+dv5G9/qOVfUV1Tf7+z49e2pwcmx2fj6aiO/fujPo85duLwn2qlpUi3FZ5ijq/goZ1N/8zd/cN0aE4MmZ4WRqvrW2TviKngMBmIuGI7FYe0NzQ1UNTVF3j7vwdpucyKTHp6cT6WSZz7+mtcPrdLsdToamJ+dnpxfmIYAdTc2NVbV2m2yRpHQmG0nEdEMv8wVEXljV1OJzueci4aDPjxCcmp2FCG5fu2Hv5u1uh1PTtWgiEU8mIYQWSaqrqF7b1hFw+2iaDsei89EwhKi2spqm6VQm09HYuq69gwCQSKcEjqsqK+c5rtS5WDo5F16or6xuqWswTHNwfCTg9a9pbhcFQeAFp92RzednwwuZXLYmVPHS7n0ttY3pXGZmfq6ltqG5tj6bz4/PTNZX1rQ1NOby+cn5uZpQRWdjC8uwjxeX+dbQNDOWUOwOryRJy9U1CGFhYW7o//1/5j77MHX7VvLG1cS17vzMtNzUysryHzQNlqpEmYUCNoxvYon8xoAwffPG3JGP7Z1dQiD4UMoYANgwjFwOQggpKj3YP/IPP6cF0VpT+32tE03T4vGITYIWaTnW6t0KiyUfMwDANPHMXIIX7X6/f5n7CMHAyNx//acjAZ8zFHR9e+HANHG+oEIAKerxyh8FIZwLJ/+/f/48lsy2N4buLcH83QNjPDExzjFG2bce8+8M9zr9SlY9TTOSGV22u5czgQohyZ5bQ3/3f0fPnkr13Exc645fvWLksvbWdmppq/5DMAoFrGmQYcB3Zq8xjejZ08neHteq1YztobKDEACwphmFAqQoAED86pWJX/2r4PMLgSB89CKAywJd1+OxsCQAq+Xb6gmLWNIWIAQA6Lo5OR1zugIul3t554UQcuHq0D+9fbqpNuhxPXLZ9K9C04x8US1lzXrcvtBYIvuL35wamwq3NJTz3PcZz6/r+tzsjMBjr9v2DSpXfo+4R499hOklhKSz2bGZKb/Hu6GjS+SFpUgw2WpjWWZmYX56ftY0zfbG5ta6BodVdsr2XCE/PjMdicc8Tteats4yj88p2xFEsWQilkqKvOhxujwu96ZVa7KFXFFRKgLBRDq1EI35Pd7nd+7tam4TeC6Ty0QSiVQ2IwmCwyavam5rrKnzOtwFpTgbnk9m0g6bvSJYHknEyn3BHes2Omz2aDKu6XpNqFK2WpeUE83Q52PhVDbN0ExrXWNlsAxAMB+LRGJRQeD3bt6+a+MWm8WKECr5fwgAwxOjN/r7g/5qnrvfDPo12dUAoBCC8MELoq2+qaqsXOQF7h6rFUszHY0tVWWhZCbNUJRsk62iRFGUy+54Yde+LavXF1XFIokOq8yxHIRwTWtHTXllrpDnWE4SBE3XBUFgafo/vfoGgkg3jEw+x7OcU5ZLitbeLdu7WtpM07SKFoggTVFWixVC+OKufdvWrM8rRasoOWW7iXFTVa0gCALPv7znwL7N21mGEYUlVQ1WB0N/+aOfsAzDczzHsD97+Q2KomwWC4SQoenOppbKYCidzSAK2q2yTbIiBGtDVX/95s8Ejmdoptwf+M9/9FOOZUVeKPcH/uL1Nxmalp78/GMYE00z8kVdEhmWoVauO0Q3tExGbusM7N5HsQwhkJJE1u1aLDSN8VJpYgAhIYRgXFrHECFAiFkozB39FNFMYM8+uCRPQAiXOAKEgBBACIBwqbVS44stf5nNLdaUv+dXQsjdSumkRAaAkBBATHNRhrrvkSVS77kIAFCjkZnD73l3PGNrbOYcDte69WJ5GViMCCUEYwAAWNqcShch/KKFx7vyEgEEa7oaTyKWYWxWtJLiOARQUbTZ+WShoNytEL843ggtjtLSfoAxWZwVBBfn8e4WUbqFEDI5Gzt98c66VbWtDeUQInS3UMDdNgjGBEIAIbo7OYuyM8Gk9MbSwlwqu75EA8aktFwRgqU43qUrpYuL5ZxLz5Zmf+kpBBGEFolf01ntc9spCpU6u7Q0vkzqFwQsaZqP84L5rkAyOTWdUWQbL4nMynkbzGJBz2UDu/c7u1YTggEBrN1JCcIXX/fSV7y4cnCJKZUuYlUNnzlBDOzftZcSeLDEuwBYYl+L/bn73xIDLPENiNB9/OE+Vrm4IDFefByhEhskGBO8mEW+9MgSVUt87F76CQDpwf7kjWv+3fuEQJD3+Z1r1vEe75fuvEvPvcSXxmSRksd7WZqaVpyPMlaJtlkRtYJCMAEgn1fmFhKKqhFACF7c9Eq29sV96i6PKn3yCKESG7k3UHBpF7p5Z+LqrbGX9q0N+h3gCy73BSO72zi6u0MuxpERQEo13Mkidyqtr8W+l0qBEwJKHAnCe7kWXGK5uHTTPUz4Xl4nCGxnc6UgsCxDY4zBF1scvO/+JQJKXXjKxJZgmDgaz0MIHTLPMtTSfvT7ASH0ut1//tqbCCHZYlu6CCG0W20Htj6zvr2roBQlUXTY5FJlyKaauqDXl8ikIQB2m2yTLBRFOWX7oT0HdqzbqOm6VbJQCGGCbRab3+1d1dRKUXQun1d1VbbY7DYbQ9E8X/bTl15PZDIcy1gEEWMiCjzHsE01dQGvP5lOAgAcNlkUxJpQBU3RNsmyvnN1U20dIEC22u4NM6suD/3VH/1xNpuzWa0uu52m6Nf2v7Br41ZV06yS5LDJJafCUoQbACRfyC9EFzRdg19JsPRAJQc6bA7FG2Ae5GSEEEqCIAlf8vBAAAGCLEIuu6OU8QCAL1atyAuiX7j3IgCAZVivy13KW3DvsuY5HgBACCn9tPSrJIilozX33X/v9dJPS4V9rJLFKi3WC1v69niOu+vVAQAhz93AvtINDM24HQ6340tdEHh+yZXGsewSYRRLeZx3m7oHeFFKBuQxqLH9kCCETMwm3/t8sLPRt6rV77aLhBC4MskzEUNbQpWuNWspjieEQIQIAKaqqrGoGo9TPMf7AozNCgk0CgUlElaTSVoSxUAZYtn85ETk1AnEcZaaWrE8REyDGCbrciGEDEXRU0nW4QAmVpMJSFFaMsk6XazDoSUTaiwGKUrw+Ri7Y0m4BABgw1BjUSUSpjheCAQZq5UQomezSiSMCwXG6eS9XsTdY53F2FRVJRrWEklKkkSfn7JYIABY17VEXIlGIUKcxwMpKj1wZ+7ox4zdwVhl2mLzbt3B2GQAANY0NZlQY1EAIOfx8A4noGkjmzXyeUKwGo8jmhYCAcYml6ynywcCTJPo2NS0ZdlI1GRq8t2PzaLm27HBVl9DOA6vYLrVRYo1TU9lioSQVCav6obfI3ucMgAgkcpiTDTdSKTyAs/4PXarRcAYR+MZnmPtskgISKRyhACEwK2+yY+O34AQ2q2i3+ugaYQQwpjEk1nTwATgaCJLU5TfY7fJIgVhOlPIF1TdxNlssaLcxbFMNJ6OJ3MsQ/vcst0uURARQPJ5NRxPpbOKbBX8HrvAs4qqhWPpVDovSXzAa7eIvIlxPJFbiKZoGgV9TtkqKKq+EE4lswWnXQp47RaR27auiWMZiEAilVNUTdOMZDpvswpBr0MQWABgUVHDsUwyleN5xm6TAABOu4VfgRqvmBDdwJpmPimSBwFkcCz2q496a8odOzZUVoUc+B6ZbzkBIcVytoZG19r1BBMICECIAIA1VY0n1FgUMgzv87GynUCIi8ViNKInk4jjhECAEsTi/Fz03BliGFJltVhWBrAJIGTtDoCQkcvp+RzvdBmFvFEoAEK0VEoIBGmrVUvGlWgMQsh7vZzDCe6GUWBCsKYq4bCeTFAWq+APUKIITFNLp5RwmJgm53bzri+XOyMEq6oSi6nJBMVxvN/PWKwl7UuNxbRkAnEc53YT00zcvL5w/CgfCEKEeJ/fs2U753SU/KFqMqlGIxhjweViXW7IMKaiaIk4oCgtEQeECIEy1m7/qmnpW4JgjHVsavqyrEolnhr9xW8Zu9W7bYOttgpTaEUWTAkQAAIBgIWClkznEITxVB4QEvA5HLJUYg4IwnxRzeQKVovg88gWgTNMHE/lOJaxWQUIQCpT0FTdwOTS9ZFPT9yoCnkpGrmdNoamAAAY41SmqCgqADCezEIEfR67wyYhBGKJnGmaBUVVNaMi6IIQhaPpVCYvibzfK1slASGIMc7migvRdEHRnLLk88gcyyqaFolmEum8yLMBn2yVBIxJMp2fCychhEGfwyFLmm6EI6l4OidbxaDPKfLshq46ikI0QnORFAVBvqCmc0WX3RLwOhiGAgDkcupCLJnJKXarIAocIcDrttH0ithYCSaGgVesutKKIFtQ3z3aPzGT3r25uqvF77SLNPWFTe3rACHkGPZeyXbpHwghgefLeP+9NwMAaJp2yHaHbL/3IvgaqZtj2ZJc7bDJX2oEAJfD6XI4wZdFdISQU5ad8hc3L4nTAkUJnOer9LMMW+4NEO+i/AwhtIji0qkQuGRP+dI4QPg1xcceoMYghOqqGqt8ksDd/8DXDu5de+cDb7jP4LRkb1i6/tUHv9rOl67c072H/B7+4G1fpeqBhD0UCIklCndGooWi/sjPfj+AAJChifg/vXOLotDmrvJ922pb69y6iVfiZVjX85MTsavdFMsSAgSvl3W6ImdPRc+fxYZODEOqqq589Q3G7pg/+lns8nlTVYmqOtas827ZMXf008xgH6CYqXd+E9j3bGFmSolGa976E2S1ZkeGZz96P/Ty62YhP/rP/0gJAiDEt3M3RFT49AmsKIQQIRgMvfiKtb4BIAQAIBinenum3vmNnk5DiFwbNpU994KWSswcfi83NgYRRAzj2bbT/8weePfj0dPpuc8/i3dfBiYm2LQ2NIVefo11OGIXzs8f+9TI5wkhYiAo1dTHuy8p8/Pzxz7TczlbXX3s4jnf7n32to74pQvzx44Y+RwghJKk4IGDrrUbkrduzn5ymOi6qWtYVeWWtsofvSkEAg84RvdNAQkx5+fD1wYLyxHlQQAwsrnw6Su5scnI+W73uk77+i5DYYBrZctKzIVT//T26XA0DQDJ5VWnQ/rzH+8KBV2/fPfcwOgcRSHTxLphNFQFXntho0US/vHXJ1vqyw4dWKeo+kfHrimqXlvp++jY9eGx+U9O3CgU1Tde3Ox2WgEAmm688/GVG33jLMtomq5rRlnA9drzGxprgycu9H187DpNURaJ/9ELm0YnF05fumNigjEJeO0/emFTW2N5OJZ55+PLPf2TAELTxHu2tm1d33TifN+l68MEE5Pg1a1Vrzy3IZbI/tu7Z8OxNABgTUfNS/vWXLw2fOzsbRNjjmVeO7ihqS747+9fqKv07dnW/smJ68fP9YkCmy8ouma+dGDdS/vXZnPFw0evXrg6hGDJtAftsvRnP97ZUBNc3qEmAGRzxoX+ib7R7JNjrgEj04mPjg/nivoHxwZ3b65e1x7gOWkFxFaCNTU92E+JIsAEUpRQVsbaHdEL5+aPHyGqSjAWQ5WhQ68KwbLwqePhUydMVTWLBbm5NXDgYOzShWTPTYDx5Nv/7tvxTGFmGkBY+eoblCAkblyPXTxb/ZM/Sd68MX/sCGIYxLBlL7xMDH3h8yNaNg1MzHk8oZdekVvbIKIAhETXY5cuzn70vllUIEMH9z/n27ErOzI0+9EHSjhCCKZFoez5Q45Vq5eoN4vF8Mnj4TMniWEQbFpq6ytefo2R5YUTx6LnzxDdwKZpqawUAuWxs6cLkxMzH7yrRsJiWSh+9Ur5C4ekqurE9auzHx82slmAIMXx/t17vdt25sZHR3/x3yFFY1Uz8zlrfX3lH/2xGKpYztWDsT4zG7lwR5OYZWlWy2QjF7vVRCp89rJ7fZdldYeZe6CwtHwgpH9k9n/85hQ2sWGY+YLaWBf80x/tpGj03//teCSWhhAahqGbeG1HzasHNzAU/ct3z1VXeA/u6sKEHD93e3Qi4nFaT13oG5+O/u6jS8lk7qUDaxmLAADQDfPzMz3Hz/WyDGUYpm6YLof1lefWN9QE3v7oYs+dKUxImd/57K5V12+PX+sZQwhiE9dV+19/fmNVyDs2Ff7N4YvjUxEAocAxrzy7vrO18tiZ26cu9WMTmyZpayp/48VNBVX7l7fPTM7ECCHtjaG3Xtl2s2/i/SPdmm6wDH3owLp1HTXvHem2iNyebR1//2/H5iMpmkKZXFHg2R+/tGXr+sZwNP2bwxd6h2ZoCtEUpZum323/n//0gN8rL/+AQ6Dr5oVr08MTiSel7hGEsKBoR86NdffMfXp6ZPPq8v3bajesKg94rBT1CE57+GVR+YEPfp3c+3uE4a8K8F8n0n9DoRoCuPjX17TwJY0AOGR7dTnFMTwB5D5nzgNTSAOO4RgiIlj8w6Tc++BDkA4fpJw8ssy1YmbFP6hrPQwIASNTib/9l+6pufSTYgEFBOQVbS6cVXU8u5C9cWfhwLaa9e0VdfXL/yqsqYkb3UoijigKAODasEmqqJr58H3e6/Nt3a4sLEROnxADZf49+xHP2ds6GdmeuH4leuGs3NTiXLU6ffsW5Hjvlu1isCzRfTk/M0kMg0CoZzO5kUEjlzFy+eTNa84164L7D0JETb37W8Ym+3bu0tLp8InPw7JdLCunLRYAAda05K2b2eGhwP7nIEQUz5vF4sLxzxPdV7w7d/E+f/zKpblPP7TWNywGeGCc7O2Z++Swta7B0bUmNz4Wu3ROqqiwVNdOvfc2JfDB/QcNpainUlKoAhAzc+e2s2uNe+16PZPJjgw716wrzExPf/AupKjAnv0AgIVTx6bfe5v3+LR0KnHzmqOjK7j7YPpOX+zSeefa9bzXC0rxScsCgo3p6fgHH0WUwrK0h03TyOSMopIZHlPC0fT0XKFlNahpX5bGvw6qpvcOTGu68eOXtuiG8a/vnD17eeCl/Wv7h2ev9028eWhLa0P56GT4s5M3rVZh97a2odF5u00iBGCMp2biRUXbuq5pfVfdXDi5vrN24+p6UVyMucWYTMxEzl0ZfP35jRu76uajqY+OXT98lPrLt/bMR1JXe8Zf3Lt6+4bm+Ujy398/39oY2rGhOZ7IfXzi+m8/vOjzHDjfPXjifN+2DU0tDeVjE2GKoq71jH1wtLuzubKrtWpofOHTU7eCAWcuq/T0T+3f2SkKLMsy6Uzh5Pk+VTP27+iMxFIUQqpmjEwsSCJnmmRmPnGjd/zNQ1saa4LvfnblkxM3NnTV3Rmaef/I1TXt1RtX10cT2V99cH5sOvxGftPyjzUhqZz6u6MjmjHy5Og4QFGMZEbRDPP89ZnJufT0XHrXpsampmV+CwTQLBYip05kBvoBIYjjSgFdU7/7FS1avDt2aclE+PhRzu0OvfI6Yjm5sZl1udO9tyJnjjs7uxydXckbV4lp+rbtFMtDiSsXMSbEMN9WQCsAACAASURBVAAAajKWHRnCRUWNRVO3rvv27Pds2oZYZvKd35iq4t++C2Nj4fjR2c8+ESuqWFmGAGBViV2+qETC/l37jUIOMoyeycx+8mFmsN+/51lKFMKnjk0fflcsv1spj5Ds+Oj0+7/jfX731h3FhfnwiaO8x2Oprp395EOpPOTesEVNxY1c3lpfr8TCairh2bjZ0dlVmJ7JjQ7r+ayyMD/19q+xpgT2PgsZNnL6xPQH70gVVUYum+7tsTY0B/bsz0+Mh08dk1vapVDFcg49IfrEVPS9D+Pm8tgQiWGqyTTW9fTAaHEhap2eUxs6QNfKysK5fPHKjZHmuuCh/evGp6Mnzveu7ahprA3e6p9MpQtvHtpcUe650Tvx8fEbbod1y7rGsYkwxzKl+LDZcHJyOrJxdV1HS2Uildu+oXFVWyXLLjpyCQHTc/FL14effaZzx8bmdE758OjV3xy++Fc/2TM+Fbl2e+zNl7eubq/uHZg6evrWpjX1q1qqxqcjn53ssUjCawc3vPtpd/et0Zf2rfW45enZGE1RPf1Tv3zvXEtD2cbVDWNTkRPnewM+h9XCX7w2tGtLm9NugQComn76cn8kln5p39p0tkhRSDfMiZmozSJqujEyER6ZXPhPr++wWMT3P+v+/Ozt9ubQ6Uv9R87c3ru1vaOlYmwy8s/vnInGMqqmrZA9RdONo+cm3z82iFfEcrsiME2Syiq5gp6dTC5Ec9NzGQjA/h31Is8sr1z5MHLv77nnqxrR7xHvH9YtAR6hBQhhyF/u88mWu6Fb9+KBxUDxzMJ0KjncUBHguYc9RrmMuM/q9sToCffAIrD1VU6bhXtSaCeExBKFhVgeY8Nh4xur3XWVTkFgVsJxj1jO3tbp3fEMYlgAAO/1p3pu5EaGKI7LDvabxaKWSaf7e33P7BEDwfz4eG5iVFlY0OJxo5B3rV4nBMsoUXJt2EjzAkQIAlTqQMnBBwCECHJOd2Dvc/49++c/+zg71G9rbMmNDJuKoqUSmf4+o5CnLRZAAKQQ63BCBNN9vbaGJktVtaEUk7duaOmUEp7X0yk9ncpNjuenpgE2AQDENDIDffnJCdblzvb3a5mUFo9nBgdMRdHi0bq//Gvvtp3ENLGuUxzHOR2zh9+zt3c6VnUlb1yHCAEA85PjaiJa87O/9G3fASFibPLwz/9rdngQ0gzv9pQ996Jn6zYpWJ7p71VjMYLxcoZ5QEgF/J4926VlCmsy84XIue7s+DTvdjhXtzu3rC9Cy0rH30MILRLf2VLx0v61GJvdN0fDsZSq6hSF1q+qfeuVrV6XLZnOzy4kevon13bUQLTILQkABAKIYNDvWNVaeenacGdLVVd7NfoyO+5oDv30tW3VFd5CUUtnCldujkTiaQrB6grPj17cVF8d+G//8jlFUT99dVtzfZlumIquvffp1eGx+Vt9k6Gg640XNwV9DmWDniso//Crk+PT0Yoy153h2WQ6txBNDYzMNVYHGJq6fWeytTG0blW53W7xuuWrPWM9A1PNdcFQmZtGd0PWIWBoqrWh/OUD66orfQVVe/ujS5FYumdgyiLyb72yra7KVyLy+PnelRl1aBWZfZsr3W47gQ+OBHgMMTmTOnJuNJVWayrsezZVb15d7rQvf/ZLQgjiBfemrfb2DkBKnpxQ6vat7OCArbklNzKEVU1Np9J9t8uefUEIBHOjI6mem0o0rKZSeiHn2rRFqqjEhu7ZuBkgCCka4lJFdgLIF0ZMsaK67PlD9pb22OWL6Tu9vNeXmxgFAOi5XHqgT43HWbsdAAApmnd7EoqaGeq31jVI5RVqMpG8dQOramFmEtGsWSwUpqYKs3OL4W2Gme69nR0bpi2W7PCgWSyoyXiqt0fPZIBplr1wyN6xCpgm1jSK57V4LDNwx7Vmna2xRY1GAYIEg9zoaGFmsvbP/qfA7r0AQs7pGvy7/ys9OMB7PKzTFdizP7j/ucLMTOLGVWV+bpmHHkI6GHDv3WkTliea18jm546cVmJx3utxrW23bViT1B8Qhb6cgABBZLUIz+9d8/Kz60cnF24PTM1HknXVflFgO5srf/TCJtkmdrVVTUxHLl0f7mqvBqVTKxAQTCAAFI3qq/wL0VTf4PS6VXWtjaF7VQMIQX2V/40XN61qq9Z0Axv41x+enwsnKIQ6WyrePLSFoenPTt0s87v++NXtfq89nS7Ekrlb/ZNtjeXXbo2t7ah589AWhqE1zQAA/PyXxwbH5oJ+R//IbCqdn4ukrt8eP7i7yyLy/UOzbU3laztqrRbB67Jdvz3eOzjT0lBWVeYucbFSYDjD0JtWN7z2/EaOZabn4sPjc4lk7nrveHXI89YrW/1ee6GgTsxGh0bnvnqgYrnA0NTmNSHZJqxkTPVyAgJYVLQzVyav3QnLFnZde9nBZ+o7mv0c831mo3lswXEcR9sgekA+qgcoORiT6bmJianbFT7nd6/kEEJMbA6OjYzOTHU0NIcCZdTKbOB3D+EtnkteRlUKQthQ7fpf/3SjuTLhXisBAkjvYDRfPB/wWJ7dWbepK2SzcuOTmZXQMBHDWOsbfDueoUrnr0wz1XMdsSwj2yleQDzv3blLbmhWwvOTv/0V1jRbQyNCtJqIY8NYioxclLggxLpm6jptmkYuSzS9dAabliTe50MUhXUdUjQry4jnIcd6t+6QqqqpuyfKEM14Nm1GFEr398WvXsoM3AkcOIh1jbFZaYsNMbSlps7S0CSVl+cnxkvDhHUd8TxjsyOe4zivb/deR+dqLREngFCCuHimkqbhfe7Gu3yV6AaEiJEkCBFAiJYsECKsaRTD0FYb53QiikI8T3H8Up6D5QKBiC4P+dvLPC5xWZa7Ek9iE9saa307NjpXtSK7PH1z8js4ZCzwrN8jcxxtGNBmFQBZjDYWBU7gWAghy9CSwC0Y2MQEY6yqOiZE08xMtkBTFFg6v7s0K/fQLIqcKHAAQIamLBJvmtgwMILIabc4ZAkAoGkGy1AWiS+9yCrxhmkqqq7qOs8xLEsDADme1nRa1XSeY62SyDKU22l9ae/atR01LQ3lLEff7Ju82jN2887Ef/nZgTde2lQZ8gwMz7790aX5SOrg7tV3lwtBCLkdVptNpBBy2EQEkWFiXTcYhhI4FgBIU0gUWWr5vH33AkIgW9kXd9es6ap7zM+OfwFCbtxZ0DTD57Hs21rT3uijEJyaKy4/H4OA4gVHxyrfzmdKR6qxaSZvXAMIsQ4nJQhIEHw7dllq6vRMeurd3yrhBXtzKyVJmeFBYhiAkKVFCAEkAJi6hk0DG6aeTBLTLC1P1mHnnC6IINF1AAljl5EgQghda9fzPj9jsZQitxHH+fceYGzWzED/wvHPirPTnh27iIkZm42WJIgouaWdkSycy5W9e7DdVFVE06zdQQk84vnA3met9Y3KwjygEMXxi0ysdOZnMZD73uInxNQ1QABjtQKKggCU3oI1FRBCCSLv9SGGoSwSxQtk2Y9BQMhUVbrbAn6fbVksQEo0oUYTiKG8OzY5OppNSRrtHgEr803dC4vA+dw2ikI8x4o8a5oEEEAhyiJxpSMrksCKAquoOsYYAKioOjaxYeJ0pmiaZFHtIUvc4gsXCIKQ5xlJ4CEANIWsVp4QoOsmRSGfxy5JvKJommYIPCPwLACA4WiLxBuGqai6bhgCzzIMjRDkeAabWFV0jmWsFoFlaJfDenB3V1drVVtT6K//ZO+1nvGe/qlL10f+j79+8dD+tR6n9c7wzHufXhmdXPjZj3bek+YQlPkdVosAILBKHCbEMImumzzH8BwDIWBZWuRXMgMbARxL7doUemZTNSBPBiuDEGRzqigw5QH5mY1VW9ZWVARlgaPB3byR3yNLXkpu8XtC4B5488p5LOaj4WhqrqFurShY7nvLgzw5EBimqWv6Q0pYy27s13Xj/PXuSz3XJUEs9wXIg3xVD/nS+yL57vtV0/XJuWldNyqD5Rbp0eK2v262SrlqOI72ck9SbnhCCMHgf/uzTa31nnK/laapXF5byahACCFaclPwvgDn8drqG707d2OlmB0ZtjU2F+Zm8hPjZS++7HtmT+T0iWTPDQgAQBAgSsuk1EQcOl20xaLGYtnhIVwsT968qWdSi98cQghRAADe6+e9fqm6NrD/OaJp2dERsTxE3U2Mjk1Tjcc5ny/U1BI+fWLu04+NfF4sr1AW5j1btgk+f3562ijkhGBZYWoKAAAQEgJlnMstt7a6123Ss5n81IS1rr64YAEAxi9fEsvKsa7p6bRUWQ0AAASr0aiaTGBDBwAACHivFyIU674iBIMAwlj3JUAhoSykpZIQUYsDAgEAK5GSCAKapgREi8K3ZzYEAB7CylefYySR97ohTWma8d1wXYQgohYdNEuWP8M0ewenbt6ZaKwNTkxG+gZnqiu9XpeNZZmRiYWp2ejcQmpgZK6hJgAAoCik6UYsmU2l8jarSFMQ3F2K/cNzl2+MbOiqi8Yz12+Pu5xWh12CqJRtErIMXV3pPXLm1vnuIYahU5n85Rujfo+9OuStCLpPXey/eXuirbliIZwkAIQCLp/Ltrqjem17TTKdG5uM1lX5stmiQ7b80Yubz10Z+NUH54dG5yrL3Wvaq9d11PzdvxwdGJ7dsbH5i5heACiqlB8WQIgAIDzHVFd4L14bPnP5zrb1TbFE9vzlwWxeedA4LQMoBHielgTmCXKnN9W6//e/2FTmk21WDkKYzSorIg6U9oq7eaJKGaakigrO7ZEqqgL7nsW6nh0etNQ2GIV8bmTIvWFT6KVXY9evLhw/srjNIGRks0o0ytpkiuOzw0P5iXFakpI3rplqcdErjaiSY4/3enlfUCyvDOx/DlJUdniIc7lZh6PUMazraixiqamTWzvwr3+ZGRny7dwjlpcjivLt2M3I9uzIEGJYwR9YLPtFU5aqas7lsdTV+7btNIqFzNCg3NxKCWLk7MnE9ausbDcKOSObszY0AoSwpimxqJBJY2wCACBEQlmQEoToxfNCsAzSTPTyBWJiqbISYIIQBKVDAxCUPFLLDAghRVECTwv8smTP4zyump++Kvg8nMcBEZUvKN/NCTREoVJCM1haRwAACIqKdqN3on94tjzovt0/NTIR3rGxWbaKIs+MjM9PzsaKRfXWnSmrhScAUBSlaHo0nslkC5LE03cT1WBCJmZi3bdGrRYhV1QudA9ZLaLXZUNoMe2jJHCVZe7z3YNXe8bamkJTM7GbvRNBv7O6whv0OW72Tfb0T3rdcjiadshidYXX65Y7mit2bGxJZwqjU+H2xlA6k+dY9pVn11eWu//2F0eGJxYghM11ZWs6qv/+lydu3ZnO5pR7ziYAikIIQgIIRAgQYBG5uirfkdM9F64NdbZUjU+Fr9wcYaiVFJkg5FiKWsnsecsOmkYv72/60XOtZX4be9eBc1ev+ObNPlDQfSS5mhASScTmoxG/y+NzewD8YiP+agumac5Fw7Fkoqqs3GGzPxKpD7nvEEBmw7M9Q9NlwSZJsN7364PO5BDAMCzPPxQHIYSYJjZMHUJECNENg6YolmEQQhhjwzAwAAhCw9AZmqEZulTlBxDAsgxDM4ZpGoZOUTRNUQBC0zB10wCEtNQ32m32xqraUju6YeiGTiHEshyFEADAMAzDNGmaphEyMDYMg6IpBtE6NjRVA4CwDEt/pZSKpuuariGIWJYFgMSTid98clg39LdeeLUmVElTFMZYN3TdMCiK4hgWIYQJ1nWj1IxuGAjCJRoeiNJSeYLO6S4h4LP6vRYKIvCF8W75gSiKkW1IEL/4TCG0t3e6N2yOnD+dHujDigIQEgIB3usVysqj507nxkfV8AIlCJBhKJ63VNXMfXp47B9/Htj/nL19VfzqlbF/+UfWblejEUaWIc0g1mBkGTI0IURuaQ3s3hs5fyY7MgwwxoYeevn10v5LAMC6nu7rWTh+lLHJeiZtrauXW1ul8vKJX/3r2C/+nrbJeiYlN7Y4O1cjnmNkO82LrnUbssOD80c+TV6/auRytChJldW2xubA/mcjp0/mJscIxrTFWv3WT1mrjfcH5z45rETClooqxmajON5S1+DbtTd69nRxapwQrKVSgX3Pys0t8evdrM0GaRoAgCialmWKW6mQieUxqBCCeM5aVwUBBJDclWhWCIRlaLtdYhmapiibRRQ5FgAAIbRa+JLzjKEpRdH+9Z2zVpGPJbKCyB7c3VUWcG5b3/j2R5f+z799nxCgKoYk8Qghl9NqswofHLkajqZ/8so2r9u29CYKwQ8/v3bq4p1kOmeauBT/JgqcbBMoClEU2rK+8c7QzHufXbl4bShfUHXTeOvQ1lCZa/fW1uGJ+V/89pTbZYsnslvWNW5d3zQ+Hfnt4Uunzt/J5ItOWaqt8o5NRt799IpVErL5YlXI63XLn5+5PTETtdvEcDS9fWOz026xWQRR4CgERZGzWoQSH+ZY2m6TRJ7duallciZ2+Oi105f6sYlnFhIcS6/Y2MOlLNkr9ILlBSHEbRfcdqEkCaxcZApiOVa2L5b+vGvOlJtbAnsPRC+ey46OENMgplnpdEmhCqmyKnHjmhqLq8kELYiIZiBFieUVyZvXR//hv3l37pbbOpK9N0f/x88Rx6upBGOTIU1RgshYbaUUalJFZWDv/vDJ48M//1v4/7P3psF1XFme37n35p75Mt/Ltz887AA3cIO4iKREiqJEqaRSbV29TffMeNoRbYc9HvuDJ8IT/uKI+TQxMfY43J7p6J5xdU9X90xXu7pbrr2kKm2lheK+79h34O37y+Vef0gABEGIolQAAYL5kwjg5XLzvlxO3nPvuf8DyG3UU699HWCPd2hqNTOffpK/eE4wgo2Z6WDfHq2nN/Xq62Nvfn/gO3+CRdEqFGJHjwd37yGKwgd0wvPBnbujzx2bfe+d4tUrbrOBMFbTraHde0sHDs+8+4vClUturSbFE92JhBSLI44b+d5fVgbvStEYrxtEELTO7pY3vjH11k9v/dEE5rhmLpM4fkLfsr06eJfTg8RL/oMJrxtEXv1YQYTmrdiX0gVaDidLwV3bFvuk1y5iCgGIIh8KqhxHBJ4zg6rAewYfBwKyLAkIgONIJlf5zvfeE3gyOV3oaou98fIzZlA72N/zF9//1b/54x8SDpfK1ZZEiBDcng7zHPnz//f9ofG5b7/+rKHPn2qMMAC89cHl81eGSpV6pdr49lefTSfDmipjjDBGsiS8cmzP2FTuO3/9bixi5ItVUeDeeLm/szX22984/J3//N7/8ac/0TWp0bS/8eqBQ8/03hqa+vEvzn96fqBWb2qq2J6O5nKV7/7dB5Io1OvNjtZYOml+8OmNc5cHzZA2OZ1/9pkeM6gGVMmzY0ZAURXJe+kqkhDUVVkWXn1xz+hE9q/+9sMfvX3ecd1ytREL6zD/Zl6DS+Bd2ifEjnnwHO5tDy96EKtSeQaMMmbbtleq7TgEz7fYAYBSajm2M9+MFxBCjus6rsthzHGc1xgGBI7jfnzh7C8+/uCrx18+fuCIJElLowkcx2naFgAIvIAxLlbKb3/0wcUbV37/67/Zv32nJ9psO45l2xgjkRcIIYwxy7GBMYyxZduIgSAIXyiHLKPU8QZDH2CFZKAIAU+wGRDDIZ17BN96fGby1KVz03Ozt4cHz16/PD41KQi8rmrVev3ctct3hodGpyYu37rOEQ4YXLp1/cyVS9cHblXrdV0LzGYzn16+0LCakZDpuu7NoTuXb99wKc0XC5IodbW1I4ChibEzVy6evXp5eGLUpVTXNILJraGBM9cuqbKiqero5PjZa5cRIEzwpZvXT106d2Pwbr3RCIdCPMej+aQWdDY7d/rKxTNXLt4dHabMLVUqH104+/GFs5VqBWMSUFVZkoYnxs9cvnj+xtXRiXGe5w0tUKyUPr10YXhyfGhi9OzVSwOjowAsqOkPTb/1JD1IHggh7KXhWGjQrEUyUAYAGIshM9DTI4YjiyM5nCyr7R2iGcaiqLV3xo+/FNyxUzAjckuKiJIQCoUPPBve/6zW3SuGI0I4zGkabxh6z5ZAT6/ckuZkWU6mos8fD/XvC/T0CnpQSiQC3T2cLBNZVto6pGgUi6KSTsePnQjt3ktk2fs+iOPEkMnrOhbEQHdv8pXX9J4eOZ5U2zuIrPCBQGjvvvixF6VYHAuikkxp3T1SNKZ1dArBEBbEQE9v/MWXjZ5eTlW19k45lsCSpLS0Rg8d0Xu28IGAFI1hUZQTyUDvFrW9I9DVLUYiWmu7nEhiUZTiyfixF2PHXuR1nQiilExp7Z1ElhAhgmlqXd1CMLSK7ctVTgaK5lMoLNbQdd01SgbKGHAcjkeDW7tTQV0Jm4HujoQZ1DBCmiL1dMT1gHL64kBHa+zlo7skUejtTHzz1f27treJAp9OhuNRQ5XFXdvaTr6we8+OtnTCDKiSGdRkSUwnzC1dSUnkEUKO7b5/6kbYDHz9lf2SxLe1RL52ct/Bvd2SyMui0NYS6UhHBZ6osrS9uyUa1kWR62qLfe3lfQf7eyRRCBpqb0fS80/6d3a8cGh7V1uitzNh6Ios8du7W1470b+lOxk19aCh8DzX1R7/6on+vX3tLUlTkUVVkY7s33ry2O5YxAjpam9nImLqmiJ2pGOtqbDXKkolzJ7ORFBXWpPhlqQZMrStPSlNlWr15otHdkbMwOqe9icxGSi6D1irZKDAsMBL8WSgu4cLBBZ7hLAoae2dUjSGRUlpTcePvxzauZs3dDmV5lSVN4zwgYPh/QcDW7aK4bAQNDlN47SAvmWLsb1PSbUQWVHbO5MnTgZ37tY6u3hdV1pa1XQ7FnjM82pbuxRPYkGUE8nYc8ciB57l5IU0f4STolFOUYmihnb3J146qaRa5FRKaW3DgiSEw5FnD8eeOyoYQSJJSmurkm7ldV3t6BTNMBEltb0z8dJJY3sfrxtaR5cYjmBR1Lq6os8fU1rbBN0QQiEsyWq6NdCzVWlt0zq6eF3X2jullhZOkoRoNHb0hfjxE0IwiDlOjMUCnd2coiKMBSMY6O4VI9FVvH9WORkog0VDBggBY2uaDFQQ+HQivKUroQfkZCy0tSupqTJGENTVns4ER/Dpi3f37+k6sKdLlsU9Ozq+9dqBns4Ex3HJWDAeM2RZ2NqVeuWFPf197e3pqBkMREIBSRLa09GutijPcwDgOO65K0OMsq+d3GfoSjIWev2l/uef3aqqkqZK3e3xVDxECDaDWm9nwggoksTv6E1//ZX9O7e1iQKXigV7OhKKLIZ05WB/z8G93YlYqLcrYRqqKApbOhOvndi7vaclbAbCIU3guY509Gsn9+3t60jGQpoqqbJ4cG/PV1/qj0cMPaB0tcU8deze7lQsbCCEZVFoT0c6WqO6Jne0RhOxUNQM9O/qbDRsx3G/+tIzirxKOV4XeEKTgXox2EvesKtzVhhl1Vr19JULd0eGxqanzl65NDYzqcqKpmpNyxoYHT595cLF61fHZ6ZkSdIUdXRq4tTFc5VaVQ8EBkdHzl29VCiVBsdHPzzz6cDYCCEEAYpFwiIvAACltFytXLhx7dTFczcG7jSaDQbw8bkzn1w4N5WZJQRLomgEjJns3LlrV85du3RnZJBSFjKCluOcv3bpxuDA5MzMuWuXbg7erVsNXQsI/CMFETBgc9lsvtzY0rVLkbVle6Blo0vz0XPUYs4UcqufO++ZAfz8V+/+xZt/IwqiJEh1q1Gt1ft39P1X3/rtZrPxJ9/7y9GpCU1WVEV94cChXLF46eY1jiOVag1j/FuvfU0WxL/4wfd7Wtv/8Hf+Ya1W/87f/XWxUn5h/+G3P/kgpBt/+Fu/Nzk78+bbP52YmcaE1Bv1RDT6u69/s69n6/d+9oMPzpz6b3/nH+7v2/Pj93/x4/d/+a2TrwNjP3znLQBwKW1vafkn3/qdVCzhOTmlauVvf/bDD86eVhXZdpz+7X3JaPznH74/MDaiykpbMvWNl1+VRfnH7/2iUC5xhOSLxb7eLf/o67+ZLeb/3V/9eblW1WTFcuxSudzd1v6Pv/lb2zp7yCqnMdlQsHKleeNuvqOzLxqNrpZpYAvpGAEh7xleXDqfF81xgGCMCfOeacaoF7/O8/fGaBmjjsMYJRwPGM9vA4AJmZdKB7QoOogAKACilLoOQggRji20hLxNKKWIMde2EcaY4+4dwnWBUsRx9x6BpamnKGWOgwjxkvxghBaPAghhMl8Oo5Q5NiCMOQ4A2MIIElDqhapjjntQapEt6YJGaNXi1srlyq1bV1tiOB5dHrS6KjSb9qkzd41wx549e1f3XbKYw27+4izpRfAWTs3m//W//2EyFvwf/uBV703PkXt9EC6lrksxxt4ArLfYpcxxXIwRR4jXw1erNf/l//l3AOx//WffkiQeGHDcvfmA3oEQQl4KTkqZ61IvDAMAvAFnhJDrUtelhJs/FgNgLnNc1xsFml9Cme04GGGOm0/R6Dqu61KOm4+mYGw+Dm9pBkBvOWPs6q2x0xcGdm9PJ2KhuVzp//kv74oC/y/+6TcSMWN1u1ccx3n33V8G5MbBfb1PipOzDEpZudwYHK+1tW8Lh1fNVbtnx2DemsDC40sZQ5RSxwGM5y0SwKKNQguZbTwDyBwbKMMcB4R4JgUQ8mzF4o6L4Sle8k3XthFCmCOA8PxymM90zFyXui66/7jMcRgAJoQt6jQusTPgusx1EcbzKbnuWa35+ntbUtcBx0WE3LcZAJr/XgwRztOB9BYyhLBneBnzzOOqDLl41Gq1WzcvR01IxfVVvy0ZY7Va84OPb3Zv6d+yZesqls8WEgrDvSwa98JtvVtpaGz2X/3fbz63f8tvf+MIhwkmXjZObw4GpRTsBZMFi3bMpY7rEkw8YwIA9Yb1J3/5i8HhmX/+338tEQ0CA8JhvHDEhUuHEZoPw3FdignmCPbeyN4MCtelLqMcvmeRKKOuSLnAkAAAIABJREFUQzHBZEkqT8d1AYAjBGPEGLiu61JGyHwNFw31slS3XjPzzKWBy9dHD+ztDgW10fG5/+vPfr69J/Uv/uk3FXk1+uCWUK1Wz5w+FTKcvq0tm7rN9khQSofGR//4r//T5MxMyAiWyuWGbX3jxCtfO3Hy6u1bP3z3rVqjgQAKpeK+vt3/4Gvfmpie/s7f/mdBEE88+9zHF86WKpUXnz18e3jokwtnG1YzFY3v2d73j77xbdMIAYBlW++c+vDvf/Fz7xJ3ptsO79n3g3feujl0FyPckki8dPj5Hd1bfvbBe8OTYzzPFUulcND8r7/9uwFV+5Pvfff28EBID1JKi5WyaRi/8/o3jvQfEPjPF0qilM3l89kK6mzbI0vLO7NWHKhh9UbNapQ0EXEPbawwxiijM9lMvlTat3P3q88fRwB//4ufXbh+5cWDRxRZnslkFEn+yrETHan0lTs33/30477eLQd27pmcnfnJB+9cu3PrxYOHZVEaGh+dzWbujgzfHh588eARI6Blstm4GSlXqz/94J2pzOwbL77c1dp+/vrVtz56//z1K4lofGZujlGmSLJt27PZbK1WV0Txk0vnp7NzLx0+2p5qiYWj5pLcRtlC/uLN65Zjn9jzXCRktiVTpmGWKpW5XPbQ3n2vHDmKMPneT94cm5p89eiLkaD54blPrw/cGZ+drtfrc7lMMpZ44/jLphH85Scfnr5y4frd270dXQSe9gfmi7L4gof5yXNscQgZAQAhsGCDFoN55wNC7i/lvoWfsc28eQXAAEAIWVbyQgW85ji3zPYhtEJE4pJHB91f1QeP8uBmi4de+ZsuKX9pyO0TGfi42iw08xY+3rcKAIAjJKgruiZjjL0IkKVwhCy/vgAcQdyy+GwERkAGBISgBwtZbDR6bUVC0NLw7ns3Ekc47v4rziHC4fuWEESIsHQJ5rmllnzFb+p9Zi6zLPvCtaF3P75qBJRqvclx+De/+qwZ1NZ3KurTw72+jvtP97w9QehBO7CijUIIgXAvJHWZrVjcCJa2jBHilkSxesYBeQluARDH4WUBHgihheOubGc4Dh6ICUEPWCfC8cAtb2qglb4XWih/3iQu7bV5uu/OeSMG926bpefD+5snOGioiiJxmAjCveviuY2EwINTSpYanMU7U1PFoKHyhCyzY4tH9nwuhNDS3RffyAghjDF//44YllvRZTYQIcD4vrtkyat2eR0ch1Vr1oenb33w6Y2AKhdK1UTE+I3XnvUG1b9kfkKfR4AxlisWsvl8SDe+/crrs9nM93/+o4mZ6dHJib9/+6e5Yv61Yyd0LfDLTz68cufWS5lMRzq9Z1vfTz5457sz06osf/Pl1w/v7U/Fk+PTk7bj/PZrX+9qbQ8sCDdbtn326qXZ7NxLh55rb2mLR6KdLa22a89k51oTqW+dfC0SMn/ywS/PXr147MChbV09V27f+Oj82Wt3bm7r6p3LZQVeePnI0e62jgvXr/70g3cu3ry+d9vOR3FyEIJIKByJRDAvP7h2JeEBSm8O3picvPzCvn0BbQXZ6aVlWw2rWCqqsnL84JHDe/fZlnPl9s3B0eF6s+FNpNm/a//JI8cc1337419lcpnbQ2QmM9dsNm3HYYwaAb01kTp77dKV2zcv3bgW1PRn+nbni3nLsQ09kC8VhyfGt3X1HDt4xNQNBvDxxbPlarVSrRTKJVWWA6pabzbzpYIkiUHdiIejPMefvnJxYmbqpUPPL31OJFGMhyOTczPvnz7V3drmuUCyLHOE9LR3bO3quXD96tDYaLVe++j8GY6QXLFIMLasZr5YwJg8u6f/6L5nBUHIF4unL1+sNxqMPhlChBuZx2DIHn6A1arA2n0N39J/LowxTZW+/uo+WRB47sv3O/A8ef2lfmBM4LlHyWv8KMtXHYzRru1t/+wPXr1xZ2IuVzYCct/W1p72BM+vSZpwnwd5yHleo0twn4u/bPlnrFp30LK/N2QlNxSMsVBI+82vHoqGdXy/M/OI95W3Gcfhowe3VXY2DF35bG9h5cWPx4YwBhijZ/t7zKB6a2CyXG6EzcCeHe1tLWGMF91knzWBUloolx3H6e/bdXB3/42BO6qscoSMTk0Mj4+6lL5/+hQhOFvIS4LoOI4iyV2t7TzHz2Yzrx49fqR/X0g3wsEiwjgWDvf1bomFIouhM4SQeDjGc9zpK5cmZ2dPHHpOUxQzaBJCWuLJHT1bsoX8rcGBYqV88ca128ODlVqNUtq07VK10mg2dm/d8cKBw2YwhAB9dP50vV5354X1Px/bsW27pnAGQQ/0cj64NQMoV0qZXMahnyf+yFitUc+XioAQpazRaE5n5samp4K6EQzoY9NTCFAqGpclOV8s1Jv1gBbo374zHDILpSIhZF/f7nDI7Ey3fXju05/96t16o/Ha0RNtydTA6BBGKBwMOY5jOxZCyLHtUrUyNDbaaDYTkSggKFXKGGHXpZOz0+PTkwFV0xTt+f0HY+HwjYE7py6eA4BdW7fHTBEAGGNBTX/9+Mvbunsv3rx2+solRVa60m25Qt52XUWSXUqr9Zrj0tZk+sDuva7rlCqVVCyeiiVuDNx1XBcYa9pWsVq6NTwgSUIsHHmCgjt9fB4PbI3UKh4KQkgS+b07On7NzmKC8a5trQBe9/hGfMt63eGSKGztTvV2JiljCIGnvrYQJbTa1X5Cckr4PCWsRd62jYMqi/v2dC0qbH45CMY9HcmF0bqNaMc8L0ZVxD072ndta/XGlDBGGCF2X1S4z+pDGS2WCo7rpmNJgeOrtRoDZgQCTctiAJ2tbf3bd9qOXalVWxOpRDQ2MTPzycVztm3Lkjw5O53J54IBvVqvlyuVZDSGEXapSwjxxt8IJi8cPJyMxa4P3Dl18Twg1NeztVgsOq6ryDKlrGlZlmPHw9EDu/aIolQslQKaunvb9snZ2WqthhDYjl2ulAfHhhtNKx6JSvwjyS8xgMHR4Tvj2WOH3ggZ4WVrV3ZyEEKPKM5YbTTypWKlWn3rw/eGxkemZmdHJ8eP9B9IxZOXb9/ABIcMAyOkyHJXum1wdNR2HW+8LBVLdKbbZElqTaY0RR0eH93Zu/3A7r2iIOaKRcJx0VA4GgonwtHLt25w+AeY4Ot3brXGk3u396mSIgrC+PTU//fOz+uNxsjkRP/2XYVS8fz1yzzPhYygIiuarPILA/EudW8M3vn4/JmIGQ4bIU1WdC2AADmO02w0zl69pCmKaQSTsVij2QTGmpZVqpYPxvuDAX0un63Wqh+eP1uqVMrV6tXbN3d0bdnR0/sQgbVNA2PMsmzLsnyjswmwLIu6LoO1u28ZY8y2rHp9DdKSPALeRPO1Y2lmgHXHm8wDAM6atftc17WdtSv+cYGAUWpZVrPZ3CDXzufXwbKaLqWwhnYMGLBm06rX62t3iM9icSber1XIGlvCVWTpjNQ1OkSj0bAdG56YnIVri+04+XKJ4zgjoHvSZ67rRkJma7IlGg7btg0A9UajXKu2pdJN2/rRe28PjA6/eOhItVY/e/XiO6c+jJph13UppSMT4++e/ui5vQdS8YQ3lWtiZuqXn/xKEqWwEVRlWVNUjiOW49i2fXPw7icXz3a3tbcnW24PDznU5VwnVyp0tram48nrd27Xm81LN69zhMMYX719Mx6O9O/YKUqPmKiTlaqlyZlJ27YeVEdcSUIaUMgINWMp/hEU3Gq1WqlSjoRCCKHz1y5zHP/cMwdeO3pC1zRJFNtTrTEzgjBWRPm5Zw4USqWB8dGRiXFVUZLRmCSI3lDPzq3bjYBx7MCz6XgSgEmi2NnSlorGWxLJV54//otPPrw+cJvjuLaW9EuHn+9t77Qc58CuPfVGfWh8LBwMdaZbu9raCcEz2cx0Zk7guN72zhOHntMUbSF1JKvV6+MzU7eHB3mO29e36/DefYosd7d1tKZaRibGh8fHXj589LVjJ9799KMzVy4SjmtPtoQMw6FurlDQtYAmy5dv3wCAnVu2fuXoiWQ04U3R28RvTYQRMDo1OVYsZjftl1wNvOngC9OPNy6WbTcaNYSMtToAQgB0fHyk0axv8FPxJaCUFvJFBiwUCj4lo7iU0nw+Gw2F1rsivxYIIcexJiZGc7m5TXdXPo3YjtNs1DBang1j1UCAMRoZulssZJ8QT+HLwlizaSGEBIHfqGM+q4BtO/ncXCIcW++KbAgoZbIobenoNENBABB4ri3Zkooneto7vnrspQ/OfXrm8gVMSE97h6aoA6MjkzPTh/bse/2FE7lioVqvzWQz2ULeNELburrvjAxduXVjz5Y+BMjTbm40m7PZ7GwuI3B8b3vX8YOHdU1PxWJdrW1zudzt4YFdW7a9evRFyuD63TsYoUjIjIbCAJAr5hVJDhnB28ODjuPEItGTh49u7ex+9LEEbyLZiiOgK6mrMdZolO3GmCI+MCH7flzXPX3lwh/95Z/t2br9N05+td6si4IYC0d0VQME2Xyu3mxGzbAsSgDgUrdQKs7lco7rGAE9EgpLgoAQsh1nLp+zrKZpBAOqxhjLFHKNZjNmRkRBaFrWXD5bKBV5jg8HQ0HD4AnPGC2Wy1OZGQRIVzXLsVVF0RUtU8jnigUAFg6GIiGT5+bFvxljtUZ9Npsplss8z0XNcEgPEozLterkzFTDsuJmJBqOOI4zl8sWyiWB5yOhkBEwxqen/vV//HeGFvi9r30LIUQwiZimqQcJx8Gm9nAYY7bjZrLVRtPZxObv1wcBFEvVi5du7+zrCoeDG7zbm2AUNVV5bXI7Oo47NZ3L5iub77lAAM2m9dYvPrQd57VXXpDktUphtNFAAIl4MBoxntBrShlzbDeTrzYavh3bPPAEmSFl1WW4YF6Ozp2cyhVKtU1/uzQt64NfnZEk8fDBfo7ftCpKDIBglEyEQkHtKemfegi242QLedu2I6GQKIj5UrFcqUbMoCIpjWZzNpcpVcqSIERMU5O1fLlYrdWCAd0IGI7rzOUytu1ETVMQxOnMbCafUyS5NZFSZNnzcyzbnstlc8U8AmQGQ+FgSOD5pmVNzE6XKuWQbnhyx9lCPlfIA4AZDIaDZrVe/aPv/tnU3MzvvfHNkBFklJnBUCQUEnjBU8P4XNNNKb07OjI0VTr0zElDNz9fXQ0hJAqCgFTEag8vmjGWKxYZY8lovL0lvWzkJxaOwpIYD4JJOGiGgybAwqAsQgiA57iWWHzplvHFHRFIotiaTLUmUnBP/QMAUFDXg/pCCj8vHyFjLfFESzzhSd97TsjiYIsiyZ0trYuSrN4fuqrpXb2LClYcIW2pllaWWtymUC7Wm42eto62ZNoIaAAL0sOwYaNdVwvEcyQRW7Pess0CA7hxozA4OLxnZ1tbi7Hx74kFKbvVl20jBLekwqmkuQnlEhDU640zZ6Wm5Wzb2qKpq5/fcEMyL7e+3tX4kngCXzxPElHfjq0OjuMWS9Vm02o27XrTsiy7JRmNRoOPPTpqDe9KjiOt6Uh6Q/dWrQ61av39Dz7kOX77thbhQYXSzQSCJy0R6FrBEZKI3GuZh41gOBjy/pYlqb0l7Umbe05LLBxF4flNBcynE6nFsMLWRCqdSC2eUQYMISTw/GIjfME9QZIodre2L3VVkpGYVwevJWJZTqFcVBWlLZVuTaa8a7XYgH+UljZCqDWZjscNTV3B1K/g5FDKpjPT5eJAeyIiPTTtOgNGCO5oaW1vaf2s5JhLcwjcv2L+3C0uX7bBgkwn3Pu5ROXwsw50b+sFneKlq+7fYsUP9yoMAIzSlli8q7VdFAUEeDHv7OYOVAPwsi88we2bx0bTsi5fG5yczt6+O7ZzRyf/gPTwhmT1799F7dHVLHQjgT0QItjLmbveFXq8PIkWb9H0P3E137CUyuWfvXVqaGS6Xm/WG01C8O98+6VEwtw0WqPLGgybG7yQNwxh/KA49abkSbRjq8jSr7/0PNx3Tu61ltEKq5e3s1cufKmk4rIMEMsLB+a6bjRohoLBgBrAgBZ3+0IXS+B5gVMxJgui9fdWrSg8QAdH746MnI+HXni4k0MwObBz77bOnrARevhrfxUFCx/nPdrT3vmHv/X7uqYLHM+ALV6Yp+A52fRfcBVACGZnCzduDlcq9YGhiVK5GjbXbMbLarL69+9T8EQ81fjX1wcADF19pn9bsVS9ODZTrTVMU5/NFAYGJgxdVVVZFNckDtbHZ7V4yu/PNf36X65wBmAGg7//jW8LPB9QlaXuyRcqcC6XyZQyXZ39iqQu229ldTXXdW3HfnjnjNfVbxrBxZybm8lL9oZrAqq2mOdo03w1n9WCUjYyOj2bKXAcmZ0tTE1nIxt+Wo6Pj4/Pl4AxxvPcjm3tkbAeiYQ++fRqLBYyQ4G7gxPUpYGAHAoFTNMwAqogcJ8V2eHj8+tg287Y+CwABAKKokgCz2GC8aYOItjEeC6DKAjehBSAL9m7zoBNzExeuTORiPcq0vLcnivNyWHA84IkSitLFSxuBpt5XsqDDttmcuF8VgXGIBE3X3h+7+RUJhEPSeKmDmv28fF5ilkM5YpFQ9944/ne7haMUd+OLmCsUq3ncqVcoTQ1nXUcGjQ009RDwYAeUHie89+bPquF69KLl+9cuHxXFHlNkbWAfGDf9l07Ov177ElkhakfX3aysOM4DatJGX1w7xWcHIxxZ7orrFHxobFqm5sHnxn/KfJZBsaou6uF47lbt0cPHehTVdEfxvHx8dn0yJLQv6fXS12PEDIFPmwajuPWao1iqZrJFMYn5kbHZgSeCwYDpqnrAUUSBY4j/mvU59dBFPlDB/smJufOnL9p224goGztafXfuk8uK8zV/1IQjhMFESP8oJe03MnxDhmPxmMGQ2wdkmH5+DxBIIQIQhwhiiJyj5BXysfHx+eJxmskLFPjZYxhjAIBJRBQ0i1R23HK5Vo2V8pmi+OTcxihoKFFwrppGgFNWZzm7vs8Pl+UZCL8xmtHSuXarTtjYdNoWHYmW4iEDT9C8ikGtSXSqppWFe3BwaDlzbKFPDl1q17WZIRXGurx8fFZxKXUkxlc74r4+Pj4rBtLs9fzHGeGdDOkd7Ynm027VKpk86XpmfzI6AzGOBjUzJBu6Kqiyjy3aTO0+Kw63j3W3pb41tePvfP++f49vYauXrk2qKlyR3syEjY4/3Z6+kAAkVA4HI1iboXsDisJDzA2MDowPX3l8O7dmuo7OT4+D8N1KULL+zV9fHx8nk6WdqgTglVVUlUplYpall0qV3P5ciZTuDE7wnFcQJM8X0hRJZ7jvOC3day5z8aHMYYx3tLbmkqEFUXiOS6ZCN8dnLx05U48ara3J/SA6t9ITxtNy2o2y5qmPxhQs1KeHGC5YnZietLu2/FYqufj8wTjUkowQeixJ8Tz8fHx2djcN7zDc2HTMEN6d2fKspxCsZLNFWdmc3cGJwSOM009bOrBoKYqEiF+f7zPyniz1TlCgsH5zI+mqe83Arl8aWBo8tSn11KpSGdHMqApvp/z9DA8OTo4UXju4GtB3Vy26jMGavzmmo/PI8AYc13qx6ptEJYKP8znS17y8cENHmfdfHx8YOG5kyQhKZuJuGlZdrXWyBfKmUxxYHACEEiiGAoFzFBAVWVJ5P25FhuH+5V1EEIrWNQlS9bqui1PHA+IEBSLBoOGNjObGxiaOHOu2JKKpluiiixh7N88mxwGrFQujU2NWXYTPaBdsJK6GoChB+ORuN+b4uPzubguxRz2+wXWF8YAgFFKKaUIIa9hxBijlDLGFk0ZpZRS5oUX+i0nH591YaE1DADA81woGAgFA10dqXqjWSxWMpnS9Ezu7sC4qkqhYCASNkLBgCQJXkiw/9iuI4wxShllFCNCCDDmdfO5DBBH7plcl1KMMCH4cWYVZwx4nku3xOJRc2RiZmh4anIq09WZSiVMnvfT1G56PrMFtpKTg8j27h09aUPm3LWsk4/PEw9j4LqUw8T3cdYb5rju9et3fvXRuY72lheOHtA0tVKpvfP+qbGxqRdfeHb7tm4AGBwaf+e9U6Gg/uLxQ5Fw0H/z+fisL4vd/wghWRJlSYzHTMdx6/VmvlDO5UuDQ5P1pqVIYtjUQyFdD6iyLPhzINcDVq83f/XR2Vu3h44c7t+7ezsheHx8+u1ffkwIfuXk88lE1LLss+evnjl7dc+urYcP7RVF4fHbWF7gujtSqUR4YjIzODQ5Mjrd3pZIJcJ+yqbNCgIIaIFkLMlzAgOGHq6u5u3Bczxhoi8h7ePzeTCXusRXdNkA1OuNv/rrH/35d9/c17+ju7N1x47ewaGx//3f/vnA0Gi5XO3sbOU58uOfvvdv/u2fpVKxRDxy7OiB9a6yj48PwP3jMwghnud4njMMrb0tXqtbpVIlmy3NZYsTU1le4AKaHAkHQ4YqSiLPEeQnvH9MoInJ6X//J//l1KcXf/8ffK23p11VlPc+OP2v/s1/4AgxzeDX3ziRzxf/03fffPMHv3zpxKHe3o50S3y96qrIUm93OhE3h4enbt0enZic6+lsMU3dT9a0GUFd6c50y15VMx5ct5LwAKUz2elSfrA9GZGe4nygPj6fizeSw/tzcjYAGCFFlsygEQmHBEEAYDxH9IAaCYeMoI4RAkCSJAaDgWjElGVpvevr4+PzMLzQU0UWZUmIx0zGWLXWyOVL2WzpzsC41bQDAcUM6ZGwHjQ0QfBDktYcQrCmyuFw0DQNjAlCIIhC0AjIiqSqCgBgjFVFDoUCkXCI59dNmxch5OVLCWhK347Ottb43cGJsxduxaKhnu6WoKH5t8omQxB4gWgIr9DdvJKENLCh0cGR0Qtx85jv5Pj4PBRGHReL/HpXwwdkWfqDf/wbzz+3P5EIp9NxSllnZ9u//N/+x3KlunVLpygKAPDNr7+0dUunoWtbt3TCQpDMelfcx8dnBRafTW+yB8Y4oCm6prS2xJqWXSnXs7lSrlCancsDYwFNMU3dMFRVkUXRd3hWH8ZYSyrxv/zzP5zL5Lf2dqiKhBB6+cVDqURMFPnt27oZY6GQ/t/9N7/7+mvHOtpbTNNYVwM7HwaJMTYMbe/u3my+NDIydfbCzVg41NYa03XNVwzaNMxmM5nSXHdnvyypy1at6OSA7djNZpP5k6l9fB4KY+BQyvm2cl3xXqWEkLa2VFtbavG1qijSM8/0LX3HxmOReCyydBrAetTXx8fni3FPihoAY+zN3onFgi6llXI9Vyhns8W7QxPMpZqmhEKBcFg3AirPc77EyGqBEJIkcfeurUujC8Ph0LGj+wHAGznheb63t6O3txMANsJZX6woITgWCYZDgenZ/MDAxJnzt1pbY20tMVmRkK9m8YTDgE3MTFy+O5GI98qStmztCk4OYkAI4XjOv+w+Pp+L61Jfh3B9WXhFsUUxn0UH5n4jtsIGjw5j82ptlFIAgAe1Kn9dPru81T/W2uI3GnweA4wBRljXVV1X2tIxx6WVcjWbL+Xy5cnpDHWpYWhh0wgFNT2gcJw/73xVmFfG8/Sjl5zSRf3oL29j1xRPZjOVCMciwZnZ3ODw1NjYTHtboq01Lq2HQILPKuI4TrPZpIw+eBVXcnIw6kh3hlTXj1Xz8Xk4Xp4cvFIkqM9j59576jPeWJ+7wWcXDUAZGxwaf/f9T2VJAoQwBgQIEMLI+73IwrJ7fwIg5CXhRjD/b2GyNEIY3bfGO9hC/bxNvB8IgMHCHOt5t2ehkIVaoiU73Iv1WfwDeXVeLGD+E0JLj7JkI29vBGjxr/mjLK0EwogtVojjOFEQCPli3efz0rSU+jnafL40CCAQUHVda005tXqjWKrOZYqDQxOMgSDwZjAQiRoBTeF5jmDst2ltx3G9/povwtLz9uAzfv+SjXWKF2wl8pSmw2FjfHx2eGx6djbf1hqPx03Rn9b1xMJxnCSKGGH2wG233MlBCGHALfHWljDP3Mpjq6KPzxOK61KO+JZxk4MQMoN6qVR+971PCYfBy/LBAO798Ka6LvxDC3lAwOvwXNp6Z4v58u7Lreftxtg9DwctcVgYLHNQFh2ipQM9y90bBBjhJT4YLPnheV4AgBBesgiBtw9CC84WQhgAMF7qoQEC7K2Y9+MQQuA4bjBoHH52T0d7yxdSMbIse3BobGh4wrZtjPEGax35PJF4N5HtuKVitVCslCt1y3aDwUC6JaZrCqUupQ57sE301NBsNIcGx8PP7HgKTwBjTJbEnu50Syo6ODx549bw2MRsT3c6Gg56vVHrXUGfLwRKxpJEiCmyujRew2O5k8MYY4zVGjWrVgzIyFej9/F5CAzApa4frrbp4XnuxeOH9vX3iZKI5j0YxigwoF5GPAYAFBgwxuiSv71VzPsIjFEAxihQYLCwaskvRmHRBVr4OV/OQmEAXknzn73ldH5Ldm/V/A+vNDpf8EJdPYAtfoP5yrGFn/NbAQUK3ufFdYgyCvcVM78PpfTGzYEPP77wza+/9D//T//EMAKPfnoLxdIf/fFfnT139Zn+7fFYxG9j+KwmCAEDl1LXpYWCXa/XKIN6rVGrNZrNBmOuIkuqKj1t09Cpy+KxcN+OLU/hnNLFUR1Fkfq2dbamY2Njs1evDaqq3NmWiESCX3Qs2mcdQQDxSCwWj3C88uDalSSkGR0cuzszde3Qnp0at24igD4+TwCMUZdy3FP3knjawBgn4uFEPAIAD/YVrcjCsM48C8Muy8KxvnDU3OKvhcGgz9xqyTq2tDKMeQNG3hbef/cNNN3bgS0rhd23zUIx3g9K6Q9+/O5bb380PDJuO84X+l5Nyx4YGLUs+43XXzy4f5ffvPBZO+bde8qKpdr4xEwmU8AEa6pshgKmqauyxPHkKeneJRirqoKf8k46BIau6TvUVDJyZ3D84pWBWDTY1ZkKaMrT5vc+udiW1aCVQMB48JKtrK6WK2THp8ftvm2PpXo+Pk8qzBceeAp4YAbtIzXBH9Q9ePR9P7Mm9/36nK2RxCmjAAAgAElEQVSWHnRpZe6bxrN6uK4r8jzCGOEvXLZXPZ7jgoYejZi+k+PzGEjE2ZaedNOyi4VKJlvMFcsDg9OiyJvBgGnqoVBAVaRN7+14xm2jiQQ8Tha/vmnq+42t2Vzp7sD4J6euptPRzvaUqkpP7Zl5ghieGL07kX/+4OtB3Vy26rMGavwcwj4+nw+llFJGNvuL8CnHt4WPk6e5veXzOPFuM1kSlaSYSISbll2r1nP58ly2ODA0wYZAFgXT1ENGQNVkSRQ2Zb/+YuDWeldkPVlMKkAIiUVDoWBgeiY7PDpz+tz1VDKaTkUUVfalKjYsDFixUpqYnrBs60Eh0hWcHAxgaHrEjPr90z4+D8d1KUIIYey3zHx8fHyeLBZatwAAAs+JIT0U0ru7UvW6lS9UsrnC5FTmzt0JTZNCwYCnRi1Jgje84xv8TcbiBeV5rjUdj8fM8Ym5weHJqalMZ2cqGTcFgQf/um9oVghyWMnJQWRL57aOhCb7CtI+Pg+FupQQ5Oux+Pj4+DzRLM0RLMuiLIvJhOk4Tr1u5QqlXK48MDTRaFiqKpmmbgZ1PaAsOjw+mwzGmCDwnR3JZDI8MZG5OzAxNDzV1ZlMJSI8789U33AYWiCdaBF4kQFDD1dXAwBASJJkEWsY6o+pgj4+n82S6c4bC4TAcR2EkZcWbb2rsyIMwHfAfHx8nmDmlQIfl9jzUmPOcZyuc4ahtrfG67VmqVLNZktzs4WJyTmB4/SAEg4Hg4amKOIGjnx58t4C89KR61ll5N0Foih2daWi0dDQyOT1m6PTM/mOtkQ4bHjS/BsONj/b8om62r8uCFBrsjUa3a4pK0h6rqSuRunM3FS5MNCejIh+PlCf9YY6Nbc+DdRe74qsAK3UdDLLarLNNuSTQkRebQEkrHc9fDY5S4WpFwSmAeDzYzgpZQgtSGUvKebJapP5rDWulaf1zPrmiuUATBFCKehKiNUazedK2fzEteGqw/DuvvZU3NiYXV1I0IkUQ+gJGn9gk3kymecQ2jjnU2CqIUSrV4Ynztwa3dG3RdeNDZi5GCEUDThp033a7KcsyQoXBsI9qKKxoroaHRobHBm7GAsf9Z0cn/UG0UamNvoT18o/OKVs/aGsR3Xp5MXKRrQpDMvxQNfvENF3cnzWFtt2isVyLl90LLtWbWSyBVmWVFV++DPr9dCXK7VMrtBsWs2mlc0VSqVKIKD5eSp8luKURmrjPwf2xaTJ1w4MEEEopNImb9calGSvlSsbdCRHCO9VWk4CfmKcHATw8W3pzbPKRjMACAVdN2E3qx9nRcwJG8/HAY7AV3bXvn2w9pQFUbLZ7FymNNvV2a9I6rIXx8oS0rZjNxuNjdkt4fP0QZnbYE5jAw7BIgAOA1BnAz4qjDHkNjdgb5PP5qNQKP3dm29//+9+PpfNn794/U//4/d++zdfO3hgN/68hp/ruh9+fP7v33z77sBouVL5zp/9bbNhvfH6cVkWfSfHZxHGXObWgbnrXZF7eOFUEg8SDwA2deyNecMyulE8w0fHclC1uSEjwhgBYrgugMM2YIOEYGY7G65Waw0DmJieuHRnPBHvVSRt2doV3D3EgON4QRA2Yse5j89qwRhDBHgDEIG18+cZAywCFn1Xw2cTI4pCsVS+fPV2o2GNjk1evXpHFPhHmZONMRYF/tPTl6emZ8vl2sXLNxzbFoQnptfZ58nGs8+8zgD9mv1Bn93iZcAAsMQQ7/c4bQQQYrqMovr8/zEDGQrC6NFaAYuXeeN5OE8zjutYtkUZffCqrPAuQQi1p9oN2RL9KBefTQxCnNYrxo9bs+/ZxRvzzwYDwAQYA+YCAgYYIcLYF+wbYQCIADBgLgMsmPsRFq3Z9wDc9Z1K6eOzRmiacvyFZ3/4k/cyn+Q1TTl+/OCW3o5H6SbDGO/ds/2lE4cGhkYtyz6wf9eBA7s5boXQah+fVYYxhrAYPsgFttYnf0zrE/MCawAIcYy5COi8MUfoiw4iLRYCjCEii9HnaWPGKl5BvqOz3kg8OrlXbI0QywEAQAhG59xfXm5UG49YAOMwogxc6ns6GwVCOFEQMcIPylWsJCGNcSqeTpoEsdrjqZ+Pz2OGMYawIJrPCMYu5lSdyhC4DUAIMOH07dQuudVhxBAWw5zSZpdugFt7dHvGEOa0HkYttzYEjIHbXIj89C3ik4ofu/sQEEIY421bO08cP3Tt+p1tW7pOvnhEVZVHPG1BQ3/tKy/8/O0Pi6XKV04+35qOw8Ke/mnfxKy7B8sAMB8UzP1E7XQqA83GFAAAYwiLvNHn1CdoYwaAETmFRdMpXvtCfg5CHB/c5dan3foEMMrcBqOW/wLYCHAEtUe5iaxzacTBCBCCco01H1nYiMNoRxuXKdHxrOuHO20IGKTiSV6MK5L6oAzjSnNyGGtaDbtRU0SKV4pn8/HZBBA5jcV4ffoXvL6VKK1O+Q4AxoIpRp5z6lPMLgJzSaBHjByhbtmtTTK3CoAwF0BEZrTJ7BIwFzAHWAZmYy7AAJhdZMzBQlAIHwC33nBKzC7ZpeuAMCCCiEqdKmIuQwgRBRgDt8YQwbyOsMjcOnXKiPm9QxsRxhil1HboGkY2PtkgjuNfPnH4408uHD92sLunrdG0H/U+Rmjblq6TLz+fmcsdPLiXAW40rDWtq8/6QjjCkfXPp4kQ5vVtjNrN2ff44C67cJE2cwjzWE6KseMof852G8AoH9zNqR20MUftPHMbCAjidUQE5tSoUwHGEBEBYQCMOZW5TeqUABCRYmLsuJW/xJwKdet24SKjNmAJIczc6sJIj8qow9wGwgLidYQJtavgVAGts3zypocyGMvQqyO2F1HrnWuEQOZRQMGMseKC20Mw02QsC8h2WLFGGYNwgBzbIdyedCsNWm+AwCPHZU2HAYDEI4SgbjFFQJSBwCGEoFSnAKDLWOJRw2alOmXMv7irCUIoHo7FYhHCqw+uXUlCmtE7w7enpq4c2bs7oC6fxOPj8+TDEOb44E7XyllzH3FKijd2OJUBRGTB3M9pXViKIsxRK8Pruzi1TYy9aOcv2blznN4rmPsRCTBmWbmzTuEyEiJi9Ah1akROYaLYhYt24YoQ6uf1bUBthog19wFR2hARnfJdIfqcNfexW59AiBcjz7tWxslfFoK7+NAehBVGa83MKbd8G5jr+zkbDcrYxFR+dDzjh1B9JgyqDXz4yJGWdPrG7ZlH3w8B2LbTu2V7Ot2YzdZLlaG1q6PP+sIYAKPxmNHZHuf5dZUjYww4jQvudip37cJVJdDLaVus5ikkmELkCKe1ASaIKMAcIdSPhaAYP2HlzrrVET64WwjuAiJRu9Cc+9itjvD6DqKkAREsJYDWG7PvM6sgRp7nlDZAPMKClT8nGDvd+gwgzAW6G7PvMquAeUOMHbOL193GtGAe4PUtgAXanGvOfejWJn0js6YgBAEZRfX5aYN1i9WaLB7Eh7eKqRAGQHen7Y9vWpUG60lyB3qEgIwQoLMD1t0p59ktfEec02Qs8XD6jr29lZsr0qujNkZobydPGZwfsA72CrqCZQEVavTjG83uJLe3k1clVG+yU7ftG+M2pf57ZNVgAJS6LnMwRxFablVWVlfLl3JTs1OO2/dYaujj83hhgKUYr29pzH5Am7N24YoQPkDEiGvlneJ1N7DVacxY2TNALUA8FkN27pxTHcFyQkp8xancccqfEq1HSrxcs7IIsGAecMp3mnMfc1qHGDvq1ifs0g2idYPbsHNnqF0Q5cPAyXbhChaifGgvbUxhKcYF+9ypt4jWJSZetvPn3do4F9wlJ1+pWhnamPOt30aDUTY9k5/NWi2pNs7PeP0ZSBr76hudGGFMvlgIgMTYgYNpACDYE1Tyn4DNCaV0amrasnOt6cj6OjkMGK91YiHYnPo5bUy7tQk+uNMuXGJ20S5c5rQup3jdLl4B5iIhxCltdu6c25jhjZ1i9KiV/ZQ2M7zZLyVfqY98D0sRIXa0MfUze/a6FD8hxY7XRv/GKlziAt1O+aZduMyoxWkdwBy7Osrp27jKkN28QNQOonVbubOCuZ8P9VuZj5lTESJHxPjL9dG/AVr3n4K1g2B4foe4pYXDCCiFc4PWxSH75B5JEtD715qqhE/sEuoW+/C6hRHcnXIyZbotzR3tE6fy7tVRZ2sLNzDjnhuw603aGeMAHAQII2gxicvg4hDqipPOOPfTC42BaTcdIa/sFS8M2iMZt6+Vf3WvOFd0Z4vUv76ryMDo0N2J888feD1omMtWfdbbGiG/M9lnU8IYA8QbOxFvADBe6wLqYMHk9T46977bmKR2kTVn3eogIIzqYWqX3eowbWbE+Akshln5FhZjAID5IJHTtD7BaN0uXnXK16k1xxt9iChOdYRaOXBqbnVwIbgJUbvklG8Kob1W9hSndoFTcWoTUuwY5lQGBIsxoA4Wo1iM0cYMwAZNufA0gzFOJlJ79u4VBF+Rxcfny+C6riTdyGWG13f6PWMMYYkP7QHmIk7h1A5qF0T9MFFanfItWhtndsltTLq1UWCUNmYYbzjVQWAOH9qNOAUwj4UIY5STEliMAABtZOzceWplbTEuhPYCIFobZXbFrU+5tVHEB7wWLa1PudURIbjbqQ7x+ja3MkSdihDqB0QQkREWGHOIkka8QRt1vwW2dlAK18fsqyM2xogxNlt0wwG8Pc3dnHBMnXAYKEPtUe5Tzs6UmK5AZ4zoMjI1JPFoNOOWamw67w7Nurp8X5cMWpDoQxiNZNwzd6yGDfu7pZBGMLbjBqGUhXUcC+LZIl23L78JYYVycWxyzLKbD86SWkl4AMDQ9Gg4Sojf0vLZbDAAJBh8sA8RUYweBcYAY0QkPrS7mTsDzEYIASAvxhohL2IXAcKISIAw5g2GRUDILl6hzVkAxOyq25gFwMBcoBYgAuCVgAAwwLwtQwBu6TaYB3hjJ6d1OqVb4FaBSAxhLASBqoCwVbjE7KLfwbNRQRgTQgjH+SM5Pj5fBoQQIWT9I3UQIkqKD2wBRqXkq8AYYA7zGh/c41aHFvp4EcDiuKJnzDHCEsI8FkxgFJhr5y8xtwaMuY1p5jYAMKMNAIYQWZj/jBe6ixkAMNp0Sjel5Ku80YfleGPqLaAOYAlhjEUTGDCnaucvgS9RsMZQBiOz7oWh+Tk5wKA7QQQeKQKKBjACGJlzx+ZcRUAv7RaiBhmedRwHEAKC528NjBBeUMrzCiEYDBnlawwAXAr5Cm3YQDCIPBAEQRWrImAMF4fscs2flLPKeOI3KzadVpSQxr2d29oTqiz5qgM+mw2EsBDYBliqDv0Vs3IACIBhOS0nX+W0bqd0nVEXC0HE6eA2GLURFpEQRnbZrY0xt2ZX7rrlO4g3sBh1a5NEjgMwoMtUdxhQB/NBxBvMLi8e2G3OOpUhMf4itUtW+eeMWm5thNd7ndJ1tzaOxQjiArQ55wu2bFwQ+NLGm4DFUQT/Kj5+NsCjwxBwfGif28w0Jn8ErgWAACgX7BdCe6xMjNolhAgWTEQU5tYAKPABxOvMLjmVIcSpdv4yteawFAfE00YGDADmALuvb54BBUBYCCKiwsI8AYSQUxmkTlVOve5UhtzaGDDHqQ4SKWFlzzG3TKQWxhxmF9fjtDxlIEAI8LxoOCtU2WTOzVXoB9ebBKHWCBnLOpIAnXHu09vWmbv2vm6OIB4AGAOXspCKdGVecqAtQkIaCqq4K8ldHJqXaXMpIABKYSLrVpvs5pgzknHDARyQ0UyB+soSqwgCMNRAS7xF4EUGDH2uuhpCSJEUmehAq4+rkj4+jwXGgIhcYItbuesUrzE2b49QM8cb27wBFqc6KkaelVKvN+d+RZsZ5jalxEkrd9YuXrULl8XIERroRVyAWhmnfJMxlzo1ANcrnLp1YA5Q161P8ImXpdTrzdn3GG0CxcAYY027eFkw+2l9kjUyAMwu3uC0LjF2nFpZzAed2ohTurGe58fnqWeJajOCJ83hXio5vaIj6glTu5Q5lHEYEYzW2l/93Cr5PGYYAywaRErY+UtOeWDR52XU4fWtRG2jubNuY5Y39wHmm3Mfuo1ZkUhy8itW7pydO4ulqJR8mdolzAfs0i2nfJu5FnMb86VQm7k1AAbUdmoTfHAPIGwXLlGnzqjNAMAp24WrXMvrTvk2uHXGqDX3kdTyVTn1GnUqmA9Y+YuOf6usJYxBzaK2szRiEhWq9FfXraPbxTf2IwTAEZQpuXMlNjzrbm3hghrSZVyoMsrAdtnYHO3v4nkO/ep68/qo/Uq/9M1DkutCvsrqFkMAdYs1bQYACKEb405H3H6hT8hWqK7gsYx7a8JZr+++KWGAWlOt0fgObSWltBUlpGkmP1ctjSWjuoj96HOfzQV1GnPvgVNlzEHzQWXAaK0x8SMgImOOnT9N7RwAArtM3Vpj4u+xnKD1aXCqjam3iNKKhSCzK259nNllSp3m5I9pM4sAqFttTP6U2UVAYBeuMLeBMGF22cqeZgh7HXtudagy8KfMLjNwECDmlOrjPyBqG+E0yyq4tQnmNvyXm886QhlzXIYQcAQjtiE63h8RxoAx5lBgwPiVvBfGgAEr1uybE6XZktWXDnTF1DVtTzIAxpjLgFLGc/iJOZWbHebU6pM/ZtYcIDTvyDNGm3P1sb+hTp1RpzH1M07tpG4FXMutDNbG/hbzAbcxS625+vibvNoKWKFW1q1PAG3ahcsIC8BsAHAqd93GLHOqDGhz5pdOdQjcBrPyzdn3mFPzjmPlzri1MbcxxRgFANqYrI9+n1NbAQm0OefUJ32BzTWlbtGfnG0U62zxgUQIPFW0yZybCmGbwlSOzpVcxuDH5+rpEJFENFOwEf7/2XvPJ7uO7MDzZOb1z9/7/KsqFICqQsGRBAmSINtJarVRG2mkkUYmRhOxO7OxsZ8mYv6OjdiPuxEbsbExMzHbo5ZC0vaq1VI32zdtwxGmCuXNq+e9uzbz7IdXVSgARYIEXZN6vwAQF/edzLw3z01/8iS0BygEvLbs1bqcCxg4cGs7aA/tVJQ2+2LoIhfoBfjT244f7FcsXRu/95Yzk5SiOumM/L2mGLmThZwPEwKgabrO4oTKj5paHOtCGu9tLm9vX/3mF7+kypNBzoTPEIQgBny4DfBAH4ggcrcOgASI8AeifWP/PkAw3Ibh9r4ct4P+vbGF2zgG5HYw2hlfExFwuzi2DkU+8js3jySM4wEVcpcPNvZ7juPiGAyC7p3gfpwwqf4mfCIgIiDuNe3vX6/mEtrvXEiFtU9+9xEicgGIyCihjxkmoOOLX95rDpzgdy+mI9qj4xx0ffHKrdo/XK2k4qoZVmZTIfYRlDZE5AIRkVHqcXxzrVXuuF++kLLCymSG/hNnXG/z4f16eHwXkQf7TQMIt+G5jcMgQW95PywA+l2v0znaCgivfVjDC78Pfm8cqfDaonX1IIrhYXIYDILB6v02CFF4Lc9rjuM8nHqb8BERcLLT4OTB6Q1CCBdQbPK9Jof9EyUJAPRGeGcUHDgUgHGori2ubdy3TtyoBpvV+wIApNwW9+NHMnTwbtEnAIjjDV8T/X6oILa6rXa/MzN9QdOMh7L3eBfSPAh8358cejfhs8e+X4Hj7sJxzmsfFT16+4HYDicFj5kcPk7+wXQnY5sJnzi+wF9vdr77WnE2bSzkwgv5MP1EW2RERIBic9QcemcLEV2W3uVhCIDPxWZt2Bl4n1+0IvrDrRsBGLnB0l5/JmX8xeenpyyd0o/EIE8g7jRHA4fPZcKIuNuw16uDl+ZNMzwp5L8RHNsKHL357p/Zu7QCD1w/Gu7Y1CetwMcLeQc73KP3H1DPw3cerhOPEXgggvvD1sno5qMACeyWdm+tlUzrhKY9fB7ocXtyECRJUmRloo4JEyZM+JfAeEqrOfDeXGsnIkpn6F/f6s6mQ5qMiIAAARcjl3MBhkoBgBEiSxQRPC5slwMBXWaIKEkUEHyOhIDrc1miusI4x5HHhUBNYaq8vxwjBNq+cAOuSlRmVCCoEkEgrs8dXxACIZUxShxf/Hyp/vZ273/56qkpS1ckygXanvC40GSqy+xwZhQBDFX6vWeyfiDihhIEGHCOBFxfUEIMlRGAvhOMnCCX0MywrMkMAFyP2z4nhBgykyWCAAEfr8OA63P1wO7N48IPhKEymdGRx7lAXWaKRAkBBHB84XicEjBUSaKkbwc/vdMotux/+/npbFz7rfPJF+YSqahKAIQQboCOzykBXWEyowDgB8gFIqDjC4kRQ2GMkke6UhMmTJgw4Rj8wLddW6B4tMo83vHAifxsXPc1Vf0YHm7ChAkTJnzCIAYCb233Si37W89m7xb71zfbX1y0CpYuEOo958219npl6HKRjakSI6fS4UsnY5WO+8Zqa7dpEwK5uMYRnz0Z1xX2+koLARsD/7mTsTP5yLWNznKp7wc4ZemfWzQLCd12+c2d7s3tbncUJEJSIqRoMn35jNUe+q+ttModhwC5MB25eCJ2Z7f3q+XWTmP0N2/ufW7BWixElvb6N7e6fTdIRdUX5xILubAsscOB025zNPJ43tQ2a6OrG+1AYL3nMkKenzMLpvaT2/W18rDWc5Mx7atPpbuj4M21ZrFpU0JPZowr82YyoiyXBrd3u44vmn3/0mzM8Xl74HWGfs8OTqSMbFxdLQ+6o+BUOvTb51OJsLxeHb6+2iq3HULg4nT02ZOJN9dbv1hqtIe+JrPLp+JhjTX7fi6uCUY2asM3VluljitRMp8Lv3A6boaVO8X+7WLXC7DRc1WJXlkwL83GFYlO5vUnTJgw4bEwJimyQgl9dLfTcefkUJrLFDIJysD+eJ5vwoQPHXzAruCBXz6ETX+IQAiRY1RJCLcp/N5k0nXCpxoCMLSDX91rRjTp84tJXWZ/91ZptTLImdrQ4f90o/aDm5WZZChqSL9YahSb9h9czudM7buvFd9aa5+dijIG379eaQ+8qC6lIup3Xy3qKlucjvocf3y7/v1rlbypayr9wY1qa+D+xedmlvZ6//dPtiklJ9LG8t5gtTw4lTIW8pE7xd6NrU4iotQ67tJeDwF8gQEiAPoCnEBc2+z8zet7uspSMe2N1dZWdfjvvzw7kzTGliA+F9c3Oo2+d/lUYrsx/KtXi7GwMpsyig17tdT/48/PeAI5IEfgAht9929e37tXGpzMGr4PVzdb5Zb9Jy9NbVQH3/nlbkSXFwuRoct/dre2UhosTkV8jq/ea8QN+UQ65Abi2kbbjMhX5q23d7o3t7uJkFzp2Le2u7JM3UBwBCDgc3QCsV0c3dvrXzoZaw/9//zzne366HQubLvBtY12vev+4Yu5lXL///llMRNXpyz9zu5ouz7KxLQTSWNSqXwwxjsg4NH6HgHJ4Y9PHjsSKhE1RYnEnRoId2KN9ElzvKcUPPIpPGG8CACoSCQVowSg0uEBn6y0/saAJJ/OSWrG0EP3u34HHOtdDT3fC1zHUCa7ciZ8WiFApdgFZkw/+MUHQXeZj7Y+YOQIwNSMVvgWIbJTfUX4vQ8Y4YQJnywCcanUu7PTvXLGUiSat3RGyasrzWdmY9Wu+/pq68JU9C+/dCJmyNc22v/7DzZcXyzv9W9sdb52KfMHz+UogX9+u/bff1UMOCKCxMhvX0j90YuF9tD/b7/YVSTypXNJQ2XI62+stJ47lXh9tUUA/qcvn1zIhSsd5//44ebQ8Rmlz55MJEIK57hVH77ydq3Wdv7wSr7asq8B/OlLhbAq/Z8/2ujZwVefSaejWkyXfn6nvlIaTJk6OzjULRDocQQAgSBR8q1L2a88nb663vm/frw1coJvPJ3erQ2nk/o3n8nc2O7e2un/wQvZrz2V4QL+6rXir5YbT52MIxKFsT96Mf87F9LNvvfK29Vzhcj//JVTXiD+179fiRryf/jyySAQ/9s/rK6VB1fmredOxs2QwoXYqKnfv1bZaY6+fSlX6bjbjdGfvVxIRpS/eWPP44ILeHO9vVTs/9svzvz2+eTI5f/1F7s/X64/NxcXCLpM//ULhZfPmL+81/zvvyzuNEYzSeOT/CA+AyAQpsmJS0y18GhfRrhe66rwmh+wi0oIk83nFetFPtzltR+D536w+CZ8UHSFPD+vRPUHdscMHXF9w2t/0PNQUGLkpTPKs6fl9XLw49tiYE+6x78pEALpZDqTSVL5mDrz+EHO5u56rXL38oXFsPHwJp4JEz4dEEKkCFWThFA5tiiCER9uo/BB0j+UyFlkjlDdLn1POOUPIcIJEz45ELHnBK+vtht9b606+C8/33Z90R35V9c7a9WhQHADfqYQycZVmdHFQiRnalxgo+9RSi7Nxq2IAoRcmI79U6g6njGNh+Qz+YgVUootu9X3EPAnt2uEkN7IN1Spa/vNgTdlGXPZUFiXTsj6uULk6kbbC/hm1X7lTt1zOQewPe4GQmJUliijRJepz0Wj7/VG/q+WWzIjtsdDmsRx7J7gmC5rLKws5MNWWC1YuqExLxCKxCRKZUYVmXZGviLRxXzUDClI4MJM9OdLjVbfowTMqHwmF4npUncUKDI9lQ3nTW3kciuiZGNaLq65Po+HFTsQIy+4Vx789E7d9Xkg0OPC9oQsUVkiEqO6zGRG97cMIdS6Tkhj56YiMV0Oq2yxEPn1Rrs79AkBK6rOZ8NmWJm2dFVhjs9h0on64BBKlRhVk4RpUnieOyXhNpHbhMofNGZEYLKcuMSHu27tFQgGH8bjTvhAMAqJME2EaFgjp3PSTo23hkKRUJIOvaM9OSGVPHNKvrXtv7nq2xMf0L9h+L4f+CODxdjhdNcBx3pXw0artrm39fTi3MfyeBMmfPggcr/5qt98DagcOv0fuF1yin8PAAAfwmHDBCiV48KrCbuIIpgsW0/49IIACLBVG93Y7Jyfip7OhglASIVLJ+O/Xu+8ttJ6+YwpU7rbtDtDP2pIuy271fdOpEJRXRIC16vDhVyYELLVGB5MwtsAACAASURBVA2cYFwUZEY1mQIBQ2EhTTJD8jcuZXWVVTuOxOhcJnxto1Nu2eW2oyus1vd2miNErHXdH9ys6gr711+Y6Yy87/xydzwBTwG4EJyjIrOQKqWj6pcvpJJRtTPwBi4/NxU51rU0IUSWqMQoANBD99MExq6OCEBIYX7AKx3Hm4pwgaWWTQDDmtS3A1libP+gUGSUqDJjhBBCGKESo5QCAFACAKTZ935wo6or7M8+N90c+v/5J1uIAAgEgAvk+0eBjo8FhIguu76odNyTacPxRKXjyIwaKiNAFIkyiQAAo5QxgjipUj4M+Mgt/zMAUi1jnPgLr/Yzr30DAAHE48M+FqoSInF7R3gdmLiJ+A1g4MD/+6ZDAKaT7M+/YPzzDeduMSDjJv8Do8pEorDT4N2hIB/5GcIT3h+75d2tyt0Xn/1KLJJ46KfjjkFAIIQAIooPoyKYMOGTYOygHkAAUgAEREROqMRCCwCcKhYKL+jdZcaUZJwAqnKnEvSWQHgsdBKIRCSDaRnhNvzuXRQ2VUwpfJrKscCp8MGGFJqVIvOUSnLikt9dIkCkyAJVLUQ/GGyKURGAs9BJwlTCQgDIR7tUyyJ3mFEAxGCwRiRDMmYRfb97W7gNQKBKXIqcoUoCg77fWxZug8pxFppB4UpazuvfE3aJkIdnKSZM+KAgOh6/utH2ufjzL04/NxsHQgCwNfDdYP3mZufFOfOp2dhba20hMBGS7+71yx3nMiVncuGFXOQfr1fqXVdicH2z2x354yjJ/ilQkImpVxYSb6127uz2Yoa8Vh3Opo0r8+bzp83vVHb+y8935rPhcte5sd3NRlWBAAgjl+82R9uNUXOwf4xBSJOaA//716sXT0QvzMQqXef2bnfGMnZaNqPk8ukE3ffJ+3BfhhKgByXmEafuZC4bLpj6P16r1DuOy/HN1dZiIXI6E7qx1aVHjio56NA87HWY7GceoMChE+w07M3asG8HKJBSEtakatv+/vXyYi7K+f4DPD0be2O1+bdv7m3XhiOPv7XWfmomOmUa69Uh+Uh8Wf/LZl+FHBEBxf5hsMCBqiwyD8JjaorbJe5UpfAppmUBaDDc4MNNIIoUPoXCZ1qGMC0YrPPhFgBSPSeFTgJV+XBTeB058TTTMlLkrPA6wWCDKKYUmadyFINB0F/jbo0QxsKnAZCqaeE1hNukWpogMj0vgkEw2GB6lml54XeC7m3h94FQpmWlyDyRDOHU/d4yBn2qZqieJkCpHPW7t9HrTHb+vAtCAAAKRDw419gKk+mkFAhIRsm9vcD1YSEvmRHqB7i8F5Ra3FDJ6YzkBZhLMInBvVJQbHBKoWCx2ZTEGKyWgqGLz52W01F6aVZ2Pdxt8EyczeWkkEb6I7FSCpp9lBicyTNfQDLCKp3A9SFmUEohF6edIW7VgymLZeKs0eO3dgLbRYmSvElP5yRdJqU2XykFIxenLRYLUZkRTYFb2/7Awclw6rEgYrPT2twtXrroPTqDfdwgh0A0nEiaKcrYx/GAEyZ8hDx0VoGiJF9kWkq4Lb+/RqSYYj4PRCFMkhPPOAB+97aceFqKLPBRCQhTrOcI1bzOdS3zu0S1MBiqxrTjd4kUoVKYUEaVBJUiSvIFFjolnAqRQnLiGaf8A967J8efkWPnuFPhgw2h2Hr+W9xrY9BnWk6xLguviUIwY4ppGbv4d0BkLfd1pmWE16HqORY6YRf/nqiWXvi28FrC65HB5ieUgRM+4xACLheEkM8tJs/lI5rCxgOGdJR++WLq9eUmo+T3nsmoMlvZ65XaTiIkZxKaxCCX0P/kpcIP365tVAcyo3lLbw1chdF4SDk3HY0aMgBENOnbz+YoIcvFPkdMRdWFbCSkSs+dijs+f3Ol9fZOJxZS5rMh1xf5uPbli+mf3Kn/crlphuXnTycKps4IOTcdnc+Fb+924yHpyrxJCPx6rb1TtyOG/NIZK2ZI47dABEbJbMqIG7JESSqqXpiKhlUJACKqdGE6mompqkQXsuFUTGEUpkz937w89cO3a7/e6ADA4lT068+ks3E1E1PPT0VDKgNAXWFn8uGCqRECEiMLhXDCkCmAxOh8PhLV5HRU/fJT6Z/fqb+20jTDystnrClLVyVyfip6d6d3c7OrSiyf0ASiKtP5bPjPPjf9o7drb661GCVPz8a+9nQmEZZzMe3cVNRQGABEdOnidDQZVSaDng+Jh0e/hOlG7msChXAb3GtRPaeYl5H7VA7LiYujnb+CYKTlvooohNugiinHz422vgPI9cK3UQSAyFTLa71F5ARhGlXiVI5QNaXnv05YWHhNGjklRc/ae9+DoK+mvkCVuPBaXnvItII+/ft8VAZuy6Fp2byMfh8oVY0rDlXd+s+YntPy3yREQT6SYxeoarqVVyRjWpv6FndqYlQCMumSPYZxPXCUZJT+qyt6q89rPdyq8ukkfXpWHnmYidGTGemvfjUyFPKt57WBg62+SMXofF76zi9tTSZ/8II+dFBiEFLJzS3fjFBVoYkIDWkkE6d/8ILGKLQHuJCXzhSkv3/T9gL4yjMaY6TWFZ0hn0myL55Xik0RcHxxQWoNRX8kVJk8PydT4ryx6k+n6Lcu65yjx+Gpk3I85P78jn+mIH3urFLpiGKTP2J4NeF4EMDzPUIIY9J7cjxACV2YXZzNRkMa/7gecsKEjwWChKrAPbv49+h3kVCn9jNCVSrpSupLcnQx6K0QIhFC3eqPhFvXCr8vxc77/XtUS3O74rffQsGFUxNOhek5wlS39jMpclaKLNh73+ODdaCqnv+GmnxpNCwSSQNAu/QP6FRYaBZkQ3RuOJUfybELxok/d2u/8Fu/lhPPadnfoVKEhU9K4Tmn8s/cLjNjSst9VQqfwmBAWCjov+nWfgrIJ1O9Ez4KECGqSX9ypUAI0RU6XoMBIIzCl84mXzydAELKbfvKXPzrT6cJgc3aaLM6NMMKIgYCf+9SJqzJXODVjfZGeZCMKnPZ0EzyhCaz8QLIlKX/uy+e6Dk+5xjSpLAqMQojlxdM7d9/eZZROnT9//bLXUPBVFQ5lQldPp3wuIhojBEiMarJ9Ewu8p++Pe94IqpLYU3KJfQvX0i5vtBVFlYlRSKEkLFdmCrRrz6dQQRdoU/NRBdzEU2hiJiNq//jb80qEpUo+aMrBUpBYZQQ8uzJ+Jl8eOhyAhDWJF1lDODZk/GLM1FNZgDECiv/5soUpcAoCSnsT16aIgQYJYZK//iFAiGgyvSrT6VfnEv4HMOqxBiRKFEkem4q8h+/NWd7IqJLukQDgSGVEUJemDPPT0WHHqcAEV0an/Pzwpz57MmEplBEmE7o/8NvnVCkY03wJnwIEAAiJ3j7urP3/wF6QFWn+goQRuW4XvimFJr1O3eoHPd7d+3i31LFNE78BTMKwmlQJeE23+T9NRSecOrC70uhGa/1ut95W8t+jcix0fZ30GsSOW6c+DPVesGt/pjKYQxGo52/Qr+vmJeoHLebfxv0lrT8NxXrhUHp+8IuYu73pMgpr3VVTX6OSlG79A8YDOTEM7J52WvfJJRROTba/i4frABOumTvj7Eb1ESI/PCG/+t1n3PsjLDRcynB6ZT02xfUVJQOHYiH6bV195Vbbj5B//Tz+pTFbBfjBrm24RUbwvZEo4c/ueXmE/Snt731Cv/WZY0L+OvX7O4Q03H6Jy/pF08o1za8WIiuloK/ec12fMiZTFPIz++4Ow3+r17UF/Ls795wG13xhy9qZ6fkO7vBy4sqAXzlluv6eOWMcnlOubnlKzJRZfKjm85WTYgPwxHsvxAUWc2mCob2HhwPjJfGNM1QpAQETSHG1oeTjJ7wWQG5P1gXfgcAqZRQrctUTiIIqqUEckIYAATDbe42QHjCbTItC9x2G68p5nNa7hvcLrv1XwivDSAABaBgWhr9Ph/tovBB+H5vRcv9LpEMQOD2nnBqgAIQ0e/7gw0UHneb3K0Lu4LCE14DkQNVqJYlcliKnpciC0Al4M540k743WCwgcInhEysFCZ8FBBCGCERfX/acLyJHxEoJSplqsxqXef716uVjv30bFyR6I2tjqayM/lIo+9+97UipfTCdNQNxJurrUJKn7YMRaKqzI7Gb6gkpDIk+7bQXsCvbrZfebu2WIik49p2fbhVt7/9XDaiS5rCMgoFOLCa3o8BUxEVDoJLFMYbfg5lEHFsYk0oHZ9VCgAqBfWgfZPY/RcMHZkglRiJGvJ40Yng/jSCSuHw+Rkj9+UJCWn3w4a0/dg1hWoyO/o8AKA8+MyHoWRGYoYcC8lHXRtryn11SBKJSJMp3I8SAhgM+WATxQiASlpGSV4hTAOgVE4QqgGACAbBYBO5I7ye8DuE6dytec1fy5FFKTzPB2uu/ypgAIiAHFBQLSOcOro1AECvxe0KVS0gDLkTDLcgGI53AQmnyu09FL5wW9yuCKeK3OV2iWlZQhWm56gSV8zLAEAkHYMRoQoACrss7NL+CGfSCrx/Gn2xXed+gIySUxn21AmZUaIqJGIQRSJDwMEIt2vc9bE9wJELIZVsVvm1Df/SSeX8NC7t+p2hHwhABC6QUcgl6Fo5qHcFpaTWEaV2kIlTmRHbw80aH7rjHXWk1sFSi3s+NHo8pJJWXwxdbPTFqaykyySXoJpMXlhQCEBIpY6PikQQoNIRpZbgAiZd7/cIAXLxzDMBTaqKNl7KO5pvxx8G6gu+WyoxbBfSKTYxWpvwmQLRHwIKQqiceEYKLzh73xN+T8t9nVBpfyuPPwQx3l2AAIgogs7tYLAhhU7ohW9xt+E1Xj2MTfg9ImlECmEwJIRR1UTugvAABPIRGW96JADCx2AIAAQEoEAQAID7u74RgwEGQ799VXgtIMxjOh/tMj0L6CO3JxXdhI+N+xtQAAAAEcOadPl0/Kd3gjfW2gAY1+U/vjJ1diriBuLKvPnqSusXyw1KSMHUvvZMNhs/5gjp/Tj3/wIlZDEX2anbK+XB3b2BKpGvPJX+0rmkIlMAII8ecHV/uDPewv+wzP7vT9gj2A+GT7pUej+/joTHB5/5gZgPfprM035CEBAuChcAgDAl+TKRo075+wSJZEyN9z2i8DAY7asKkQAB4XqNV73OTTl2QU19IRgVhX3fryb6A6JEgarAHWAqlaPIbQCByNE/9F6MGAxABONrQDEe+RAUY5s64Q+AULfxKgiXUBUIcKcq6Vnkw8kazhNDAGwPfQ4AENHJb19Ut6rBq/e8TJydSO1P/Ns+OgHCkRN1bA9/csu9uu4/Myv/1kVtoxa4+/sNgXPo2SIeoopMAg6qDDGDlttCCPACcHw83K03OkhXIHCB45jHPkUCAX0bBzb+6q7nc9RkwhFafQEAtgdcTAaz7xUhBAJqWkxSTXiw8Rpz3J6csRfpvd1a7d7XPvf5RDT2MTzohAkfOwjICaFUMYliMj0rvNaxckSOqNYVIWzAAHC/o3UYSdBfUeLn9fy3/N4ylSJS/LzffAv3PYo+pqLaX51B4feW5PgFOX4h6K9SNU2oxEe7H85bTpjwgSCawl6at85NRXsjnyPEdCkekmVGVZl+5anM86fNvhMQAnFDjhkyo+Sxnz2j5HQ29O/iM52R5/hoqNQMKZpMCZD9NZmHnuAdrj+c1/toYn6XZ/6IUpzwRBBATpjKFIuqFpEj7+SIi+pTSvKKcCpECgPwo/t8EIXXvqYXvqHlvz2enKJyzG68BvjeXDftd4q513xTy31NiZ3jTo0ZU8JtBYMPeqTbhIcQAgyNZmLsTF5SpHccS8yk2POn5VJbhHTCOcIRb4degNfW/a9f0r59WSu1+Ik0C2n09q4bvB9HXbaH1zb837moLk5JrYGYTbHdJt+qTqqE9wciCiHWdrY8ETl3JiNJ8N4cDwBIklzIzC6tXC3VKrFwhFI6WTab8GkFhd9dRr8DACC4318TTg0AEMHvXCdMYdEF9Htu8w0AQBEEgy3AYDzNyp0qIRIGQ+G1pOgCEMnv3PS7twGQD3eAyIiIftsu/5NqvaTEzqEIvObrfus6IA8Gm4cTzcIf+t2745UcwYd+9zbyERCKft/r3EHuiKDnlP5RsV5U4heRu173FghX+H2/exeD0aQ39BvCuErF/YNZ/gXBKFhh2QqPzaoQcWzVBjIj6ZiSjqkP3n989hCAiMYiukEOVkvhwX8nfCYRQgjxwc8seb8QwR2/e1e4TQQQ3PW6d4XXHhuuuY1XFfOyHLvI/ZZT/TG3S4he0L07dgyNIggGa8KtYtDDYChFzgAhbu2XfLgNQIPeXe40ASAYbNiVHyqJ5+T4BeSOU/kh768gkYLeCneqOG5N3JbfW0bhAQB3q6S3PF7V4U4T+vdQuEFvyWGqEr/A1IwIuny4Dci52/C79xD9d3/DCUcgQwdvb3vdoaAEuiO8uxM4HgJA38Yfve1cPKE8PStXu/wnt92Bg46Ht3f8gS0IAT/A5T2/3hXdkfACODvFAOAnt91al2sKvbPr90YCCKyUAkVynz4pX4jIIxd/cM3ZrQtFgru7frPHxwvN5RYXCEIAAlba3Pch4EgAym0uEAMOb2/5MoOzU1IuQTsj3KlzRNxrctv9cHxef+YZtxS267x6/WoquXBu8fh+Ejm2RUHAwaD/jz/961SUvHzpOVmSJoOcCZ8QxO9vDDb+mrvtD/ARjr1ICyT7nloRBdk3KaFAZUA+tgfAA6OVsQAQCkAABRACVAZgIFxEcWgwg4gExhagFJgCggMGiAIOEhp7r94XAHEwUU0BxMFOgv1rIASIBEQG4QMED0g+kWELIjIjG53/S6Y+7Dl+wvvF94PrNzd7I3nhzDlF+cAnCU74+MF9WxQAmGxw+6TgnG9tbbt27cpzp3RdeY9VOiI69V+Pdr73hFZbR2rag5r0sNYFAALjVkAEB+fn4INV9OG+LwpUAQLA3YO5/YN4YPxVMSAKoA8Y4NjIbbxUDwgH9TmCIIj7LcuRFgFB7MsQGQgD4SPwB0I9yZsDACjJy6Hp36OS9qQRfNwQwP/6y/B33wgR+iTze+O2lBIQuK9ASkAgIu63+RIFRuHQkAwADgXGAREBASkhigwowAtA3I/zfjwyBYmBx4GLowntfw7jJe3xvM24vzCeHKPkgWtZAkr2k0A8GupJYBR//9Loz14eysevX3ymQESBeGdl+fu/+NXvf/Uvz84/TekxuxmPPwyUADGM0Oef/10iupRKAAf6nzDhU4kAODSFx8NLAgDAgd/f0PmQwP5JieN2io9tuI/+dDQQh8DeT+WIwGHM++bXR64P/iPuywgfwN+38T8qOVnK+aQhhBi6UixXb17vTfxefUrxbKyscM4hM8f0yKRB+wRARM/z8pnox1qIjtS0B6keqXUB9lsBcuT3Y5qMsZh95P4j8WAAIniwAt/fknnYChxc44MNjbgvIzyAg41nR3+d8N7Yz8X9gSc5uL7f5vt8f4RzX4tHVHGwikI4gu3uix356X48HgePHwqQI4kCjLV7ENXBNSEEHro+3OozTuVIqAmPJwh4pdU5t3h5dnrunSr04xwPAAEASmguPY2YdkdF3+mrqgJHi/aECR8bRKZamkj6pK//PsGxh59P+jE+C1BKTs5m0ukYTtx6flrBTs1f+eeia4uXv5TJn9TJZLD6CYAARNcU+f1NNSNhGjPyk/33TwBVwp/0I7w/EMAM8dNpf9LffL8winFDfOYbqEMDNCapl85/XtVTuh5+1K/amHd0PLDvVQTlzb3m2savnzt/LpNMs8lHN+HjBpmWDM18czK/8SQQRqVjPMdPeL8QQgxDNYxjXIdN+JSALHAVRRIBNxPhdCpCJo6aPz0o0VOSkZu0Ak8ClQj9lFnYfu6M+9SMN+lvPgGajJ/tU0QR9rfiNDvdRGI2lSoAkQDGpp3HTEEeP8g5WLEhAMQwrEpr9LO33vit569kkqljjd4mTPiIQEQqaZ8ie+LfSCaLDx+cyTL2pxwc25EcegNBMhnlfHIcO+f6ThBCiRyicuijfKLPOJ+iHQeIJGqI2GR27okYW8x90k/xUTH2+uN4zq3le2ulypeuTEdiMuy75YRjX/zxtfxUbvZ3Xv72yJPvrG8GwWSxeMLHyqelXv7NZpKHH5TJZzhhwofIpEB9zHyKWtJxbxUnf57oz2e+uXdc5/Ub13918+1seiERz+CRzVfH8m52sYg4dh49O336G8afIreZorte13YHhqZJTCKTE1knTJgwYcKECRMmTJjwYYOICCgEAgClkuOzgSu/dPlrF89eNvQQIcefrnbIuw1yDgMzJmVTeQAA9Iul8hs3fjaTyZyanrHipizLcOTUiKMpPXCTkMNDEA7lxvE/KHZgcPfI6Oyo2H7Ah8QIecyTvFOiD918B7HxnSOxjf1sjZ8E4ZHR5GPFHkz0eLGHE33g9d850XcWe+c8PyJG9pc8H5/oo3n+YNh3TPTBm+8k9kiev6MGPyZFf0iJ7uf5Q7EdvfkuiR7Nc3Lgy/ohDb63r+uDiO2/O+yXwcfF9s5ix5XoA6knzPOx5MN5fjTg+8rzAydJD+b5uEJ7b5n5bt/DO+Q52d8TeVyef0gafOwrHMm548UeqakeUvQxeU4OnKq+h4bgeLF3qR4fU6JRCDH2DjuOYXxU9rvH9ujrv1v98KAG4RGxR4vqw7G9Q54fK3asoh/I8wcUfV81DxeQBxqCx4g9WYkGMk7hPYntv/wTNATHfV0PZMg7a/A9ir2HSul4sXdT9OPEnizP30dsD+XbcWHfKdGHwr5TwX+3wvWRtfjHJ/pI43t8opSgeDjRB5J4rx/he+vafeCqGx7pjB1TuN45zx/7de0HPEj03fP8PSb6HhXtep7t2tVmgxBldvpsLF748udPqao+XmjBx9lhPsbDyeELH7yhnEicyKbO3dm4vbS5/YXnriycPOV6o+29bcdzKSHRSDSfyjImNdvNarMuUEhMyqezsXDM9dy9amnojAAgEgpPZackShqdVrVRFygYZdlUxowmXN8tVcsDezgWy6dziqQ0Os1qoyZQUEpzyawZT/jc3y0Vh/YICISNcCGdU2Sl3e+UaxUuOKM0k8yYMTMI/FKt3Bv2AcHQjZnclCzJh2KUkLSZSpkpz/dL9Upv0AMAQzMKmZymaJ1+p1Kv+jyghKTMVNpMcoF7lb3usA8AuqoXMjld1fuj/l6l5POAEJI2kykzKYQo16udXhcBNUWbzhY0VeuN+qVq2Q98AJKMJ3KpbMCx3Kh2uh0EVBV1KpM3dKM/6pdqFc/3gJBkLJFJZgBIuVZp9zoIqMjKVCYfNkK2a++Wd13fJ4SY0Xg2mQFCas16o9NEREVWCpl8xAiNnFGpWrI9FwHjkcRUJk8Aas16vdVEQFmS8+lsLBwduaO9Stn2HAIQi8RyqSyjrNaq1dtNRJSYVEjnYpGo53vbpV3HcwhANBwtpHOU0Ua7VTuq6EjM8dxSrTS0R4AYDUemsgVGaaPdrjZrAoVEWSaVsWIJx/P2qqXhWNFGJJ/JKpLc7LSrjRo//B5iCT/wdyt7Q3sIiGEjXMgUFFnu9DulWpkLMVa0FU94vl+uVcaKDunGdHZKluVOr1OqV7jghNCslUyZKT/w92qV3qAHCIauT2XyqqJ1+51SvRrwgBKSttLJhCWE2KuWu4MeIhiaNpWb0hV1MBrsVooB55SQlJlMmUkuRKVea/fagKBrWiFbMFStP+yVaxU38AEwGU/mUhkusFyrtHodRNBVtZDJhfRQfzTYq5a9wCNArLiZSaZAkHKj0up2AFCRlelMPmSEbXe0U971fB+AWPFELplBhFqz0Wg3x9/DWNFDe1Sql23XAcRELJFL5yiSarPebDc5oCrJ+XQ2Go7Z7qhYKTmeA0ASkVg2lWGU1lqNequBgBKTC5lcLBxxPWe3sjeOLR6N5dN5Rkmj0642qgJRYlI+nYtFoo7rlGrlA0VHC5kCY6TRbtWbdY6CUlZIZROxhOe7xUpx6NgHJTqvSFKr0y43auOCn0tlEtG4HwTFSmlgDxEhYoSmcgVFkjv97l61JFBQQnPpjBk1vcAvH5TokBGayubHBb9aq/oiACC5VCaVsIIgKFZLhwV/KpNTVa3b75aq5UBwSmjaSiUTJg9EqV7u9seK1qdzeU3RB6P+WNEESNoaF3xRrlfavc5Y0VPZgq5q3WG/XC97vg8AqUQyY6W4gEq90u51BIAuq4VsPqSHBna/WCn5gU+AJBNm2koDQrlebXXbCKApaiGTD+uhkTMsVvZc3wMEK2HlUmlEqDYbjXZDAKiyMpXNh/TQ0N4v0QTBjCdyqQwg1JqNZqc5Vs10Nh8NRW1vtFPecz0XgJjRWDaVpYTUW41aq44AsiTn07lYOGJ7brGyN3JtAEhEYvlMjhLabDcqjSoCSIxNZfLRcNR23VK1NLBHBCAWieYzeUZIo9Out2rjMphP5xKxhOu5xcre0BkRhGg4kk/nZEludlqVRkUgSlTKptKJaNzzg71qqT8aAoGoES5k87Ikd3rtvVpFoGCE5tK5RCzuB36pWu4O+4RAWA8VsgVFktu9dqVRHZfBjJVJmpYfBKVaqTfoI4GQpk9lC5qidfudYrUs8FDRFueiVCvvbraG9pCiyhGBsN6gv1ctBTwAINlkOp1IcsFL9XK72yUEdFWbzk2pitrr98v1shv4FCBlJtNWWggs1yudXgcBVFmdyhVCujEY9ovVPT8ICCFW3MpYKUBSblSanTYh+4oO6cbAGe1V9hzfIwDJhJWx0gCk1qjV200goMryVHYqpBtDe7RXLdmuSwmYsUQ2mQEgtVZ9rGhFkvOZfCwcGTqjYrno+h4BiEfjuVSWUlpr1GqtBhBQJCWfzkbCEWdcoh2HEEhE47lkhjLWaDVrzboAlKg0lctHQlHXc4qV0tAZEQKxcDSfyUmE1TuteqvOhWCU5dPZRDThes5etTRufKNGJJ/NK5LU2P9sUGJSxlGwSQAAIABJREFULpWOR+KeHxSre4PRiBCIhiK5dE6R5Xa3VW5UuRCU0Hw6Z8biPveLlVJ/2CeEhPXQVLYgS1K726k0x4qm2WTaips+56VquTfsA0BI1wuZgqao7V6nXC9zISilGTNlJSwuxF6l1B30CCGGbhTSOV3VOv1euVYet9FZK20lLCFEqVrpDLoAoCvadH5KVdTeoF+qlf3Ap4Qk48m0leJCVOrVTr9zv6gaod6gt1fdb/GTcStjpRCgVCu3u20gRFO0QjobMkJDe1isljzfG4ulrRQAqdarzW4LARRJnslNG7o+tEd7lZLtuwSIGY3n0hlAUmvWGt0WjhWdzsUi0aE93KuUHN8dV925dJZRWm5UGu0mACiSkktnoqGo4znFcnHkuoSQRDSeTaUpZY1xwUeUGJvKFKLhiOM5xcreyHHGqpnKFighjU6z1moIISTKculsPBp3PKdULY/7bNHQfomutxu1Zm1c22ST6UQ04QXebrk4tO0DRWcVSWl125VGZayaQioXj8b9wCtWy4PRAABCWmg6X5CZ1Op2qo1qIDgjNG2lkwnT83mpVurvixmFbF6V1XavXa5X+f2q2xJC7JZ3e8MBISSkGflMTlO03qC3VysHPKCEZqzUQ4rWFPVEfkZVlO6wV6qVx0U1GbcyyTTnY0V3EVBT1UI6HzZCvWGvVCt7gU8IScbNtJUhiMVqqd3vEQBN0QqZrKGFhvZwt1Lyg/uKRoRqs97qtBBQkeXp3FRIM4bOcK9Sdn0XABLReCGdE0hqzVrzvqLz0XBk6AxK1bLjuQRIPBrLprKMkEqj2uy0D/psuWgo4nrudrnoes44tmwywxhttJq1Vn2smqlMIRIKO66zVyuP9jUYns5OEUobrUat1Rh3xnKpbDwaPyJGYqFwLp2TJaneah6KZVPZRDTuB/52add2bQASCYXzB4ouN6pC8IOmPOH6Xrle7g8HiBDWjZnCjERZu9sqN2pjDWaS6WTc8nyvVK/090u0UUjnVVVr95qVem3cRo816HrBr65dXd/dCTg9t/DczEycyeGwcv8ooXcf4Tx+kHN0tIOIhFIznvrCla+eW3im0tiLmxmQTGfUuLNRbnUalLDZ6dmktaApWqlVurG0Hvi+rhmakYvFLXvUXtoqVxs1RJzKTeWy5xhTq63K1bvrQeCrinZZsUzTsked5e1auVYCgKnslGUtyGqo2q5cW97wPU+WleefTpqW5fuju5ulaqNGCMln8pY1p+jRRrd5fXnDdV1ZUS5fNE3TdL3h6m5jp7SDiJlkJps9J0tGs9e+trzhuS6TpGfORpMp0/NHa7u3t/e2ATBlZRKJU5phNvvt6/e2bHvEmPTMuUgyZQbCX9m9uVPaAUTLTJrmKT2U7AxH1+9t2/ZQkqSLZ0KWZQYQbJburW2vCSHMWMKyTmuhZHc4urmyPRwOCKVn585mMmcD5Fule6tbq0KIRDQejc4Y4WRnOLq1utPr9whl5+YWk8kzhMBW5d7K5ooQGIlEorET4Why6NZuruz2Bz1K6cKpxVRqkRCyW9u6s7rGOY+EI9HoTCSS7LuVW+t77W4LEU7PnC7kzgEhu7Wt2/fWuOAhPaQb+Vg8OXBrtzdKrU6DEHJq5nQqdYYwpdjYvn1vPQgCXTOMUCGWSDqjzu31YrvTAkJOTp1MpRdVqlRbpWt31/wgMHRD07OxuGX77aXNarVRQRTT+Zls9jxlSqVVvra07vu+qqgvKEnLSrqjzvJWtVIvA8BUbspKzslquNquXl3e8DxPUdQXlaSZsDwxWN6qVOoVRMxnCqnUGUUKN7qta0ubrucqinL5omWaSU8MVnfv7JS2ETGbyqbTZ2QpUu+1btzbsh2bMfbs+UgqZfm+vbp7e2dvGxBTyUzCPK0aZqPXGStakqRnzkYty/S5u1q8tV3cRhRWIplMzuuG2bWd68tbtmNLkvTUYjiZtALubZZW1rZWBQorbpnmacNItoeDG6s7/UEfCFxYULO5c9wPNsrLq5uriBiPJaKx2VAk2bWdm6s7/UGPMXZu7lwytQAAW5WVlfVVgSIajsbjJ8PR5NCrHip68fRiKrVIAIr1zdv3VrkQkXA0GjsRiSYHbvn22l6z0wSA+dmFbOacIGS3vnlndY0HPGSE9HAhFk8Ovdrt9WKr0yKEzp2YS6YWCFX2GttvL69xzg09FArnYzHLDtq31/ea7SYBODlzKp0+O9bg1TvrAQ8MXdeMfDyRtAetpa1KpVYBgBNTs5nMWcrUart8fWnD8z1FVtRn02bScuzu3a1qtV4hBKZyM0lrQVZDlU712tKG53uqqr0gpxKm5bqD5e1qqVpCxEK2kMmcVaRQs9+5urTu+76iKM8rlmVanjtY3W2Mi2ounU+lFhQt0ug2r93bHCv68sV4KpX0/NHK7ts7e9sAkE5mLPO0FjJbve615S3HtWVZfuZs1LSsgHtru7c3dzcBMGmmk8l53Uh0RqOxohljl85FUikr4N5meXl1YxVBWImUac3pIaszHN5c2ekP+oSQi2f0dHqR82CjtDQu+PFoPGaeDEeTvZF9c2V7MBwwxs7NnbeS8bGi762tImA8Go/FZiMRa+D6N8cFn5Bz80omswgIu7XNW/fWEEU0HI3FZ8OR5MCp3F7fa3VaBMjC6TPp9CIhpFjburO6FnBu6EY0eiIWTw37tbdXd7u9DqV07sSclVxQmFKsb9+8ty44D4fCRigfi1m237qzXhz3k06fOJ3JnGNULrf2rt5d41zommGEp6LxlD1oLm1WKo0yATI7NZtOL1JJqbRK15c2fM9TFVXTs6aV9Eadpc1ytVEhhE7nppPJBVkKVduVq3fX/SDQNf15NRlPWN6+ovcAyHRuOpU+I0vheq85/h4URX5RTZtm0nMHK7tv7+ztEAK5TC6ZPiNL4Ua3eVgGL19MJFOW541Wdmu7pSIiZJIpKzmvh8zmoH1tecPzXFlRLp2NWpYZcHd199a9ezvdYSiq6ZxECUt2hsMby1sjZ0QpvXwhlkpaHL2NvaW1zVUgkExYyeSCpic6o8HNlZ3+sE8pfeqMkUqZgfA3S8uHijatU5FIqmfb15e3RvZIkqRzc2oyOU8I2Swt39tYAQAzbkajs6FIcuCUb67s9AY9QsiFBTWdWgSAnerG7dVVRIxGIvHEqVAk1XfKt9aK7W6LUrZwciGVWgQCu7XNO2trPOBhIxyOTMfiyaFbvbVW7BwoOpU8o1B5t7b59r1VRIyEI3ooH4lZI791Z73UbNcJofOzc6nUGYUppVbx+t01zrmu6ZHodDRmjYatu5ulWqNGKJyYOplOLxJJKTdLN5c2PN/TVE3VMomEafPO3c1ytVkjANO56WT6jCKFqu3SW3fWhOC6rktKMha3XHe4vFkt1UqUkOn8jGXNK1q41mtcvbvh+Z4sSZqeTVhJzxvc264VK0UKkMvk0ulFiYXqvX1Fy7L87IW4aSU9b7CyU98t7wJiOpmxrAXdSDT77XFsiqI8czZmWmbA/ZWdm9t724SQbCqbiJ/SQ2ZnOLi2vF8/PHchbiUtX3jrpaX1nbXxnEIqfUY14p3B4Oa97cFoIDF24YyeTC8Ewt8oLa/vrAshEjEzHj8Zjlid0fDGyvZwNGSMnZ9Xk6kFQNjYu7uytUKAmAkrEp0JRa2+47+9stMb9CilFxY0KzlPALZra0tra0KISChsWnNGJNl3Km+v7XZ6HUrJwsmFdGYRCezUNpbW1gLOI6FIKDwVi1t9x7+1ttvudyiQudn5dGaRMWW3unZ7ZQURIuGoFspFY9Zo0Lq1Xmp1GpTQ+dl5KzmvUKXULN5cWuMBV1UtEj0RjSftQfPuZrnerBNCThRmsplzkiSVm6UbS+u+72ua/qKWjics22/d3SzXmlUAMp2fTqYWZClUbu1dv7MWcK7r+mU5GU+Ynjtc2qxU6hVK6Ux+xjTnFC1c69auLm14nqfIinIpEzct1+3f26mVKkUAyKayuexZSdXr3ca15U3HdRRZvnQ+ZiUt1x2s7NaL5SIAZJIZ05pT9US927y2vOm5jiQrl87GLMsMhL+8fbVYLlJKM6ls3DylG2Z72L+xvDlybEmSnj0fTVimx9310t2NnU1EkYiZmcxZlcU6w8GNe/savDCvpdOmH3gbpaX1nQ1EkYhZsdjJcMRqDfs3VraHwwFl7Pzc+WQqToCs791e314nBBIxKxo7EQon+47/9sp2f9hnjJ2bVy1rHghuVzfura1yISKhiGnOhULJvu3dWtvp9LqEkPnZ+Wz2HArcqW4sra8JzsPhiBGeisatvu3dXiu2e+1xG51KnaFM3qmt3V1dRSFC4YgRKkRj1mjYvr222+62KaWnT8wlk/OEKHvN4s2l9SAIDN0IR6YiseRo0Li7Uaq36oh4ojCTy12QKCvti/mapstaOm5ao0FrabNca9YAYCY/YyUXJGaUW3s3ltYCP1BV7QU1nTAt3x+OYyP7JXpOUcP1Tv3a3XXf9xRFfVFNxROm5/Tv7dT2ynuIIpvK5/MXGNNq3fq1pQ3PcyVZfvZ8LJm0XLe/Oi7RAJlk1jTnVCNe69SuLW+6riPJ8qVzMSuZJLIwwjMLc/l8ZqaQndG00Hsb2hwZvByuDb0XHl0YQkQ/8NqdpuM540nTeMxkhPaG/V6/g4iU0UTMMrRQEHjNTsPzPADQNM2KJyll/WG/22sjIqU0HkuE9LAf+O1OazxC1VQ9ETclJg2G/U6/jQIJJfGoGTbCnAeNdsPzXADQVC0RsyRJGo4GnV5bCEEpjUVjYT3CUbQ7LdsZAYCqqGYiKTFpZA9a3TYKQQiJRmLRcJQL3um2R/a+WDxmKrI8soedbocLvi8WigoUrW7LtkcAoCiKGbNkWbWdUbvb5JwTQiLhaDQcQxSdXns4GgGgLCtW3JIV1bb3xcaD4Hg0IQC7vfZgOAAAWZYTMVNVNMe1291WEARjsVg0DgCdAzFJYmY8pama6zqNToMHAQAJh8LxaAIAu/3uYNhHREmSzLipqYbjOu1u0/d9ADT0kBlPEkK6vfZ4zUpi/3977xVk15EeaGYe78015S1QhQIKhnAkyKa62WKLbaTpHo1iTEizM6GYGD3u47zrZV43Yh/2bWO1u9Jsz0haSdNqsQ3JJpsEQQfCFmwVyvt77/HeZM7DLV8FsACqgxAnvxeCp/7zZ+b/Z57z/zfzZDKmboqinKaJ7VpZngEAJEk2VZOiadd3/MBre7CiVyVRzrOs6TbyLAcASKJk6hWKov3AdQMXI0zTtKGbsiBnRW47rTRLAcCiIFX0KkXTfuC57f5AUYZmKrKS57nttpI0BQCIgmhoFYah/dB3fQcjTFGUrpuqqBRlYTmtJE0wAAInVM0qTTNBFLqeteFo1VBktSgLx7XiJN4pFkaB49uobDva0BWtLEvLbbXFeI6vGBWW4aIkdFyr3BTTFBUhZLtWFEcAA5Zjq2adZbgkjSyn7WigKbqmGgiVjueE0YYHq0aNY7kojRzXKooSAKwqmq5VAMa2a22JVfQqzwtJElmOVZQFgECVNU01IMCO5wShDzBgWLpq1HleSLOkZTeLogAQKJLadrTnu17oA4QZljGNqsiLSRrbjpUXOQBAlmRDq1AUdD3HCz2AAM3Qpl6VRDHNUstubYopumrQNOX6rhd4AGGaoU29IgpSXmSW3cryDAMgS5KpVSiK9gLP8x2MMM3QhlaRRSkrMtux0izFAEiCaOpVmqa90PV8t+1BQzcVScnzouU0syzFAIiCaOoVhqb9yHe9DUcbmilLclEWtmMlaYIxEAWhYtZoig7jwHYtjDAFoa6birTb0TxfNWo0zYRx4Hp2WSBIQV3VVUVHqGw5rWRTrKJXWZaLosByLYQQhFBXdUXW8NaIxoDjuapRY1k2TmLLaZVFCSmoKdqmo+0wCgEGHMdWzBrH8lEc2q5dlgUEQFF1XdEBwLZrh3EAEGA4tqJXBZ7f0FaWEEBVVVXZgBBvjGgMWJY1jYrAtR3dKsoCAKDI6taI9kMPIMCwdEWvCbyQZIntWnmWAwhkWTHUCqSA1x6qCNAMXTGqoiClWdqym0WRQwAkSda1CkVBz3e9wAUI0Cxd0SqiIKVFZtmtPNsc+EaFgpQfeI5vAwRohjL1miiIeXtEpymAm094ivJCz/ddVGKK3nB0URRNu5mlKYBAFEVTq9I0HYSe49kYAZqmDM2UJLksS8tpJUkCABBEsaJXaJoJI9/2bFxiSENTqyiSUpSF7VpxHAMAeIGvGDWWZoLNJzyEQFdNVdFKVFpOK05iiAHH8xWjyjFcGAeW02q/rXTNUCS17eiV+dY//B93cU794X96dfB4Lcliy7EQKgEAumboql6Wpe3ZYRTCtqONGsfyURLarl0WBaCApuiaomOAHdcKoxAAwDJsxazynBAnsWU3y7KEFFBkTVcNALDtWkEUQrzZHzg+yRLLaRV5ASBQFU3XDIBB+2ELAKAZpmrWBJbfdjQFFEnVVQNC4PpOEPoYA4ahTb0qClKWJU2nWWQFoIAiKrpmtge+G3gQAJqhK1pFEKQ8z1pOs91tJEk2tQqkYPuZDDCgKKpi1iRezPLMcq00TSEEoihW9CpFUV7geb67+eiuyJKcF7nltNIshW0PalWGpr3AczwHAExRtKEZsqQUZWHZzaStTRANvcK0He3abdeYekWR1aLILacVpwkEgN8c0UHku56zOVSNTUc3kzQBGHBce6hyQRTYjoUxoiioKoamaAihltOM4xhCwPF8RatyLBslUdvRW9oQQrZnRXEAMGQ5tmbUGYaNk6jtaEhBVdE0VccI2Z4dxyHGgGNZU6/yvBAnUctpoaKEFFQVVVMMALDtWEEcQAAZlq1qFV4QkiRpOa2yLACAqqLqqo4B8HwnCHwMAM3QNaPO83ySJrZj5XkOINh8lQPXc4IowBgzDG1qVVGUdj3hZcXQTApSjmf5gQcAZBjG0ExRkPM8azmNjeeDpBiaASH0Q3/Lg1WzJgpSlqWWa7XDJ1EUK3oNQuiHnud7GCOKpgzVlCU1LzLLbWbpRsxW0Ws0zfiB425q0zVzMxhrZGkGIBBE0dQqDMWEsW+7DsYIQsrUTXljRG8MfI7na2adougwClzPQghDitJVTZX1nWI8x5lGjWO5IPRtz8YIbYkhhFp2M05iCAHP8aZR4RguakdZm6GdKmsIIce3o82hWq90MCwbxaHtWu1gTFNUXTMRKm3XjuJw5zt6WwxCTVY11QAQWE4zikIAIMuypl4VeCFJ45bd3NCmqqqiQwBcz/EjH2BA03StUm+HdpbTKooCACDLsqlVAQCubwdhgDGmGbqy6WjLbRV5AQGQJMXQTIpqO9oHANAMbWoVUZDzIm3ajSIvAACSpJiaASHlh67ne23XVIyaKEh5kVpOazPqFmtmHQLghRsjmqZpXTNkUd0p1n5H0zTjBe5Gt6FpQzNkUSnLsmmttwNFof0qp+ggClzPRpuhnSTKZVnaXitJEoAB33Y0vSmG2u9oQ5W1zTd+DADged7UqyzD7hWTNABhe/6nvUHAgWnIk3m6JGc/uxdibq/EA6C90A0DDDcX8bXl8OaN25cAaIuBre3vdqjbr21LDG6fD7tVAoB7xLasgQHcLrUtBuDWGsOt1ZqHENunDbaXkMOtVYdfoG3vYmCMMdzR9k1t+8R2GnOz0G1jHii2vdz4YJvjjYoeaPMDCt1q/hNcAyHEB4htagMba78fI7apbVNsR6EYgj3NP1DsQNfs6qt4l7bH2ny/2DZPL7bb5juEdlupbcUvsvlusY3u9nibP9E128bcIbYlAncPabBLDIDN05z3ie0cNU+y0uFtvvGwembXHNLmjzfmbrHDatuoxuPF9tl8xyN5h813Plp2N/9Amx/czze0ga0xuF/bTmPua8WXsfmOpu3r5wdp+wKbb1vpUDaHADRXgj//z+/HUfZH/+nVgeO1zeMQ8E6x7ZcUBnjnoxHuds32uwzijZt3enDLSlvaDrT5lrb9Nv8i1zzLI+iLxZ7d5jvfR1vGPHhwbTxst9f3b4tt2nSjfhjsDFH22XzHcxXsqhrYKhTsflLt1LbzlQf3iYH9VsK4/eHDk8TwxhNtp823xbY/CtkZLTw+zNh6s+IvEAO7KrJHbMuYGO6OIDYruzlAHm/zL4hG9ottG/OgCHBXD9kW22rDQYHiAWL7Y5sDbL7b0Y8V2xM/tL+s2W/MHdoOFU/uepXvfC5hsF9so9DtoOUwEeBumz/WNf9YNv/SUfdesfZw2WfznYVutuNp05s2T3Xq8AHsLnLzCbbzyo6v+rZkHiO2/dcd6p4sBg8ndmDl4C7ZrQYdSuxx2vZ44DHa9spBuLcNB4s9jTEP6ApPENtn0C/Q9kU2h08Q2/7PYcV21h9+sRgAB9l8pzW3RJ5s8wPFdlbmqcTA4Yx5cH97VrGdQl9s88cMrj2d+nBie6v3BCsd3uaH0XYo1/wmbb5f7ECb7+y7+9u1t4D9A//g5h/G5ntHzZfT1v7bM42aA415SLG9I+ug2m7WZuOLXIzaX+ti3N6AYOeHtrvqe0jXbD1YDhTbXZPH2nx/43+zNv8yrnkqmz9RG9x3ba+BdlR47437WrG/rk/w4OMG7xfbvH0rhE8Sg2CnzOPENhTBvVcOfLbsvPplnlRwj67tyu5rwUE2P2Q0ciixA8x2kLPA/i53UGh3gNjjXHNYsZ3D82Cb7xvAT7T5HrGD27Wv0OfU5ofUtiW63yB7xLbNvd38A7U9fYYDvnySQyAQCATC8wsGGOH1RW9mYj30kjQqpifWOZ7uHNJphv6qK0cgEAiE3xQkySEQCATC1xmMwfyD5tv/3+3VRRcX+N2/nmA4qj6gkRSHQCAQvsZQX3UFCAQCgUD4jQEBRcHeo6ZaEcoclQgJEtt71GRZkuMQCATC1xmS5BAIBALhaw0E9V797GtDssYLEnf6GwNdQ+ZjvokhEAgEwtcEslyNQCAQCF9b2nvysDw9cq5rYKyWBNn4pT5RYbdO3SYQCATC1xKS5BAIBALha8vWnjy1bu3868ORl/UcNSFFgWfdrodAIBAI/yQgP2URCAQC4WtOexfpwInLAulVCdIUeKZTFwgEAoHwTwWS5BAIBALhaw7eeXwdmcMhEAiE/wkgSQ6BQCAQ/ufi2Q7PJhAIBMI/IUiSQyAQCAQC4evM1lTevsPrCQTC1xay8QCBQCA8pxz4I9QzRGl7Fmvt0vblJjQO0vzczZHsNOPjKrfH1E/bhi95+2N0gl1L7A7t999EZb4M/4j1eQZVW2ZECAEAKepxQ+GwtAvdXZOv3MYEAuEASJJDIBAIzyMYA4xwnpUIYQAAhICiKJqlKOoZfovGZYHWFtwyRx19Gs1SqMQMS1P0lw/NMEbYt2NrLTTrklaTIATgefqpHGOMMU6inKIgJ7BPCEaLrGwseWWOOgZ1XmCfqogyR+uLbp6WnYM6Lz3FvU9WXBaosehlSd45YAgSe3jD4hLlOaIoSLPUVxuAY4wBwJ6VNJd9oy6ZHQoAz75WEGMc+Vlj0VNN0eyU6cN0YIwRwpGfzj9o6jWp3quxHA0gLIuyyNGWFEXB9ohoezNLSwAwyzEMR0EIIy9tLHmSxte6VUhDADbGJsaY5Zn2Xn3P1iICgfCbg/7TP/3Tr7oOBAKBQNgHxlGQ3b48//Dqyvz95sKk1VrxIYSiwkHqqX86Dr3kZ392/f5nS70j1dVZ59HtNdUURYXbowchhEpUFggAAOGhSikLdOvywjs/vi0bQtegQVHwGUJYhBFCqCxQe9Ozp9KAMcAYlSUqC9zOsHbejjEIvfT6r2Z8J6l2qzRNPS4cdVvRL//i1sPrq8MnOySV/4IKI7xpKAwhDJz4l39+6/aV+eHTnaouHr7y+9S27d9Oa2Hkpb/8i5u3Ls8PjXeo5uHUYoAxttejiSsLoZ/qVYlh6Weuzz8KCOE7Vxbf/L+uiQrbf6z6tP7dpapEj26uvvln1yEF+0ZrNPOkA83bW+rlabE4Zd18f+7Tn08uz9hZUsgazwnMwsPW7cvzsxON+fvN+XtNuxHqVYnjGc+K73+2fPvy3PTttSTKFVNkWWp6ovHmn13HJe4/vlFomuT3Pl1qLLiVTpXhaDKVQyA8h5CZHAKBQHgewQC3lr0P/vbe+oKrmmJZ4jwt+o5Vv//vzw4crz6dLghCL12ZdQSRyZLixq/nlmes7uGK2SXvEUQlXp21V+fcwRP1Wo96CMWgLHBj0bNWA4qCkHrWUA+B5pI/f7/ZM1LpHjKeMmTEZYnn7zacZjTyQqdWlbb/gHGRl/c+Wbr83+9deP3IiYt9+PE/uUduujrryLoAnxQ5b6tefuSsLTj9o9WOAT300pVZm2IomjrMzU9iddZZnXX6Rqv1AS3y05VZG2D4dHNuGKzOOR/+5P7Iua7+0Sov/mPNLD0jRY7WFz1nPaS+tHEwBq2VoLUaYIQoiDcvYlRijDFNUxgCakfnQQhN3lh5+7/cXp13irxcW3BXpm1RYo+d77n78eLl/36PlziWowEAA2O1I+N1COGHP7n/6VtTRVYWOZYU9rv/7uz53x5urfjNZR/j7c6TxsXEhwueHXUOmN1HTJLjEAjPISTJIRAIhOcRjIFvJYGbDo7Xv/mjE2mSX3nzweyd9aUpq7Nfh3RJ0bDISoahWZ7BGGVpWeYlzdCcQFM0BQDAGOdpmaclxUC3ESVh1tGrKoZw/GLP0Ml6rVsBCBSozJOyLEqapViOCd3k5vtzEx8vvvFHZ1RT4HgGAFDkZZ6WAAJOYBiGBhAADMqiTJMCIZynpdeKKAaqFZHaTHIwxgCDEqEsKcoCMQzNCnQ7AcizoiwQyzM0TRV5WRSIYagsK+9/tvTh3z/85u8fr3QoDEeVBYIQYgyKrKRoyAkMTVMYgDwtMMIsT1MUlWdFWWKKhqGTfvLLqdVZRzUFUeV0t7nCAAAcp0lEQVRYltlKt9bmnM/emjLryrGLPWVRFhmgWRqVKE8LSFEsTwMAi6zACAdeFgVZx4BeFih0E4anWY6B7caWKEuLskAMS3MCAzBIouz6ezN3P1l4/d+c1uty6Gehl3YPmRiAwE1YjmY5GlKwbYQ8KcoC0SzNCQwFYVmiPCspCmKEyxLxItueHEAIp1F+8/L8rQ/mXv/XJ/W6FPlZ4KSd/ToAeEMtT0O4qXbL4yKzNYGGAQYAVLuUl7430n3UZHk6DjOKggjjMkfbGgBA5d4+gzHOs7JISwwAJ9AMSwMAi7wsC0TTsMgRxpjjGQBBnpYIYV5gaJaGEGAMyqLMkrZrGJajIbWda+Rp6TYjhmf0mthuZp4WRVZAmuIFpu1HhDDL0TRDbS3RZHmaomCRoSwtIACcyDAMjRB2mxGEQDVFuJkyYYTXF5yFSaujX+vo1wWRhRQEAEIIQzf97JeP1hfdoRMdvMgcOd3B8szAiXqel60Vn+WZ1//Vyc5BHVJQUnm1It79ePGzt6erXepL3x1prviX/+7eg6vL4y/2elYEMFArIoAgiTKEMEXDzgF99t768rTVOahD+BUvCyQQCPshSQ6BQCA8j+ASB05SZGXXkHHkTGcS5fc+XVqddoq8nPh4wVkLtarYXPYHT9SGT3WuzjmPbq66zdioi+OX+ruGDAhhay14eHVpecYRZS7PitjPVFNECNnroVoReIHJknz+YevRrTWvFRodytCJ+ty9xsRHC41F/+avZwHCx1/qDd1k6ubqyowNIXXkTOfYhW5eYKMgm769Oj2xnka5VpHWFz1BYCWFb3+QgzHAGKdRsfCw+ejmmu/EWkU8drG3b6RCU/D+1eXmonfmW4NGTXo0sbY8ZQ8cr63NOdffm11f8m5fWaAo0DtSnX/QpCgqz4vWki/I3NiFnsET9bJEdz9ZDJzkzKsDsi5MXV9dW3Drfdr0ncbktZU4zD5/Z7rMy5FzPSxHYwyKvJy6sWqvhW/80RmMwYd/f3/gWG34dOf6nHP30yW1Ip5+tR8hcOfKAkIIAJCEWeSln/xsMouL/uO1ky/3SQoXh/nc/cbMxLrvJLUe9eTLfZzA3r4yP/HxQmPRu/XhHM1SCOE4yNI4+/ztqcDL+o6aJ1/pV00hiYvFydb0rTW3FRsd0qlX+jsH9Oayf/ejBU5ksyRPk/Li7xxpT5r5dnzz/bnbH86vzbs335+naYpiqMhPkyi7+tZ0HGY9RyqnvjGgGkKa5AsPW9O319xmpNfkk6/0dQ+bNLXxrRYqsdOI0rQQJba1HNz/fEmQ2DjInUbYM2yeerVfMYQ8KRanrKmba24z1KrSqVf6Owd1uxFO3VhdmbYBAH2j1eMXeySNn7m9tjhlyRrfWvaLAg2drFMUnL3byJJy7GL36NlulqN9J5mZWJ+/38iSovtoZfxSr16Vweb3+Hla+lbE8bRqimWOVuacqRtrrWVPkNnjL/V0D1emb641lrzxS32dg3roZXc/ni9yNP5yf5GXk9dWVudsSFFHz3SOnuuGEHh2TEGomMLOjLq55L//t3cZhh5/ue/Ei70dfTrL04CCcZA3Fj2Wo2VD0KvC6VcHlIrIMNT6guc7CQAgjvI8K7uHK5VOOQ6yyesreVK88rvHzv728NqsM3FlwbOiKMg8O4YQKLpgrwX3PlkqcjR6vqv7iEmzdHPJK3P05IVzBALhK4EkOQQCgfA8UpbId+I4yubvN3/x5zecRjg90egeNo269PHPpiavrxg1SVR5tSK6zZmPfz4FAWBYauKjYHnG+eF/vFDk5c/+7xtTt1YFicUIeFacp7lWkZxG9PGbD4++0HXsXPfdT5be/5u7SVzQNMQIR266+Ki1OusACFbnnO4jhjYtXf67e2vzrqjxbiO6++kiBS8On+64+supD35yHxWIE9jATUI3HX2hixMYAGB7JiGN8qtvTX/49/eztKQZKvLSh9dXfu8/nO/o1669M7M6Zx850ylr/MSH83c/WXpDPTM9sb4w2UIFai55S1M2pKj3/upOEheqIWCE3VY0eWPlR39yUa9Ln/58Kg7SsfPdNEvdvDy38KB5+rcGH1xdaq36vMiuTNsDx2sYIQBojHHgptN31qs96pEzncvT1pWfPrRfimp9+tV3pj/42/s9I5WeYdO1onf/cmLkbJdRl+Mon3/YstdDez2cuLKgGPzweOcnP5+8+vY0y1EYgzsfLVgr/vjL/ZPXlxsLHsZ4fd5bmbFFhcvTcumRHXqZ0wjvXOEkTRi70H3z17OXf/IAUoCm4c0P5lZnnH/2J+eXplrv/vWdssCyLvQMG6jc+AIqdNOH15bX5hyM8dqCszJjK6aYpcXKjBMFudsMWX5OMYWxc93X35u98tMHEACKpm5dnl+ZtX/4JxcqXUo7y8mzcuLjhclryz3DptuMfvVfJxiOFhXOa0W3WJoXmfGX+yc+nH/3/78TBxnNUEVecjydZ+V7f31n7l6DE9k0zm/8etZa9V/6/ujERwuf/HxKq4gAQrcZXvvVtGKIRV5aa8HyI8uoSZImvP83d+98vKiaQhrnt64spGH26o/GuM3NG+IgDd1UVDlB5iZvrPzqv92Jg0yQ2eayN3Nn/Qd/fG7pkXXl7x/wIlvtVqdurvzqL++OvNBpdsofvTnZWHAlTfCs6MHny/+Mhn1HK4GTCDIra9urCiEF+47VLn1v9OYHc5f/7v6N92bHLvacemWgd6QiqWzvSOXauzO3Ls919mtmh3LiUp9Zl2M/TaM8S4r3/+YuBmD0TNd3//0LDE2tzDr1Xm1ovM6yVHtKiqKoLC0CO2Z5xm2G1389M31r7fzrw4oh5hliOToKsrJEB49hAoHwlUKSHAKBQHgeKbLSsxJUoNZqEPs5RYPhk/UX3ziqVSXfjlmePvvtoWPne9I4f+vHtyI3+cYPxySF/+ytRwsPmo0lb2my9eDzpRMv9l5846jvJO/8+La1Gsg6H7pJEueiwjWXgys/fVAi/J0/PGXWZd+K+49VBxfrzWVfq0hv/OHpWq/22VuP7n22dPrVgdHzPXN316++Mz09scZw9GdvT/MC+61/caLSrXz2i0dX336kVkROYAAAEECE8cqM/ekvpiBFfe9/OaXXpc/fnr51ZX72bkOQOacZsjzDiWyWlvZ6hBHu6NOqXcravBP56e/+8dm+0dr0xJrvJN1Dxrf+YFzW+Cv/8OD+Z8sLky2Wp91mKKm8qHJpVDjrIc3Swyfriim0VvyRM13f/pfj9T5t81N77DUjtxkdPd2p6IJqiAxDWyv+8nTr0a21skBuM1ydcxYnWxiAo2c6FyYthqVPvtJ/6uW+j3/28OHnK24rXnpkffyzSQrC898boSj40c8mZ+81z7429OIbI0tTtqhw3/93L9T79OvvzUAKHL/Ye/714eu/mpn4eMG34rU59/JPHsRB9o3fGxUV7spPH87cbbRWfLcVp1E+cLz28g+OdfTrRl0GAGAMql3KpR+Mrs+7nMC88W/PdA4a19+bhRAeu9B94TtHb7w3e+uDWd9OGov+lZ8+jP3s5R+MSir/8c8fzt1r2GtBtUsFAEAIirxw1kOMgCCziw/jOMxOnu578bsjty/P3/xgzmlEzWXvozcfZkn5+r86Ve1VnfWw94h556PF6Vurp14deOG1YWvFf/vHt+9fXR4c73CbMQDg7GtD3UfMd358e3XOPf+dI8Mn62//eMJphk4zXpy0Pn9nuqNPe/G7I54VXf7Jg7n7zQuvH9lKckIvTeK81qclYf7xz6bW5tyLbxzpPVq5/uuZ2Yl1ay2odatFgVZm7Naqf+vDOQDw4In6/U+X719dPvvNwdFzXXP3mtfenVl40DLrcuiliiHs2GsOQwCNuvTS90cHT9SuvTvz2S8fvftXd5Yf2T/4D+f6jla++fvHOZ6+fWVhedr++f9zfXXe/e6/PS2q3IXXj0AaplF+6/L8vc+WRs939QxXAjvpGa2oFRFjkIRZGuVGXS7zMnDSOMw+enPSd+Jzrw1944djek1yGiFFAYalAFmoRiA8l5Akh0AgEJ5Hsqzw7Fgxxdf+4Hj/WF0QWdUUtKo0e7cR+engido3fjhm1KSrbz1qLHgQwttXFigA3FbMS0zsZ49ur0sK/+J3R8Yu9Ph2fOejhcjPJJX3rBgjoBjCyqzdWPIufX/kwutHeJHFGEMI4zCnKKrWqw6O19OknL2zniXl4qTVWgvSKOd4GiG8PG05jfDVHx0/+9oQzdHOenTno4WtJAcAgBBennHcZnTpd0dfeG2IpqHTCO9fXUqiPPLSwElqvZogs5GXBk4sa7xaEcsC0TSl1+TBE3W9Jt3+MGU5+oVvDZ1+dYBmqOay//DzlTwrAydN46Lep/Mi61ux58RGVTI7lcBLaYbqHNQHjtcZnoIYAgAABoGbpFGuVQSGo9WKoFVFez26fXk+jfLRC12LD1tTN1ZXZu2h8XrvkcrER4uaKZz91uDQeH3y+gorNBiaWnpkWasBL7LX3pvBGEReqtUkXuIoikIIV7vUwfEOhqV8OxEV/txvD42e7Vp40ORFlhOYhcnW6qzDCfTtDxcgBKGX8iKDcuzbMSuyF75z9OxrgxRDwc394HiJ1SoiQqDarQ6Od/AC47ciQebOfmvw2LmuxckmL7IsS63MOWuzDsNR7aV9gZ3wIrt1agsGMI3LwE14meV4JnATjmfOvjZ0/MWe1VmH5WmWp1fn3LUF99y3h899Z1hW+bJEzlo496Bh1OWXvjc6eLzm9ms3P5jzW7HXiiI/7ejXL3znCMcziiFUs/Lst4aq3apiTKVRjgo0e6/h2wkn0J/8fLIoUHt38p3HyIRukkS5WZe9VjR/v5FE2eT1lbl7Dd9JeImjKcrsUrSquDxt3f1oYfZOY/zFvmqX8tE/PMySYnGq1Vrxk7igGQpSMA7y2M8qXRVOZABo7yIBMUBFitxm2FzyQy9lWNqoy5UumecZSMHeo5XX/82pskBuK15+ZN++PHfxO8O9RyovfX+EE5n2911v/tn1yMvSpChLTNMQQljk5fq8m0R5rVdFJQ6cJHBi345GznS9+N2jRl2GGCRRXuZYMQSGJWvVCITnEZLkEAgEwvNInpReK9Iq4sjZnsHjta3PyiMvTYKs3qurhoAxyDMEEOgeMY6d706jInSTnpGK2Sm3v/iP/NRrxfMPm2vzriBzosYtTrUAAFpFDL0ElThNysCOfStmWFqriqGb5HnJckz7A/QiR4opjJ7rklXeWgvk8z1jF3rmHzTLAqVhHjhJnpePbq+VCGtVcTvUw7jMUVGgNMp9J87iYvZug2boWq9a5GXkZxjh0EmWp217Newfq3I807L8JMrNDqXIURLnTjMsc5REeeAkUZA+urUmKlylU4nDtH04ideM5u63nPWo72iFl1inEWEEaJbO04JmOLi5Z3JRoLJE7XhbkLl6rzb/YNp34uMXe0bPdq/NOrevzKumePLlPk5kvWYkylylU0YFDtyUF1lZ4z07pinYP1oZPFFPwjzys+FTdaNDnr2znoQ5y9MI4STMfSsWRLbWoyGEAzflBEZS+ShIIQQ9RyojZzraiUf/WFWrS34r5gWm2qPQDL2xQcLmpm+xn0dByvA0LlES5W6zLakhhEM35URW0UXPiiAFuofNkRe6sqTw7XhgrFbr1TDAEEAIQOSlSZBXu1UAgGfFksobHQpGIPITmoJqRYzDHJUojfPQTiIvpRmqLFGeo6JAkZe6rWh6Yr21EnQN6hRNhV5a71MljQ+cdsYoKoaQ52XgJLzEigpb5Ijl6SOnOms9mm8nvUcr4y/1CQoHNnb3xoGTZklhdsgAAIRwtVsdu9hDUdBeC+u9av+xCieynf36/c+XfScRJO70NwcElSuKUjOFY+e6BYl1mpF0vvvYue7QS+Mg1UxREFmMN2ZQYj+/+f7s3U8X7fVIUtmL3zly5HRHz9GqovPr8+7qnCPrPKCoWo9iLQcY4jjIrr4zHfnpsXPdDM+sz7u8xJldsiCxLE83l/2FyRYE4OYHcyxPD43XkziPg3RwrFYUyFoLFx60ar0awGB11kEY13t1mqFAezsOcloOgfA8QZIcAoFAeM7AAEOcxnnoJnpNlhRu4zLGZYl8N0YYt2cnAAAdfZrZpaRRnieF7yahk9R6tGq32jVszNxdf/9v7z/8fGV1wV2ddfqPVXmBDZyE4WitIupVSa+J9z5ZzKK8LFDHgPbN3z9RlLjM0fz95o33ZsYu9vaNVuz1IA4yiobWamh2Kr0jlTTOJYW/dXkudJM8Kx5cX6UooBpCe0s3AABFwXqvqhj8rQ/n4yCNw3xx0ho+WR8arwdWwrLU4iPrnf82Ya0GrhWdqvVzPFOWGBVobd75/J3pY+d73GYYBumN92adRujbycKD5tiLvf1j1ZVZh6apufvNX/zFrdU5Jw4zxRQZli7yMkuLyesrlU751MsDkr5x/g/H0jRNxVFeFiUvMPVeNU9LiqbGLvT0HjEllW+utMYu9g4cqyVRFgWpYgiCzOVZ6duxILNKRawXSKuKcZjneem1ojQt6n2arPGoQBjhxSnr2jvTnQNG6GeixosKVxbItyOWpyWN6+aNapeShFmaFL6dhF7a0a9zHB24qSCxksKDrQmAjYVXoCxKVKClSevau7Pdw0bop6LCSipfFsi3Eo5nJI1jBdrsVNI4z5LcsxLfiWu9mmoIAEMAMQAwDtM0ytSKgDHw7VhUOUnh0jgPnJSXWMUQ9Jpk1OX7V5eLDJUlqveqF3/naM8R8+pbj371lxOVbnVpsgUAPvWNfpaj4yDVKp0cT0d+mkR5d5fCcLRvx0mYV7sVvSr1HDEefM6FXqpVC7cZCgpX79f4jWk9XOYocBMAgF6Tqt1q95DZWvHTKEcI241w+HSH2aUgBLqGzdsfzrdW/G//wXj/aLUsUc+Qaa+FcZgBAOxGWOlSqz3K2rxTllg1eIbbsh0O3PjBtWWE0MXfGT56urPWqwkSCykYeunn7zy69u6MUZPdZlSWKE+Ll743Ikrcr9+/O3ev+eDqMs3Sy9PW0VMdg8frLEd3DRn3Plv86f95DQKwvuie+a3BvqPVhzeWEQIjL3SpVfGd/zrx0ZuT3cOGqPAzt9eNutTRr1EUyXAIhOcRchgogUAgPH9g4FnJ6qzTN1oZPdfF8Uw7ai9LtD7vJmF+4qW+zgEdQihrvKwL1lrQPuhweLzj2IUetSLpNSlLCqcRRGHe0acqhtB3rHr0dGdzyZM07sSLvZ0DmmKIvhW1lv0iRz3DZt+xGs1AezX0WjHNUMfOd3cfqWRJuTJr2+tRpUs+9Up/R7+mGiLL0/Z65DYjTmLrvWqlSz35cr/RIW9seAWBYgiiynmtuLnsoxKPX+p99UfHO/p0XmCytHStCCFs1mVR5ccv9Q2M1QAAbjNym3FRoI4+9cHVJQCprkGjuewXWTl+qfeb/7x9O5uEmW9HqERGh6xXpOMXenqPmAhhazUMnUTWhcETNU5kIIQY4CIvp26uRn567GyPpPJ5WrhWPHi8dvGNo6opWOuhKHOXvj/SP1bznWRt1u0dqR59oavM0cLDVqVTOfPqgNmlCDLXWPbXZp2yxCMvdI280CXIHCqRtRaEbgIpWOlSIj/tGjSOnevCCC88tPSqePLl/lqvJutCa8VfnXPytDx6pnPkbBfAYGXWrnarYxd6BIWDuyNjjLC9Fvp2QtNUpUsNnbhzwBi72AMwWJpqKaZw8pX+apeq6Ly1GqzMunlaHDnVeex8j6RxFAUxhhACpxGuL/gjL3TV+9TlR3a9Vxu/1IdKvDLjKIZw/MW+Wo+qmoJvx61lP8/L7iFj+FRnvVctc9Ra9r1WXOlSfuv3j49f6o+8tLXsj57v7j9W86yoseQPnagPjddDJ12bd/vHaiNnu2rdGk3DlTm3seRxPH3ipd6BsRrb7rEQ5Fm5OutgDE6+3N81ZOhV0beT5RkncNKeEfPky/16TaZpCmDgNsPuIeMb//x4rUdjOcaoy1mSL884znpodMgnL/VVu9T1RS+N87EXe7sGjPapOxgDSFMd/drZbw2PvNBtdMgsz1AUBQAEGKdx4TbCxpIXBVm9R7v0/dGXvjdS6VYZjg7sxG3FCOHxl/q++S9OdPQbvMgquhC6qdMIIQXOvDrw6g/HjLq8vuAlYTp+qf/Y+e4yR54Vsxy9Ous8+Hz53LeHR893MwzZP5pAeB6BOxfOEggEAuGrBwOMcZ6XkZe298Vqn4KCMcYYp1GexIWkcFvfwBRZ6TtJ6KWcwKimIEgsBBBjHHpp4MSQomSNLwtMM1CQ2STMMcKSxlM0Veal58SRm7I8o1UkQWIQwk4jDJxEUnmzU6ZoKvYz344xxoouyDoPKQoCnCaFZ8V5WkiqwDAUwlhUOJbdWHzVPmm+yEvfjiMv5UVGNUVeYttNiP3MbUUMSwsKW+ZYkFlBZBHCnhV5Vtz+jOQv/7cr9V7t9/7jhfbxKWpFECUOUhAhHHmpZ0UszwgSh0okSCwnMkWG7PUgDnPNFLSqTDMb5orD7Bf/743Jayt/8L++fPSFziwuIj9jWErSeABA5KVFgWSVY3kmz8rYy2iOkhSuRDhyU0hBWeMgRRVZ4dlJ7KeCzGmmwAoMBLAskdMMAzuRVE4xxDwraZqSVA5hHLkpgEDSeIqiyrYR/IwTGc0UOZFBBY6CFEIoqRxF7wqOMcZlgdxm5NuxpPKKIeRpSTNQVHmAQeglABygVjVFXmRhe6UagBjjLC1iL+UlluHoyMsoGkoajxGOgwxjLKk8RcOyQL6dhG7KcrReFXmZxRjEQeZbESqxYgiyLtA0zNIy9lNe5gSRybMy8jOOZwSZLXIU+ynD06LMQQjSuHCtOIsLWecVg2dYmqKodnSBEY7DrMhKUeVZlipLHLqJ7yQMSyuGIClc+zShIi8DN6VoKGv81qlBcZD5VowQVk2hXe0kzLOkEBWOExgI2t28HcZgCOHmntVtW0KAcVGUvp1M3VxpzPtnXhvs6NM2TkbKS8+KIi/jJUY1RUFiN35EKJBvxZ4VswJtVGVBYQGASZRlcSHIHMvT7d0IGkveW//llmKKP/jjcx29KoCQJDkEwnMISXIIBALhOQMDDDE8YPXL3iUx7d0C2v/YvLYdbrWDzL1X92jcfeOeN0L73Em8T8mBxW1VsP1xyE4xCDYu7H7p7Lp36/rdTxb/6n//aPzFvt/7kwvtpXqbtz+26J0tBaA9iwMBBGWJHlxdevD58sU3RvpHK8+8oGi7IQdYYL8Vdt64XbGdrdiheK8B8XZDHqsWHGDbp+YADQf5+nC69t7YbthWTziw3CeYDYA9vfpJHXhXZrPv3wihNCrytJB0nt6RVe7z6WELRQgtPmx9+svpky/3HjvXTbM0WatGIDyfkCSHQCAQ/mmz9QV2+/82YzUA4RfEXrtD7H0BN9gbvO0u6PF37fvDY7K2be07hR9eX/n4Hx6Mvdh7/tvDLM/svP1wLd1WhjFO4yLPClHm6GddU7Q7dH7a7YJ3tPGgiH+P7GOS2/1V2q7GF6s9WMNut2EAwK7Sn6qlO+vw2A5xwF+fIjd4ston3AXA9hzXVtryhanREwpFCJUFioO8vVEBmcMhEJ5bSJJDIBAIhOcFjHHkZ74Vyzov69un2j+bqj0B6LMFygTCFgd0ITKLQyA8r5Akh0AgEAjPC4dcBkYgEAgEwpMhSQ6BQCAQCAQCgUD4WkGO6SUQCAQCgUAgEAhfK0iSQyAQCAQCgUAgEL5WkCSHQCAQCAQCgUAgfK34H/u4SqIx2Wd5AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "fbbcd0c8",
   "metadata": {
    "id": "fbbcd0c8"
   },
   "source": [
    "# TabNet\n",
    "TabNet은 Sequential Attention의 아이디어를 사용하여 decision tree의 동작을 모방합니다. 간단히 말해서 각 단계에서 두 가지 주요 작업을 적용하는 multi-step neural network로 생각할 수 있습니다:\n",
    "\n",
    "1. Attentive Transformer는 다음 단계에서 처리할 가장 중요한 feature를 선택합니다.\n",
    "\n",
    "2. Feature Transformer는 feature를 보다 유용한 표현으로 처리합니다.\n",
    "\n",
    "Feature Transformer의 output은 나중에 예측에 사용됩니다. Attentive와 Feature Transformer를 모두 사용하여 TabNet은 tree-based model의 의사 결정 프로세스를 시뮬레이션할 수 있습니다.\n",
    "\n",
    "모델은 해석 가능성과 학습을 향상시키는 task에 가장 유용한 feature를 선택하고 처리할 수 있습니다.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Attentive와 Feature Transformer의 key building block은 Feature Blocks입니다. 이제 이들을 살펴봅시다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7389ed84",
   "metadata": {
    "id": "7389ed84"
   },
   "source": [
    "# Feature Blocks\n",
    "Feature Block은 순차적으로 적용된 FC (Fully-Connected)(or Dense) layer와 Batch Normalization (BN)으로 구성됩니다. 또한, Feature Transformers의 경우 output이 GLU activation layer를 통과합니다.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "GLU(sigmoid gate와 반대)의 주요 기능은 hidden unit이 모델에 더 깊이 전달되도록 하고, gradient exploding이나 vanishing을 방지하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b7da6",
   "metadata": {
    "id": "e97b7da6"
   },
   "outputs": [],
   "source": [
    "def glu(x, n_units=None):\n",
    "    \"\"\"Generalized linear unit nonlinear activation.\"\"\"\n",
    "    return x[:, :n_units] * tf.nn.sigmoid(x[:, n_units:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a3e94",
   "metadata": {
    "id": "4c4a3e94"
   },
   "source": [
    "또한, 원본 논문은 training 중 convergence speed를 향상시키기 위해 Ghost Batch Normalization을 사용합니다. 관심이 있는 경우, [여기](https://github.com/ostamand/tensorflow-tabnet/blob/master/tabnet/models/gbn.py)에서 Tensorflow implementation을 찾을 수 있지만, 이 tutorial에서는 default Batch Normalization layer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4f094",
   "metadata": {
    "id": "b1c4f094"
   },
   "outputs": [],
   "source": [
    "class FeatureBlock(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Implementation of a FL->BN->GLU block\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim,\n",
    "        apply_glu = True,\n",
    "        bn_momentum = 0.9,\n",
    "        fc = None,\n",
    "        epsilon = 1e-5,\n",
    "    ):\n",
    "        super(FeatureBlock, self).__init__()\n",
    "        self.apply_gpu = apply_glu\n",
    "        self.feature_dim = feature_dim\n",
    "        units = feature_dim * 2 if apply_glu else feature_dim # desired dimension gets multiplied by 2\n",
    "                                                              # because GLU activation halves it\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(units, use_bias=False) if fc is None else fc # shared layers can get re-used\n",
    "        self.bn = tf.keras.layers.BatchNormalization(momentum=bn_momentum, epsilon=epsilon)\n",
    "\n",
    "    def call(self, x, training = None):\n",
    "        x = self.fc(x) # inputs passes through the FC layer\n",
    "        x = self.bn(x, training=training) # FC layer output gets passed through the BN\n",
    "        if self.apply_gpu: \n",
    "            return glu(x, self.feature_dim) # GLU activation applied to BN output\n",
    "        return x"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ff58c781",
   "metadata": {
    "id": "ff58c781"
   },
   "source": [
    "# Feature Transformers\n",
    "FeatureTransformer(FT)는 기본적으로 순차적으로 적용되는 feature blocks의 collection입니다. 논문에서 하나의 FeatureTransformer는 2개의 shared blocks(즉, weight은 steps에서 재사용)과 2개의 step dependent blocks으로 구성됩니다. shared weights는 모델의 parameters를 줄이고 더 나은 일반화로 이어집니다.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "이전 section의 Feature Block 구현을 고려하여, Feature Transformer를 구축하는 방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232ca34",
   "metadata": {
    "id": "a232ca34"
   },
   "outputs": [],
   "source": [
    "class FeatureTransformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim,\n",
    "        fcs = [],\n",
    "        n_total = 4,\n",
    "        n_shared = 2,\n",
    "        bn_momentum = 0.9,\n",
    "    ):\n",
    "        super(FeatureTransformer, self).__init__()\n",
    "        self.n_total, self.n_shared = n_total, n_shared\n",
    "\n",
    "        kwrgs = {\n",
    "            \"feature_dim\": feature_dim,\n",
    "            \"bn_momentum\": bn_momentum,\n",
    "        }\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = []\n",
    "        for n in range(n_total):\n",
    "            # some shared blocks\n",
    "            if fcs and n < len(fcs):\n",
    "                self.blocks.append(FeatureBlock(**kwrgs, fc=fcs[n])) # Building shared blocks by providing FC layers\n",
    "            # build new blocks\n",
    "            else:\n",
    "                self.blocks.append(FeatureBlock(**kwrgs)) # Step dependent blocks without the shared FC layers\n",
    "\n",
    "    def call(self, x, training = None):\n",
    "        # input passes through the first block\n",
    "        x = self.blocks[0](x, training=training) \n",
    "        # for the remaining blocks\n",
    "        for n in range(1, self.n_total):\n",
    "            # output from previous block gets multiplied by sqrt(0.5) and output of this block gets added\n",
    "            x = x * tf.sqrt(0.5) + self.blocks[n](x, training=training) \n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def shared_fcs(self):\n",
    "        return [self.blocks[i].fc for i in range(self.n_shared)]"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9b797943",
   "metadata": {
    "id": "9b797943"
   },
   "source": [
    "# Attentive Transformer\n",
    "AT(Attentive Transformer)는 각 step에서 feature selection을 담당합니다. feture selection은 prior scale을 고려하면서 (GLU 대신) sparsemax activation를 적용하여 수행됩니다. prior scale를 사용하면 모델에서 feature를 선택할 수 있는 빈도를 제어할 수 있으며, 이전 단계에서 사용된 빈도에 따라 제어할 수 있습니다.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "이전 Attention Transformer는 이전 step에서 사용된 feature에 대한 정보를 따라 prior scale로 전달됩니다. Feature Transformer와 유사하게, Attentive Transformer는 나중에 더 큰 아키텍처에 통합될 TensorFlow 모델로 구현될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c618062",
   "metadata": {
    "id": "6c618062"
   },
   "outputs": [],
   "source": [
    "class AttentiveTransformer(tf.keras.Model):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(AttentiveTransformer, self).__init__()\n",
    "        self.block = FeatureBlock(\n",
    "            feature_dim,\n",
    "            apply_glu=False, # sparsemax instead of glu\n",
    "        )\n",
    "\n",
    "    def call(self, x, prior_scales, training=None):\n",
    "        # Pass input trhough a FC-BN block\n",
    "        x = self.block(x, training=training)\n",
    "        # Pass the output through sparsemax activation\n",
    "        return sparsemax(x * prior_scales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8e492",
   "metadata": {
    "id": "4ff8e492"
   },
   "source": [
    "Feature와 Attentive Transformer block은 parameter가 상당히 무거울 수 있으므로 TabNet은 몇 가지 메커니즘을 사용하여 복잡성을 제어하고 overfitting을 방지합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119403d9",
   "metadata": {
    "id": "119403d9"
   },
   "source": [
    "# Regularisation"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "20e460f4",
   "metadata": {
    "id": "20e460f4"
   },
   "source": [
    "## Prior Scales Calculation\n",
    "Prior scales(P)를 사용하면 모델에서 feature를 선택할 수 있는 빈도를 제어할 수 있습니다. prior scale(P)은 이전 Attentive Transformer activation 및 relaxation factor($γ$) parameter를 사용하여 계산됩니다. 다음은 논문에 제시된 공식입니다.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "이 방정식은 prior scales가 어떻게 업데이트되는지 보여줍니다. 업데이트는 현재 step $i$까지의 모든 단계에 대한 product입니다. 직관적으로, 이전 steo에서 feature가 사용된 경우, 모델은 overfitting을 줄이기 위해 나머지 feature에 더 많은 주의를 기울입니다.\n",
    "\n",
    "예를 들어, $γ$=1일 때 multiplicative activations(예: 0.9)가 있는 feature는 작은 prior scales(1–0.9=0.1)를 갖습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4d0d2",
   "metadata": {
    "id": "c3d4d0d2"
   },
   "source": [
    "## Sparsity regularisation\n",
    "loss에 대한 sparsity regularization은 attention mask가 sparse하도록 장려하기 위해 사용됩니다. hyperparameter $λ$에 의해 스케일링된 entropy of activations는 전체 모델 loss에 추가됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7d430",
   "metadata": {
    "id": "e0f7d430"
   },
   "outputs": [],
   "source": [
    "def sparse_loss(at_mask):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.reduce_sum(tf.multiply(-at_mask, tf.math.log(at_mask + 1e-15)),\n",
    "                      axis=1)\n",
    "    )\n",
    "    \n",
    "    return loss\n",
    "\n",
    "not_sparse_mask = np.array([[0.4, 0.5, 0.05, 0.05],\n",
    "                      [0.2, 0.2, 0.5, 0.1]])\n",
    "\n",
    "sparse_mask = np.array([[0.0, 0.0, 0.7, 0.3],\n",
    "                      [0.0, 0.0, 1, 0.0]])\n",
    "\n",
    "print('Loss for non-sparse attention mask:', sparse_loss(not_sparse_mask).numpy())\n",
    "print('Loss for sparse attention mask:', sparse_loss(sparse_mask).numpy())\n",
    "\n",
    "# Loss for non-sparse attention mask: 1.1166351874690217\n",
    "# Loss for sparse attention mask: 0.3054321510274452"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531131f",
   "metadata": {
    "id": "0531131f"
   },
   "source": [
    "다음으로 이러한 구성 요소를 사용하여 TabNet 모델을 구축하는 방법을 알아보겠습니다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d22d33c7",
   "metadata": {
    "id": "d22d33c7"
   },
   "source": [
    "# TabNet Architecture\n",
    "\n",
    "## Putting It All Together\n",
    "\n",
    "TabNet의 기본 아이디어는 Feature 및 Attentive Transformers 구성 요소가 순차적으로 적용되어 모델이 decision tree를 만드는 과정을 모방할 수 있다는 것입니다. Attentive Transformer는 feature selection을 수행하고 Feature Transformer는 모델이 데이터의 복잡한 패턴을 학습할 수 있도록 하는 transformations를 수행합니다. 아래에서 2-step TabNet 모델에 대한 data flow를 요약한 다이어그램을 볼 수 있습니다.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "우선 초기 input features를 Feature Transformer를 통해 전달하여 초기 feature representations를 얻습니다. 이 Feature Transformer의 output은 다음 단계로 전달할 features의 subset을 선택하는 Attentive Transformer에 대한 input으로 사용됩니다. 이 프로세스는 필요한 단계 수만큼 반복됩니다. (이 [code snippet](https://gist.github.com/aruberts/5e97edb8e8d1820db70b427c7ee74995)에서 위에 정의된 클래스를 사용하여 TensorFlow 구현을 볼 수 있습니다)\n",
    "\n",
    "모델은 각 decision step의 Feature Transformer output을 사용하여 최종 예측을 생성합니다. 또한 각 step에서 attention mask를 집계하여 예측에 사용된 feature를 이해할 수 있습니다. 이러한 mask는 global importances뿐만 아니라 local feature importances를 얻는 데 사용할 수 있습니다.\n",
    "\n",
    "<br/>\n",
    "\n",
    "이제 실습을 시작해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b6069",
   "metadata": {
    "id": "f96b6069"
   },
   "source": [
    "# 실습: Fraud Detectioin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429864a",
   "metadata": {
    "id": "8429864a"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3e933e",
   "metadata": {
    "id": "fe3e933e"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from category_encoders.woe import WOEEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, confusion_matrix\n",
    "from tensorflow_addons.activations import sparsemax\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7eafae",
   "metadata": {
    "id": "5e7eafae"
   },
   "source": [
    "## Data\n",
    "\n",
    "([데이터 경로](https://www.kaggle.com/competitions/ieee-fraud-detection/data))\n",
    "\n",
    "데이터가 2개로 나뉘어 있기 때문에, merge가 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29bb2928",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29bb2928",
    "outputId": "da20f745-f16e-4714-d6c9-4d72b03523d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.98441\n",
       "1    0.01559\n",
       "Name: isFraud, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transactions = pd.read_csv('train_transaction.csv')\n",
    "train_identity = pd.read_csv('train_identity.csv')\n",
    "\n",
    "# merge two datasets\n",
    "train = pd.merge(train_transactions, train_identity, on='TransactionID', how='left')\n",
    "train['isFraud'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b6d00c6",
   "metadata": {
    "id": "0b6d00c6"
   },
   "outputs": [],
   "source": [
    "test_transactions = pd.read_csv('test_transaction.csv')\n",
    "test_identity = pd.read_csv('test_identity.csv')\n",
    "\n",
    "# merge two datasets\n",
    "test = pd.merge(test_transactions, test_identity, on='TransactionID', how='left')\n",
    "test.columns = [c.replace('-', '_') for c in test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960161db",
   "metadata": {
    "id": "960161db"
   },
   "source": [
    "## Feature Engineering\n",
    "feature engineering은 fraud detection 영역에서 가장 중요한 단계입니다. 그러나 이 프로젝트의 주요 목표가 아니므로 이 단계를 건너뛰고 독자에게 맡기겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a32299e",
   "metadata": {
    "id": "2a32299e"
   },
   "outputs": [],
   "source": [
    "# Make an hour feature from datetime stamp \n",
    "def make_hour_feature(f):\n",
    "    #Creates an hour of the day feature, encoded as 0-23.  \n",
    "    hours = f / (3600)        \n",
    "    encoded_hours = np.floor(hours) % 24\n",
    "    return encoded_hours\n",
    "\n",
    "train['hour'] = make_hour_feature(train['TransactionDT'])\n",
    "test['hour'] = make_hour_feature(test['TransactionDT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ec030",
   "metadata": {
    "id": "965ec030"
   },
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- missing values가 많은 칼럼 제거\n",
    "\n",
    "- median 값을 missing values에 채워넣기\n",
    "\n",
    "- categorical 칼럼의 missing values에 \"missing\"이란 값으로 채워 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e0b3ac2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e0b3ac2",
    "outputId": "307f28dd-fc78-47a8-a56c-b97c1ccb6409"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "cat_features = ['ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', \n",
    "               'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'M1',\n",
    "               'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'DeviceType', 'DeviceInfo',\n",
    "               'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20',\n",
    "               'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30',\n",
    "               'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']\n",
    "\n",
    "exclude = ['TransactionID', 'TransactionDT', 'isFraud']\n",
    "num_features = [f for f in train.columns if (f not in cat_features) & (f not in exclude)]\n",
    "\n",
    "# 결측치 90% 이상 칼럼 제거\n",
    "col_na = train.isnull().sum()\n",
    "to_drop = col_na[(col_na /  train.shape[0]) > 0.9].index\n",
    "\n",
    "use_cols = [f for f in train.columns if f not in to_drop]\n",
    "cat_features = [f for f in cat_features if f not in to_drop]\n",
    "num_features = [f for f in num_features if f not in to_drop]\n",
    "\n",
    "train[cat_features] = train[cat_features].astype(str)\n",
    "train[num_features] = train[num_features].astype(np.float)\n",
    "train = train[use_cols]\n",
    "\n",
    "test[cat_features] = test[cat_features].astype(str)\n",
    "test[num_features] = test[num_features].astype(np.float)\n",
    "test = test[[f for f in use_cols if f != 'isFraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b42ba90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b42ba90",
    "outputId": "7402a9ca-56e7-4ce0-bf18-c42acdd63f13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# median 값 채워 넣기\n",
    "\n",
    "train[num_features] = SimpleImputer(strategy=\"median\").fit_transform(train[num_features])\n",
    "train[cat_features] = train[cat_features].replace(\"nan\", \"missing\")\n",
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ab49d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3ab49d7",
    "outputId": "bb2e4804-4449-4c4d-9923-55ce8bb33eb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[num_features] = SimpleImputer(strategy=\"median\").fit_transform(test[num_features])\n",
    "test[cat_features] = test[cat_features].replace(\"nan\", \"missing\")\n",
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e654347",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e654347",
    "outputId": "edb5ac31-9201-455a-c43f-29c771b2d21c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 423)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee71df",
   "metadata": {
    "id": "f5ee71df"
   },
   "source": [
    "## Train/Val Split\n",
    "testing은 미래 시점에 수행되므로 validationi split은 datetime 칼럼을 사용하여 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d62f7b3",
   "metadata": {
    "id": "2d62f7b3"
   },
   "outputs": [],
   "source": [
    "train_split = train[\"TransactionDT\"] <= np.quantile(train[\"TransactionDT\"], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8462417f",
   "metadata": {
    "id": "8462417f"
   },
   "outputs": [],
   "source": [
    "train_X = train.loc[train_split.values, num_features + cat_features]\n",
    "train_y = train.loc[train_split.values, \"isFraud\"]\n",
    "\n",
    "val_X = train.loc[~train_split.values, num_features + cat_features]\n",
    "val_y = train.loc[~train_split.values, \"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6960280",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6960280",
    "outputId": "42aff419-ad55-411d-88f9-0764af1356ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808 train examples\n",
      "90 validation examples\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), 'train examples')\n",
    "print(len(val_X), 'validation examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c0dea",
   "metadata": {
    "id": "f55c0dea"
   },
   "source": [
    "## Pre-processing\n",
    "neural network는 숫자 데이터만 처리할 수 있으므로 input을 전처리해야 합니다. 아래 코드는 매우 단순화한 전처리 파이프라인이며 categoy embeddings와 같은 보다 정교한 방법 바꿀 수 있습니다.\n",
    "\n",
    "- numeric features 스케일링\n",
    "\n",
    "- categorical features 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be24683",
   "metadata": {
    "id": "7be24683"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "woe = WOEEncoder()\n",
    "column_trans = ColumnTransformer(\n",
    "    [(\"scaler\", scaler, num_features),\n",
    "     (\"woe\", woe, cat_features)], remainder=\"passthrough\", n_jobs=-1\n",
    ")\n",
    "\n",
    "train_X_transformed = column_trans.fit_transform(train_X, train_y)\n",
    "val_X_transformed = column_trans.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4ea2956",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4ea2956",
    "outputId": "147e269d-eb44-4d22-8d20-ed7135cfc28c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 420) (90, 420) (1834, 420)\n"
     ]
    }
   ],
   "source": [
    "test_X_transformed = column_trans.transform(test[num_features + cat_features])\n",
    "print(train_X_transformed.shape, val_X_transformed.shape, test_X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5430a7c",
   "metadata": {
    "id": "e5430a7c"
   },
   "outputs": [],
   "source": [
    "train_X_transformed = pd.DataFrame(train_X_transformed, columns=[num_features + cat_features])\n",
    "val_X_transformed = pd.DataFrame(val_X_transformed, columns=[num_features + cat_features])\n",
    "test_X_trinsformed = pd.DataFrame(test_X_transformed, columns=[num_features + cat_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d40ab0",
   "metadata": {
    "id": "94d40ab0"
   },
   "source": [
    "## TF Data\n",
    "training과 inference를 더 빠르게 하려면 데이터를 TF Data object로 변환해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d56ccfc",
   "metadata": {
    "id": "8d56ccfc"
   },
   "outputs": [],
   "source": [
    "def prepare_tf_dataset(X, batch_size, y=None, shuffle=False, drop_remainder=False):\n",
    "    size_of_dataset = len(X)\n",
    "    if y is not None:\n",
    "        y = tf.one_hot(y.astype(int), 2)\n",
    "        ds = tf.data.Dataset.from_tensor_slices((np.array(X.astype(np.float32)), y))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(np.array(X.astype(np.float32)))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=size_of_dataset)\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    \n",
    "    autotune = tf.data.experimental.AUTOTUNE\n",
    "    ds = ds.prefetch(autotune)\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_tf_dataset(train_X_transformed, 16384, train_y)\n",
    "val_ds = prepare_tf_dataset(val_X_transformed, 16384, val_y)\n",
    "test_ds = prepare_tf_dataset(test_X_transformed, 16384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b5994",
   "metadata": {
    "id": "558b5994"
   },
   "source": [
    "## Model\n",
    "\n",
    "### TabNet\n",
    "\n",
    "위에서 언급한 클래스를 모두 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a97ce683",
   "metadata": {
    "id": "a97ce683"
   },
   "outputs": [],
   "source": [
    "def glu(x, n_units=None):\n",
    "    \"\"\"Generalized linear unit nonlinear activation.\"\"\"\n",
    "    return x[:, :n_units] * tf.nn.sigmoid(x[:, n_units:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90e97950",
   "metadata": {
    "id": "90e97950"
   },
   "outputs": [],
   "source": [
    "class FeatureBlock(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Implementation of a FL->BN->GLU block\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim,\n",
    "        apply_glu = True,\n",
    "        bn_momentum = 0.9,\n",
    "        fc = None,\n",
    "        epsilon = 1e-5,\n",
    "    ):\n",
    "        super(FeatureBlock, self).__init__()\n",
    "        self.apply_gpu = apply_glu\n",
    "        self.feature_dim = feature_dim\n",
    "        units = feature_dim * 2 if apply_glu else feature_dim # desired dimension gets multiplied by 2\n",
    "                                                              # because GLU activation halves it\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(units, use_bias=False) if fc is None else fc # shared layers can get re-used\n",
    "        self.bn = tf.keras.layers.BatchNormalization(momentum=bn_momentum, epsilon=epsilon)\n",
    "\n",
    "    def call(self, x, training = None):\n",
    "        x = self.fc(x) # inputs passes through the FC layer\n",
    "        x = self.bn(x, training=training) # FC layer output gets passed through the BN\n",
    "        if self.apply_gpu: \n",
    "            return glu(x, self.feature_dim) # GLU activation applied to BN output\n",
    "        return x\n",
    "\n",
    "    \n",
    "class FeatureTransformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim,\n",
    "        fcs = [],\n",
    "        n_total = 4,\n",
    "        n_shared = 2,\n",
    "        bn_momentum = 0.9,\n",
    "    ):\n",
    "        super(FeatureTransformer, self).__init__()\n",
    "        self.n_total, self.n_shared = n_total, n_shared\n",
    "\n",
    "        kwrgs = {\n",
    "            \"feature_dim\": feature_dim,\n",
    "            \"bn_momentum\": bn_momentum,\n",
    "        }\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = []\n",
    "        for n in range(n_total):\n",
    "            # some shared blocks\n",
    "            if fcs and n < len(fcs):\n",
    "                self.blocks.append(FeatureBlock(**kwrgs, fc=fcs[n])) # Building shared blocks by providing FC layers\n",
    "            # build new blocks\n",
    "            else:\n",
    "                self.blocks.append(FeatureBlock(**kwrgs)) # Step dependent blocks without the shared FC layers\n",
    "\n",
    "    def call(self, x, training = None):\n",
    "        # input passes through the first block\n",
    "        x = self.blocks[0](x, training=training) \n",
    "        # for the remaining blocks\n",
    "        for n in range(1, self.n_total):\n",
    "            # output from previous block gets multiplied by sqrt(0.5) and output of this block gets added\n",
    "            x = x * tf.sqrt(0.5) + self.blocks[n](x, training=training) \n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def shared_fcs(self):\n",
    "        return [self.blocks[i].fc for i in range(self.n_shared)]\n",
    "    \n",
    "class AttentiveTransformer(tf.keras.Model):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(AttentiveTransformer, self).__init__()\n",
    "        self.block = FeatureBlock(\n",
    "            feature_dim,\n",
    "            apply_glu=False,\n",
    "        )\n",
    "\n",
    "    def call(self, x, prior_scales, training=None):\n",
    "        x = self.block(x, training=training)\n",
    "        return sparsemax(x * prior_scales)\n",
    "    \n",
    "class TabNet(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,\n",
    "        feature_dim,\n",
    "        output_dim,\n",
    "        n_step = 2,\n",
    "        n_total = 4,\n",
    "        n_shared = 2,\n",
    "        relaxation_factor = 1.5,\n",
    "        bn_epsilon = 1e-5,\n",
    "        bn_momentum = 0.7,\n",
    "        sparsity_coefficient = 1e-5\n",
    "    ):\n",
    "        super(TabNet, self).__init__()\n",
    "        self.output_dim, self.num_features = output_dim, num_features\n",
    "        self.n_step, self.relaxation_factor = n_step, relaxation_factor\n",
    "        self.sparsity_coefficient = sparsity_coefficient\n",
    "\n",
    "        self.bn = tf.keras.layers.BatchNormalization(\n",
    "            momentum=bn_momentum, epsilon=bn_epsilon\n",
    "        )\n",
    "\n",
    "        kargs = {\n",
    "            \"feature_dim\": feature_dim + output_dim,\n",
    "            \"n_total\": n_total,\n",
    "            \"n_shared\": n_shared,\n",
    "            \"bn_momentum\": bn_momentum\n",
    "        }\n",
    "\n",
    "        # first feature transformer block is built first to get the shared blocks\n",
    "        self.feature_transforms = [FeatureTransformer(**kargs)]\n",
    "        self.attentive_transforms = []\n",
    "            \n",
    "        # each step consists out of FT and AT\n",
    "        for i in range(n_step):\n",
    "            self.feature_transforms.append(\n",
    "                FeatureTransformer(**kargs, fcs=self.feature_transforms[0].shared_fcs)\n",
    "            )\n",
    "            self.attentive_transforms.append(\n",
    "                AttentiveTransformer(num_features)\n",
    "            )\n",
    "        \n",
    "        # Final output layer\n",
    "        self.head = tf.keras.layers.Dense(2, activation=\"softmax\", use_bias=False)\n",
    "\n",
    "    def call(self, features, training = None):\n",
    "\n",
    "        bs = tf.shape(features)[0] # get batch shape\n",
    "        out_agg = tf.zeros((bs, self.output_dim)) # empty array with outputs to fill\n",
    "        prior_scales = tf.ones((bs, self.num_features)) # prior scales initialised as 1s\n",
    "        importance = tf.zeros([bs, self.num_features]) # importances\n",
    "        masks = []\n",
    "\n",
    "        features = self.bn(features, training=training) # Batch Normalisation\n",
    "        masked_features = features\n",
    "\n",
    "        total_entropy = 0.0\n",
    "\n",
    "        for step_i in range(self.n_step + 1):\n",
    "            # (masked) features go through the FT\n",
    "            x = self.feature_transforms[step_i](\n",
    "                masked_features, training=training\n",
    "            )\n",
    "            \n",
    "            # first FT is not used to generate output\n",
    "            if step_i > 0:\n",
    "                # first half of the FT output goes towards the decision \n",
    "                out = tf.keras.activations.relu(x[:, : self.output_dim])\n",
    "                out_agg += out\n",
    "                scale_agg = tf.reduce_sum(out, axis=1, keepdims=True) / (self.n_step - 1)\n",
    "                importance += mask_values * scale_agg\n",
    "                \n",
    "\n",
    "            # no need to build the features mask for the last step\n",
    "            if step_i < self.n_step:\n",
    "                # second half of the FT output goes as input to the AT\n",
    "                x_for_mask = x[:, self.output_dim :]\n",
    "                \n",
    "                # apply AT with prior scales\n",
    "                mask_values = self.attentive_transforms[step_i](\n",
    "                    x_for_mask, prior_scales, training=training\n",
    "                )\n",
    "\n",
    "                # recalculate the prior scales\n",
    "                prior_scales *= self.relaxation_factor - mask_values\n",
    "                \n",
    "                # multiply the second half of the FT output by the attention mask to enforce sparsity\n",
    "                masked_features = tf.multiply(mask_values, features)\n",
    "\n",
    "                # entropy is used to penalize the amount of sparsity in feature selection\n",
    "                total_entropy += tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        tf.multiply(-mask_values, tf.math.log(mask_values + 1e-15)),\n",
    "                        axis=1,\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # append mask values for later explainability\n",
    "                masks.append(tf.expand_dims(tf.expand_dims(mask_values, 0), 3))\n",
    "                \n",
    "        #Per step selection masks        \n",
    "        self.selection_masks = masks\n",
    "        \n",
    "        # Final output\n",
    "        final_output = self.head(out)\n",
    "        \n",
    "        # Add sparsity loss\n",
    "        loss = total_entropy / (self.n_step-1)\n",
    "        self.add_loss(self.sparsity_coefficient * loss)\n",
    "        \n",
    "        return final_output, importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ccf9fb",
   "metadata": {
    "id": "43ccf9fb"
   },
   "source": [
    "## HP Tuning\n",
    "메모리가 부족하면 pass\n",
    "\n",
    "- Feature Dimension - between 32 and 512\n",
    "\n",
    "- Number of steps - from 2 to 9\n",
    "\n",
    "- Relaxation factor - from 1 to 3\n",
    "\n",
    "- Sparsity Coefficiet - from 0 to 0.1\n",
    "\n",
    "- Batch Momentum - from 0.9 to 0.9999\n",
    "\n",
    "- Class weight - from 1 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1531919d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1531919d",
    "outputId": "e10b7fde-76ed-4bec-f9af-f5992286c618"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:54:38,368]\u001b[0m A new study created in memory with name: TabNet optimization\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.8826 - output_1_loss: 0.8594 - val_loss: 0.7357 - val_output_1_loss: 0.6824\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.7294 - output_1_loss: 0.7059 - val_loss: 0.7196 - val_output_1_loss: 0.6711\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.4196 - output_1_loss: 0.3964 - val_loss: 0.6963 - val_output_1_loss: 0.6508\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.3602 - output_1_loss: 0.3406 - val_loss: 0.6732 - val_output_1_loss: 0.6309\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.2112 - output_1_loss: 0.1912 - val_loss: 0.6510 - val_output_1_loss: 0.6109\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0974 - output_1_loss: 0.0798 - val_loss: 0.6174 - val_output_1_loss: 0.5790\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1715 - output_1_loss: 0.1558 - val_loss: 0.5751 - val_output_1_loss: 0.5381\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0692 - output_1_loss: 0.0555 - val_loss: 0.5252 - val_output_1_loss: 0.4894\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0624 - output_1_loss: 0.0495 - val_loss: 0.4746 - val_output_1_loss: 0.4401\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0546 - output_1_loss: 0.0422 - val_loss: 0.4274 - val_output_1_loss: 0.3940\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0472 - output_1_loss: 0.0353 - val_loss: 0.3826 - val_output_1_loss: 0.3502\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0421 - output_1_loss: 0.0303 - val_loss: 0.3414 - val_output_1_loss: 0.3098\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0380 - output_1_loss: 0.0263 - val_loss: 0.3068 - val_output_1_loss: 0.2758\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0360 - output_1_loss: 0.0247 - val_loss: 0.2753 - val_output_1_loss: 0.2448\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0291 - output_1_loss: 0.0181 - val_loss: 0.2480 - val_output_1_loss: 0.2180\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0286 - output_1_loss: 0.0181 - val_loss: 0.2247 - val_output_1_loss: 0.1954\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0247 - output_1_loss: 0.0147 - val_loss: 0.2040 - val_output_1_loss: 0.1752\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0257 - output_1_loss: 0.0162 - val_loss: 0.1864 - val_output_1_loss: 0.1582\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0352 - output_1_loss: 0.0253 - val_loss: 0.1740 - val_output_1_loss: 0.1462\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0253 - output_1_loss: 0.0154 - val_loss: 0.1642 - val_output_1_loss: 0.1367\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0200 - output_1_loss: 0.0104 - val_loss: 0.1554 - val_output_1_loss: 0.1282\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0226 - output_1_loss: 0.0133 - val_loss: 0.1476 - val_output_1_loss: 0.1209\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0158 - output_1_loss: 0.0069 - val_loss: 0.1411 - val_output_1_loss: 0.1149\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0147 - output_1_loss: 0.0062 - val_loss: 0.1351 - val_output_1_loss: 0.1095\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0177 - output_1_loss: 0.0094 - val_loss: 0.1293 - val_output_1_loss: 0.1042\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0127 - output_1_loss: 0.0045 - val_loss: 0.1233 - val_output_1_loss: 0.0985\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0116 - output_1_loss: 0.0035 - val_loss: 0.1178 - val_output_1_loss: 0.0932\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0158 - output_1_loss: 0.0080 - val_loss: 0.1128 - val_output_1_loss: 0.0886\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0104 - output_1_loss: 0.0030 - val_loss: 0.1088 - val_output_1_loss: 0.0848\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0157 - output_1_loss: 0.0084 - val_loss: 0.1054 - val_output_1_loss: 0.0817\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0090 - output_1_loss: 0.0017 - val_loss: 0.1024 - val_output_1_loss: 0.0789\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0185 - output_1_loss: 0.0112 - val_loss: 0.0996 - val_output_1_loss: 0.0765\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0118 - output_1_loss: 0.0047 - val_loss: 0.0968 - val_output_1_loss: 0.0741\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0086 - output_1_loss: 0.0016 - val_loss: 0.0943 - val_output_1_loss: 0.0719\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.0133 - output_1_loss: 0.0064 - val_loss: 0.0921 - val_output_1_loss: 0.0697\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0083 - output_1_loss: 0.0015 - val_loss: 0.0896 - val_output_1_loss: 0.0673\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0084 - output_1_loss: 0.0017 - val_loss: 0.0872 - val_output_1_loss: 0.0652\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0079 - output_1_loss: 0.0013 - val_loss: 0.0852 - val_output_1_loss: 0.0633\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0086 - output_1_loss: 0.0020 - val_loss: 0.0835 - val_output_1_loss: 0.0617\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0175 - output_1_loss: 0.0111 - val_loss: 0.0816 - val_output_1_loss: 0.0603\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0069 - output_1_loss: 5.6915e-04 - val_loss: 0.0799 - val_output_1_loss: 0.0591\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0068 - output_1_loss: 4.6272e-04 - val_loss: 0.0786 - val_output_1_loss: 0.0581\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0069 - output_1_loss: 5.3815e-04 - val_loss: 0.0777 - val_output_1_loss: 0.0575\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0067 - output_1_loss: 5.4179e-04 - val_loss: 0.0769 - val_output_1_loss: 0.0571\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0065 - output_1_loss: 5.0627e-04 - val_loss: 0.0765 - val_output_1_loss: 0.0572\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0062 - output_1_loss: 4.4200e-04 - val_loss: 0.0766 - val_output_1_loss: 0.0576\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0060 - output_1_loss: 3.9227e-04 - val_loss: 0.0768 - val_output_1_loss: 0.0582\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0058 - output_1_loss: 3.7208e-04 - val_loss: 0.0772 - val_output_1_loss: 0.0589\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0057 - output_1_loss: 3.6454e-04 - val_loss: 0.0775 - val_output_1_loss: 0.0596\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0055 - output_1_loss: 3.3720e-04 - val_loss: 0.0777 - val_output_1_loss: 0.0601\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:55:25,976]\u001b[0m Trial 0 finished with value: 0.1 and parameters: {'feature_dim': 512, 'n_step': 2, 'n_shared': 0, 'relaxation_factor': 1.4, 'sparsity_coefficient': 0.0072571939788118765, 'bn_momentum': 0.9283788473853494}. Best is trial 0 with value: 0.1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 54s 54s/step - loss: 0.6800 - output_1_loss: 0.6773 - val_loss: 0.7003 - val_output_1_loss: 0.6877\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.6397 - output_1_loss: 0.6369 - val_loss: 0.6904 - val_output_1_loss: 0.6794\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.5925 - output_1_loss: 0.5899 - val_loss: 0.6781 - val_output_1_loss: 0.6680\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.5777 - output_1_loss: 0.5752 - val_loss: 0.6735 - val_output_1_loss: 0.6637\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.5503 - output_1_loss: 0.5479 - val_loss: 0.6686 - val_output_1_loss: 0.6595\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.5846 - output_1_loss: 0.5822 - val_loss: 0.6619 - val_output_1_loss: 0.6533\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.5810 - output_1_loss: 0.5784 - val_loss: 0.6536 - val_output_1_loss: 0.6456\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.5583 - output_1_loss: 0.5558 - val_loss: 0.6446 - val_output_1_loss: 0.6370\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.5124 - output_1_loss: 0.5099 - val_loss: 0.6349 - val_output_1_loss: 0.6275\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.4609 - output_1_loss: 0.4585 - val_loss: 0.6278 - val_output_1_loss: 0.6205\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5316 - output_1_loss: 0.5291 - val_loss: 0.6235 - val_output_1_loss: 0.6162\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.4018 - output_1_loss: 0.3994 - val_loss: 0.6095 - val_output_1_loss: 0.6022\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.3706 - output_1_loss: 0.3682 - val_loss: 0.5963 - val_output_1_loss: 0.5894\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.4582 - output_1_loss: 0.4562 - val_loss: 0.5895 - val_output_1_loss: 0.5826\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.4392 - output_1_loss: 0.4370 - val_loss: 0.5825 - val_output_1_loss: 0.5759\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 0.3844 - output_1_loss: 0.3823 - val_loss: 0.5783 - val_output_1_loss: 0.5724\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.4255 - output_1_loss: 0.4231 - val_loss: 0.5692 - val_output_1_loss: 0.5632\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.3733 - output_1_loss: 0.3713 - val_loss: 0.5557 - val_output_1_loss: 0.5501\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.3844 - output_1_loss: 0.3820 - val_loss: 0.5479 - val_output_1_loss: 0.5420\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4374 - output_1_loss: 0.4349 - val_loss: 0.5364 - val_output_1_loss: 0.5302\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5230 - output_1_loss: 0.5209 - val_loss: 0.5275 - val_output_1_loss: 0.5216\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.3843 - output_1_loss: 0.3821 - val_loss: 0.5199 - val_output_1_loss: 0.5140\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.2509 - output_1_loss: 0.2488 - val_loss: 0.5116 - val_output_1_loss: 0.5059\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3620 - output_1_loss: 0.3598 - val_loss: 0.5032 - val_output_1_loss: 0.4973\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.3616 - output_1_loss: 0.3594 - val_loss: 0.4919 - val_output_1_loss: 0.4865\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3731 - output_1_loss: 0.3711 - val_loss: 0.4825 - val_output_1_loss: 0.4767\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2568 - output_1_loss: 0.2546 - val_loss: 0.4682 - val_output_1_loss: 0.4626\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 0.3130 - output_1_loss: 0.3108 - val_loss: 0.4556 - val_output_1_loss: 0.4500\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3202 - output_1_loss: 0.3181 - val_loss: 0.4432 - val_output_1_loss: 0.4383\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.4521 - output_1_loss: 0.4500 - val_loss: 0.4401 - val_output_1_loss: 0.4352\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3089 - output_1_loss: 0.3066 - val_loss: 0.4246 - val_output_1_loss: 0.4197\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2608 - output_1_loss: 0.2587 - val_loss: 0.4149 - val_output_1_loss: 0.4100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.2237 - output_1_loss: 0.2218 - val_loss: 0.4125 - val_output_1_loss: 0.4082\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.2339 - output_1_loss: 0.2320 - val_loss: 0.3960 - val_output_1_loss: 0.3914\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.2067 - output_1_loss: 0.2048 - val_loss: 0.3788 - val_output_1_loss: 0.3742\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.2283 - output_1_loss: 0.2263 - val_loss: 0.3716 - val_output_1_loss: 0.3668\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 0.2149 - output_1_loss: 0.2129 - val_loss: 0.3600 - val_output_1_loss: 0.3556\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.1595 - output_1_loss: 0.1575 - val_loss: 0.3482 - val_output_1_loss: 0.3442\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.2244 - output_1_loss: 0.2227 - val_loss: 0.3428 - val_output_1_loss: 0.3386\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.3091 - output_1_loss: 0.3073 - val_loss: 0.3364 - val_output_1_loss: 0.3321\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.2098 - output_1_loss: 0.2077 - val_loss: 0.3244 - val_output_1_loss: 0.3200\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.2587 - output_1_loss: 0.2567 - val_loss: 0.3182 - val_output_1_loss: 0.3138\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.2542 - output_1_loss: 0.2523 - val_loss: 0.3106 - val_output_1_loss: 0.3064\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2721 - output_1_loss: 0.2703 - val_loss: 0.3108 - val_output_1_loss: 0.3064\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.2382 - output_1_loss: 0.2362 - val_loss: 0.3005 - val_output_1_loss: 0.2961\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1702 - output_1_loss: 0.1681 - val_loss: 0.2920 - val_output_1_loss: 0.2877\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1837 - output_1_loss: 0.1815 - val_loss: 0.2761 - val_output_1_loss: 0.2719\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.2125 - output_1_loss: 0.2103 - val_loss: 0.2721 - val_output_1_loss: 0.2674\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.2043 - output_1_loss: 0.2023 - val_loss: 0.2695 - val_output_1_loss: 0.2647\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1630 - output_1_loss: 0.1609 - val_loss: 0.2537 - val_output_1_loss: 0.2492\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1587 - output_1_loss: 0.1569 - val_loss: 0.2453 - val_output_1_loss: 0.2408\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.2346 - output_1_loss: 0.2322 - val_loss: 0.2403 - val_output_1_loss: 0.2359\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1809 - output_1_loss: 0.1785 - val_loss: 0.2293 - val_output_1_loss: 0.2249\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2382 - output_1_loss: 0.2360 - val_loss: 0.2340 - val_output_1_loss: 0.2297\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1563 - output_1_loss: 0.1542 - val_loss: 0.2288 - val_output_1_loss: 0.2245\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2757 - output_1_loss: 0.2738 - val_loss: 0.2282 - val_output_1_loss: 0.2238\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1834 - output_1_loss: 0.1816 - val_loss: 0.2210 - val_output_1_loss: 0.2165\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1877 - output_1_loss: 0.1857 - val_loss: 0.2153 - val_output_1_loss: 0.2109\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1538 - output_1_loss: 0.1516 - val_loss: 0.2095 - val_output_1_loss: 0.2051\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1547 - output_1_loss: 0.1525 - val_loss: 0.1950 - val_output_1_loss: 0.1908\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1148 - output_1_loss: 0.1127 - val_loss: 0.1871 - val_output_1_loss: 0.1827\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1364 - output_1_loss: 0.1341 - val_loss: 0.1812 - val_output_1_loss: 0.1770\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.1552 - output_1_loss: 0.1530 - val_loss: 0.1742 - val_output_1_loss: 0.1702\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1444 - output_1_loss: 0.1423 - val_loss: 0.1744 - val_output_1_loss: 0.1704\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.1273 - output_1_loss: 0.1253 - val_loss: 0.1671 - val_output_1_loss: 0.1631\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.1346 - output_1_loss: 0.1325 - val_loss: 0.1672 - val_output_1_loss: 0.1632\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.1383 - output_1_loss: 0.1363 - val_loss: 0.1661 - val_output_1_loss: 0.1623\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1284 - output_1_loss: 0.1265 - val_loss: 0.1533 - val_output_1_loss: 0.1496\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.1168 - output_1_loss: 0.1149 - val_loss: 0.1515 - val_output_1_loss: 0.1479\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1111 - output_1_loss: 0.1090 - val_loss: 0.1477 - val_output_1_loss: 0.1442\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1487 - output_1_loss: 0.1468 - val_loss: 0.1430 - val_output_1_loss: 0.1396\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0948 - output_1_loss: 0.0929 - val_loss: 0.1434 - val_output_1_loss: 0.1400\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1196 - output_1_loss: 0.1175 - val_loss: 0.1415 - val_output_1_loss: 0.1379\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0958 - output_1_loss: 0.0938 - val_loss: 0.1351 - val_output_1_loss: 0.1315\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2162 - output_1_loss: 0.2141 - val_loss: 0.1319 - val_output_1_loss: 0.1283\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.1458 - output_1_loss: 0.1441 - val_loss: 0.1294 - val_output_1_loss: 0.1261\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.1157 - output_1_loss: 0.1139 - val_loss: 0.1184 - val_output_1_loss: 0.1150\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1379 - output_1_loss: 0.1363 - val_loss: 0.1221 - val_output_1_loss: 0.1188\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.0904 - output_1_loss: 0.0888 - val_loss: 0.1158 - val_output_1_loss: 0.1124\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1116 - output_1_loss: 0.1100 - val_loss: 0.1126 - val_output_1_loss: 0.1093\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1007 - output_1_loss: 0.0992 - val_loss: 0.1231 - val_output_1_loss: 0.1199\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1452 - output_1_loss: 0.1437 - val_loss: 0.1124 - val_output_1_loss: 0.1091\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1772 - output_1_loss: 0.1758 - val_loss: 0.1143 - val_output_1_loss: 0.1112\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1480 - output_1_loss: 0.1466 - val_loss: 0.1140 - val_output_1_loss: 0.1109\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1235 - output_1_loss: 0.1220 - val_loss: 0.1086 - val_output_1_loss: 0.1056\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1379 - output_1_loss: 0.1365 - val_loss: 0.1045 - val_output_1_loss: 0.1016\n",
      "1/1 [==============================] - 46s 46s/step - loss: 0.7599 - output_1_loss: 0.7599 - val_loss: 0.6914 - val_output_1_loss: 0.6910\n",
      "Epoch 87/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.7872 - output_1_loss: 0.7872 - val_loss: 0.6921 - val_output_1_loss: 0.6917\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0944 - output_1_loss: 0.0930 - val_loss: 0.1031 - val_output_1_loss: 0.1002\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.6744 - output_1_loss: 0.6743 - val_loss: 0.6835 - val_output_1_loss: 0.6832\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.1335 - output_1_loss: 0.1323 - val_loss: 0.1018 - val_output_1_loss: 0.0989\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0995 - output_1_loss: 0.0981 - val_loss: 0.0846 - val_output_1_loss: 0.0819\n",
      "Epoch 90/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1379 - output_1_loss: 0.1363 - val_loss: 0.1094 - val_output_1_loss: 0.1066\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1765 - output_1_loss: 0.1748 - val_loss: 0.1112 - val_output_1_loss: 0.1084\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.7268 - output_1_loss: 0.7267 - val_loss: 0.6833 - val_output_1_loss: 0.6830\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0877 - output_1_loss: 0.0864 - val_loss: 0.0934 - val_output_1_loss: 0.0907\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7322 - output_1_loss: 0.7321Epoch 93/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.7322 - output_1_loss: 0.7321 - val_loss: 0.6772 - val_output_1_loss: 0.6769\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1136 - output_1_loss: 0.1121 - val_loss: 0.0894 - val_output_1_loss: 0.0867\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.6960 - output_1_loss: 0.6959 - val_loss: 0.6687 - val_output_1_loss: 0.6684\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.1251 - output_1_loss: 0.1237 - val_loss: 0.0816 - val_output_1_loss: 0.0791\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1048 - output_1_loss: 0.1035 - val_loss: 0.0826 - val_output_1_loss: 0.0802\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.6591 - output_1_loss: 0.6590 - val_loss: 0.6637 - val_output_1_loss: 0.6634\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1086 - output_1_loss: 0.1072Epoch 8/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1086 - output_1_loss: 0.1072 - val_loss: 0.0855 - val_output_1_loss: 0.0831\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1622 - output_1_loss: 0.1608 - val_loss: 0.0870 - val_output_1_loss: 0.0845\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 0.6531 - output_1_loss: 0.6531 - val_loss: 0.6627 - val_output_1_loss: 0.6624\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.1120 - output_1_loss: 0.1106 - val_loss: 0.0822 - val_output_1_loss: 0.0798\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.1803 - output_1_loss: 0.1788 - val_loss: 0.0796 - val_output_1_loss: 0.0772\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0967 - output_1_loss: 0.0951Epoch 9/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0967 - output_1_loss: 0.0951 - val_loss: 0.0884 - val_output_1_loss: 0.0861\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.6006 - output_1_loss: 0.6005 - val_loss: 0.6597 - val_output_1_loss: 0.6594\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.6368 - output_1_loss: 0.6367 - val_loss: 0.6575 - val_output_1_loss: 0.6573\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.6376 - output_1_loss: 0.6376 - val_loss: 0.6583 - val_output_1_loss: 0.6581\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.5744 - output_1_loss: 0.5743 - val_loss: 0.6480 - val_output_1_loss: 0.6478\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5525 - output_1_loss: 0.5525 - val_loss: 0.6492 - val_output_1_loss: 0.6490\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.5753 - output_1_loss: 0.5752 - val_loss: 0.6426 - val_output_1_loss: 0.6424\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.5088 - output_1_loss: 0.5087 - val_loss: 0.6357 - val_output_1_loss: 0.6355\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.5511 - output_1_loss: 0.5510 - val_loss: 0.6281 - val_output_1_loss: 0.6279\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.5401 - output_1_loss: 0.5400 - val_loss: 0.6223 - val_output_1_loss: 0.6221\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.4747 - output_1_loss: 0.4746 - val_loss: 0.6152 - val_output_1_loss: 0.6150\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:56:22,658]\u001b[0m Trial 1 finished with value: 0.016129032258064516 and parameters: {'feature_dim': 128, 'n_step': 8, 'n_shared': 2, 'relaxation_factor': 2.9000000000000004, 'sparsity_coefficient': 0.004390369257508038, 'bn_momentum': 0.9487575515274111}. Best is trial 0 with value: 0.1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.5116 - output_1_loss: 0.5115 - val_loss: 0.6102 - val_output_1_loss: 0.6100\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4581 - output_1_loss: 0.4580 - val_loss: 0.6024 - val_output_1_loss: 0.6023\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5035 - output_1_loss: 0.5035Epoch 1/100\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.5035 - output_1_loss: 0.5035 - val_loss: 0.5997 - val_output_1_loss: 0.5995\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.5324 - output_1_loss: 0.5323 - val_loss: 0.5943 - val_output_1_loss: 0.5941\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.4694 - output_1_loss: 0.4694 - val_loss: 0.5885 - val_output_1_loss: 0.5884\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.5075 - output_1_loss: 0.5074 - val_loss: 0.5824 - val_output_1_loss: 0.5822\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.4265 - output_1_loss: 0.4264 - val_loss: 0.5786 - val_output_1_loss: 0.5784\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.5351 - output_1_loss: 0.5350 - val_loss: 0.5615 - val_output_1_loss: 0.5613\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.4925 - output_1_loss: 0.4924 - val_loss: 0.5589 - val_output_1_loss: 0.5587\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.4170 - output_1_loss: 0.4169 - val_loss: 0.5530 - val_output_1_loss: 0.5529\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5302 - output_1_loss: 0.5301 - val_loss: 0.5545 - val_output_1_loss: 0.5543\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.3856 - output_1_loss: 0.3855 - val_loss: 0.5457 - val_output_1_loss: 0.5456\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.4941 - output_1_loss: 0.4941 - val_loss: 0.5368 - val_output_1_loss: 0.5367\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.2948 - output_1_loss: 0.2948 - val_loss: 0.5356 - val_output_1_loss: 0.5355\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.4115 - output_1_loss: 0.4114 - val_loss: 0.5290 - val_output_1_loss: 0.5289\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 0.3778 - output_1_loss: 0.3777 - val_loss: 0.5196 - val_output_1_loss: 0.5195\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.4028 - output_1_loss: 0.4028 - val_loss: 0.5137 - val_output_1_loss: 0.5136\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.4502 - output_1_loss: 0.4501 - val_loss: 0.5057 - val_output_1_loss: 0.5056\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.3964 - output_1_loss: 0.3963 - val_loss: 0.4991 - val_output_1_loss: 0.4990\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.4446 - output_1_loss: 0.4445 - val_loss: 0.4939 - val_output_1_loss: 0.4937\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.3435 - output_1_loss: 0.3434 - val_loss: 0.4837 - val_output_1_loss: 0.4836\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.4520 - output_1_loss: 0.4519 - val_loss: 0.4778 - val_output_1_loss: 0.4777\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.3974 - output_1_loss: 0.3973 - val_loss: 0.4693 - val_output_1_loss: 0.4691\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.3856 - output_1_loss: 0.3856 - val_loss: 0.4607 - val_output_1_loss: 0.4606\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.3383 - output_1_loss: 0.3382 - val_loss: 0.4518 - val_output_1_loss: 0.4517\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.4371 - output_1_loss: 0.4370 - val_loss: 0.4478 - val_output_1_loss: 0.4477\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 0.4071 - output_1_loss: 0.4070 - val_loss: 0.4428 - val_output_1_loss: 0.4427\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.4237 - output_1_loss: 0.4236 - val_loss: 0.4356 - val_output_1_loss: 0.4355\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.3343 - output_1_loss: 0.3342 - val_loss: 0.4309 - val_output_1_loss: 0.4308\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.3761 - output_1_loss: 0.3760 - val_loss: 0.4232 - val_output_1_loss: 0.4231\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.3457 - output_1_loss: 0.3456 - val_loss: 0.4178 - val_output_1_loss: 0.4177\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.3863 - output_1_loss: 0.3862 - val_loss: 0.4196 - val_output_1_loss: 0.4195\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.3293 - output_1_loss: 0.3292 - val_loss: 0.4109 - val_output_1_loss: 0.4108\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2670 - output_1_loss: 0.2669 - val_loss: 0.3949 - val_output_1_loss: 0.3948\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.2952 - output_1_loss: 0.2951 - val_loss: 0.3908 - val_output_1_loss: 0.3907\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3371 - output_1_loss: 0.3370 - val_loss: 0.3882 - val_output_1_loss: 0.3881\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3252 - output_1_loss: 0.3251 - val_loss: 0.3774 - val_output_1_loss: 0.3773\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.2817 - output_1_loss: 0.2816 - val_loss: 0.3660 - val_output_1_loss: 0.3659\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.2920 - output_1_loss: 0.2920 - val_loss: 0.3514 - val_output_1_loss: 0.3513\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3297 - output_1_loss: 0.3297 - val_loss: 0.3442 - val_output_1_loss: 0.3441\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1871 - output_1_loss: 0.1871 - val_loss: 0.3446 - val_output_1_loss: 0.3445\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.3043 - output_1_loss: 0.3043 - val_loss: 0.3373 - val_output_1_loss: 0.3372\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.2531 - output_1_loss: 0.2531 - val_loss: 0.3336 - val_output_1_loss: 0.3335\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.3420 - output_1_loss: 0.3419 - val_loss: 0.3367 - val_output_1_loss: 0.3366\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.2273 - output_1_loss: 0.2273 - val_loss: 0.3294 - val_output_1_loss: 0.3293\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.2266 - output_1_loss: 0.2265 - val_loss: 0.3149 - val_output_1_loss: 0.3148\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.2415 - output_1_loss: 0.2414 - val_loss: 0.2787 - val_output_1_loss: 0.2786\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 0.2487 - output_1_loss: 0.2487 - val_loss: 0.2682 - val_output_1_loss: 0.2681\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2529 - output_1_loss: 0.2528 - val_loss: 0.2530 - val_output_1_loss: 0.2529\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.5902 - output_1_loss: 0.5902 - val_loss: 0.6847 - val_output_1_loss: 0.6846\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2742 - output_1_loss: 0.2742 - val_loss: 0.2738 - val_output_1_loss: 0.2737\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2571 - output_1_loss: 0.2570 - val_loss: 0.2665 - val_output_1_loss: 0.2664\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2260 - output_1_loss: 0.2260 - val_loss: 0.2680 - val_output_1_loss: 0.2679\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2425 - output_1_loss: 0.2425 - val_loss: 0.2547 - val_output_1_loss: 0.2546\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2497 - output_1_loss: 0.2497 - val_loss: 0.2512 - val_output_1_loss: 0.2511\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2073 - output_1_loss: 0.2073 - val_loss: 0.2528 - val_output_1_loss: 0.2527\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2519 - output_1_loss: 0.2519 - val_loss: 0.2500 - val_output_1_loss: 0.2500\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2658 - output_1_loss: 0.2658 - val_loss: 0.2425 - val_output_1_loss: 0.2424\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2104 - output_1_loss: 0.2104Epoch 2/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2104 - output_1_loss: 0.2104 - val_loss: 0.2403 - val_output_1_loss: 0.2402\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5654 - output_1_loss: 0.5654 - val_loss: 0.6772 - val_output_1_loss: 0.6772\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2673 - output_1_loss: 0.2672Epoch 3/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.2673 - output_1_loss: 0.2672 - val_loss: 0.2274 - val_output_1_loss: 0.2273\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5588 - output_1_loss: 0.5588 - val_loss: 0.6700 - val_output_1_loss: 0.6700\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2555 - output_1_loss: 0.2555Epoch 4/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2555 - output_1_loss: 0.2555 - val_loss: 0.2193 - val_output_1_loss: 0.2192\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5634 - output_1_loss: 0.5634 - val_loss: 0.6623 - val_output_1_loss: 0.6623\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4793 - output_1_loss: 0.4793 - val_loss: 0.6541 - val_output_1_loss: 0.6540\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.1737 - output_1_loss: 0.1736 - val_loss: 0.2151 - val_output_1_loss: 0.2150\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5743 - output_1_loss: 0.5742 - val_loss: 0.6466 - val_output_1_loss: 0.6466\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4317 - output_1_loss: 0.4317Epoch 80/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4317 - output_1_loss: 0.4317 - val_loss: 0.6372 - val_output_1_loss: 0.6372\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4017 - output_1_loss: 0.4017 - val_loss: 0.6294 - val_output_1_loss: 0.6293\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.2254 - output_1_loss: 0.2253 - val_loss: 0.2110 - val_output_1_loss: 0.2109\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5133 - output_1_loss: 0.5133 - val_loss: 0.6210 - val_output_1_loss: 0.6210\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4548 - output_1_loss: 0.4548 - val_loss: 0.6137 - val_output_1_loss: 0.6136\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.1603 - output_1_loss: 0.1603 - val_loss: 0.2002 - val_output_1_loss: 0.2001\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.4424 - output_1_loss: 0.4424 - val_loss: 0.6033 - val_output_1_loss: 0.6033\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3578 - output_1_loss: 0.3578 - val_loss: 0.5934 - val_output_1_loss: 0.5934\n",
      "Epoch 13/100\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4621 - output_1_loss: 0.4621 - val_loss: 0.5871 - val_output_1_loss: 0.5870\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3543 - output_1_loss: 0.3543 - val_loss: 0.5732 - val_output_1_loss: 0.5732\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.2376 - output_1_loss: 0.2376 - val_loss: 0.1899 - val_output_1_loss: 0.1898\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3742 - output_1_loss: 0.3742 - val_loss: 0.5596 - val_output_1_loss: 0.5596\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2377 - output_1_loss: 0.2376 - val_loss: 0.5422 - val_output_1_loss: 0.5422\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3687 - output_1_loss: 0.3687Epoch 83/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3687 - output_1_loss: 0.3687 - val_loss: 0.5250 - val_output_1_loss: 0.5250\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1510 - output_1_loss: 0.1509 - val_loss: 0.2079 - val_output_1_loss: 0.2078\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2206 - output_1_loss: 0.2206 - val_loss: 0.4982 - val_output_1_loss: 0.4982\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2127 - output_1_loss: 0.2126Epoch 19/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.2127 - output_1_loss: 0.2126 - val_loss: 0.1726 - val_output_1_loss: 0.1726\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.2565 - output_1_loss: 0.2565 - val_loss: 0.4778 - val_output_1_loss: 0.4778\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1996 - output_1_loss: 0.1995Epoch 20/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1996 - output_1_loss: 0.1995 - val_loss: 0.1700 - val_output_1_loss: 0.1700\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2186 - output_1_loss: 0.2186 - val_loss: 0.4573 - val_output_1_loss: 0.4573\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1965 - output_1_loss: 0.1965 - val_loss: 0.4385 - val_output_1_loss: 0.4385\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1871 - output_1_loss: 0.1870 - val_loss: 0.1700 - val_output_1_loss: 0.1699\n",
      "Epoch 87/100\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.1901 - output_1_loss: 0.1900 - val_loss: 0.1797 - val_output_1_loss: 0.1796\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.1400 - output_1_loss: 0.1399 - val_loss: 0.4136 - val_output_1_loss: 0.4136\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.2238 - output_1_loss: 0.2238 - val_loss: 0.1789 - val_output_1_loss: 0.1789\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.1441 - output_1_loss: 0.1441 - val_loss: 0.3916 - val_output_1_loss: 0.3916\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1711 - output_1_loss: 0.1711 - val_loss: 0.2215 - val_output_1_loss: 0.2214\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1613 - output_1_loss: 0.1613Epoch 90/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1613 - output_1_loss: 0.1613 - val_loss: 0.3775 - val_output_1_loss: 0.3775\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.1775 - output_1_loss: 0.1775 - val_loss: 0.1798 - val_output_1_loss: 0.1797\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.1114 - output_1_loss: 0.1114 - val_loss: 0.3544 - val_output_1_loss: 0.3544\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.1507 - output_1_loss: 0.1506 - val_loss: 0.1793 - val_output_1_loss: 0.1792\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1046 - output_1_loss: 0.1046 - val_loss: 0.3316 - val_output_1_loss: 0.3316\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.1314 - output_1_loss: 0.1314 - val_loss: 0.3166 - val_output_1_loss: 0.3166\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1148 - output_1_loss: 0.1148 - val_loss: 0.3005 - val_output_1_loss: 0.3005\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0959 - output_1_loss: 0.0959 - val_loss: 0.2850 - val_output_1_loss: 0.2849\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0972 - output_1_loss: 0.0972 - val_loss: 0.2695 - val_output_1_loss: 0.2694\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0914 - output_1_loss: 0.0914 - val_loss: 0.2541 - val_output_1_loss: 0.2541\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0983 - output_1_loss: 0.0982 - val_loss: 0.2413 - val_output_1_loss: 0.2413\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0756 - output_1_loss: 0.0756 - val_loss: 0.2250 - val_output_1_loss: 0.2250\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0729 - output_1_loss: 0.0729 - val_loss: 0.2073 - val_output_1_loss: 0.2073\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1090 - output_1_loss: 0.1090 - val_loss: 0.1944 - val_output_1_loss: 0.1944\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0758 - output_1_loss: 0.0758 - val_loss: 0.1822 - val_output_1_loss: 0.1822\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0799 - output_1_loss: 0.0799 - val_loss: 0.1676 - val_output_1_loss: 0.1676\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0826 - output_1_loss: 0.0826 - val_loss: 0.1599 - val_output_1_loss: 0.1599\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0750 - output_1_loss: 0.0750 - val_loss: 0.1512 - val_output_1_loss: 0.1512\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1006 - output_1_loss: 0.1006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:57:01,075]\u001b[0m Trial 2 finished with value: 0.013888888888888888 and parameters: {'feature_dim': 64, 'n_step': 9, 'n_shared': 1, 'relaxation_factor': 2.7, 'sparsity_coefficient': 0.0001388852628966294, 'bn_momentum': 0.9380306946377736}. Best is trial 0 with value: 0.1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.1006 - output_1_loss: 0.1006 - val_loss: 0.1463 - val_output_1_loss: 0.1463\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0863 - output_1_loss: 0.0863 - val_loss: 0.1379 - val_output_1_loss: 0.1379\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.0934 - output_1_loss: 0.0934 - val_loss: 0.1276 - val_output_1_loss: 0.1276\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0865 - output_1_loss: 0.0865Epoch 1/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0865 - output_1_loss: 0.0865 - val_loss: 0.1213 - val_output_1_loss: 0.1213\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0906 - output_1_loss: 0.0906 - val_loss: 0.1193 - val_output_1_loss: 0.1192\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0844 - output_1_loss: 0.0844 - val_loss: 0.1238 - val_output_1_loss: 0.1238\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0895 - output_1_loss: 0.0895 - val_loss: 0.1179 - val_output_1_loss: 0.1178\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1033 - output_1_loss: 0.1033 - val_loss: 0.1131 - val_output_1_loss: 0.1131\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0851 - output_1_loss: 0.0851 - val_loss: 0.1112 - val_output_1_loss: 0.1112\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0889 - output_1_loss: 0.0889 - val_loss: 0.1097 - val_output_1_loss: 0.1097\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.0871 - output_1_loss: 0.0871 - val_loss: 0.1089 - val_output_1_loss: 0.1089\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0794 - output_1_loss: 0.0794 - val_loss: 0.1027 - val_output_1_loss: 0.1027\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0775 - output_1_loss: 0.0775 - val_loss: 0.0948 - val_output_1_loss: 0.0947\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.0731 - output_1_loss: 0.0731 - val_loss: 0.0864 - val_output_1_loss: 0.0864\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0738 - output_1_loss: 0.0738 - val_loss: 0.0830 - val_output_1_loss: 0.0830\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0721 - output_1_loss: 0.0721 - val_loss: 0.0784 - val_output_1_loss: 0.0784\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0674 - output_1_loss: 0.0674 - val_loss: 0.0752 - val_output_1_loss: 0.0752\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0659 - output_1_loss: 0.0659 - val_loss: 0.0733 - val_output_1_loss: 0.0733\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.0649 - output_1_loss: 0.0649 - val_loss: 0.0706 - val_output_1_loss: 0.0706\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0680 - output_1_loss: 0.0680 - val_loss: 0.0673 - val_output_1_loss: 0.0673\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0751 - output_1_loss: 0.0751 - val_loss: 0.0673 - val_output_1_loss: 0.0673\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0832 - output_1_loss: 0.0832 - val_loss: 0.0679 - val_output_1_loss: 0.0678\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.2811 - output_1_loss: 0.2811 - val_loss: 0.0713 - val_output_1_loss: 0.0713\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1182 - output_1_loss: 0.1182 - val_loss: 0.0733 - val_output_1_loss: 0.0733\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1336 - output_1_loss: 0.1336 - val_loss: 0.0745 - val_output_1_loss: 0.0745\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:57:12,148]\u001b[0m Trial 3 finished with value: 0.1 and parameters: {'feature_dim': 128, 'n_step': 4, 'n_shared': 2, 'relaxation_factor': 2.7, 'sparsity_coefficient': 8.376461623297162e-06, 'bn_momentum': 0.9262092665048373}. Best is trial 0 with value: 0.1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.7932 - output_1_loss: 0.7932 - val_loss: 0.6816 - val_output_1_loss: 0.6815\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6485 - output_1_loss: 0.6485 - val_loss: 0.6685 - val_output_1_loss: 0.6684\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.5487 - output_1_loss: 0.5486 - val_loss: 0.6545 - val_output_1_loss: 0.6545\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2836 - output_1_loss: 0.2836 - val_loss: 0.6363 - val_output_1_loss: 0.6363\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.1450 - output_1_loss: 0.1449 - val_loss: 0.6077 - val_output_1_loss: 0.6076\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0859 - output_1_loss: 0.0859 - val_loss: 0.5566 - val_output_1_loss: 0.5565\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0761 - output_1_loss: 0.0761 - val_loss: 0.5074 - val_output_1_loss: 0.5073\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0690 - output_1_loss: 0.0690 - val_loss: 0.4629 - val_output_1_loss: 0.4629\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0643 - output_1_loss: 0.0643 - val_loss: 0.4267 - val_output_1_loss: 0.4266\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0610 - output_1_loss: 0.0610 - val_loss: 0.3955 - val_output_1_loss: 0.3955\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0581 - output_1_loss: 0.0581 - val_loss: 0.3663 - val_output_1_loss: 0.3663\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0537 - output_1_loss: 0.0537 - val_loss: 0.3421 - val_output_1_loss: 0.3421\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0563 - output_1_loss: 0.0563 - val_loss: 0.3214 - val_output_1_loss: 0.3214\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0565 - output_1_loss: 0.0564 - val_loss: 0.3018 - val_output_1_loss: 0.3017\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0529 - output_1_loss: 0.0529 - val_loss: 0.2868 - val_output_1_loss: 0.2867\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.6909 - output_1_loss: 0.6907 - val_loss: 0.6910 - val_output_1_loss: 0.6901\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0492 - output_1_loss: 0.0492 - val_loss: 0.2774 - val_output_1_loss: 0.2773\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6987 - output_1_loss: 0.6984 - val_loss: 0.6882 - val_output_1_loss: 0.6874\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6731 - output_1_loss: 0.6729Epoch 17/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0521 - output_1_loss: 0.0520 - val_loss: 0.2676 - val_output_1_loss: 0.2676\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.6731 - output_1_loss: 0.6729 - val_loss: 0.6840 - val_output_1_loss: 0.6832\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0452 - output_1_loss: 0.0452Epoch 4/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0452 - output_1_loss: 0.0452 - val_loss: 0.2571 - val_output_1_loss: 0.2570\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6233 - output_1_loss: 0.6231 - val_loss: 0.6805 - val_output_1_loss: 0.6797\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5949 - output_1_loss: 0.5946Epoch 19/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5949 - output_1_loss: 0.5946 - val_loss: 0.6759 - val_output_1_loss: 0.6752\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0473 - output_1_loss: 0.0472 - val_loss: 0.2452 - val_output_1_loss: 0.2452\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.5675 - output_1_loss: 0.5673 - val_loss: 0.6718 - val_output_1_loss: 0.6711\n",
      "Epoch 7/100\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0468 - output_1_loss: 0.0467 - val_loss: 0.2384 - val_output_1_loss: 0.2384\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5640 - output_1_loss: 0.5638 - val_loss: 0.6666 - val_output_1_loss: 0.6659\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5995 - output_1_loss: 0.5992 - val_loss: 0.6629 - val_output_1_loss: 0.6623\n",
      "Epoch 21/100\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0465 - output_1_loss: 0.0465 - val_loss: 0.2387 - val_output_1_loss: 0.2386\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0415 - output_1_loss: 0.0414 - val_loss: 0.2300 - val_output_1_loss: 0.2299\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.6359 - output_1_loss: 0.6356 - val_loss: 0.6581 - val_output_1_loss: 0.6575\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0404 - output_1_loss: 0.0404 - val_loss: 0.2202 - val_output_1_loss: 0.2202\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0379 - output_1_loss: 0.0378 - val_loss: 0.2120 - val_output_1_loss: 0.2119\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.5370 - output_1_loss: 0.5367 - val_loss: 0.6532 - val_output_1_loss: 0.6526\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0339 - output_1_loss: 0.0339Epoch 11/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0339 - output_1_loss: 0.0339 - val_loss: 0.2056 - val_output_1_loss: 0.2056\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0320 - output_1_loss: 0.0319 - val_loss: 0.2017 - val_output_1_loss: 0.2017\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5409 - output_1_loss: 0.5407 - val_loss: 0.6477 - val_output_1_loss: 0.6471\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5807 - output_1_loss: 0.5804Epoch 27/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5807 - output_1_loss: 0.5804 - val_loss: 0.6404 - val_output_1_loss: 0.6398\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0305 - output_1_loss: 0.0305 - val_loss: 0.1984 - val_output_1_loss: 0.1984\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0286 - output_1_loss: 0.0286Epoch 13/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0286 - output_1_loss: 0.0286 - val_loss: 0.1949 - val_output_1_loss: 0.1949\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0277 - output_1_loss: 0.0277 - val_loss: 0.1913 - val_output_1_loss: 0.1913\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5220 - output_1_loss: 0.5218 - val_loss: 0.6356 - val_output_1_loss: 0.6350\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0262 - output_1_loss: 0.0262Epoch 14/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0262 - output_1_loss: 0.0262 - val_loss: 0.1874 - val_output_1_loss: 0.1874\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4627 - output_1_loss: 0.4624 - val_loss: 0.6292 - val_output_1_loss: 0.6286\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5862 - output_1_loss: 0.5860Epoch 31/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5862 - output_1_loss: 0.5860 - val_loss: 0.6230 - val_output_1_loss: 0.6224\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0254 - output_1_loss: 0.0253 - val_loss: 0.1838 - val_output_1_loss: 0.1838\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.5024 - output_1_loss: 0.5021 - val_loss: 0.6179 - val_output_1_loss: 0.6174\n",
      "Epoch 17/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0246 - output_1_loss: 0.0246 - val_loss: 0.1811 - val_output_1_loss: 0.1811\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4602 - output_1_loss: 0.4599 - val_loss: 0.6106 - val_output_1_loss: 0.6101\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0235 - output_1_loss: 0.0235Epoch 18/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0235 - output_1_loss: 0.0235 - val_loss: 0.1793 - val_output_1_loss: 0.1793\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0226 - output_1_loss: 0.0225 - val_loss: 0.1780 - val_output_1_loss: 0.1780\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4186 - output_1_loss: 0.4183 - val_loss: 0.6027 - val_output_1_loss: 0.6022\n",
      "Epoch 19/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0206 - output_1_loss: 0.0206 - val_loss: 0.1769 - val_output_1_loss: 0.1769\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4489 - output_1_loss: 0.4486 - val_loss: 0.5952 - val_output_1_loss: 0.5947\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0212 - output_1_loss: 0.0212Epoch 20/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0212 - output_1_loss: 0.0212 - val_loss: 0.1763 - val_output_1_loss: 0.1763\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0193 - output_1_loss: 0.0192 - val_loss: 0.1768 - val_output_1_loss: 0.1767\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0193 - output_1_loss: 0.0193 - val_loss: 0.1757 - val_output_1_loss: 0.1756\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.3904 - output_1_loss: 0.3901 - val_loss: 0.5869 - val_output_1_loss: 0.5864\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0188 - output_1_loss: 0.0188 - val_loss: 0.1722 - val_output_1_loss: 0.1722\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0162 - output_1_loss: 0.0162 - val_loss: 0.1716 - val_output_1_loss: 0.1715\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.4079 - output_1_loss: 0.4077 - val_loss: 0.5797 - val_output_1_loss: 0.5791\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0191 - output_1_loss: 0.0191 - val_loss: 0.1715 - val_output_1_loss: 0.1714\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0913 - output_1_loss: 0.0913 - val_loss: 0.1705 - val_output_1_loss: 0.1705\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0343 - output_1_loss: 0.0343Epoch 22/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0343 - output_1_loss: 0.0343 - val_loss: 0.1773 - val_output_1_loss: 0.1772\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0306 - output_1_loss: 0.0306 - val_loss: 0.1717 - val_output_1_loss: 0.1716\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0289 - output_1_loss: 0.0288 - val_loss: 0.1629 - val_output_1_loss: 0.1629\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.3451 - output_1_loss: 0.3449 - val_loss: 0.5722 - val_output_1_loss: 0.5717\n",
      "Epoch 23/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0274 - output_1_loss: 0.0274 - val_loss: 0.1582 - val_output_1_loss: 0.1581\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3780 - output_1_loss: 0.3777 - val_loss: 0.5632 - val_output_1_loss: 0.5627\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3824 - output_1_loss: 0.3821Epoch 47/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3824 - output_1_loss: 0.3821 - val_loss: 0.5561 - val_output_1_loss: 0.5556\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0248 - output_1_loss: 0.0247 - val_loss: 0.1552 - val_output_1_loss: 0.1552\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.3389 - output_1_loss: 0.3386 - val_loss: 0.5490 - val_output_1_loss: 0.5485\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3485 - output_1_loss: 0.3483Epoch 48/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0231 - output_1_loss: 0.0231 - val_loss: 0.1533 - val_output_1_loss: 0.1533\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3485 - output_1_loss: 0.3483 - val_loss: 0.5422 - val_output_1_loss: 0.5417\n",
      "Epoch 49/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0269 - output_1_loss: 0.0269 - val_loss: 0.1513 - val_output_1_loss: 0.1512\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3816 - output_1_loss: 0.3814Epoch 50/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0232 - output_1_loss: 0.0232 - val_loss: 0.1493 - val_output_1_loss: 0.1493\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.3816 - output_1_loss: 0.3814 - val_loss: 0.5370 - val_output_1_loss: 0.5365\n",
      "Epoch 51/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0227 - output_1_loss: 0.0227 - val_loss: 0.1488 - val_output_1_loss: 0.1487\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0222 - output_1_loss: 0.0222 - val_loss: 0.1491 - val_output_1_loss: 0.1491\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.3697 - output_1_loss: 0.3695 - val_loss: 0.5318 - val_output_1_loss: 0.5314\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0205 - output_1_loss: 0.0205 - val_loss: 0.1492 - val_output_1_loss: 0.1491\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0188 - output_1_loss: 0.0188 - val_loss: 0.1486 - val_output_1_loss: 0.1486\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.4017 - output_1_loss: 0.4015 - val_loss: 0.5249 - val_output_1_loss: 0.5244\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0173 - output_1_loss: 0.0173Epoch 30/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0173 - output_1_loss: 0.0173 - val_loss: 0.1481 - val_output_1_loss: 0.1481\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2979 - output_1_loss: 0.2976 - val_loss: 0.5153 - val_output_1_loss: 0.5148\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3204 - output_1_loss: 0.3201Epoch 56/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3204 - output_1_loss: 0.3201 - val_loss: 0.5076 - val_output_1_loss: 0.5072\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0157 - output_1_loss: 0.0157 - val_loss: 0.1474 - val_output_1_loss: 0.1473\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3334 - output_1_loss: 0.3331 - val_loss: 0.5004 - val_output_1_loss: 0.5000\n",
      "Epoch 33/100\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0143 - output_1_loss: 0.0143 - val_loss: 0.1458 - val_output_1_loss: 0.1458\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3176 - output_1_loss: 0.3173 - val_loss: 0.4937 - val_output_1_loss: 0.4933\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0129 - output_1_loss: 0.0128 - val_loss: 0.1422 - val_output_1_loss: 0.1422\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2954 - output_1_loss: 0.2952 - val_loss: 0.4816 - val_output_1_loss: 0.4812\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0117 - output_1_loss: 0.0117Epoch 35/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0117 - output_1_loss: 0.0117 - val_loss: 0.1388 - val_output_1_loss: 0.1387\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0106 - output_1_loss: 0.0106 - val_loss: 0.1348 - val_output_1_loss: 0.1347\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2579 - output_1_loss: 0.2576 - val_loss: 0.4702 - val_output_1_loss: 0.4698\n",
      "Epoch 61/100\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0092 - output_1_loss: 0.0092 - val_loss: 0.1302 - val_output_1_loss: 0.1302\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.3098 - output_1_loss: 0.3095 - val_loss: 0.4611 - val_output_1_loss: 0.4606\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0118 - output_1_loss: 0.0118 - val_loss: 0.1281 - val_output_1_loss: 0.1281\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0075 - output_1_loss: 0.0074 - val_loss: 0.1254 - val_output_1_loss: 0.1254\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2675 - output_1_loss: 0.2672 - val_loss: 0.4504 - val_output_1_loss: 0.4500\n",
      "Epoch 38/100\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0069 - output_1_loss: 0.0069 - val_loss: 0.1218 - val_output_1_loss: 0.1217\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3099 - output_1_loss: 0.3097 - val_loss: 0.4422 - val_output_1_loss: 0.4417\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0777 - output_1_loss: 0.0776Epoch 39/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0777 - output_1_loss: 0.0776 - val_loss: 0.1168 - val_output_1_loss: 0.1167\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0070 - output_1_loss: 0.0070 - val_loss: 0.1105 - val_output_1_loss: 0.1104\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2559 - output_1_loss: 0.2557 - val_loss: 0.4284 - val_output_1_loss: 0.4280\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0109 - output_1_loss: 0.0108Epoch 40/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0109 - output_1_loss: 0.0108 - val_loss: 0.1030 - val_output_1_loss: 0.1029\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0195 - output_1_loss: 0.0195 - val_loss: 0.0987 - val_output_1_loss: 0.0987\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.2979 - output_1_loss: 0.2976 - val_loss: 0.4167 - val_output_1_loss: 0.4163\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0157 - output_1_loss: 0.0157Epoch 41/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0157 - output_1_loss: 0.0157 - val_loss: 0.0973 - val_output_1_loss: 0.0973\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3855 - output_1_loss: 0.3853 - val_loss: 0.4067 - val_output_1_loss: 0.4063\n",
      "Epoch 42/100\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0168 - output_1_loss: 0.0168 - val_loss: 0.0946 - val_output_1_loss: 0.0946\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2007 - output_1_loss: 0.2004 - val_loss: 0.3887 - val_output_1_loss: 0.3883\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0133 - output_1_loss: 0.0132 - val_loss: 0.0922 - val_output_1_loss: 0.0921\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2482 - output_1_loss: 0.2479 - val_loss: 0.3782 - val_output_1_loss: 0.3778\n",
      "Epoch 44/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0123 - output_1_loss: 0.0122 - val_loss: 0.0904 - val_output_1_loss: 0.0904\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1891 - output_1_loss: 0.1888 - val_loss: 0.3634 - val_output_1_loss: 0.3630\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0080 - output_1_loss: 0.0080 - val_loss: 0.0898 - val_output_1_loss: 0.0897\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0060 - output_1_loss: 0.0060 - val_loss: 0.0845 - val_output_1_loss: 0.0844\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.2043 - output_1_loss: 0.2040 - val_loss: 0.3483 - val_output_1_loss: 0.3479\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0052 - output_1_loss: 0.0052 - val_loss: 0.0818 - val_output_1_loss: 0.0818\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2337 - output_1_loss: 0.2334Epoch 76/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - output_1_loss: 0.0049 - val_loss: 0.0844 - val_output_1_loss: 0.0844\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - output_1_loss: 0.0044 - val_loss: 0.0855 - val_output_1_loss: 0.0855\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.2337 - output_1_loss: 0.2334 - val_loss: 0.3366 - val_output_1_loss: 0.3363\n",
      "Epoch 78/100\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0041 - output_1_loss: 0.0041 - val_loss: 0.0859 - val_output_1_loss: 0.0858\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - output_1_loss: 0.0037 - val_loss: 0.0869 - val_output_1_loss: 0.0868\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1956 - output_1_loss: 0.1953 - val_loss: 0.3213 - val_output_1_loss: 0.3209\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - output_1_loss: 0.0033Epoch 48/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0033 - output_1_loss: 0.0033 - val_loss: 0.0873 - val_output_1_loss: 0.0873\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1602 - output_1_loss: 0.1599 - val_loss: 0.3042 - val_output_1_loss: 0.3039\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1720 - output_1_loss: 0.1718 - val_loss: 0.2934 - val_output_1_loss: 0.2930\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1214 - output_1_loss: 0.1211 - val_loss: 0.2770 - val_output_1_loss: 0.2766\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2313 - output_1_loss: 0.2311 - val_loss: 0.2696 - val_output_1_loss: 0.2692\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4aae8087a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:57:45,679]\u001b[0m Trial 5 finished with value: 0.03333333333333333 and parameters: {'feature_dim': 512, 'n_step': 2, 'n_shared': 4, 'relaxation_factor': 1.4, 'sparsity_coefficient': 1.20933305460041e-05, 'bn_momentum': 0.9227022894136431}. Best is trial 0 with value: 0.1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1931 - output_1_loss: 0.1929 - val_loss: 0.2607 - val_output_1_loss: 0.2604\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1948 - output_1_loss: 0.1946Epoch 1/100\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.1948 - output_1_loss: 0.1946 - val_loss: 0.2531 - val_output_1_loss: 0.2527\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1223 - output_1_loss: 0.1221 - val_loss: 0.2389 - val_output_1_loss: 0.2385\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1104 - output_1_loss: 0.1101 - val_loss: 0.2290 - val_output_1_loss: 0.2286\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.1064 - output_1_loss: 0.1061 - val_loss: 0.2152 - val_output_1_loss: 0.2149\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.0780 - output_1_loss: 0.0778 - val_loss: 0.2013 - val_output_1_loss: 0.2010\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.0762 - output_1_loss: 0.0759 - val_loss: 0.1844 - val_output_1_loss: 0.1841\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0841 - output_1_loss: 0.0839 - val_loss: 0.1705 - val_output_1_loss: 0.1702\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0749 - output_1_loss: 0.0747 - val_loss: 0.1550 - val_output_1_loss: 0.1547\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.0812 - output_1_loss: 0.0809 - val_loss: 0.1411 - val_output_1_loss: 0.1408\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0733 - output_1_loss: 0.0731 - val_loss: 0.1401 - val_output_1_loss: 0.1397\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.0801 - output_1_loss: 0.0798 - val_loss: 0.1260 - val_output_1_loss: 0.1257\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.0713 - output_1_loss: 0.0710 - val_loss: 0.1158 - val_output_1_loss: 0.1155\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.0736 - output_1_loss: 0.0734 - val_loss: 0.1080 - val_output_1_loss: 0.1077\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0717 - output_1_loss: 0.0715 - val_loss: 0.1010 - val_output_1_loss: 0.1007\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0650 - output_1_loss: 0.0647 - val_loss: 0.0956 - val_output_1_loss: 0.0953\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.0624 - output_1_loss: 0.0621 - val_loss: 0.0895 - val_output_1_loss: 0.0892\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.0632 - output_1_loss: 0.0630 - val_loss: 0.0843 - val_output_1_loss: 0.0841\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0600 - output_1_loss: 0.0598 - val_loss: 0.0794 - val_output_1_loss: 0.0792\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0586 - output_1_loss: 0.0583 - val_loss: 0.0747 - val_output_1_loss: 0.0745\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0575 - output_1_loss: 0.0573 - val_loss: 0.0707 - val_output_1_loss: 0.0704\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0558 - output_1_loss: 0.0556 - val_loss: 0.0679 - val_output_1_loss: 0.0676\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0588 - output_1_loss: 0.0586 - val_loss: 0.0651 - val_output_1_loss: 0.0648\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0517 - output_1_loss: 0.0515 - val_loss: 0.0628 - val_output_1_loss: 0.0625\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0572 - output_1_loss: 0.0570 - val_loss: 0.0602 - val_output_1_loss: 0.0599\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0946 - output_1_loss: 0.0943 - val_loss: 0.0587 - val_output_1_loss: 0.0585\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0477 - output_1_loss: 0.0474 - val_loss: 0.0573 - val_output_1_loss: 0.0571\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0514 - output_1_loss: 0.0512 - val_loss: 0.0578 - val_output_1_loss: 0.0575\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0484 - output_1_loss: 0.0482 - val_loss: 0.0590 - val_output_1_loss: 0.0587\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0484 - output_1_loss: 0.0481 - val_loss: 0.0632 - val_output_1_loss: 0.0630\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0460 - output_1_loss: 0.0458 - val_loss: 0.0683 - val_output_1_loss: 0.0680\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.0441 - output_1_loss: 0.0439 - val_loss: 0.0705 - val_output_1_loss: 0.0703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4a58546b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:58:01,871]\u001b[0m Trial 4 finished with value: 0.1111111111111111 and parameters: {'feature_dim': 64, 'n_step': 5, 'n_shared': 1, 'relaxation_factor': 1.3, 'sparsity_coefficient': 0.00013712780924840138, 'bn_momentum': 0.9109992327159016}. Best is trial 4 with value: 0.1111111111111111.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.8608 - output_1_loss: 0.8608 - val_loss: 0.6897 - val_output_1_loss: 0.6897\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7724 - output_1_loss: 0.7724 - val_loss: 0.6858 - val_output_1_loss: 0.6858\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7403 - output_1_loss: 0.7403 - val_loss: 0.6819 - val_output_1_loss: 0.6819\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7471 - output_1_loss: 0.7471 - val_loss: 0.6781 - val_output_1_loss: 0.6781\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6761 - output_1_loss: 0.6761 - val_loss: 0.6737 - val_output_1_loss: 0.6736\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6296 - output_1_loss: 0.6296 - val_loss: 0.6694 - val_output_1_loss: 0.6693\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5876 - output_1_loss: 0.5876 - val_loss: 0.6641 - val_output_1_loss: 0.6641\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5581 - output_1_loss: 0.5581 - val_loss: 0.6589 - val_output_1_loss: 0.6589\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5358 - output_1_loss: 0.5358 - val_loss: 0.6537 - val_output_1_loss: 0.6537\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.4896 - output_1_loss: 0.4896 - val_loss: 0.6474 - val_output_1_loss: 0.6474\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4608 - output_1_loss: 0.4608 - val_loss: 0.6406 - val_output_1_loss: 0.6406\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4218 - output_1_loss: 0.4218 - val_loss: 0.6334 - val_output_1_loss: 0.6334\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3808 - output_1_loss: 0.3808 - val_loss: 0.6256 - val_output_1_loss: 0.6255\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3626 - output_1_loss: 0.3626 - val_loss: 0.6172 - val_output_1_loss: 0.6172\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3459 - output_1_loss: 0.3459 - val_loss: 0.6081 - val_output_1_loss: 0.6081\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7040 - output_1_loss: 0.7039Epoch 16/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3167 - output_1_loss: 0.3167 - val_loss: 0.5984 - val_output_1_loss: 0.5984\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2868 - output_1_loss: 0.2868 - val_loss: 0.5884 - val_output_1_loss: 0.5884\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2667 - output_1_loss: 0.2667 - val_loss: 0.5781 - val_output_1_loss: 0.5781\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2474 - output_1_loss: 0.2474 - val_loss: 0.5675 - val_output_1_loss: 0.5675\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2296 - output_1_loss: 0.2296 - val_loss: 0.5567 - val_output_1_loss: 0.5567\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2130 - output_1_loss: 0.2130 - val_loss: 0.5459 - val_output_1_loss: 0.5459\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1977 - output_1_loss: 0.1977 - val_loss: 0.5349 - val_output_1_loss: 0.5349\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1852 - output_1_loss: 0.1852 - val_loss: 0.5239 - val_output_1_loss: 0.5239\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1720 - output_1_loss: 0.1720 - val_loss: 0.5129 - val_output_1_loss: 0.5129\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1611 - output_1_loss: 0.1611 - val_loss: 0.5017 - val_output_1_loss: 0.5017\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1520 - output_1_loss: 0.1520 - val_loss: 0.4904 - val_output_1_loss: 0.4904\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1435 - output_1_loss: 0.1435 - val_loss: 0.4790 - val_output_1_loss: 0.4789\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1356 - output_1_loss: 0.1356 - val_loss: 0.4674 - val_output_1_loss: 0.4674\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1289 - output_1_loss: 0.1289 - val_loss: 0.4556 - val_output_1_loss: 0.4556\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1226 - output_1_loss: 0.1226 - val_loss: 0.4438 - val_output_1_loss: 0.4438\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1170 - output_1_loss: 0.1170 - val_loss: 0.4322 - val_output_1_loss: 0.4322\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1115 - output_1_loss: 0.1115 - val_loss: 0.4207 - val_output_1_loss: 0.4207\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1067 - output_1_loss: 0.1067 - val_loss: 0.4093 - val_output_1_loss: 0.4093\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1024 - output_1_loss: 0.1024 - val_loss: 0.3977 - val_output_1_loss: 0.3977\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.7040 - output_1_loss: 0.7039 - val_loss: 0.6892 - val_output_1_loss: 0.6889\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0979 - output_1_loss: 0.0979 - val_loss: 0.3860 - val_output_1_loss: 0.3860\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0939 - output_1_loss: 0.0939 - val_loss: 0.3744 - val_output_1_loss: 0.3744\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0927 - output_1_loss: 0.0927 - val_loss: 0.3632 - val_output_1_loss: 0.3632\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0928 - output_1_loss: 0.0928 - val_loss: 0.3522 - val_output_1_loss: 0.3522\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1287 - output_1_loss: 0.1287 - val_loss: 0.3438 - val_output_1_loss: 0.3438\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0904 - output_1_loss: 0.0903 - val_loss: 0.3334 - val_output_1_loss: 0.3334\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0851 - output_1_loss: 0.0851 - val_loss: 0.3233 - val_output_1_loss: 0.3233\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0821 - output_1_loss: 0.0821 - val_loss: 0.3134 - val_output_1_loss: 0.3134\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0831 - output_1_loss: 0.0831 - val_loss: 0.3036 - val_output_1_loss: 0.3036\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0775 - output_1_loss: 0.0775 - val_loss: 0.2938 - val_output_1_loss: 0.2938\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0763 - output_1_loss: 0.0763 - val_loss: 0.2845 - val_output_1_loss: 0.2845\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0736 - output_1_loss: 0.0736 - val_loss: 0.2757 - val_output_1_loss: 0.2757\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0709 - output_1_loss: 0.0709 - val_loss: 0.2675 - val_output_1_loss: 0.2675\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0698 - output_1_loss: 0.0698 - val_loss: 0.2599 - val_output_1_loss: 0.2599\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0680 - output_1_loss: 0.0680 - val_loss: 0.2527 - val_output_1_loss: 0.2527\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0663 - output_1_loss: 0.0663 - val_loss: 0.2461 - val_output_1_loss: 0.2461\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0643 - output_1_loss: 0.0643 - val_loss: 0.2397 - val_output_1_loss: 0.2397\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0627 - output_1_loss: 0.0627 - val_loss: 0.2334 - val_output_1_loss: 0.2334\n",
      "Epoch 2/100\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0635 - output_1_loss: 0.0635 - val_loss: 0.2275 - val_output_1_loss: 0.2275\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7150 - output_1_loss: 0.7148 - val_loss: 0.6847 - val_output_1_loss: 0.6844\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0606 - output_1_loss: 0.0606 - val_loss: 0.2218 - val_output_1_loss: 0.2218\n",
      "Epoch 55/100\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0597 - output_1_loss: 0.0597 - val_loss: 0.2166 - val_output_1_loss: 0.2166\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6828 - output_1_loss: 0.6827Epoch 56/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0575 - output_1_loss: 0.0575 - val_loss: 0.2117 - val_output_1_loss: 0.2117\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.6828 - output_1_loss: 0.6827 - val_loss: 0.6814 - val_output_1_loss: 0.6811\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0563 - output_1_loss: 0.0563Epoch 4/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0563 - output_1_loss: 0.0563 - val_loss: 0.2071 - val_output_1_loss: 0.2071\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0554 - output_1_loss: 0.0554 - val_loss: 0.2029 - val_output_1_loss: 0.2029\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.6637 - output_1_loss: 0.6636 - val_loss: 0.6771 - val_output_1_loss: 0.6768\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0546 - output_1_loss: 0.0546 - val_loss: 0.1990 - val_output_1_loss: 0.1990\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0540 - output_1_loss: 0.0540 - val_loss: 0.1953 - val_output_1_loss: 0.1953\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.6285 - output_1_loss: 0.6284 - val_loss: 0.6723 - val_output_1_loss: 0.6720\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0531 - output_1_loss: 0.0531 - val_loss: 0.1920 - val_output_1_loss: 0.1920\n",
      "Epoch 62/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0522 - output_1_loss: 0.0522 - val_loss: 0.1890 - val_output_1_loss: 0.1890\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0514 - output_1_loss: 0.0514 - val_loss: 0.1863 - val_output_1_loss: 0.1863\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.6652 - output_1_loss: 0.6650 - val_loss: 0.6679 - val_output_1_loss: 0.6676\n",
      "Epoch 7/100\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0502 - output_1_loss: 0.0502 - val_loss: 0.1842 - val_output_1_loss: 0.1842\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5439 - output_1_loss: 0.5438Epoch 65/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0494 - output_1_loss: 0.0494 - val_loss: 0.1826 - val_output_1_loss: 0.1826\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.5439 - output_1_loss: 0.5438 - val_loss: 0.6626 - val_output_1_loss: 0.6623\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0485 - output_1_loss: 0.0485 - val_loss: 0.1812 - val_output_1_loss: 0.1812\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0477 - output_1_loss: 0.0477 - val_loss: 0.1793 - val_output_1_loss: 0.1793\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5636 - output_1_loss: 0.5635 - val_loss: 0.6589 - val_output_1_loss: 0.6586\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0469 - output_1_loss: 0.0469 - val_loss: 0.1772 - val_output_1_loss: 0.1772\n",
      "Epoch 9/100\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0462 - output_1_loss: 0.0462 - val_loss: 0.1750 - val_output_1_loss: 0.1750\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5363 - output_1_loss: 0.5362 - val_loss: 0.6555 - val_output_1_loss: 0.6552\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0457 - output_1_loss: 0.0457 - val_loss: 0.1728 - val_output_1_loss: 0.1728\n",
      "Epoch 71/100\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0449 - output_1_loss: 0.0449 - val_loss: 0.1708 - val_output_1_loss: 0.1708\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0443 - output_1_loss: 0.0443 - val_loss: 0.1688 - val_output_1_loss: 0.1688\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.5504 - output_1_loss: 0.5502 - val_loss: 0.6508 - val_output_1_loss: 0.6505\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0438 - output_1_loss: 0.0438 - val_loss: 0.1668 - val_output_1_loss: 0.1668\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0433 - output_1_loss: 0.0433 - val_loss: 0.1645 - val_output_1_loss: 0.1645\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.4859 - output_1_loss: 0.4858 - val_loss: 0.6456 - val_output_1_loss: 0.6453\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0429 - output_1_loss: 0.0429Epoch 12/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0429 - output_1_loss: 0.0429 - val_loss: 0.1623 - val_output_1_loss: 0.1623\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0423 - output_1_loss: 0.0423 - val_loss: 0.1600 - val_output_1_loss: 0.1600\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.5089 - output_1_loss: 0.5088 - val_loss: 0.6404 - val_output_1_loss: 0.6401\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0418 - output_1_loss: 0.0418 - val_loss: 0.1577 - val_output_1_loss: 0.1577\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0414 - output_1_loss: 0.0414 - val_loss: 0.1555 - val_output_1_loss: 0.1555\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.4527 - output_1_loss: 0.4526 - val_loss: 0.6354 - val_output_1_loss: 0.6352\n",
      "Epoch 14/100\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0409 - output_1_loss: 0.0409 - val_loss: 0.1534 - val_output_1_loss: 0.1534\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4552 - output_1_loss: 0.4550Epoch 80/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0405 - output_1_loss: 0.0405 - val_loss: 0.1514 - val_output_1_loss: 0.1513\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.4552 - output_1_loss: 0.4550 - val_loss: 0.6306 - val_output_1_loss: 0.6304\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0403 - output_1_loss: 0.0403 - val_loss: 0.1492 - val_output_1_loss: 0.1492\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0397 - output_1_loss: 0.0397 - val_loss: 0.1472 - val_output_1_loss: 0.1472\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.4214 - output_1_loss: 0.4212 - val_loss: 0.6249 - val_output_1_loss: 0.6246\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0394 - output_1_loss: 0.0394Epoch 16/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0394 - output_1_loss: 0.0394 - val_loss: 0.1453 - val_output_1_loss: 0.1453\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0391 - output_1_loss: 0.0391 - val_loss: 0.1433 - val_output_1_loss: 0.1432\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.4538 - output_1_loss: 0.4536 - val_loss: 0.6197 - val_output_1_loss: 0.6195\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0385 - output_1_loss: 0.0385Epoch 17/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0385 - output_1_loss: 0.0385 - val_loss: 0.1414 - val_output_1_loss: 0.1413\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3815 - output_1_loss: 0.3814 - val_loss: 0.6139 - val_output_1_loss: 0.6136\n",
      "Epoch 18/100\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0381 - output_1_loss: 0.0381 - val_loss: 0.1395 - val_output_1_loss: 0.1395\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4112 - output_1_loss: 0.4110 - val_loss: 0.6071 - val_output_1_loss: 0.6069\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0377 - output_1_loss: 0.0377Epoch 19/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0377 - output_1_loss: 0.0377 - val_loss: 0.1377 - val_output_1_loss: 0.1377\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0373 - output_1_loss: 0.0373 - val_loss: 0.1358 - val_output_1_loss: 0.1358\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.3860 - output_1_loss: 0.3859 - val_loss: 0.6003 - val_output_1_loss: 0.6001\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0370 - output_1_loss: 0.0370 - val_loss: 0.1340 - val_output_1_loss: 0.1339\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0366 - output_1_loss: 0.0366 - val_loss: 0.1321 - val_output_1_loss: 0.1321\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.3455 - output_1_loss: 0.3454 - val_loss: 0.5914 - val_output_1_loss: 0.5912\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0362 - output_1_loss: 0.0362 - val_loss: 0.1303 - val_output_1_loss: 0.1303\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0358 - output_1_loss: 0.0358 - val_loss: 0.1285 - val_output_1_loss: 0.1285\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3761 - output_1_loss: 0.3760 - val_loss: 0.5836 - val_output_1_loss: 0.5834\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0354 - output_1_loss: 0.0354Epoch 22/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0354 - output_1_loss: 0.0354 - val_loss: 0.1275 - val_output_1_loss: 0.1275\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0350 - output_1_loss: 0.0350 - val_loss: 0.1263 - val_output_1_loss: 0.1263\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3463 - output_1_loss: 0.3462 - val_loss: 0.5774 - val_output_1_loss: 0.5771\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0346 - output_1_loss: 0.0346Epoch 23/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0346 - output_1_loss: 0.0346 - val_loss: 0.1250 - val_output_1_loss: 0.1250\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0342 - output_1_loss: 0.0342 - val_loss: 0.1239 - val_output_1_loss: 0.1238\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3169 - output_1_loss: 0.3168 - val_loss: 0.5701 - val_output_1_loss: 0.5699\n",
      "Epoch 24/100\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0338 - output_1_loss: 0.0338 - val_loss: 0.1227 - val_output_1_loss: 0.1227\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0334 - output_1_loss: 0.0334 - val_loss: 0.1215 - val_output_1_loss: 0.1215\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3122 - output_1_loss: 0.3121 - val_loss: 0.5618 - val_output_1_loss: 0.5616\n",
      "Epoch 25/100\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0330 - output_1_loss: 0.0330 - val_loss: 0.1201 - val_output_1_loss: 0.1200\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4075 - output_1_loss: 0.4074 - val_loss: 0.5542 - val_output_1_loss: 0.5540\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0326 - output_1_loss: 0.0326 - val_loss: 0.1185 - val_output_1_loss: 0.1185\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.3350 - output_1_loss: 0.3349 - val_loss: 0.5473 - val_output_1_loss: 0.5471\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.3200 - output_1_loss: 0.3199 - val_loss: 0.5405 - val_output_1_loss: 0.5403\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3356 - output_1_loss: 0.3355 - val_loss: 0.5341 - val_output_1_loss: 0.5338\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:58:32,741]\u001b[0m Trial 7 finished with value: 0.012195121951219513 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 1.2952477100350326e-06, 'bn_momentum': 0.9544608322993061}. Best is trial 4 with value: 0.1111111111111111.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2467 - output_1_loss: 0.2466 - val_loss: 0.5235 - val_output_1_loss: 0.5233\n",
      "Epoch 30/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.3139 - output_1_loss: 0.3138 - val_loss: 0.5150 - val_output_1_loss: 0.5148\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.2918 - output_1_loss: 0.2917 - val_loss: 0.5072 - val_output_1_loss: 0.5070\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.3140 - output_1_loss: 0.3139 - val_loss: 0.4997 - val_output_1_loss: 0.4995\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.3415 - output_1_loss: 0.3414 - val_loss: 0.4935 - val_output_1_loss: 0.4933\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.2578 - output_1_loss: 0.2577 - val_loss: 0.4845 - val_output_1_loss: 0.4843\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.2674 - output_1_loss: 0.2673 - val_loss: 0.4772 - val_output_1_loss: 0.4770\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.1996 - output_1_loss: 0.1995 - val_loss: 0.4667 - val_output_1_loss: 0.4665\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2467 - output_1_loss: 0.2466 - val_loss: 0.4567 - val_output_1_loss: 0.4565\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.1790 - output_1_loss: 0.1789 - val_loss: 0.4442 - val_output_1_loss: 0.4440\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.1849 - output_1_loss: 0.1848 - val_loss: 0.4334 - val_output_1_loss: 0.4332\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.2175 - output_1_loss: 0.2174 - val_loss: 0.4235 - val_output_1_loss: 0.4233\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1703 - output_1_loss: 0.1702 - val_loss: 0.4121 - val_output_1_loss: 0.4119\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.1445 - output_1_loss: 0.1443 - val_loss: 0.4001 - val_output_1_loss: 0.3999\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.1633 - output_1_loss: 0.1632 - val_loss: 0.3885 - val_output_1_loss: 0.3883\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1824 - output_1_loss: 0.1823 - val_loss: 0.3786 - val_output_1_loss: 0.3784\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.1461 - output_1_loss: 0.1460 - val_loss: 0.3649 - val_output_1_loss: 0.3647\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.1503 - output_1_loss: 0.1502 - val_loss: 0.3541 - val_output_1_loss: 0.3539\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.1612 - output_1_loss: 0.1611 - val_loss: 0.3469 - val_output_1_loss: 0.3467\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.1292 - output_1_loss: 0.1291 - val_loss: 0.3335 - val_output_1_loss: 0.3333\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.1119 - output_1_loss: 0.1118 - val_loss: 0.3217 - val_output_1_loss: 0.3215\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.1061 - output_1_loss: 0.1059 - val_loss: 0.3100 - val_output_1_loss: 0.3098\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1146 - output_1_loss: 0.1145 - val_loss: 0.3001 - val_output_1_loss: 0.2999\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0991 - output_1_loss: 0.0990 - val_loss: 0.2880 - val_output_1_loss: 0.2878\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1167 - output_1_loss: 0.1166 - val_loss: 0.2798 - val_output_1_loss: 0.2796\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.1082 - output_1_loss: 0.1080 - val_loss: 0.2705 - val_output_1_loss: 0.2703\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.1240 - output_1_loss: 0.1239 - val_loss: 0.2601 - val_output_1_loss: 0.2599\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.1553 - output_1_loss: 0.1552 - val_loss: 0.2555 - val_output_1_loss: 0.2553\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1407 - output_1_loss: 0.1406 - val_loss: 0.2509 - val_output_1_loss: 0.2507\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1170 - output_1_loss: 0.1169 - val_loss: 0.2419 - val_output_1_loss: 0.2418\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0936 - output_1_loss: 0.0935 - val_loss: 0.2322 - val_output_1_loss: 0.2320\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1220 - output_1_loss: 0.1219 - val_loss: 0.2274 - val_output_1_loss: 0.2272\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1168 - output_1_loss: 0.1167 - val_loss: 0.2218 - val_output_1_loss: 0.2216\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1119 - output_1_loss: 0.1118 - val_loss: 0.2163 - val_output_1_loss: 0.2161\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0854 - output_1_loss: 0.0853 - val_loss: 0.2078 - val_output_1_loss: 0.2077\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1185 - output_1_loss: 0.1184 - val_loss: 0.2030 - val_output_1_loss: 0.2028\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0865 - output_1_loss: 0.0864 - val_loss: 0.1943 - val_output_1_loss: 0.1941\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1433 - output_1_loss: 0.1432 - val_loss: 0.1941 - val_output_1_loss: 0.1939\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1149 - output_1_loss: 0.1148 - val_loss: 0.1933 - val_output_1_loss: 0.1931\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.0914 - output_1_loss: 0.0913 - val_loss: 0.1865 - val_output_1_loss: 0.1863\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.0869 - output_1_loss: 0.0868 - val_loss: 0.1814 - val_output_1_loss: 0.1812\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0919 - output_1_loss: 0.0918 - val_loss: 0.1739 - val_output_1_loss: 0.1737\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0961 - output_1_loss: 0.0960 - val_loss: 0.1721 - val_output_1_loss: 0.1719\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0803 - output_1_loss: 0.0802 - val_loss: 0.1669 - val_output_1_loss: 0.1667\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.8324 - output_1_loss: 0.8324 - val_loss: 0.6902 - val_output_1_loss: 0.6902\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0854 - output_1_loss: 0.0853 - val_loss: 0.1591 - val_output_1_loss: 0.1589\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1163 - output_1_loss: 0.1161Epoch 2/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1163 - output_1_loss: 0.1161 - val_loss: 0.1528 - val_output_1_loss: 0.1526\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.8117 - output_1_loss: 0.8117 - val_loss: 0.6880 - val_output_1_loss: 0.6880\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0769 - output_1_loss: 0.0768 - val_loss: 0.1405 - val_output_1_loss: 0.1403\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8019 - output_1_loss: 0.8019 - val_loss: 0.6849 - val_output_1_loss: 0.6849\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0905 - output_1_loss: 0.0903 - val_loss: 0.1357 - val_output_1_loss: 0.1355\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7594 - output_1_loss: 0.7594 - val_loss: 0.6819 - val_output_1_loss: 0.6819\n",
      "Epoch 5/100\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7390 - output_1_loss: 0.7390 - val_loss: 0.6793 - val_output_1_loss: 0.6793\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0964 - output_1_loss: 0.0963 - val_loss: 0.1317 - val_output_1_loss: 0.1316\n",
      "Epoch 78/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0970 - output_1_loss: 0.0969 - val_loss: 0.1263 - val_output_1_loss: 0.1261\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.7961 - output_1_loss: 0.7961 - val_loss: 0.6765 - val_output_1_loss: 0.6765\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0808 - output_1_loss: 0.0807Epoch 7/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0808 - output_1_loss: 0.0807 - val_loss: 0.1233 - val_output_1_loss: 0.1231\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.7291 - output_1_loss: 0.7291 - val_loss: 0.6735 - val_output_1_loss: 0.6735\n",
      "Epoch 8/100\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7261 - output_1_loss: 0.7261 - val_loss: 0.6710 - val_output_1_loss: 0.6710\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0859 - output_1_loss: 0.0858 - val_loss: 0.1195 - val_output_1_loss: 0.1193\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.6974 - output_1_loss: 0.6974 - val_loss: 0.6681 - val_output_1_loss: 0.6681\n",
      "Epoch 81/100\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7259 - output_1_loss: 0.7259 - val_loss: 0.6651 - val_output_1_loss: 0.6651\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0843 - output_1_loss: 0.0842 - val_loss: 0.1195 - val_output_1_loss: 0.1193\n",
      "Epoch 82/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.7088 - output_1_loss: 0.7088 - val_loss: 0.6618 - val_output_1_loss: 0.6618\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0771 - output_1_loss: 0.0769 - val_loss: 0.1165 - val_output_1_loss: 0.1163\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6459 - output_1_loss: 0.6459 - val_loss: 0.6589 - val_output_1_loss: 0.6589\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0914 - output_1_loss: 0.0913 - val_loss: 0.1127 - val_output_1_loss: 0.1126\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6825 - output_1_loss: 0.6825 - val_loss: 0.6560 - val_output_1_loss: 0.6560\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6770 - output_1_loss: 0.6770 - val_loss: 0.6526 - val_output_1_loss: 0.6526\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1141 - output_1_loss: 0.1140 - val_loss: 0.1108 - val_output_1_loss: 0.1106\n",
      "Epoch 85/100\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0844 - output_1_loss: 0.0843 - val_loss: 0.1099 - val_output_1_loss: 0.1097\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6402 - output_1_loss: 0.6402 - val_loss: 0.6495 - val_output_1_loss: 0.6495\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6523 - output_1_loss: 0.6523Epoch 86/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6523 - output_1_loss: 0.6523 - val_loss: 0.6462 - val_output_1_loss: 0.6462\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6164 - output_1_loss: 0.6164 - val_loss: 0.6431 - val_output_1_loss: 0.6431\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0910 - output_1_loss: 0.0909 - val_loss: 0.1079 - val_output_1_loss: 0.1077\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5682 - output_1_loss: 0.5682 - val_loss: 0.6398 - val_output_1_loss: 0.6398\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0980 - output_1_loss: 0.0979Epoch 19/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0980 - output_1_loss: 0.0979 - val_loss: 0.1066 - val_output_1_loss: 0.1064\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5770 - output_1_loss: 0.5770 - val_loss: 0.6365 - val_output_1_loss: 0.6365\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6028 - output_1_loss: 0.6028 - val_loss: 0.6333 - val_output_1_loss: 0.6333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0917 - output_1_loss: 0.0916 - val_loss: 0.1062 - val_output_1_loss: 0.1061\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5506 - output_1_loss: 0.5506Epoch 89/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5506 - output_1_loss: 0.5506 - val_loss: 0.6297 - val_output_1_loss: 0.6297\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0920 - output_1_loss: 0.0919 - val_loss: 0.0976 - val_output_1_loss: 0.0975\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5787 - output_1_loss: 0.5787 - val_loss: 0.6266 - val_output_1_loss: 0.6266\n",
      "Epoch 23/100\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6161 - output_1_loss: 0.6161 - val_loss: 0.6238 - val_output_1_loss: 0.6238\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0998 - output_1_loss: 0.0997 - val_loss: 0.0954 - val_output_1_loss: 0.0953\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5628 - output_1_loss: 0.5628 - val_loss: 0.6202 - val_output_1_loss: 0.6202\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0818 - output_1_loss: 0.0817 - val_loss: 0.0914 - val_output_1_loss: 0.0912\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5915 - output_1_loss: 0.5915Epoch 92/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5915 - output_1_loss: 0.5915 - val_loss: 0.6160 - val_output_1_loss: 0.6160\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1092 - output_1_loss: 0.1091 - val_loss: 0.0917 - val_output_1_loss: 0.0916\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5611 - output_1_loss: 0.5611 - val_loss: 0.6132 - val_output_1_loss: 0.6132\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1244 - output_1_loss: 0.1243Epoch 27/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1244 - output_1_loss: 0.1243 - val_loss: 0.0875 - val_output_1_loss: 0.0874\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4836 - output_1_loss: 0.4836 - val_loss: 0.6092 - val_output_1_loss: 0.6092\n",
      "Epoch 28/100\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5755 - output_1_loss: 0.5755 - val_loss: 0.6056 - val_output_1_loss: 0.6056\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0870 - output_1_loss: 0.0869 - val_loss: 0.0830 - val_output_1_loss: 0.0828\n",
      "Epoch 29/100\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5466 - output_1_loss: 0.5466 - val_loss: 0.6021 - val_output_1_loss: 0.6021\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1007 - output_1_loss: 0.1006 - val_loss: 0.0821 - val_output_1_loss: 0.0819\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.5448 - output_1_loss: 0.5448 - val_loss: 0.5982 - val_output_1_loss: 0.5982\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0907 - output_1_loss: 0.0906 - val_loss: 0.0834 - val_output_1_loss: 0.0832\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5473 - output_1_loss: 0.5473 - val_loss: 0.5948 - val_output_1_loss: 0.5948\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0816 - output_1_loss: 0.0815 - val_loss: 0.0830 - val_output_1_loss: 0.0828\n",
      "Epoch 98/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5291 - output_1_loss: 0.5291 - val_loss: 0.5910 - val_output_1_loss: 0.5910\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1108 - output_1_loss: 0.1107 - val_loss: 0.0805 - val_output_1_loss: 0.0803\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5221 - output_1_loss: 0.5221 - val_loss: 0.5877 - val_output_1_loss: 0.5877\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0989 - output_1_loss: 0.0988 - val_loss: 0.0787 - val_output_1_loss: 0.0785\n",
      "Epoch 100/100\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1039 - output_1_loss: 0.1038 - val_loss: 0.0782 - val_output_1_loss: 0.0780\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5476 - output_1_loss: 0.5476 - val_loss: 0.5850 - val_output_1_loss: 0.5850\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.5489 - output_1_loss: 0.5489 - val_loss: 0.5820 - val_output_1_loss: 0.5820\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.4831 - output_1_loss: 0.4831 - val_loss: 0.5788 - val_output_1_loss: 0.5788\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4990 - output_1_loss: 0.4990 - val_loss: 0.5750 - val_output_1_loss: 0.5750\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.4889 - output_1_loss: 0.4889 - val_loss: 0.5714 - val_output_1_loss: 0.5714\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5009 - output_1_loss: 0.5009 - val_loss: 0.5684 - val_output_1_loss: 0.5684\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.4820 - output_1_loss: 0.4820 - val_loss: 0.5652 - val_output_1_loss: 0.5652\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4865 - output_1_loss: 0.4865 - val_loss: 0.5615 - val_output_1_loss: 0.5615\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4767 - output_1_loss: 0.4767 - val_loss: 0.5578 - val_output_1_loss: 0.5578\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.5025 - output_1_loss: 0.5025 - val_loss: 0.5540 - val_output_1_loss: 0.5540\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:59:01,635]\u001b[0m Trial 6 finished with value: 0.05555555555555555 and parameters: {'feature_dim': 64, 'n_step': 6, 'n_shared': 0, 'relaxation_factor': 1.1, 'sparsity_coefficient': 5.5306566116128045e-05, 'bn_momentum': 0.9530038069091721}. Best is trial 4 with value: 0.1111111111111111.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.5076 - output_1_loss: 0.5076 - val_loss: 0.5497 - val_output_1_loss: 0.5497\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4722 - output_1_loss: 0.4722 - val_loss: 0.5459 - val_output_1_loss: 0.5459\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4850 - output_1_loss: 0.4850 - val_loss: 0.5425 - val_output_1_loss: 0.5425\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4285 - output_1_loss: 0.4285Epoch 1/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.4285 - output_1_loss: 0.4285 - val_loss: 0.5391 - val_output_1_loss: 0.5391\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.4006 - output_1_loss: 0.4006 - val_loss: 0.5339 - val_output_1_loss: 0.5339\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4044 - output_1_loss: 0.4044 - val_loss: 0.5294 - val_output_1_loss: 0.5294\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.3718 - output_1_loss: 0.3718 - val_loss: 0.5256 - val_output_1_loss: 0.5256\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.3586 - output_1_loss: 0.3586 - val_loss: 0.5210 - val_output_1_loss: 0.5210\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.3915 - output_1_loss: 0.3915 - val_loss: 0.5167 - val_output_1_loss: 0.5167\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.4518 - output_1_loss: 0.4518 - val_loss: 0.5127 - val_output_1_loss: 0.5127\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.3689 - output_1_loss: 0.3689 - val_loss: 0.5086 - val_output_1_loss: 0.5086\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.3251 - output_1_loss: 0.3251 - val_loss: 0.5047 - val_output_1_loss: 0.5047\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.3139 - output_1_loss: 0.3139 - val_loss: 0.5006 - val_output_1_loss: 0.5006\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.3691 - output_1_loss: 0.3691 - val_loss: 0.4970 - val_output_1_loss: 0.4970\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.3671 - output_1_loss: 0.3671 - val_loss: 0.4934 - val_output_1_loss: 0.4934\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.3231 - output_1_loss: 0.3231 - val_loss: 0.4898 - val_output_1_loss: 0.4898\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.3373 - output_1_loss: 0.3373 - val_loss: 0.4857 - val_output_1_loss: 0.4857\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.4186 - output_1_loss: 0.4186 - val_loss: 0.4817 - val_output_1_loss: 0.4817\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.3663 - output_1_loss: 0.3663 - val_loss: 0.4776 - val_output_1_loss: 0.4776\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.3489 - output_1_loss: 0.3489 - val_loss: 0.4742 - val_output_1_loss: 0.4742\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.4004 - output_1_loss: 0.4004 - val_loss: 0.4709 - val_output_1_loss: 0.4709\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3951 - output_1_loss: 0.3951 - val_loss: 0.4670 - val_output_1_loss: 0.4670\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.3882 - output_1_loss: 0.3882 - val_loss: 0.4630 - val_output_1_loss: 0.4630\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3618 - output_1_loss: 0.3618 - val_loss: 0.4588 - val_output_1_loss: 0.4588\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3373 - output_1_loss: 0.3373 - val_loss: 0.4551 - val_output_1_loss: 0.4551\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3564 - output_1_loss: 0.3564 - val_loss: 0.4504 - val_output_1_loss: 0.4504\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3353 - output_1_loss: 0.3353 - val_loss: 0.4457 - val_output_1_loss: 0.4457\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3855 - output_1_loss: 0.3855 - val_loss: 0.4409 - val_output_1_loss: 0.4409\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3544 - output_1_loss: 0.3544 - val_loss: 0.4353 - val_output_1_loss: 0.4353\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3560 - output_1_loss: 0.3560 - val_loss: 0.4321 - val_output_1_loss: 0.4321\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.3426 - output_1_loss: 0.3426 - val_loss: 0.4291 - val_output_1_loss: 0.4291\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.2877 - output_1_loss: 0.2877 - val_loss: 0.4242 - val_output_1_loss: 0.4242\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.2998 - output_1_loss: 0.2998 - val_loss: 0.4194 - val_output_1_loss: 0.4194\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.2961 - output_1_loss: 0.2961 - val_loss: 0.4154 - val_output_1_loss: 0.4154\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.2420 - output_1_loss: 0.2420 - val_loss: 0.4105 - val_output_1_loss: 0.4105\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.2109 - output_1_loss: 0.2109 - val_loss: 0.4044 - val_output_1_loss: 0.4044\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.2436 - output_1_loss: 0.2436 - val_loss: 0.3978 - val_output_1_loss: 0.3978\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.2141 - output_1_loss: 0.2141 - val_loss: 0.3917 - val_output_1_loss: 0.3917\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.2147 - output_1_loss: 0.2147 - val_loss: 0.3848 - val_output_1_loss: 0.3848\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.2580 - output_1_loss: 0.2580 - val_loss: 0.3807 - val_output_1_loss: 0.3807\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.2202 - output_1_loss: 0.2202 - val_loss: 0.3757 - val_output_1_loss: 0.3757\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2015 - output_1_loss: 0.2015 - val_loss: 0.3715 - val_output_1_loss: 0.3715\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1777 - output_1_loss: 0.1777 - val_loss: 0.3668 - val_output_1_loss: 0.3668\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.1926 - output_1_loss: 0.1926 - val_loss: 0.3622 - val_output_1_loss: 0.3622\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.2073 - output_1_loss: 0.2073 - val_loss: 0.3583 - val_output_1_loss: 0.3583\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.1445 - output_1_loss: 0.1445 - val_loss: 0.3518 - val_output_1_loss: 0.3518\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1543 - output_1_loss: 0.1543 - val_loss: 0.3446 - val_output_1_loss: 0.3446\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2609 - output_1_loss: 0.2609 - val_loss: 0.3384 - val_output_1_loss: 0.3384\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2181 - output_1_loss: 0.2181 - val_loss: 0.3371 - val_output_1_loss: 0.3371\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2093 - output_1_loss: 0.2093 - val_loss: 0.3321 - val_output_1_loss: 0.3321\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.2519 - output_1_loss: 0.2519 - val_loss: 0.3282 - val_output_1_loss: 0.3282\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1820 - output_1_loss: 0.1820 - val_loss: 0.3220 - val_output_1_loss: 0.3220\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1661 - output_1_loss: 0.1661 - val_loss: 0.3152 - val_output_1_loss: 0.3152\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2489 - output_1_loss: 0.2489 - val_loss: 0.3115 - val_output_1_loss: 0.3115\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2129 - output_1_loss: 0.2129 - val_loss: 0.3066 - val_output_1_loss: 0.3066\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2472 - output_1_loss: 0.2472 - val_loss: 0.3029 - val_output_1_loss: 0.3029\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2079 - output_1_loss: 0.2079 - val_loss: 0.2984 - val_output_1_loss: 0.2984\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:59:24,196]\u001b[0m Trial 8 finished with value: 0.05263157894736842 and parameters: {'feature_dim': 32, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.8, 'sparsity_coefficient': 1.6112957055175355e-08, 'bn_momentum': 0.9841503726761143}. Best is trial 4 with value: 0.1111111111111111.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.7993 - output_1_loss: 0.7990 - val_loss: 0.6868 - val_output_1_loss: 0.6855\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.7249 - output_1_loss: 0.7246 - val_loss: 0.6785 - val_output_1_loss: 0.6773\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.7211 - output_1_loss: 0.7208 - val_loss: 0.6698 - val_output_1_loss: 0.6687\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.6525 - output_1_loss: 0.6523 - val_loss: 0.6635 - val_output_1_loss: 0.6624\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.6233 - output_1_loss: 0.6230 - val_loss: 0.6546 - val_output_1_loss: 0.6536\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.5875 - output_1_loss: 0.5873 - val_loss: 0.6453 - val_output_1_loss: 0.6444\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.5347 - output_1_loss: 0.5345 - val_loss: 0.6367 - val_output_1_loss: 0.6358\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.5408 - output_1_loss: 0.5406 - val_loss: 0.6302 - val_output_1_loss: 0.6293\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.4915 - output_1_loss: 0.4913 - val_loss: 0.6209 - val_output_1_loss: 0.6201\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.5253 - output_1_loss: 0.5250 - val_loss: 0.6085 - val_output_1_loss: 0.6077\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.4158 - output_1_loss: 0.4155 - val_loss: 0.5984 - val_output_1_loss: 0.5977\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5048 - output_1_loss: 0.5045 - val_loss: 0.5918 - val_output_1_loss: 0.5910\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.4285 - output_1_loss: 0.4283 - val_loss: 0.5830 - val_output_1_loss: 0.5822\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3797 - output_1_loss: 0.3795 - val_loss: 0.5733 - val_output_1_loss: 0.5726\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3406 - output_1_loss: 0.3404 - val_loss: 0.5633 - val_output_1_loss: 0.5625\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3972 - output_1_loss: 0.3970 - val_loss: 0.5549 - val_output_1_loss: 0.5542\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4131 - output_1_loss: 0.4128 - val_loss: 0.5449 - val_output_1_loss: 0.5442\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3774 - output_1_loss: 0.3772 - val_loss: 0.5361 - val_output_1_loss: 0.5354\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3589 - output_1_loss: 0.3587 - val_loss: 0.5265 - val_output_1_loss: 0.5258\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7944 - output_1_loss: 0.7944Epoch 20/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.3205 - output_1_loss: 0.3202 - val_loss: 0.5135 - val_output_1_loss: 0.5129\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.3485 - output_1_loss: 0.3482 - val_loss: 0.5044 - val_output_1_loss: 0.5037\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4055 - output_1_loss: 0.4053 - val_loss: 0.4946 - val_output_1_loss: 0.4940\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2975 - output_1_loss: 0.2972 - val_loss: 0.4849 - val_output_1_loss: 0.4842\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2888 - output_1_loss: 0.2885 - val_loss: 0.4744 - val_output_1_loss: 0.4738\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.7944 - output_1_loss: 0.7944 - val_loss: 0.6911 - val_output_1_loss: 0.6911\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2488 - output_1_loss: 0.2485 - val_loss: 0.4641 - val_output_1_loss: 0.4635\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2453 - output_1_loss: 0.2451 - val_loss: 0.4544 - val_output_1_loss: 0.4538\n",
      "Epoch 2/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.7812 - output_1_loss: 0.7812 - val_loss: 0.6882 - val_output_1_loss: 0.6881\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3204 - output_1_loss: 0.3202 - val_loss: 0.4443 - val_output_1_loss: 0.4438\n",
      "Epoch 3/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7340 - output_1_loss: 0.7340 - val_loss: 0.6850 - val_output_1_loss: 0.6849\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2731 - output_1_loss: 0.2728 - val_loss: 0.4351 - val_output_1_loss: 0.4345\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6857 - output_1_loss: 0.6857 - val_loss: 0.6818 - val_output_1_loss: 0.6817\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2274 - output_1_loss: 0.2272 - val_loss: 0.4246 - val_output_1_loss: 0.4240\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6720 - output_1_loss: 0.6720 - val_loss: 0.6781 - val_output_1_loss: 0.6781\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.7377 - output_1_loss: 0.7377 - val_loss: 0.6746 - val_output_1_loss: 0.6745\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2696 - output_1_loss: 0.2694 - val_loss: 0.4132 - val_output_1_loss: 0.4126\n",
      "Epoch 7/100\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6981 - output_1_loss: 0.6981 - val_loss: 0.6727 - val_output_1_loss: 0.6726\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2515 - output_1_loss: 0.2513 - val_loss: 0.4010 - val_output_1_loss: 0.4005\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6797 - output_1_loss: 0.6796 - val_loss: 0.6692 - val_output_1_loss: 0.6692\n",
      "Epoch 9/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6317 - output_1_loss: 0.6317 - val_loss: 0.6658 - val_output_1_loss: 0.6658\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.1803 - output_1_loss: 0.1801 - val_loss: 0.3837 - val_output_1_loss: 0.3832\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5843 - output_1_loss: 0.5843 - val_loss: 0.6628 - val_output_1_loss: 0.6627\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.5906 - output_1_loss: 0.5906 - val_loss: 0.6559 - val_output_1_loss: 0.6558\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.2639 - output_1_loss: 0.2637 - val_loss: 0.3709 - val_output_1_loss: 0.3704\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5264 - output_1_loss: 0.5263Epoch 34/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5264 - output_1_loss: 0.5263 - val_loss: 0.6487 - val_output_1_loss: 0.6486\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2007 - output_1_loss: 0.2004 - val_loss: 0.3619 - val_output_1_loss: 0.3614\n",
      "Epoch 35/100\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4987 - output_1_loss: 0.4987 - val_loss: 0.6421 - val_output_1_loss: 0.6420\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2053 - output_1_loss: 0.2051 - val_loss: 0.3588 - val_output_1_loss: 0.3583\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5060 - output_1_loss: 0.5060 - val_loss: 0.6340 - val_output_1_loss: 0.6340\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3098 - output_1_loss: 0.3095Epoch 15/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4218 - output_1_loss: 0.4218 - val_loss: 0.6248 - val_output_1_loss: 0.6247\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.3098 - output_1_loss: 0.3095 - val_loss: 0.3469 - val_output_1_loss: 0.3464\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.3718 - output_1_loss: 0.3717 - val_loss: 0.6127 - val_output_1_loss: 0.6126\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1951 - output_1_loss: 0.1949 - val_loss: 0.3385 - val_output_1_loss: 0.3380\n",
      "Epoch 17/100\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.3414 - output_1_loss: 0.3414 - val_loss: 0.5989 - val_output_1_loss: 0.5988\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2186 - output_1_loss: 0.2184 - val_loss: 0.3315 - val_output_1_loss: 0.3311\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2379 - output_1_loss: 0.2377Epoch 18/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.3309 - output_1_loss: 0.3308 - val_loss: 0.5850 - val_output_1_loss: 0.5849\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2379 - output_1_loss: 0.2377 - val_loss: 0.3233 - val_output_1_loss: 0.3228\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3119 - output_1_loss: 0.3119 - val_loss: 0.5697 - val_output_1_loss: 0.5696\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2028 - output_1_loss: 0.2026 - val_loss: 0.3048 - val_output_1_loss: 0.3044\n",
      "Epoch 20/100\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2699 - output_1_loss: 0.2699 - val_loss: 0.5536 - val_output_1_loss: 0.5535\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2895 - output_1_loss: 0.2893 - val_loss: 0.3024 - val_output_1_loss: 0.3019\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2434 - output_1_loss: 0.2432Epoch 21/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2434 - output_1_loss: 0.2432 - val_loss: 0.2835 - val_output_1_loss: 0.2830\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2712 - output_1_loss: 0.2712 - val_loss: 0.5367 - val_output_1_loss: 0.5366\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1915 - output_1_loss: 0.1913Epoch 22/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1915 - output_1_loss: 0.1913 - val_loss: 0.2796 - val_output_1_loss: 0.2791\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2394 - output_1_loss: 0.2393 - val_loss: 0.5162 - val_output_1_loss: 0.5161\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3098 - output_1_loss: 0.3098Epoch 44/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.3098 - output_1_loss: 0.3098 - val_loss: 0.5027 - val_output_1_loss: 0.5026\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1946 - output_1_loss: 0.1946 - val_loss: 0.4795 - val_output_1_loss: 0.4794\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2346 - output_1_loss: 0.2344 - val_loss: 0.2644 - val_output_1_loss: 0.2640\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1963 - output_1_loss: 0.1963Epoch 45/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1963 - output_1_loss: 0.1963 - val_loss: 0.4571 - val_output_1_loss: 0.4571\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1676 - output_1_loss: 0.1676 - val_loss: 0.4327 - val_output_1_loss: 0.4326\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.2489 - output_1_loss: 0.2487 - val_loss: 0.2594 - val_output_1_loss: 0.2589\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1523 - output_1_loss: 0.1523Epoch 46/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1523 - output_1_loss: 0.1523 - val_loss: 0.4081 - val_output_1_loss: 0.4081\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.1451 - output_1_loss: 0.1451 - val_loss: 0.3851 - val_output_1_loss: 0.3851\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1949 - output_1_loss: 0.1946 - val_loss: 0.2540 - val_output_1_loss: 0.2535\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1481 - output_1_loss: 0.1481Epoch 47/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1481 - output_1_loss: 0.1481 - val_loss: 0.3639 - val_output_1_loss: 0.3639\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2038 - output_1_loss: 0.2036Epoch 30/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1289 - output_1_loss: 0.1289 - val_loss: 0.3440 - val_output_1_loss: 0.3440\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.2038 - output_1_loss: 0.2036 - val_loss: 0.2473 - val_output_1_loss: 0.2469\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1280 - output_1_loss: 0.1280Epoch 48/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1280 - output_1_loss: 0.1280 - val_loss: 0.3264 - val_output_1_loss: 0.3263\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1812 - output_1_loss: 0.1810 - val_loss: 0.2411 - val_output_1_loss: 0.2407\n",
      "Epoch 49/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1703 - output_1_loss: 0.1700 - val_loss: 0.2326 - val_output_1_loss: 0.2322\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1134 - output_1_loss: 0.1133 - val_loss: 0.3067 - val_output_1_loss: 0.3067\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1635 - output_1_loss: 0.1632 - val_loss: 0.2272 - val_output_1_loss: 0.2267\n",
      "Epoch 33/100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1116 - output_1_loss: 0.1116 - val_loss: 0.2881 - val_output_1_loss: 0.2880\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2004 - output_1_loss: 0.2001 - val_loss: 0.2180 - val_output_1_loss: 0.2175\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1071 - output_1_loss: 0.1070 - val_loss: 0.2705 - val_output_1_loss: 0.2705\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1350 - output_1_loss: 0.1348 - val_loss: 0.2129 - val_output_1_loss: 0.2124\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1013 - output_1_loss: 0.1013 - val_loss: 0.2545 - val_output_1_loss: 0.2544\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1688 - output_1_loss: 0.1686Epoch 36/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1688 - output_1_loss: 0.1686 - val_loss: 0.2107 - val_output_1_loss: 0.2103\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0955 - output_1_loss: 0.0954 - val_loss: 0.2395 - val_output_1_loss: 0.2394\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0908 - output_1_loss: 0.0908 - val_loss: 0.2251 - val_output_1_loss: 0.2251\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1301 - output_1_loss: 0.1299 - val_loss: 0.1992 - val_output_1_loss: 0.1987\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1178 - output_1_loss: 0.1176Epoch 38/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1178 - output_1_loss: 0.1176 - val_loss: 0.1884 - val_output_1_loss: 0.1880\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0879 - output_1_loss: 0.0879 - val_loss: 0.2122 - val_output_1_loss: 0.2121\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0919 - output_1_loss: 0.0917 - val_loss: 0.1805 - val_output_1_loss: 0.1801\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0852 - output_1_loss: 0.0852 - val_loss: 0.2000 - val_output_1_loss: 0.2000\n",
      "Epoch 40/100\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0822 - output_1_loss: 0.0822 - val_loss: 0.1889 - val_output_1_loss: 0.1889\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1670 - output_1_loss: 0.1668Epoch 41/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0799 - output_1_loss: 0.0799 - val_loss: 0.1789 - val_output_1_loss: 0.1789\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1670 - output_1_loss: 0.1668 - val_loss: 0.1774 - val_output_1_loss: 0.1770\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0779 - output_1_loss: 0.0779 - val_loss: 0.1700 - val_output_1_loss: 0.1700\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1273 - output_1_loss: 0.1271 - val_loss: 0.1685 - val_output_1_loss: 0.1681\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0760 - output_1_loss: 0.0760 - val_loss: 0.1622 - val_output_1_loss: 0.1622\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0748 - output_1_loss: 0.0748 - val_loss: 0.1552 - val_output_1_loss: 0.1552\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1527 - output_1_loss: 0.1525 - val_loss: 0.1673 - val_output_1_loss: 0.1669\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0720 - output_1_loss: 0.0720 - val_loss: 0.1485 - val_output_1_loss: 0.1484\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1344 - output_1_loss: 0.1342 - val_loss: 0.1580 - val_output_1_loss: 0.1576\n",
      "Epoch 61/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2471 - output_1_loss: 0.2469 - val_loss: 0.1684 - val_output_1_loss: 0.1679\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0722 - output_1_loss: 0.0722 - val_loss: 0.1416 - val_output_1_loss: 0.1415\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2785 - output_1_loss: 0.2783 - val_loss: 0.1692 - val_output_1_loss: 0.1687\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3189 - output_1_loss: 0.3187Epoch 47/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3189 - output_1_loss: 0.3187 - val_loss: 0.1653 - val_output_1_loss: 0.1648\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0710 - output_1_loss: 0.0710 - val_loss: 0.1357 - val_output_1_loss: 0.1357\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1691 - output_1_loss: 0.1689Epoch 48/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1691 - output_1_loss: 0.1689 - val_loss: 0.1609 - val_output_1_loss: 0.1604\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0694 - output_1_loss: 0.0694 - val_loss: 0.1303 - val_output_1_loss: 0.1303\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1357 - output_1_loss: 0.1355 - val_loss: 0.1551 - val_output_1_loss: 0.1546\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0682 - output_1_loss: 0.0681 - val_loss: 0.1258 - val_output_1_loss: 0.1258\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0669 - output_1_loss: 0.0669 - val_loss: 0.1217 - val_output_1_loss: 0.1217\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1296 - output_1_loss: 0.1295 - val_loss: 0.1512 - val_output_1_loss: 0.1507\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0656 - output_1_loss: 0.0656Epoch 67/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0656 - output_1_loss: 0.0656 - val_loss: 0.1181 - val_output_1_loss: 0.1181\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0645 - output_1_loss: 0.0644 - val_loss: 0.1148 - val_output_1_loss: 0.1148\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1309 - output_1_loss: 0.1307 - val_loss: 0.1488 - val_output_1_loss: 0.1483\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1051 - output_1_loss: 0.1049Epoch 53/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1051 - output_1_loss: 0.1049 - val_loss: 0.1479 - val_output_1_loss: 0.1474\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0633 - output_1_loss: 0.0633 - val_loss: 0.1118 - val_output_1_loss: 0.1118\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0623 - output_1_loss: 0.0623Epoch 69/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0623 - output_1_loss: 0.0623 - val_loss: 0.1091 - val_output_1_loss: 0.1091\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2092 - output_1_loss: 0.2090Epoch 55/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2092 - output_1_loss: 0.2090 - val_loss: 0.1398 - val_output_1_loss: 0.1394\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0615 - output_1_loss: 0.0614 - val_loss: 0.1062 - val_output_1_loss: 0.1062\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0602 - output_1_loss: 0.0602 - val_loss: 0.1033 - val_output_1_loss: 0.1033\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1831 - output_1_loss: 0.1829 - val_loss: 0.1369 - val_output_1_loss: 0.1364\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1536 - output_1_loss: 0.1534Epoch 57/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0606 - output_1_loss: 0.0606 - val_loss: 0.1013 - val_output_1_loss: 0.1013\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.1536 - output_1_loss: 0.1534 - val_loss: 0.1361 - val_output_1_loss: 0.1357\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0588 - output_1_loss: 0.0588 - val_loss: 0.0989 - val_output_1_loss: 0.0989\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0980 - output_1_loss: 0.0978 - val_loss: 0.1378 - val_output_1_loss: 0.1374\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1110 - output_1_loss: 0.1108 - val_loss: 0.1363 - val_output_1_loss: 0.1359\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0726 - output_1_loss: 0.0726 - val_loss: 0.0960 - val_output_1_loss: 0.0960\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1012 - output_1_loss: 0.1010 - val_loss: 0.1362 - val_output_1_loss: 0.1358\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0591 - output_1_loss: 0.0591 - val_loss: 0.0919 - val_output_1_loss: 0.0918\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0593 - output_1_loss: 0.0593 - val_loss: 0.0898 - val_output_1_loss: 0.0897\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1651 - output_1_loss: 0.1649 - val_loss: 0.1237 - val_output_1_loss: 0.1233\n",
      "Epoch 76/100\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0584 - output_1_loss: 0.0583 - val_loss: 0.0887 - val_output_1_loss: 0.0887\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1112 - output_1_loss: 0.1110 - val_loss: 0.1166 - val_output_1_loss: 0.1162\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0813 - output_1_loss: 0.0811Epoch 63/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0813 - output_1_loss: 0.0811 - val_loss: 0.1259 - val_output_1_loss: 0.1255\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0578 - output_1_loss: 0.0578 - val_loss: 0.0869 - val_output_1_loss: 0.0868\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0876 - output_1_loss: 0.0874Epoch 64/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0876 - output_1_loss: 0.0874 - val_loss: 0.1269 - val_output_1_loss: 0.1265\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0569 - output_1_loss: 0.0569 - val_loss: 0.0849 - val_output_1_loss: 0.0848\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1074 - output_1_loss: 0.1073Epoch 65/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0566 - output_1_loss: 0.0566 - val_loss: 0.0835 - val_output_1_loss: 0.0835\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.1074 - output_1_loss: 0.1073 - val_loss: 0.1037 - val_output_1_loss: 0.1033\n",
      "Epoch 66/100\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0555 - output_1_loss: 0.0555 - val_loss: 0.0828 - val_output_1_loss: 0.0827\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1124 - output_1_loss: 0.1122 - val_loss: 0.1054 - val_output_1_loss: 0.1050\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0545 - output_1_loss: 0.0545 - val_loss: 0.0820 - val_output_1_loss: 0.0819\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1071 - output_1_loss: 0.1069Epoch 68/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1071 - output_1_loss: 0.1069 - val_loss: 0.1072 - val_output_1_loss: 0.1067\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0543 - output_1_loss: 0.0543 - val_loss: 0.0814 - val_output_1_loss: 0.0814\n",
      "Epoch 69/100\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0537 - output_1_loss: 0.0537 - val_loss: 0.0723 - val_output_1_loss: 0.0723\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1142 - output_1_loss: 0.1140 - val_loss: 0.1015 - val_output_1_loss: 0.1011\n",
      "Epoch 70/100\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0529 - output_1_loss: 0.0529 - val_loss: 0.0634 - val_output_1_loss: 0.0634\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1015 - output_1_loss: 0.1014 - val_loss: 0.1010 - val_output_1_loss: 0.1006\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0525 - output_1_loss: 0.0525 - val_loss: 0.0618 - val_output_1_loss: 0.0617\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2961 - output_1_loss: 0.2959 - val_loss: 0.1004 - val_output_1_loss: 0.1000\n",
      "Epoch 72/100\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0522 - output_1_loss: 0.0522 - val_loss: 0.0635 - val_output_1_loss: 0.0635\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1339 - output_1_loss: 0.1337Epoch 73/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0516 - output_1_loss: 0.0516 - val_loss: 0.0699 - val_output_1_loss: 0.0699\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1339 - output_1_loss: 0.1337 - val_loss: 0.0910 - val_output_1_loss: 0.0906\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0513 - output_1_loss: 0.0513 - val_loss: 0.0694 - val_output_1_loss: 0.0694\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0507 - output_1_loss: 0.0506 - val_loss: 0.0684 - val_output_1_loss: 0.0683\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0501 - output_1_loss: 0.0501 - val_loss: 0.0672 - val_output_1_loss: 0.0672\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1073 - output_1_loss: 0.1071 - val_loss: 0.0882 - val_output_1_loss: 0.0879\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1080 - output_1_loss: 0.1078 - val_loss: 0.0932 - val_output_1_loss: 0.0929\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1283 - output_1_loss: 0.1281 - val_loss: 0.0904 - val_output_1_loss: 0.0901\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.1575 - output_1_loss: 0.1573 - val_loss: 0.0775 - val_output_1_loss: 0.0771\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1340 - output_1_loss: 0.1338 - val_loss: 0.0761 - val_output_1_loss: 0.0758\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1050 - output_1_loss: 0.1048 - val_loss: 0.0771 - val_output_1_loss: 0.0768\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 03:59:58,324]\u001b[0m Trial 10 finished with value: 0.5 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 2.2, 'sparsity_coefficient': 1.3396191306549097e-05, 'bn_momentum': 0.9170835757295724}. Best is trial 10 with value: 0.5.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 470ms/step - loss: 0.0896 - output_1_loss: 0.0895 - val_loss: 0.0718 - val_output_1_loss: 0.0715\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1184 - output_1_loss: 0.1182 - val_loss: 0.0734 - val_output_1_loss: 0.0731\n",
      "Epoch 94/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1399 - output_1_loss: 0.1398 - val_loss: 0.0827 - val_output_1_loss: 0.0824\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.1079 - output_1_loss: 0.1077 - val_loss: 0.0683 - val_output_1_loss: 0.0679\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1128 - output_1_loss: 0.1126 - val_loss: 0.0836 - val_output_1_loss: 0.0832\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1088 - output_1_loss: 0.1087 - val_loss: 0.0866 - val_output_1_loss: 0.0862\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1031 - output_1_loss: 0.1029 - val_loss: 0.0809 - val_output_1_loss: 0.0806\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.1402 - output_1_loss: 0.1400 - val_loss: 0.0817 - val_output_1_loss: 0.0813\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.1215 - output_1_loss: 0.1213 - val_loss: 0.0855 - val_output_1_loss: 0.0851\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:00:04,790]\u001b[0m Trial 9 finished with value: 1.0 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 3, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 0.0003182140913822515, 'bn_momentum': 0.9497510368233014}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 41s 41s/step - loss: 0.9174 - output_1_loss: 0.8345 - val_loss: 1.0447 - val_output_1_loss: 0.6880\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 48s 48s/step - loss: 0.7673 - output_1_loss: 0.7673 - val_loss: 0.6836 - val_output_1_loss: 0.6836\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8729 - output_1_loss: 0.7873Epoch 2/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.8729 - output_1_loss: 0.7873 - val_loss: 1.0080 - val_output_1_loss: 0.6827\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.7271 - output_1_loss: 0.7271 - val_loss: 0.6732 - val_output_1_loss: 0.6732\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.8317 - output_1_loss: 0.7586 - val_loss: 0.9753 - val_output_1_loss: 0.6735\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.6553 - output_1_loss: 0.6553 - val_loss: 0.6660 - val_output_1_loss: 0.6660\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6410 - output_1_loss: 0.6410Epoch 4/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6410 - output_1_loss: 0.6410 - val_loss: 0.6543 - val_output_1_loss: 0.6543\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7925 - output_1_loss: 0.7168Epoch 5/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.7925 - output_1_loss: 0.7168 - val_loss: 0.9541 - val_output_1_loss: 0.6643\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.6887 - output_1_loss: 0.6887 - val_loss: 0.6432 - val_output_1_loss: 0.6432\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7282 - output_1_loss: 0.6528 - val_loss: 0.9240 - val_output_1_loss: 0.6558\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6924 - output_1_loss: 0.6191 - val_loss: 0.9034 - val_output_1_loss: 0.6470\n",
      "Epoch 7/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.7072 - output_1_loss: 0.6398 - val_loss: 0.8825 - val_output_1_loss: 0.6414\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.4780 - output_1_loss: 0.4780 - val_loss: 0.6336 - val_output_1_loss: 0.6336\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.7022 - output_1_loss: 0.6336 - val_loss: 0.8606 - val_output_1_loss: 0.6334\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.4171 - output_1_loss: 0.4171 - val_loss: 0.6209 - val_output_1_loss: 0.6209\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5738 - output_1_loss: 0.5075 - val_loss: 0.8476 - val_output_1_loss: 0.6227\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4623 - output_1_loss: 0.4623Epoch 10/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.4623 - output_1_loss: 0.4623 - val_loss: 0.6081 - val_output_1_loss: 0.6081\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6589 - output_1_loss: 0.5878 - val_loss: 0.8329 - val_output_1_loss: 0.6148\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6170 - output_1_loss: 0.5450 - val_loss: 0.8128 - val_output_1_loss: 0.6047\n",
      "Epoch 9/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.4083 - output_1_loss: 0.4083 - val_loss: 0.5950 - val_output_1_loss: 0.5950\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5801 - output_1_loss: 0.5081 - val_loss: 0.7990 - val_output_1_loss: 0.5981\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6171 - output_1_loss: 0.5478 - val_loss: 0.7907 - val_output_1_loss: 0.5862\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4024 - output_1_loss: 0.4024Epoch 14/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.4024 - output_1_loss: 0.4024 - val_loss: 0.5690 - val_output_1_loss: 0.5690\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5185 - output_1_loss: 0.4498 - val_loss: 0.7638 - val_output_1_loss: 0.5735\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5794 - output_1_loss: 0.5078 - val_loss: 0.7486 - val_output_1_loss: 0.5622\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5292 - output_1_loss: 0.4568Epoch 11/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.5292 - output_1_loss: 0.4568 - val_loss: 0.7300 - val_output_1_loss: 0.5499\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3685 - output_1_loss: 0.3685 - val_loss: 0.5396 - val_output_1_loss: 0.5396\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.5008 - output_1_loss: 0.4345 - val_loss: 0.7089 - val_output_1_loss: 0.5385\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.5098 - output_1_loss: 0.4471 - val_loss: 0.7020 - val_output_1_loss: 0.5282\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.4513 - output_1_loss: 0.4513 - val_loss: 0.5232 - val_output_1_loss: 0.5232\n",
      "Epoch 13/100\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.4744 - output_1_loss: 0.4096 - val_loss: 0.6880 - val_output_1_loss: 0.5150\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.3451 - output_1_loss: 0.3451 - val_loss: 0.5211 - val_output_1_loss: 0.5211\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4740 - output_1_loss: 0.4064 - val_loss: 0.6839 - val_output_1_loss: 0.5068\n",
      "Epoch 14/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.5259 - output_1_loss: 0.4518 - val_loss: 0.6539 - val_output_1_loss: 0.4921\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.2785 - output_1_loss: 0.2785 - val_loss: 0.4952 - val_output_1_loss: 0.4952\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4900 - output_1_loss: 0.4234 - val_loss: 0.6486 - val_output_1_loss: 0.4826\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3626 - output_1_loss: 0.2921Epoch 15/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3626 - output_1_loss: 0.2921 - val_loss: 0.6391 - val_output_1_loss: 0.4693\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1823 - output_1_loss: 0.1823 - val_loss: 0.4745 - val_output_1_loss: 0.4745\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4949 - output_1_loss: 0.4232 - val_loss: 0.6323 - val_output_1_loss: 0.4603\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4325 - output_1_loss: 0.3644 - val_loss: 0.6212 - val_output_1_loss: 0.4473\n",
      "Epoch 16/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.2426 - output_1_loss: 0.2426 - val_loss: 0.4561 - val_output_1_loss: 0.4561\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3473 - output_1_loss: 0.2774 - val_loss: 0.5949 - val_output_1_loss: 0.4317\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.4522 - output_1_loss: 0.3866 - val_loss: 0.5838 - val_output_1_loss: 0.4235\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.3518 - output_1_loss: 0.3518 - val_loss: 0.4412 - val_output_1_loss: 0.4412\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3789 - output_1_loss: 0.3128 - val_loss: 0.5780 - val_output_1_loss: 0.4275\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4241 - output_1_loss: 0.3583Epoch 18/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.4241 - output_1_loss: 0.3583 - val_loss: 0.5608 - val_output_1_loss: 0.4143\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2380 - output_1_loss: 0.2380Epoch 30/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.2380 - output_1_loss: 0.2380 - val_loss: 0.4163 - val_output_1_loss: 0.4163\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.4855 - output_1_loss: 0.4299 - val_loss: 0.5507 - val_output_1_loss: 0.4028\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1737 - output_1_loss: 0.1737 - val_loss: 0.3879 - val_output_1_loss: 0.3879\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1133 - output_1_loss: 0.1133 - val_loss: 0.3606 - val_output_1_loss: 0.3606\n",
      "Epoch 31/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.3321 - output_1_loss: 0.2739 - val_loss: 0.5475 - val_output_1_loss: 0.3957\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.2055 - output_1_loss: 0.2055 - val_loss: 0.3377 - val_output_1_loss: 0.3377\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3353 - output_1_loss: 0.2821 - val_loss: 0.5305 - val_output_1_loss: 0.3812\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3202 - output_1_loss: 0.2575Epoch 22/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3202 - output_1_loss: 0.2575 - val_loss: 0.5208 - val_output_1_loss: 0.3718\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2173 - output_1_loss: 0.2173Epoch 34/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.2173 - output_1_loss: 0.2173 - val_loss: 0.3017 - val_output_1_loss: 0.3017\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3313 - output_1_loss: 0.2759Epoch 23/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3313 - output_1_loss: 0.2759 - val_loss: 0.5200 - val_output_1_loss: 0.3761\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.3598 - output_1_loss: 0.2995 - val_loss: 0.4883 - val_output_1_loss: 0.3500\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.1475 - output_1_loss: 0.1475 - val_loss: 0.2643 - val_output_1_loss: 0.2643\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.3597 - output_1_loss: 0.2925 - val_loss: 0.4688 - val_output_1_loss: 0.3304\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.2026 - output_1_loss: 0.2026 - val_loss: 0.2508 - val_output_1_loss: 0.2508\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.3308 - output_1_loss: 0.2570 - val_loss: 0.4481 - val_output_1_loss: 0.3167\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.2083 - output_1_loss: 0.2083 - val_loss: 0.2330 - val_output_1_loss: 0.2330\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3562 - output_1_loss: 0.2927Epoch 26/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.3562 - output_1_loss: 0.2927 - val_loss: 0.4491 - val_output_1_loss: 0.3161\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1039 - output_1_loss: 0.1039Epoch 39/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1039 - output_1_loss: 0.1039 - val_loss: 0.2077 - val_output_1_loss: 0.2077\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3235 - output_1_loss: 0.2575Epoch 27/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.3235 - output_1_loss: 0.2575 - val_loss: 0.4103 - val_output_1_loss: 0.2760\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.1159 - output_1_loss: 0.1159 - val_loss: 0.1937 - val_output_1_loss: 0.1937\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3398 - output_1_loss: 0.2810 - val_loss: 0.4285 - val_output_1_loss: 0.2998\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.2865 - output_1_loss: 0.2289 - val_loss: 0.3981 - val_output_1_loss: 0.2737\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.1609 - output_1_loss: 0.1609 - val_loss: 0.1849 - val_output_1_loss: 0.1849\n",
      "Epoch 42/100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.3389 - output_1_loss: 0.2844 - val_loss: 0.4017 - val_output_1_loss: 0.2793\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.1478 - output_1_loss: 0.1478 - val_loss: 0.1779 - val_output_1_loss: 0.1778\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.2636 - output_1_loss: 0.2086 - val_loss: 0.3842 - val_output_1_loss: 0.2644\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0891 - output_1_loss: 0.0891 - val_loss: 0.1649 - val_output_1_loss: 0.1649\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1372 - output_1_loss: 0.1372Epoch 44/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1372 - output_1_loss: 0.1372 - val_loss: 0.1505 - val_output_1_loss: 0.1505\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3134 - output_1_loss: 0.2541 - val_loss: 0.3559 - val_output_1_loss: 0.2411\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2443 - output_1_loss: 0.1863Epoch 32/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2443 - output_1_loss: 0.1863 - val_loss: 0.3599 - val_output_1_loss: 0.2480\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1191 - output_1_loss: 0.1191Epoch 46/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.2313 - output_1_loss: 0.1741 - val_loss: 0.3511 - val_output_1_loss: 0.2414\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.1191 - output_1_loss: 0.1191 - val_loss: 0.1424 - val_output_1_loss: 0.1424\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2461 - output_1_loss: 0.2461 - val_loss: 0.1488 - val_output_1_loss: 0.1488\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.3075 - output_1_loss: 0.2490 - val_loss: 0.3354 - val_output_1_loss: 0.2307\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.1470 - output_1_loss: 0.1470 - val_loss: 0.1294 - val_output_1_loss: 0.1294\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.2626 - output_1_loss: 0.2072 - val_loss: 0.3306 - val_output_1_loss: 0.2300\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1929 - output_1_loss: 0.1929Epoch 49/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2389 - output_1_loss: 0.1863 - val_loss: 0.3451 - val_output_1_loss: 0.2535\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.1929 - output_1_loss: 0.1929 - val_loss: 0.1274 - val_output_1_loss: 0.1274\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.2414 - output_1_loss: 0.1866 - val_loss: 0.3026 - val_output_1_loss: 0.2090\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.0887 - output_1_loss: 0.0887 - val_loss: 0.1096 - val_output_1_loss: 0.1096\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.2163 - output_1_loss: 0.1623 - val_loss: 0.2692 - val_output_1_loss: 0.1768\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0877 - output_1_loss: 0.0877 - val_loss: 0.0997 - val_output_1_loss: 0.0997\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0964 - output_1_loss: 0.0964 - val_loss: 0.1063 - val_output_1_loss: 0.1063\n",
      "Epoch 52/100\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.2319 - output_1_loss: 0.1795 - val_loss: 0.2675 - val_output_1_loss: 0.1770\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0845 - output_1_loss: 0.0845 - val_loss: 0.0860 - val_output_1_loss: 0.0860\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2073 - output_1_loss: 0.1519 - val_loss: 0.2792 - val_output_1_loss: 0.1926\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2237 - output_1_loss: 0.1639 - val_loss: 0.2791 - val_output_1_loss: 0.1948\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.1434 - output_1_loss: 0.1434 - val_loss: 0.0782 - val_output_1_loss: 0.0782\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1515 - output_1_loss: 0.1515 - val_loss: 0.0890 - val_output_1_loss: 0.0890\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.2029 - output_1_loss: 0.1502 - val_loss: 0.2500 - val_output_1_loss: 0.1671\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1384 - output_1_loss: 0.1384Epoch 56/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1384 - output_1_loss: 0.1384 - val_loss: 0.0796 - val_output_1_loss: 0.0796\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2057 - output_1_loss: 0.1539 - val_loss: 0.2403 - val_output_1_loss: 0.1610\n",
      "Epoch 57/100\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.2405 - output_1_loss: 0.1943 - val_loss: 0.2229 - val_output_1_loss: 0.1453\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1421 - output_1_loss: 0.1421 - val_loss: 0.0771 - val_output_1_loss: 0.0771\n",
      "Epoch 58/100\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2657 - output_1_loss: 0.2136 - val_loss: 0.2283 - val_output_1_loss: 0.1555\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.1155 - output_1_loss: 0.1155 - val_loss: 0.0727 - val_output_1_loss: 0.0727\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2058 - output_1_loss: 0.1483Epoch 45/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0835 - output_1_loss: 0.0835 - val_loss: 0.0769 - val_output_1_loss: 0.0769\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.2058 - output_1_loss: 0.1483 - val_loss: 0.2182 - val_output_1_loss: 0.1474\n",
      "Epoch 46/100\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1229 - output_1_loss: 0.1229 - val_loss: 0.0760 - val_output_1_loss: 0.0760\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.1975 - output_1_loss: 0.1492 - val_loss: 0.2131 - val_output_1_loss: 0.1412\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1086 - output_1_loss: 0.1086 - val_loss: 0.0670 - val_output_1_loss: 0.0670\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1099 - output_1_loss: 0.1099 - val_loss: 0.0695 - val_output_1_loss: 0.0695\n",
      "Epoch 49/100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1212 - output_1_loss: 0.1212 - val_loss: 0.0793 - val_output_1_loss: 0.0793\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.1932 - output_1_loss: 0.1340 - val_loss: 0.2020 - val_output_1_loss: 0.1344\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0925 - output_1_loss: 0.0925 - val_loss: 0.0662 - val_output_1_loss: 0.0662\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1128 - output_1_loss: 0.1128Epoch 62/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.1128 - output_1_loss: 0.1128 - val_loss: 0.0645 - val_output_1_loss: 0.0645\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1763 - output_1_loss: 0.1138 - val_loss: 0.1994 - val_output_1_loss: 0.1309\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1762 - output_1_loss: 0.1249 - val_loss: 0.2053 - val_output_1_loss: 0.1355\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2479 - output_1_loss: 0.1961Epoch 52/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2479 - output_1_loss: 0.1961 - val_loss: 0.2209 - val_output_1_loss: 0.1513\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0947 - output_1_loss: 0.0947Epoch 65/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0947 - output_1_loss: 0.0947 - val_loss: 0.0594 - val_output_1_loss: 0.0594\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2338 - output_1_loss: 0.1830 - val_loss: 0.2122 - val_output_1_loss: 0.1454\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1280 - output_1_loss: 0.1280 - val_loss: 0.0632 - val_output_1_loss: 0.0632\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2125 - output_1_loss: 0.1660Epoch 54/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2125 - output_1_loss: 0.1660 - val_loss: 0.2090 - val_output_1_loss: 0.1438\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1579 - output_1_loss: 0.1579 - val_loss: 0.0729 - val_output_1_loss: 0.0729\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0983 - output_1_loss: 0.0983Epoch 67/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1892 - output_1_loss: 0.1434 - val_loss: 0.2013 - val_output_1_loss: 0.1464\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.0983 - output_1_loss: 0.0983 - val_loss: 0.0594 - val_output_1_loss: 0.0594\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1602 - output_1_loss: 0.1602 - val_loss: 0.0675 - val_output_1_loss: 0.0675\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.0856 - output_1_loss: 0.0856 - val_loss: 0.0577 - val_output_1_loss: 0.0577\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1060 - output_1_loss: 0.1060 - val_loss: 0.0647 - val_output_1_loss: 0.0647\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1355 - output_1_loss: 0.1355 - val_loss: 0.0652 - val_output_1_loss: 0.0652\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.1303 - output_1_loss: 0.1303 - val_loss: 0.0565 - val_output_1_loss: 0.0565\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1886 - output_1_loss: 0.1886 - val_loss: 0.0679 - val_output_1_loss: 0.0679\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1587 - output_1_loss: 0.1587 - val_loss: 0.0612 - val_output_1_loss: 0.0612\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1024 - output_1_loss: 0.1024 - val_loss: 0.0588 - val_output_1_loss: 0.0588\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1298 - output_1_loss: 0.1298 - val_loss: 0.0567 - val_output_1_loss: 0.0567\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1006 - output_1_loss: 0.1006 - val_loss: 0.0593 - val_output_1_loss: 0.0593\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:01:12,947]\u001b[0m Trial 12 finished with value: 0.02040816326530612 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 4, 'relaxation_factor': 2.0, 'sparsity_coefficient': 0.08797868663193417, 'bn_momentum': 0.9014487103657095}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:01:14,497]\u001b[0m Trial 11 finished with value: 0.14285714285714285 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 0, 'relaxation_factor': 1.9, 'sparsity_coefficient': 1.1588281060085983e-07, 'bn_momentum': 0.9056341079753147}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.6592 - output_1_loss: 0.6592 - val_loss: 0.6833 - val_output_1_loss: 0.6833\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.8933 - output_1_loss: 0.8894 - val_loss: 0.7055 - val_output_1_loss: 0.6916\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.5835 - output_1_loss: 0.5835 - val_loss: 0.6741 - val_output_1_loss: 0.6741\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5894 - output_1_loss: 0.5894 - val_loss: 0.6645 - val_output_1_loss: 0.6645\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5538 - output_1_loss: 0.5538Epoch 2/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5538 - output_1_loss: 0.5538 - val_loss: 0.6546 - val_output_1_loss: 0.6546\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.9085 - output_1_loss: 0.9046 - val_loss: 0.7025 - val_output_1_loss: 0.6894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8887 - output_1_loss: 0.8848Epoch 5/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.8887 - output_1_loss: 0.8848 - val_loss: 0.6996 - val_output_1_loss: 0.6870\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5387 - output_1_loss: 0.5387Epoch 4/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5387 - output_1_loss: 0.5387 - val_loss: 0.6450 - val_output_1_loss: 0.6450\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.8481 - output_1_loss: 0.8443 - val_loss: 0.6973 - val_output_1_loss: 0.6852\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8403 - output_1_loss: 0.8363Epoch 6/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8403 - output_1_loss: 0.8363 - val_loss: 0.6948 - val_output_1_loss: 0.6831\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4889 - output_1_loss: 0.4889 - val_loss: 0.6345 - val_output_1_loss: 0.6345\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.7708 - output_1_loss: 0.7669 - val_loss: 0.6918 - val_output_1_loss: 0.6806\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4543 - output_1_loss: 0.4543Epoch 7/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4543 - output_1_loss: 0.4543 - val_loss: 0.6241 - val_output_1_loss: 0.6241\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7984 - output_1_loss: 0.7944 - val_loss: 0.6897 - val_output_1_loss: 0.6788\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4258 - output_1_loss: 0.4258 - val_loss: 0.6134 - val_output_1_loss: 0.6134\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8281 - output_1_loss: 0.8241 - val_loss: 0.6873 - val_output_1_loss: 0.6768\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4237 - output_1_loss: 0.4237 - val_loss: 0.6028 - val_output_1_loss: 0.6028\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3868 - output_1_loss: 0.3868Epoch 9/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.3868 - output_1_loss: 0.3868 - val_loss: 0.5923 - val_output_1_loss: 0.5923\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7900 - output_1_loss: 0.7861 - val_loss: 0.6853 - val_output_1_loss: 0.6750\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2445 - output_1_loss: 0.2445 - val_loss: 0.5808 - val_output_1_loss: 0.5808\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7724 - output_1_loss: 0.7685Epoch 12/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7724 - output_1_loss: 0.7685 - val_loss: 0.6833 - val_output_1_loss: 0.6730\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1898 - output_1_loss: 0.1898 - val_loss: 0.5703 - val_output_1_loss: 0.5703\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1719 - output_1_loss: 0.1719Epoch 11/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1719 - output_1_loss: 0.1719 - val_loss: 0.5590 - val_output_1_loss: 0.5590\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7503 - output_1_loss: 0.7463 - val_loss: 0.6809 - val_output_1_loss: 0.6710\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7214 - output_1_loss: 0.7174Epoch 14/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7214 - output_1_loss: 0.7174 - val_loss: 0.6784 - val_output_1_loss: 0.6687\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1221 - output_1_loss: 0.1221 - val_loss: 0.5479 - val_output_1_loss: 0.5479\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7548 - output_1_loss: 0.7509 - val_loss: 0.6763 - val_output_1_loss: 0.6669\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7344 - output_1_loss: 0.7304Epoch 15/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7344 - output_1_loss: 0.7304 - val_loss: 0.6741 - val_output_1_loss: 0.6649\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1464 - output_1_loss: 0.1464 - val_loss: 0.5365 - val_output_1_loss: 0.5365\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7384 - output_1_loss: 0.7344Epoch 16/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.7384 - output_1_loss: 0.7344 - val_loss: 0.6720 - val_output_1_loss: 0.6629\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1572 - output_1_loss: 0.1572 - val_loss: 0.5256 - val_output_1_loss: 0.5256\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0885 - output_1_loss: 0.0885Epoch 16/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0885 - output_1_loss: 0.0885 - val_loss: 0.5133 - val_output_1_loss: 0.5133\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7062 - output_1_loss: 0.7022 - val_loss: 0.6696 - val_output_1_loss: 0.6607\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7130 - output_1_loss: 0.7090Epoch 18/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7130 - output_1_loss: 0.7090 - val_loss: 0.6675 - val_output_1_loss: 0.6586\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0795 - output_1_loss: 0.0795 - val_loss: 0.5015 - val_output_1_loss: 0.5015\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1119 - output_1_loss: 0.1119Epoch 18/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1119 - output_1_loss: 0.1119 - val_loss: 0.4887 - val_output_1_loss: 0.4887\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6836 - output_1_loss: 0.6794Epoch 20/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.6836 - output_1_loss: 0.6794 - val_loss: 0.6651 - val_output_1_loss: 0.6562\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0794 - output_1_loss: 0.0794 - val_loss: 0.4773 - val_output_1_loss: 0.4773\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6944 - output_1_loss: 0.6904 - val_loss: 0.6629 - val_output_1_loss: 0.6541\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6786 - output_1_loss: 0.6746 - val_loss: 0.6607 - val_output_1_loss: 0.6519\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0754 - output_1_loss: 0.0754 - val_loss: 0.4649 - val_output_1_loss: 0.4649\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6507 - output_1_loss: 0.6468 - val_loss: 0.6580 - val_output_1_loss: 0.6496\n",
      "Epoch 22/100\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6576 - output_1_loss: 0.6538 - val_loss: 0.6546 - val_output_1_loss: 0.6463\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0802 - output_1_loss: 0.0802 - val_loss: 0.4542 - val_output_1_loss: 0.4542\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0775 - output_1_loss: 0.0775Epoch 23/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0775 - output_1_loss: 0.0775 - val_loss: 0.4439 - val_output_1_loss: 0.4439\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.6544 - output_1_loss: 0.6505 - val_loss: 0.6523 - val_output_1_loss: 0.6441\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6805 - output_1_loss: 0.6767Epoch 24/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6805 - output_1_loss: 0.6767 - val_loss: 0.6506 - val_output_1_loss: 0.6425\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0738 - output_1_loss: 0.0738 - val_loss: 0.4343 - val_output_1_loss: 0.4343\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6323 - output_1_loss: 0.6283 - val_loss: 0.6481 - val_output_1_loss: 0.6402\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0879 - output_1_loss: 0.0879 - val_loss: 0.4253 - val_output_1_loss: 0.4253\n",
      "Epoch 26/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6425 - output_1_loss: 0.6385 - val_loss: 0.6451 - val_output_1_loss: 0.6373\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0801 - output_1_loss: 0.0801 - val_loss: 0.4176 - val_output_1_loss: 0.4176\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0755 - output_1_loss: 0.0755Epoch 27/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0755 - output_1_loss: 0.0755 - val_loss: 0.4088 - val_output_1_loss: 0.4088\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6461 - output_1_loss: 0.6422 - val_loss: 0.6424 - val_output_1_loss: 0.6347\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0778 - output_1_loss: 0.0778 - val_loss: 0.3977 - val_output_1_loss: 0.3977\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6012 - output_1_loss: 0.5973 - val_loss: 0.6391 - val_output_1_loss: 0.6314\n",
      "Epoch 29/100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6373 - output_1_loss: 0.6334 - val_loss: 0.6362 - val_output_1_loss: 0.6284\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0885 - output_1_loss: 0.0885 - val_loss: 0.3869 - val_output_1_loss: 0.3869\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5920 - output_1_loss: 0.5879Epoch 30/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5920 - output_1_loss: 0.5879 - val_loss: 0.6335 - val_output_1_loss: 0.6256\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0769 - output_1_loss: 0.0769 - val_loss: 0.3780 - val_output_1_loss: 0.3780\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6076 - output_1_loss: 0.6037Epoch 31/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.6076 - output_1_loss: 0.6037 - val_loss: 0.6316 - val_output_1_loss: 0.6238\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0832 - output_1_loss: 0.0832 - val_loss: 0.3683 - val_output_1_loss: 0.3683\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0777 - output_1_loss: 0.0777Epoch 32/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0777 - output_1_loss: 0.0777 - val_loss: 0.3577 - val_output_1_loss: 0.3577\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6079 - output_1_loss: 0.6039Epoch 33/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6079 - output_1_loss: 0.6039 - val_loss: 0.6287 - val_output_1_loss: 0.6209\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1127 - output_1_loss: 0.1127 - val_loss: 0.3493 - val_output_1_loss: 0.3493\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6026 - output_1_loss: 0.5987Epoch 34/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6026 - output_1_loss: 0.5987 - val_loss: 0.6253 - val_output_1_loss: 0.6176\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0808 - output_1_loss: 0.0808 - val_loss: 0.3391 - val_output_1_loss: 0.3391\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0711 - output_1_loss: 0.0711Epoch 34/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0711 - output_1_loss: 0.0711 - val_loss: 0.3300 - val_output_1_loss: 0.3300\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5979 - output_1_loss: 0.5940 - val_loss: 0.6228 - val_output_1_loss: 0.6151\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0758 - output_1_loss: 0.0758 - val_loss: 0.3236 - val_output_1_loss: 0.3236\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5826 - output_1_loss: 0.5788Epoch 37/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5826 - output_1_loss: 0.5788 - val_loss: 0.6200 - val_output_1_loss: 0.6124\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0730 - output_1_loss: 0.0730 - val_loss: 0.3177 - val_output_1_loss: 0.3177\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0768 - output_1_loss: 0.0768Epoch 36/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0768 - output_1_loss: 0.0768 - val_loss: 0.3116 - val_output_1_loss: 0.3116\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.5797 - output_1_loss: 0.5757 - val_loss: 0.6174 - val_output_1_loss: 0.6097\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1000 - output_1_loss: 0.1000Epoch 37/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1000 - output_1_loss: 0.1000 - val_loss: 0.3051 - val_output_1_loss: 0.3051\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5567 - output_1_loss: 0.5529 - val_loss: 0.6149 - val_output_1_loss: 0.6072\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5157 - output_1_loss: 0.5119Epoch 40/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.5157 - output_1_loss: 0.5119 - val_loss: 0.6122 - val_output_1_loss: 0.6047\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0750 - output_1_loss: 0.0750 - val_loss: 0.3009 - val_output_1_loss: 0.3009\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0682 - output_1_loss: 0.0681Epoch 39/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0682 - output_1_loss: 0.0681 - val_loss: 0.2934 - val_output_1_loss: 0.2934\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5301 - output_1_loss: 0.5264 - val_loss: 0.6106 - val_output_1_loss: 0.6033\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5601 - output_1_loss: 0.5565Epoch 42/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.5601 - output_1_loss: 0.5565 - val_loss: 0.6078 - val_output_1_loss: 0.6006\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0680 - output_1_loss: 0.0680 - val_loss: 0.2854 - val_output_1_loss: 0.2854\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5277 - output_1_loss: 0.5241 - val_loss: 0.6046 - val_output_1_loss: 0.5976\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0842 - output_1_loss: 0.0842 - val_loss: 0.2803 - val_output_1_loss: 0.2803\n",
      "Epoch 44/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0729 - output_1_loss: 0.0729 - val_loss: 0.2729 - val_output_1_loss: 0.2729\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5105 - output_1_loss: 0.5070 - val_loss: 0.6017 - val_output_1_loss: 0.5948\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0678 - output_1_loss: 0.0678 - val_loss: 0.2683 - val_output_1_loss: 0.2683\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5144 - output_1_loss: 0.5107 - val_loss: 0.5987 - val_output_1_loss: 0.5919\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0847 - output_1_loss: 0.0847 - val_loss: 0.2643 - val_output_1_loss: 0.2643\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5423 - output_1_loss: 0.5386 - val_loss: 0.5954 - val_output_1_loss: 0.5888\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1394 - output_1_loss: 0.1394Epoch 45/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1394 - output_1_loss: 0.1394 - val_loss: 0.2598 - val_output_1_loss: 0.2598\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.5344 - output_1_loss: 0.5307 - val_loss: 0.5920 - val_output_1_loss: 0.5855\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5023 - output_1_loss: 0.4985Epoch 48/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5023 - output_1_loss: 0.4985 - val_loss: 0.5889 - val_output_1_loss: 0.5823\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1013 - output_1_loss: 0.1013Epoch 47/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1013 - output_1_loss: 0.1013 - val_loss: 0.2562 - val_output_1_loss: 0.2562\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.4726 - output_1_loss: 0.4689 - val_loss: 0.5859 - val_output_1_loss: 0.5794\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4787 - output_1_loss: 0.4749Epoch 49/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4787 - output_1_loss: 0.4749 - val_loss: 0.5827 - val_output_1_loss: 0.5761\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0681 - output_1_loss: 0.0681Epoch 49/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0681 - output_1_loss: 0.0681 - val_loss: 0.2501 - val_output_1_loss: 0.2501\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.5225 - output_1_loss: 0.5187 - val_loss: 0.5790 - val_output_1_loss: 0.5723\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0672 - output_1_loss: 0.0672 - val_loss: 0.2445 - val_output_1_loss: 0.2445\n",
      "Epoch 51/100\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1121 - output_1_loss: 0.1121 - val_loss: 0.2405 - val_output_1_loss: 0.2405\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4933 - output_1_loss: 0.4894 - val_loss: 0.5750 - val_output_1_loss: 0.5685\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0694 - output_1_loss: 0.0694 - val_loss: 0.2367 - val_output_1_loss: 0.2367\n",
      "Epoch 53/100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0837 - output_1_loss: 0.0837 - val_loss: 0.2325 - val_output_1_loss: 0.2325\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.5053 - output_1_loss: 0.5015 - val_loss: 0.5704 - val_output_1_loss: 0.5640\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4548 - output_1_loss: 0.4510 - val_loss: 0.5664 - val_output_1_loss: 0.5600\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4561 - output_1_loss: 0.4524 - val_loss: 0.5622 - val_output_1_loss: 0.5557\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0779 - output_1_loss: 0.0779 - val_loss: 0.2296 - val_output_1_loss: 0.2296\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4683 - output_1_loss: 0.4644 - val_loss: 0.5589 - val_output_1_loss: 0.5525\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0648 - output_1_loss: 0.0648 - val_loss: 0.2269 - val_output_1_loss: 0.2269\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4202 - output_1_loss: 0.4163 - val_loss: 0.5542 - val_output_1_loss: 0.5478\n",
      "Epoch 56/100\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3932 - output_1_loss: 0.3893 - val_loss: 0.5490 - val_output_1_loss: 0.5425\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0708 - output_1_loss: 0.0708 - val_loss: 0.2226 - val_output_1_loss: 0.2226\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4275 - output_1_loss: 0.4238 - val_loss: 0.5452 - val_output_1_loss: 0.5386\n",
      "Epoch 58/100\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4498 - output_1_loss: 0.4461 - val_loss: 0.5421 - val_output_1_loss: 0.5355\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0666 - output_1_loss: 0.0666 - val_loss: 0.2189 - val_output_1_loss: 0.2189\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.4799 - output_1_loss: 0.4762 - val_loss: 0.5369 - val_output_1_loss: 0.5303\n",
      "Epoch 60/100\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4832 - output_1_loss: 0.4796 - val_loss: 0.5325 - val_output_1_loss: 0.5259\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0675 - output_1_loss: 0.0675 - val_loss: 0.2149 - val_output_1_loss: 0.2149\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4876 - output_1_loss: 0.4841 - val_loss: 0.5291 - val_output_1_loss: 0.5225\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0688 - output_1_loss: 0.0688 - val_loss: 0.2106 - val_output_1_loss: 0.2106\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4858 - output_1_loss: 0.4824 - val_loss: 0.5263 - val_output_1_loss: 0.5198\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0791 - output_1_loss: 0.0791 - val_loss: 0.2071 - val_output_1_loss: 0.2071\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4870 - output_1_loss: 0.4836 - val_loss: 0.5250 - val_output_1_loss: 0.5185\n",
      "Epoch 61/100\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0808 - output_1_loss: 0.0808 - val_loss: 0.2052 - val_output_1_loss: 0.2052\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4649 - output_1_loss: 0.4610 - val_loss: 0.5217 - val_output_1_loss: 0.5151\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4967 - output_1_loss: 0.4928Epoch 62/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.4967 - output_1_loss: 0.4928 - val_loss: 0.5214 - val_output_1_loss: 0.5144\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0841 - output_1_loss: 0.0841 - val_loss: 0.2011 - val_output_1_loss: 0.2011\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4153 - output_1_loss: 0.4113 - val_loss: 0.5197 - val_output_1_loss: 0.5125\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3893 - output_1_loss: 0.3852Epoch 63/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3893 - output_1_loss: 0.3852 - val_loss: 0.5163 - val_output_1_loss: 0.5090\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.3831 - output_1_loss: 0.3790 - val_loss: 0.5131 - val_output_1_loss: 0.5059\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0792 - output_1_loss: 0.0792 - val_loss: 0.1980 - val_output_1_loss: 0.1980\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0756 - output_1_loss: 0.0756 - val_loss: 0.1953 - val_output_1_loss: 0.1953\n",
      "Epoch 65/100\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0748 - output_1_loss: 0.0748 - val_loss: 0.1929 - val_output_1_loss: 0.1929\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3773 - output_1_loss: 0.3730 - val_loss: 0.5097 - val_output_1_loss: 0.5025\n",
      "Epoch 70/100\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3481 - output_1_loss: 0.3440 - val_loss: 0.5049 - val_output_1_loss: 0.4978\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0725 - output_1_loss: 0.0725 - val_loss: 0.1902 - val_output_1_loss: 0.1902\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3845 - output_1_loss: 0.3805 - val_loss: 0.4999 - val_output_1_loss: 0.4929\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0699 - output_1_loss: 0.0699 - val_loss: 0.1882 - val_output_1_loss: 0.1882\n",
      "Epoch 68/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3499 - output_1_loss: 0.3459 - val_loss: 0.4924 - val_output_1_loss: 0.4855\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0689 - output_1_loss: 0.0689 - val_loss: 0.1867 - val_output_1_loss: 0.1867\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3426 - output_1_loss: 0.3387 - val_loss: 0.4857 - val_output_1_loss: 0.4790\n",
      "Epoch 69/100\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0704 - output_1_loss: 0.0704 - val_loss: 0.1837 - val_output_1_loss: 0.1837\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.3627 - output_1_loss: 0.3588 - val_loss: 0.4815 - val_output_1_loss: 0.4748\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0695 - output_1_loss: 0.0695 - val_loss: 0.1813 - val_output_1_loss: 0.1813\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3573 - output_1_loss: 0.3533 - val_loss: 0.4780 - val_output_1_loss: 0.4714\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3603 - output_1_loss: 0.3562Epoch 71/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3603 - output_1_loss: 0.3562 - val_loss: 0.4756 - val_output_1_loss: 0.4691\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0693 - output_1_loss: 0.0693 - val_loss: 0.1798 - val_output_1_loss: 0.1798\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3325 - output_1_loss: 0.3283 - val_loss: 0.4729 - val_output_1_loss: 0.4665\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0728 - output_1_loss: 0.0728 - val_loss: 0.1778 - val_output_1_loss: 0.1778\n",
      "Epoch 73/100\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0706 - output_1_loss: 0.0706 - val_loss: 0.1767 - val_output_1_loss: 0.1767\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3226 - output_1_loss: 0.3185 - val_loss: 0.4670 - val_output_1_loss: 0.4608\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0716 - output_1_loss: 0.0716 - val_loss: 0.1765 - val_output_1_loss: 0.1765\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3677 - output_1_loss: 0.3635 - val_loss: 0.4614 - val_output_1_loss: 0.4552\n",
      "Epoch 75/100\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0686 - output_1_loss: 0.0686 - val_loss: 0.1761 - val_output_1_loss: 0.1761\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3141 - output_1_loss: 0.3100 - val_loss: 0.4565 - val_output_1_loss: 0.4503\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0682 - output_1_loss: 0.0682 - val_loss: 0.1752 - val_output_1_loss: 0.1752\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3250 - output_1_loss: 0.3209 - val_loss: 0.4522 - val_output_1_loss: 0.4460\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0677 - output_1_loss: 0.0677 - val_loss: 0.1741 - val_output_1_loss: 0.1741\n",
      "Epoch 82/100\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3021 - output_1_loss: 0.2978 - val_loss: 0.4481 - val_output_1_loss: 0.4418\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0672 - output_1_loss: 0.0672 - val_loss: 0.1730 - val_output_1_loss: 0.1730\n",
      "Epoch 83/100\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0709 - output_1_loss: 0.0709 - val_loss: 0.1720 - val_output_1_loss: 0.1720\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2896 - output_1_loss: 0.2853 - val_loss: 0.4433 - val_output_1_loss: 0.4369\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0681 - output_1_loss: 0.0681Epoch 84/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0681 - output_1_loss: 0.0681 - val_loss: 0.1707 - val_output_1_loss: 0.1707\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.3051 - output_1_loss: 0.3007 - val_loss: 0.4378 - val_output_1_loss: 0.4315\n",
      "Epoch 85/100\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3953 - output_1_loss: 0.3911 - val_loss: 0.4331 - val_output_1_loss: 0.4268\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0712 - output_1_loss: 0.0712 - val_loss: 0.1690 - val_output_1_loss: 0.1690\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0702 - output_1_loss: 0.0702Epoch 86/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0702 - output_1_loss: 0.0702 - val_loss: 0.1671 - val_output_1_loss: 0.1671\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3437 - output_1_loss: 0.3394Epoch 83/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3437 - output_1_loss: 0.3394 - val_loss: 0.4281 - val_output_1_loss: 0.4219\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0695 - output_1_loss: 0.0695 - val_loss: 0.1652 - val_output_1_loss: 0.1652\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3288 - output_1_loss: 0.3246 - val_loss: 0.4235 - val_output_1_loss: 0.4172\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0687 - output_1_loss: 0.0687 - val_loss: 0.1633 - val_output_1_loss: 0.1633\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0682 - output_1_loss: 0.0682Epoch 88/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0682 - output_1_loss: 0.0682 - val_loss: 0.1611 - val_output_1_loss: 0.1611\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3022 - output_1_loss: 0.2981 - val_loss: 0.4194 - val_output_1_loss: 0.4132\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0690 - output_1_loss: 0.0690 - val_loss: 0.1589 - val_output_1_loss: 0.1589\n",
      "Epoch 87/100\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0879 - output_1_loss: 0.0879 - val_loss: 0.1569 - val_output_1_loss: 0.1569\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3247 - output_1_loss: 0.3204 - val_loss: 0.4162 - val_output_1_loss: 0.4099\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3038 - output_1_loss: 0.2995Epoch 88/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.3038 - output_1_loss: 0.2995 - val_loss: 0.4124 - val_output_1_loss: 0.4060\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0889 - output_1_loss: 0.0889Epoch 91/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0889 - output_1_loss: 0.0889 - val_loss: 0.1549 - val_output_1_loss: 0.1549\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3630 - output_1_loss: 0.3587 - val_loss: 0.4071 - val_output_1_loss: 0.4007\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1019 - output_1_loss: 0.1019 - val_loss: 0.1530 - val_output_1_loss: 0.1530\n",
      "Epoch 90/100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0752 - output_1_loss: 0.0752 - val_loss: 0.1496 - val_output_1_loss: 0.1496\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3583 - output_1_loss: 0.3538 - val_loss: 0.4005 - val_output_1_loss: 0.3941\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0702 - output_1_loss: 0.0702Epoch 93/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0702 - output_1_loss: 0.0702 - val_loss: 0.1465 - val_output_1_loss: 0.1465\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2849 - output_1_loss: 0.2804 - val_loss: 0.3956 - val_output_1_loss: 0.3891\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0936 - output_1_loss: 0.0936 - val_loss: 0.1430 - val_output_1_loss: 0.1430\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0776 - output_1_loss: 0.0776Epoch 94/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0776 - output_1_loss: 0.0776 - val_loss: 0.1395 - val_output_1_loss: 0.1395\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.2998 - output_1_loss: 0.2955 - val_loss: 0.3934 - val_output_1_loss: 0.3869\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2793 - output_1_loss: 0.2751Epoch 94/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2793 - output_1_loss: 0.2751 - val_loss: 0.3901 - val_output_1_loss: 0.3835\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0808 - output_1_loss: 0.0808 - val_loss: 0.1357 - val_output_1_loss: 0.1357\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2651 - output_1_loss: 0.2610 - val_loss: 0.3844 - val_output_1_loss: 0.3779\n",
      "Epoch 95/100\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0691 - output_1_loss: 0.0691 - val_loss: 0.1318 - val_output_1_loss: 0.1318\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3241 - output_1_loss: 0.3199 - val_loss: 0.3816 - val_output_1_loss: 0.3752\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0691 - output_1_loss: 0.0691 - val_loss: 0.1292 - val_output_1_loss: 0.1292\n",
      "Epoch 98/100\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2794 - output_1_loss: 0.2752 - val_loss: 0.3794 - val_output_1_loss: 0.3730\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0692 - output_1_loss: 0.0692 - val_loss: 0.1263 - val_output_1_loss: 0.1263\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0690 - output_1_loss: 0.0690Epoch 99/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0690 - output_1_loss: 0.0690 - val_loss: 0.1236 - val_output_1_loss: 0.1236\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.2916 - output_1_loss: 0.2875 - val_loss: 0.3761 - val_output_1_loss: 0.3697\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0677 - output_1_loss: 0.0677 - val_loss: 0.1215 - val_output_1_loss: 0.1215\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2294 - output_1_loss: 0.2254 - val_loss: 0.3728 - val_output_1_loss: 0.3665\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0615 - output_1_loss: 0.0615 - val_loss: 0.1194 - val_output_1_loss: 0.1194\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:02:09,751]\u001b[0m Trial 14 finished with value: 0.14285714285714285 and parameters: {'feature_dim': 32, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 0.0024747092055193757, 'bn_momentum': 0.974967288096383}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:02:10,072]\u001b[0m Trial 13 finished with value: 0.03225806451612903 and parameters: {'feature_dim': 256, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.1, 'sparsity_coefficient': 7.142865950024566e-07, 'bn_momentum': 0.9780677799337008}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 41s 41s/step - loss: 0.7482 - output_1_loss: 0.7475 - val_loss: 0.6876 - val_output_1_loss: 0.6846\n",
      "1/1 [==============================] - 40s 40s/step - loss: 0.6457 - output_1_loss: 0.6450 - val_loss: 0.6872 - val_output_1_loss: 0.6845\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6062 - output_1_loss: 0.6055 - val_loss: 0.6783 - val_output_1_loss: 0.6757\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.5550 - output_1_loss: 0.5543 - val_loss: 0.6690 - val_output_1_loss: 0.6665\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5425 - output_1_loss: 0.5418Epoch 2/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.5425 - output_1_loss: 0.5418 - val_loss: 0.6598 - val_output_1_loss: 0.6574\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.6161 - output_1_loss: 0.6154 - val_loss: 0.6791 - val_output_1_loss: 0.6763\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.5090 - output_1_loss: 0.5082 - val_loss: 0.6506 - val_output_1_loss: 0.6483\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5836 - output_1_loss: 0.5829 - val_loss: 0.6679 - val_output_1_loss: 0.6654\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5864 - output_1_loss: 0.5857 - val_loss: 0.6601 - val_output_1_loss: 0.6577\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.4665 - output_1_loss: 0.4658 - val_loss: 0.6502 - val_output_1_loss: 0.6479\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.4799 - output_1_loss: 0.4791 - val_loss: 0.6421 - val_output_1_loss: 0.6399\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.5085 - output_1_loss: 0.5079 - val_loss: 0.6390 - val_output_1_loss: 0.6368\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.4521 - output_1_loss: 0.4514 - val_loss: 0.6322 - val_output_1_loss: 0.6300\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.5000 - output_1_loss: 0.4993 - val_loss: 0.6282 - val_output_1_loss: 0.6261\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2871 - output_1_loss: 0.2864 - val_loss: 0.6225 - val_output_1_loss: 0.6204\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3105 - output_1_loss: 0.3099 - val_loss: 0.6146 - val_output_1_loss: 0.6126\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3957 - output_1_loss: 0.3950Epoch 8/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3957 - output_1_loss: 0.3950 - val_loss: 0.6054 - val_output_1_loss: 0.6034\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.5059 - output_1_loss: 0.5054 - val_loss: 0.6180 - val_output_1_loss: 0.6161\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2996 - output_1_loss: 0.2989Epoch 9/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.2996 - output_1_loss: 0.2989 - val_loss: 0.5966 - val_output_1_loss: 0.5947\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3698 - output_1_loss: 0.3693 - val_loss: 0.6089 - val_output_1_loss: 0.6070\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2708 - output_1_loss: 0.2703Epoch 12/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2708 - output_1_loss: 0.2703 - val_loss: 0.5939 - val_output_1_loss: 0.5920\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.2837 - output_1_loss: 0.2830 - val_loss: 0.5884 - val_output_1_loss: 0.5865\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.4746 - output_1_loss: 0.4741 - val_loss: 0.5832 - val_output_1_loss: 0.5813\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.3086 - output_1_loss: 0.3079 - val_loss: 0.5795 - val_output_1_loss: 0.5776\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.4359 - output_1_loss: 0.4354 - val_loss: 0.5757 - val_output_1_loss: 0.5739\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.2164 - output_1_loss: 0.2157 - val_loss: 0.5704 - val_output_1_loss: 0.5686\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.3363 - output_1_loss: 0.3359 - val_loss: 0.5604 - val_output_1_loss: 0.5587\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.3142 - output_1_loss: 0.3136 - val_loss: 0.5627 - val_output_1_loss: 0.5609\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.3528 - output_1_loss: 0.3523 - val_loss: 0.5509 - val_output_1_loss: 0.5492\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2052 - output_1_loss: 0.2046 - val_loss: 0.5551 - val_output_1_loss: 0.5534\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2475 - output_1_loss: 0.2469Epoch 15/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2475 - output_1_loss: 0.2469 - val_loss: 0.5480 - val_output_1_loss: 0.5462\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.3111 - output_1_loss: 0.3107 - val_loss: 0.5373 - val_output_1_loss: 0.5357\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.1892 - output_1_loss: 0.1886 - val_loss: 0.5408 - val_output_1_loss: 0.5390\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.2474 - output_1_loss: 0.2470 - val_loss: 0.5260 - val_output_1_loss: 0.5245\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2195 - output_1_loss: 0.2190 - val_loss: 0.5073 - val_output_1_loss: 0.5057\n",
      "Epoch 19/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.1190 - output_1_loss: 0.1184 - val_loss: 0.5354 - val_output_1_loss: 0.5336\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.2377 - output_1_loss: 0.2373 - val_loss: 0.4977 - val_output_1_loss: 0.4963\n",
      "Epoch 20/100\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.2652 - output_1_loss: 0.2645 - val_loss: 0.5278 - val_output_1_loss: 0.5260\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.2904 - output_1_loss: 0.2899 - val_loss: 0.4858 - val_output_1_loss: 0.4844\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1675 - output_1_loss: 0.1669 - val_loss: 0.5203 - val_output_1_loss: 0.5186\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.2389 - output_1_loss: 0.2384 - val_loss: 0.4738 - val_output_1_loss: 0.4724\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3070 - output_1_loss: 0.3065 - val_loss: 0.4646 - val_output_1_loss: 0.4632\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3483 - output_1_loss: 0.3478Epoch 22/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3483 - output_1_loss: 0.3478 - val_loss: 0.4560 - val_output_1_loss: 0.4546\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1545 - output_1_loss: 0.1539 - val_loss: 0.5127 - val_output_1_loss: 0.5109\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.3935 - output_1_loss: 0.3931 - val_loss: 0.4501 - val_output_1_loss: 0.4486\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1500 - output_1_loss: 0.1495 - val_loss: 0.5070 - val_output_1_loss: 0.5053\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2110 - output_1_loss: 0.2107Epoch 24/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.2110 - output_1_loss: 0.2107 - val_loss: 0.4292 - val_output_1_loss: 0.4279\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.2030 - output_1_loss: 0.2025 - val_loss: 0.5017 - val_output_1_loss: 0.5000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2606 - output_1_loss: 0.2603Epoch 25/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.2606 - output_1_loss: 0.2603 - val_loss: 0.4050 - val_output_1_loss: 0.4036\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1162 - output_1_loss: 0.1156 - val_loss: 0.4963 - val_output_1_loss: 0.4946\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2675 - output_1_loss: 0.2672Epoch 26/100\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.2675 - output_1_loss: 0.2672 - val_loss: 0.3926 - val_output_1_loss: 0.3913\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0884 - output_1_loss: 0.0879 - val_loss: 0.4883 - val_output_1_loss: 0.4866\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2697 - output_1_loss: 0.2694 - val_loss: 0.3849 - val_output_1_loss: 0.3835\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1413 - output_1_loss: 0.1410Epoch 27/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1413 - output_1_loss: 0.1410 - val_loss: 0.3712 - val_output_1_loss: 0.3698\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1050 - output_1_loss: 0.1044Epoch 29/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1050 - output_1_loss: 0.1044 - val_loss: 0.4826 - val_output_1_loss: 0.4809\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1218 - output_1_loss: 0.1215 - val_loss: 0.3511 - val_output_1_loss: 0.3498\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1679 - output_1_loss: 0.1673 - val_loss: 0.4781 - val_output_1_loss: 0.4764\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.1184 - output_1_loss: 0.1181 - val_loss: 0.3330 - val_output_1_loss: 0.3317\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1416 - output_1_loss: 0.1409 - val_loss: 0.4727 - val_output_1_loss: 0.4710\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1490 - output_1_loss: 0.1487 - val_loss: 0.3161 - val_output_1_loss: 0.3149\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0997 - output_1_loss: 0.0990 - val_loss: 0.4706 - val_output_1_loss: 0.4689\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1652 - output_1_loss: 0.1649 - val_loss: 0.3051 - val_output_1_loss: 0.3039\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1848 - output_1_loss: 0.1846Epoch 31/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1848 - output_1_loss: 0.1846 - val_loss: 0.3002 - val_output_1_loss: 0.2990\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.1502 - output_1_loss: 0.1496 - val_loss: 0.4659 - val_output_1_loss: 0.4642\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.2156 - output_1_loss: 0.2154 - val_loss: 0.2856 - val_output_1_loss: 0.2845\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0972 - output_1_loss: 0.0965 - val_loss: 0.4626 - val_output_1_loss: 0.4609\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.1462 - output_1_loss: 0.1460 - val_loss: 0.2774 - val_output_1_loss: 0.2762\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1688 - output_1_loss: 0.1682 - val_loss: 0.4592 - val_output_1_loss: 0.4575\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.2229 - output_1_loss: 0.2226 - val_loss: 0.2656 - val_output_1_loss: 0.2645\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0807 - output_1_loss: 0.0801 - val_loss: 0.4551 - val_output_1_loss: 0.4534\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1057 - output_1_loss: 0.1051 - val_loss: 0.4518 - val_output_1_loss: 0.4501\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0964 - output_1_loss: 0.0958 - val_loss: 0.4467 - val_output_1_loss: 0.4451\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.2183 - output_1_loss: 0.2180 - val_loss: 0.2622 - val_output_1_loss: 0.2611\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0791 - output_1_loss: 0.0786 - val_loss: 0.4443 - val_output_1_loss: 0.4427\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1692 - output_1_loss: 0.1689 - val_loss: 0.2466 - val_output_1_loss: 0.2455\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1832 - output_1_loss: 0.1826 - val_loss: 0.4426 - val_output_1_loss: 0.4410\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1106 - output_1_loss: 0.1103 - val_loss: 0.2329 - val_output_1_loss: 0.2318\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0938 - output_1_loss: 0.0933 - val_loss: 0.4403 - val_output_1_loss: 0.4386\n",
      "Epoch 40/100\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.1037 - output_1_loss: 0.1032 - val_loss: 0.4369 - val_output_1_loss: 0.4353\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1027 - output_1_loss: 0.1022 - val_loss: 0.2260 - val_output_1_loss: 0.2249\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0899 - output_1_loss: 0.0894 - val_loss: 0.4355 - val_output_1_loss: 0.4339\n",
      "Epoch 42/100\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.1175 - output_1_loss: 0.1170 - val_loss: 0.4339 - val_output_1_loss: 0.4323\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.1473 - output_1_loss: 0.1470 - val_loss: 0.2201 - val_output_1_loss: 0.2190\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1227 - output_1_loss: 0.1222 - val_loss: 0.4369 - val_output_1_loss: 0.4354\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0792 - output_1_loss: 0.0787 - val_loss: 0.2020 - val_output_1_loss: 0.2008\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1201 - output_1_loss: 0.1197 - val_loss: 0.4319 - val_output_1_loss: 0.4302\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0886 - output_1_loss: 0.0882 - val_loss: 0.4286 - val_output_1_loss: 0.4270\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0941 - output_1_loss: 0.0937Epoch 46/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0941 - output_1_loss: 0.0937 - val_loss: 0.1884 - val_output_1_loss: 0.1873\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.0979 - output_1_loss: 0.0975 - val_loss: 0.4283 - val_output_1_loss: 0.4267\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.2044 - output_1_loss: 0.2040 - val_loss: 0.4306 - val_output_1_loss: 0.4290\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0987 - output_1_loss: 0.0984 - val_loss: 0.1808 - val_output_1_loss: 0.1797\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1143 - output_1_loss: 0.1139 - val_loss: 0.4305 - val_output_1_loss: 0.4289\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0899 - output_1_loss: 0.0895 - val_loss: 0.4300 - val_output_1_loss: 0.4284\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.1645 - output_1_loss: 0.1641 - val_loss: 0.1702 - val_output_1_loss: 0.1690\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0981 - output_1_loss: 0.0977 - val_loss: 0.4303 - val_output_1_loss: 0.4287\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0789 - output_1_loss: 0.0784 - val_loss: 0.4292 - val_output_1_loss: 0.4277\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1178 - output_1_loss: 0.1173 - val_loss: 0.1629 - val_output_1_loss: 0.1617\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.0937 - output_1_loss: 0.0932 - val_loss: 0.1522 - val_output_1_loss: 0.1510\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1891 - output_1_loss: 0.1886 - val_loss: 0.1501 - val_output_1_loss: 0.1490\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.1079 - output_1_loss: 0.1074 - val_loss: 0.1491 - val_output_1_loss: 0.1480\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1480 - output_1_loss: 0.1475 - val_loss: 0.1481 - val_output_1_loss: 0.1470\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1111 - output_1_loss: 0.1105 - val_loss: 0.1436 - val_output_1_loss: 0.1424\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:03:10,062]\u001b[0m Trial 16 finished with value: 0.09090909090909091 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 1, 'relaxation_factor': 1.7000000000000002, 'sparsity_coefficient': 0.0005476258424184111, 'bn_momentum': 0.9989901459571899}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.1658 - output_1_loss: 0.1651 - val_loss: 0.1381 - val_output_1_loss: 0.1369\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1043 - output_1_loss: 0.1037Epoch 1/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.1043 - output_1_loss: 0.1037 - val_loss: 0.1334 - val_output_1_loss: 0.1321\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1101 - output_1_loss: 0.1096 - val_loss: 0.1335 - val_output_1_loss: 0.1322\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.0978 - output_1_loss: 0.0972 - val_loss: 0.1303 - val_output_1_loss: 0.1290\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.1118 - output_1_loss: 0.1112 - val_loss: 0.1242 - val_output_1_loss: 0.1229\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.1247 - output_1_loss: 0.1240 - val_loss: 0.1182 - val_output_1_loss: 0.1169\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1517 - output_1_loss: 0.1510 - val_loss: 0.1184 - val_output_1_loss: 0.1171\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.1115 - output_1_loss: 0.1110 - val_loss: 0.1088 - val_output_1_loss: 0.1075\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0944 - output_1_loss: 0.0938 - val_loss: 0.1109 - val_output_1_loss: 0.1097\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.1468 - output_1_loss: 0.1463 - val_loss: 0.1080 - val_output_1_loss: 0.1067\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.1555 - output_1_loss: 0.1550 - val_loss: 0.1036 - val_output_1_loss: 0.1024\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.1418 - output_1_loss: 0.1412 - val_loss: 0.0981 - val_output_1_loss: 0.0969\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1305 - output_1_loss: 0.1299 - val_loss: 0.1011 - val_output_1_loss: 0.0999\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1247 - output_1_loss: 0.1241 - val_loss: 0.0955 - val_output_1_loss: 0.0943\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1448 - output_1_loss: 0.1442 - val_loss: 0.0963 - val_output_1_loss: 0.0951\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.1078 - output_1_loss: 0.1072 - val_loss: 0.0810 - val_output_1_loss: 0.0798\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.1015 - output_1_loss: 0.1009 - val_loss: 0.0782 - val_output_1_loss: 0.0771\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0999 - output_1_loss: 0.0993 - val_loss: 0.0762 - val_output_1_loss: 0.0751\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.1117 - output_1_loss: 0.1112 - val_loss: 0.0751 - val_output_1_loss: 0.0740\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.1188 - output_1_loss: 0.1182 - val_loss: 0.0707 - val_output_1_loss: 0.0696\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1568 - output_1_loss: 0.1564 - val_loss: 0.0792 - val_output_1_loss: 0.0781\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1614 - output_1_loss: 0.1610 - val_loss: 0.0847 - val_output_1_loss: 0.0837\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1009 - output_1_loss: 0.1005 - val_loss: 0.0865 - val_output_1_loss: 0.0855\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1031 - output_1_loss: 0.1026 - val_loss: 0.0829 - val_output_1_loss: 0.0819\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1227 - output_1_loss: 0.1222 - val_loss: 0.0813 - val_output_1_loss: 0.0803\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:03:23,076]\u001b[0m Trial 15 finished with value: 1.0 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 1, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.0006969105398008719, 'bn_momentum': 0.964270927501524}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.8625 - output_1_loss: 0.8625 - val_loss: 0.6913 - val_output_1_loss: 0.6912\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7887 - output_1_loss: 0.7887 - val_loss: 0.6893 - val_output_1_loss: 0.6893\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.7618 - output_1_loss: 0.7617 - val_loss: 0.6873 - val_output_1_loss: 0.6873\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.8097 - output_1_loss: 0.8097 - val_loss: 0.6857 - val_output_1_loss: 0.6857\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.8221 - output_1_loss: 0.8221 - val_loss: 0.6828 - val_output_1_loss: 0.6827\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.8091 - output_1_loss: 0.8091 - val_loss: 0.6802 - val_output_1_loss: 0.6802\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.7986 - output_1_loss: 0.7986 - val_loss: 0.6776 - val_output_1_loss: 0.6776\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7213 - output_1_loss: 0.7213 - val_loss: 0.6760 - val_output_1_loss: 0.6760\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.7251 - output_1_loss: 0.7251 - val_loss: 0.6741 - val_output_1_loss: 0.6740\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.6963 - output_1_loss: 0.6963 - val_loss: 0.6713 - val_output_1_loss: 0.6713\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7182 - output_1_loss: 0.7182 - val_loss: 0.6684 - val_output_1_loss: 0.6684\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.6941 - output_1_loss: 0.6941 - val_loss: 0.6660 - val_output_1_loss: 0.6659\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.7038 - output_1_loss: 0.7038 - val_loss: 0.6631 - val_output_1_loss: 0.6631\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.6759 - output_1_loss: 0.6759 - val_loss: 0.6601 - val_output_1_loss: 0.6601\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6183 - output_1_loss: 0.6183 - val_loss: 0.6568 - val_output_1_loss: 0.6568\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6556 - output_1_loss: 0.6556 - val_loss: 0.6543 - val_output_1_loss: 0.6542\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5948 - output_1_loss: 0.5947 - val_loss: 0.6508 - val_output_1_loss: 0.6508\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5565 - output_1_loss: 0.5565 - val_loss: 0.6469 - val_output_1_loss: 0.6469\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5036 - output_1_loss: 0.5036 - val_loss: 0.6431 - val_output_1_loss: 0.6430\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4548 - output_1_loss: 0.4548 - val_loss: 0.6389 - val_output_1_loss: 0.6389\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4333 - output_1_loss: 0.4332 - val_loss: 0.6344 - val_output_1_loss: 0.6343\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4184 - output_1_loss: 0.4184 - val_loss: 0.6300 - val_output_1_loss: 0.6300\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3941 - output_1_loss: 0.3941 - val_loss: 0.6252 - val_output_1_loss: 0.6252\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4407 - output_1_loss: 0.4407 - val_loss: 0.6193 - val_output_1_loss: 0.6193\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3702 - output_1_loss: 0.3701 - val_loss: 0.6129 - val_output_1_loss: 0.6129\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3349 - output_1_loss: 0.3349 - val_loss: 0.6068 - val_output_1_loss: 0.6068\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3041 - output_1_loss: 0.3041 - val_loss: 0.6005 - val_output_1_loss: 0.6005\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.2812 - output_1_loss: 0.2812 - val_loss: 0.5942 - val_output_1_loss: 0.5942\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.2692 - output_1_loss: 0.2692 - val_loss: 0.5882 - val_output_1_loss: 0.5882\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.2575 - output_1_loss: 0.2575 - val_loss: 0.5813 - val_output_1_loss: 0.5813\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.2426 - output_1_loss: 0.2426 - val_loss: 0.5742 - val_output_1_loss: 0.5742\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.2184 - output_1_loss: 0.2184 - val_loss: 0.5668 - val_output_1_loss: 0.5668\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2167 - output_1_loss: 0.2167 - val_loss: 0.5593 - val_output_1_loss: 0.5593\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.2193 - output_1_loss: 0.2193 - val_loss: 0.5514 - val_output_1_loss: 0.5514\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1928 - output_1_loss: 0.1927 - val_loss: 0.5428 - val_output_1_loss: 0.5427\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1748 - output_1_loss: 0.1748 - val_loss: 0.5339 - val_output_1_loss: 0.5339\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.1695 - output_1_loss: 0.1695 - val_loss: 0.5249 - val_output_1_loss: 0.5249\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1585 - output_1_loss: 0.1584 - val_loss: 0.5151 - val_output_1_loss: 0.5151\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1573 - output_1_loss: 0.1573 - val_loss: 0.5056 - val_output_1_loss: 0.5056\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1733 - output_1_loss: 0.1733 - val_loss: 0.4971 - val_output_1_loss: 0.4970\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1558 - output_1_loss: 0.1558 - val_loss: 0.4881 - val_output_1_loss: 0.4880\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1355 - output_1_loss: 0.1355 - val_loss: 0.4779 - val_output_1_loss: 0.4779\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1284 - output_1_loss: 0.1284 - val_loss: 0.4673 - val_output_1_loss: 0.4673\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1280 - output_1_loss: 0.1280 - val_loss: 0.4573 - val_output_1_loss: 0.4573\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1203 - output_1_loss: 0.1203 - val_loss: 0.4472 - val_output_1_loss: 0.4472\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1165 - output_1_loss: 0.1164 - val_loss: 0.4371 - val_output_1_loss: 0.4371\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1128 - output_1_loss: 0.1128 - val_loss: 0.4272 - val_output_1_loss: 0.4272\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1110 - output_1_loss: 0.1110 - val_loss: 0.4177 - val_output_1_loss: 0.4177\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1066 - output_1_loss: 0.1066 - val_loss: 0.4084 - val_output_1_loss: 0.4084\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1018 - output_1_loss: 0.1018 - val_loss: 0.3990 - val_output_1_loss: 0.3990\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0985 - output_1_loss: 0.0985 - val_loss: 0.3897 - val_output_1_loss: 0.3897\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.0951 - output_1_loss: 0.0951 - val_loss: 0.3806 - val_output_1_loss: 0.3806\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0927 - output_1_loss: 0.0927 - val_loss: 0.3717 - val_output_1_loss: 0.3717\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0900 - output_1_loss: 0.0900 - val_loss: 0.3631 - val_output_1_loss: 0.3631\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0967 - output_1_loss: 0.0967 - val_loss: 0.3557 - val_output_1_loss: 0.3557\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1147 - output_1_loss: 0.1147 - val_loss: 0.3507 - val_output_1_loss: 0.3507\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1121 - output_1_loss: 0.1121 - val_loss: 0.3459 - val_output_1_loss: 0.3458\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1086 - output_1_loss: 0.1086 - val_loss: 0.3409 - val_output_1_loss: 0.3409\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1050 - output_1_loss: 0.1050 - val_loss: 0.3358 - val_output_1_loss: 0.3358\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1011 - output_1_loss: 0.1011 - val_loss: 0.3306 - val_output_1_loss: 0.3306\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0978 - output_1_loss: 0.0978 - val_loss: 0.3252 - val_output_1_loss: 0.3252\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0948 - output_1_loss: 0.0948 - val_loss: 0.3198 - val_output_1_loss: 0.3198\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0926 - output_1_loss: 0.0926 - val_loss: 0.3143 - val_output_1_loss: 0.3143\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0902 - output_1_loss: 0.0902 - val_loss: 0.3088 - val_output_1_loss: 0.3087\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0881 - output_1_loss: 0.0881 - val_loss: 0.3032 - val_output_1_loss: 0.3032\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0863 - output_1_loss: 0.0863 - val_loss: 0.2977 - val_output_1_loss: 0.2977\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0842 - output_1_loss: 0.0842 - val_loss: 0.2922 - val_output_1_loss: 0.2922\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0824 - output_1_loss: 0.0824 - val_loss: 0.2869 - val_output_1_loss: 0.2869\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0809 - output_1_loss: 0.0809 - val_loss: 0.2817 - val_output_1_loss: 0.2816\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0792 - output_1_loss: 0.0792 - val_loss: 0.2766 - val_output_1_loss: 0.2766\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0777 - output_1_loss: 0.0777 - val_loss: 0.2718 - val_output_1_loss: 0.2718\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0762 - output_1_loss: 0.0762 - val_loss: 0.2671 - val_output_1_loss: 0.2671\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0754 - output_1_loss: 0.0754 - val_loss: 0.2625 - val_output_1_loss: 0.2625\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0746 - output_1_loss: 0.0746 - val_loss: 0.2581 - val_output_1_loss: 0.2581\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0734 - output_1_loss: 0.0734 - val_loss: 0.2538 - val_output_1_loss: 0.2538\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0720 - output_1_loss: 0.0720 - val_loss: 0.2496 - val_output_1_loss: 0.2496\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0710 - output_1_loss: 0.0709 - val_loss: 0.2457 - val_output_1_loss: 0.2457\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0698 - output_1_loss: 0.0698 - val_loss: 0.2419 - val_output_1_loss: 0.2418\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0690 - output_1_loss: 0.0690 - val_loss: 0.2382 - val_output_1_loss: 0.2381\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0679 - output_1_loss: 0.0679 - val_loss: 0.2346 - val_output_1_loss: 0.2346\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0669 - output_1_loss: 0.0669 - val_loss: 0.2314 - val_output_1_loss: 0.2314\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0664 - output_1_loss: 0.0664 - val_loss: 0.2283 - val_output_1_loss: 0.2283\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0653 - output_1_loss: 0.0653 - val_loss: 0.2253 - val_output_1_loss: 0.2252\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0645 - output_1_loss: 0.0645 - val_loss: 0.2224 - val_output_1_loss: 0.2224\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0636 - output_1_loss: 0.0636 - val_loss: 0.2198 - val_output_1_loss: 0.2198\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0626 - output_1_loss: 0.0626 - val_loss: 0.2173 - val_output_1_loss: 0.2173\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0614 - output_1_loss: 0.0614 - val_loss: 0.2148 - val_output_1_loss: 0.2148\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0604 - output_1_loss: 0.0604 - val_loss: 0.2131 - val_output_1_loss: 0.2131\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0607 - output_1_loss: 0.0607 - val_loss: 0.2114 - val_output_1_loss: 0.2114\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0592 - output_1_loss: 0.0592 - val_loss: 0.2097 - val_output_1_loss: 0.2097\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0600 - output_1_loss: 0.0600 - val_loss: 0.2064 - val_output_1_loss: 0.2064\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0621 - output_1_loss: 0.0621 - val_loss: 0.2033 - val_output_1_loss: 0.2033\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0631 - output_1_loss: 0.0631 - val_loss: 0.2011 - val_output_1_loss: 0.2011\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0621 - output_1_loss: 0.0621 - val_loss: 0.1992 - val_output_1_loss: 0.1992\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0646 - output_1_loss: 0.0646 - val_loss: 0.1970 - val_output_1_loss: 0.1970\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0642 - output_1_loss: 0.0642 - val_loss: 0.1951 - val_output_1_loss: 0.1951\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0761 - output_1_loss: 0.0761 - val_loss: 0.1934 - val_output_1_loss: 0.1934\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0679 - output_1_loss: 0.0679 - val_loss: 0.1919 - val_output_1_loss: 0.1919\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0615 - output_1_loss: 0.0615 - val_loss: 0.1911 - val_output_1_loss: 0.1911\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0608 - output_1_loss: 0.0608 - val_loss: 0.1906 - val_output_1_loss: 0.1905\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:03:52,392]\u001b[0m Trial 17 finished with value: 0.03333333333333333 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 3, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 5.988975233349416e-06, 'bn_momentum': 0.9634223611436797}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.7580 - output_1_loss: 0.6957 - val_loss: 0.9789 - val_output_1_loss: 0.6848\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.7658 - output_1_loss: 0.7027 - val_loss: 0.9480 - val_output_1_loss: 0.6767\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.6518 - output_1_loss: 0.5882 - val_loss: 0.9125 - val_output_1_loss: 0.6683\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.6413 - output_1_loss: 0.5854 - val_loss: 0.8973 - val_output_1_loss: 0.6599\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.5826 - output_1_loss: 0.5330 - val_loss: 0.8709 - val_output_1_loss: 0.6510\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.5739 - output_1_loss: 0.5185 - val_loss: 0.8498 - val_output_1_loss: 0.6413\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5766 - output_1_loss: 0.5242 - val_loss: 0.8276 - val_output_1_loss: 0.6322\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.5575 - output_1_loss: 0.5059 - val_loss: 0.8003 - val_output_1_loss: 0.6228\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.5130 - output_1_loss: 0.4612 - val_loss: 0.7938 - val_output_1_loss: 0.6138\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.4936 - output_1_loss: 0.4427 - val_loss: 0.7767 - val_output_1_loss: 0.6041\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4956 - output_1_loss: 0.4412 - val_loss: 0.7788 - val_output_1_loss: 0.5944\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4241 - output_1_loss: 0.3729 - val_loss: 0.7628 - val_output_1_loss: 0.5848\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.4654 - output_1_loss: 0.4150 - val_loss: 0.7532 - val_output_1_loss: 0.5760\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.4833 - output_1_loss: 0.4372 - val_loss: 0.7462 - val_output_1_loss: 0.5666\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.3447 - output_1_loss: 0.3016 - val_loss: 0.7318 - val_output_1_loss: 0.5550\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.3276 - output_1_loss: 0.2841 - val_loss: 0.7110 - val_output_1_loss: 0.5441\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.3741 - output_1_loss: 0.3254 - val_loss: 0.6978 - val_output_1_loss: 0.5364\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.3872 - output_1_loss: 0.3387 - val_loss: 0.6819 - val_output_1_loss: 0.5246\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4298 - output_1_loss: 0.3823 - val_loss: 0.6543 - val_output_1_loss: 0.5131\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.3687 - output_1_loss: 0.3266 - val_loss: 0.6367 - val_output_1_loss: 0.5003\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.3522 - output_1_loss: 0.3046 - val_loss: 0.6305 - val_output_1_loss: 0.4927\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.3415 - output_1_loss: 0.2934 - val_loss: 0.6086 - val_output_1_loss: 0.4800\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.3792 - output_1_loss: 0.3417 - val_loss: 0.5941 - val_output_1_loss: 0.4732\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2553 - output_1_loss: 0.2091 - val_loss: 0.5812 - val_output_1_loss: 0.4626\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2816 - output_1_loss: 0.2365 - val_loss: 0.5786 - val_output_1_loss: 0.4474\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.3713 - output_1_loss: 0.3286 - val_loss: 0.5676 - val_output_1_loss: 0.4367\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.3028 - output_1_loss: 0.2597 - val_loss: 0.5547 - val_output_1_loss: 0.4276\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2019 - output_1_loss: 0.1616 - val_loss: 0.5426 - val_output_1_loss: 0.4136\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.3356 - output_1_loss: 0.2988 - val_loss: 0.5233 - val_output_1_loss: 0.4044\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.2661 - output_1_loss: 0.2324 - val_loss: 0.5121 - val_output_1_loss: 0.3947\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2526 - output_1_loss: 0.2140 - val_loss: 0.5075 - val_output_1_loss: 0.3847\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.3096 - output_1_loss: 0.2675 - val_loss: 0.5020 - val_output_1_loss: 0.3764\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.3834 - output_1_loss: 0.3412 - val_loss: 0.4925 - val_output_1_loss: 0.3679\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2682 - output_1_loss: 0.2215 - val_loss: 0.4863 - val_output_1_loss: 0.3543\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.2993 - output_1_loss: 0.2503 - val_loss: 0.4728 - val_output_1_loss: 0.3476\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2927 - output_1_loss: 0.2446 - val_loss: 0.4666 - val_output_1_loss: 0.3389\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.2479 - output_1_loss: 0.2017 - val_loss: 0.4654 - val_output_1_loss: 0.3276\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.2286 - output_1_loss: 0.1880 - val_loss: 0.4457 - val_output_1_loss: 0.3190\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.2983 - output_1_loss: 0.2605 - val_loss: 0.4331 - val_output_1_loss: 0.3100\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2000 - output_1_loss: 0.1636 - val_loss: 0.4157 - val_output_1_loss: 0.2968\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1798 - output_1_loss: 0.1421 - val_loss: 0.4060 - val_output_1_loss: 0.2904\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1951 - output_1_loss: 0.1561 - val_loss: 0.3846 - val_output_1_loss: 0.2789\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2235 - output_1_loss: 0.1907 - val_loss: 0.3741 - val_output_1_loss: 0.2683\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1985 - output_1_loss: 0.1633 - val_loss: 0.3691 - val_output_1_loss: 0.2594\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2948 - output_1_loss: 0.2552 - val_loss: 0.3697 - val_output_1_loss: 0.2607\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2734 - output_1_loss: 0.2379 - val_loss: 0.3614 - val_output_1_loss: 0.2512\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1714 - output_1_loss: 0.1344 - val_loss: 0.3439 - val_output_1_loss: 0.2379\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3603 - output_1_loss: 0.3295 - val_loss: 0.3424 - val_output_1_loss: 0.2312\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2813 - output_1_loss: 0.2402 - val_loss: 0.3307 - val_output_1_loss: 0.2226\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1549 - output_1_loss: 0.1224 - val_loss: 0.3376 - val_output_1_loss: 0.2212\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2397 - output_1_loss: 0.2057 - val_loss: 0.3220 - val_output_1_loss: 0.2121\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3198 - output_1_loss: 0.2848 - val_loss: 0.3159 - val_output_1_loss: 0.2086\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2164 - output_1_loss: 0.1861 - val_loss: 0.3025 - val_output_1_loss: 0.2022\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1962 - output_1_loss: 0.1623 - val_loss: 0.2926 - val_output_1_loss: 0.1959\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2842 - output_1_loss: 0.2456 - val_loss: 0.2963 - val_output_1_loss: 0.2000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1993 - output_1_loss: 0.1604 - val_loss: 0.2859 - val_output_1_loss: 0.1921\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1484 - output_1_loss: 0.1061 - val_loss: 0.2652 - val_output_1_loss: 0.1844\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1949 - output_1_loss: 0.1624 - val_loss: 0.2721 - val_output_1_loss: 0.1878\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1714 - output_1_loss: 0.1322 - val_loss: 0.2653 - val_output_1_loss: 0.1822\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.2098 - output_1_loss: 0.1772 - val_loss: 0.2565 - val_output_1_loss: 0.1754\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2580 - output_1_loss: 0.2239 - val_loss: 0.2466 - val_output_1_loss: 0.1689\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.1773 - output_1_loss: 0.1417 - val_loss: 0.2422 - val_output_1_loss: 0.1608\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.2367 - output_1_loss: 0.2009 - val_loss: 0.2387 - val_output_1_loss: 0.1547\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1721 - output_1_loss: 0.1361 - val_loss: 0.2386 - val_output_1_loss: 0.1519\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1388 - output_1_loss: 0.0998 - val_loss: 0.2481 - val_output_1_loss: 0.1515\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2385 - output_1_loss: 0.2002 - val_loss: 0.2395 - val_output_1_loss: 0.1442\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 32s 32s/step - loss: 0.8187 - output_1_loss: 0.7718 - val_loss: 0.8756 - val_output_1_loss: 0.6845\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2161 - output_1_loss: 0.1806 - val_loss: 0.2400 - val_output_1_loss: 0.1446\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1296 - output_1_loss: 0.0998 - val_loss: 0.2362 - val_output_1_loss: 0.1390\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1601 - output_1_loss: 0.1278 - val_loss: 0.2330 - val_output_1_loss: 0.1369\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2054 - output_1_loss: 0.1767 - val_loss: 0.2274 - val_output_1_loss: 0.1336\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2373 - output_1_loss: 0.2113 - val_loss: 0.2285 - val_output_1_loss: 0.1318\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3484 - output_1_loss: 0.3163 - val_loss: 0.2308 - val_output_1_loss: 0.1321\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1795 - output_1_loss: 0.1391 - val_loss: 0.2189 - val_output_1_loss: 0.1264\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2315 - output_1_loss: 0.1940Epoch 2/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2315 - output_1_loss: 0.1940 - val_loss: 0.2176 - val_output_1_loss: 0.1238\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7169 - output_1_loss: 0.6682Epoch 75/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.7169 - output_1_loss: 0.6682 - val_loss: 0.8503 - val_output_1_loss: 0.6764\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1722 - output_1_loss: 0.1349 - val_loss: 0.2179 - val_output_1_loss: 0.1238\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1741 - output_1_loss: 0.1342 - val_loss: 0.2058 - val_output_1_loss: 0.1185\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.6548 - output_1_loss: 0.6081 - val_loss: 0.8314 - val_output_1_loss: 0.6683\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1842 - output_1_loss: 0.1385 - val_loss: 0.2059 - val_output_1_loss: 0.1205\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2138 - output_1_loss: 0.1700Epoch 4/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2138 - output_1_loss: 0.1700 - val_loss: 0.1996 - val_output_1_loss: 0.1125\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5699 - output_1_loss: 0.5246Epoch 79/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.5699 - output_1_loss: 0.5246 - val_loss: 0.8183 - val_output_1_loss: 0.6609\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1552 - output_1_loss: 0.1122 - val_loss: 0.2059 - val_output_1_loss: 0.1214\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1414 - output_1_loss: 0.1002 - val_loss: 0.2010 - val_output_1_loss: 0.1159\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5594 - output_1_loss: 0.5173 - val_loss: 0.8022 - val_output_1_loss: 0.6498\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.1510 - output_1_loss: 0.1122 - val_loss: 0.1987 - val_output_1_loss: 0.1112\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.5783 - output_1_loss: 0.5338 - val_loss: 0.7867 - val_output_1_loss: 0.6413\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5020 - output_1_loss: 0.4587 - val_loss: 0.7667 - val_output_1_loss: 0.6306\n",
      "Epoch 8/100\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.1541 - output_1_loss: 0.1117 - val_loss: 0.1938 - val_output_1_loss: 0.1048\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.5153 - output_1_loss: 0.4707 - val_loss: 0.7563 - val_output_1_loss: 0.6205\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1623 - output_1_loss: 0.1161 - val_loss: 0.1985 - val_output_1_loss: 0.1080\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1761 - output_1_loss: 0.1328Epoch 9/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1761 - output_1_loss: 0.1328 - val_loss: 0.1933 - val_output_1_loss: 0.1057\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1616 - output_1_loss: 0.1298 - val_loss: 0.2012 - val_output_1_loss: 0.1065\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.4103 - output_1_loss: 0.3711 - val_loss: 0.7383 - val_output_1_loss: 0.6118\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1495 - output_1_loss: 0.1089 - val_loss: 0.1968 - val_output_1_loss: 0.1059\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1675 - output_1_loss: 0.1246 - val_loss: 0.1999 - val_output_1_loss: 0.1057\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1910 - output_1_loss: 0.1547Epoch 10/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1910 - output_1_loss: 0.1547 - val_loss: 0.1926 - val_output_1_loss: 0.1017\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5304 - output_1_loss: 0.4909 - val_loss: 0.7264 - val_output_1_loss: 0.6002\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3402 - output_1_loss: 0.3013 - val_loss: 0.7091 - val_output_1_loss: 0.5888\n",
      "Epoch 12/100\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.1807 - output_1_loss: 0.1375 - val_loss: 0.1896 - val_output_1_loss: 0.1005\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.5015 - output_1_loss: 0.4623 - val_loss: 0.6963 - val_output_1_loss: 0.5771\n",
      "Epoch 90/100\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.2360 - output_1_loss: 0.1968 - val_loss: 0.1884 - val_output_1_loss: 0.0980\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.3273 - output_1_loss: 0.2860 - val_loss: 0.6828 - val_output_1_loss: 0.5641\n",
      "Epoch 91/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.1541 - output_1_loss: 0.1157 - val_loss: 0.1882 - val_output_1_loss: 0.1015\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.3708 - output_1_loss: 0.3320 - val_loss: 0.6677 - val_output_1_loss: 0.5496\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1622 - output_1_loss: 0.1279 - val_loss: 0.1810 - val_output_1_loss: 0.1001\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2635 - output_1_loss: 0.2243 - val_loss: 0.6521 - val_output_1_loss: 0.5357\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1553 - output_1_loss: 0.1183 - val_loss: 0.1798 - val_output_1_loss: 0.0983\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3004 - output_1_loss: 0.2606Epoch 94/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.3004 - output_1_loss: 0.2606 - val_loss: 0.6394 - val_output_1_loss: 0.5235\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.1297 - output_1_loss: 0.0960 - val_loss: 0.1752 - val_output_1_loss: 0.0951\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1876 - output_1_loss: 0.1572 - val_loss: 0.1692 - val_output_1_loss: 0.0920\n",
      "Epoch 96/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1216 - output_1_loss: 0.0858 - val_loss: 0.1678 - val_output_1_loss: 0.0912\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.3111 - output_1_loss: 0.2721 - val_loss: 0.6242 - val_output_1_loss: 0.5120\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1611 - output_1_loss: 0.1315 - val_loss: 0.1762 - val_output_1_loss: 0.0936\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.2088 - output_1_loss: 0.1753 - val_loss: 0.1774 - val_output_1_loss: 0.0862\n",
      "Epoch 99/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2019 - output_1_loss: 0.1675 - val_loss: 0.1775 - val_output_1_loss: 0.0845\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3107 - output_1_loss: 0.2708 - val_loss: 0.6062 - val_output_1_loss: 0.4955\n",
      "Epoch 100/100\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1122 - output_1_loss: 0.0762 - val_loss: 0.1752 - val_output_1_loss: 0.0832\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.3490 - output_1_loss: 0.3121 - val_loss: 0.5912 - val_output_1_loss: 0.4817\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2300 - output_1_loss: 0.1972 - val_loss: 0.5747 - val_output_1_loss: 0.4669\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3689 - output_1_loss: 0.3366 - val_loss: 0.5632 - val_output_1_loss: 0.4557\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.2076 - output_1_loss: 0.1751 - val_loss: 0.5448 - val_output_1_loss: 0.4406\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2398 - output_1_loss: 0.2040 - val_loss: 0.5317 - val_output_1_loss: 0.4285\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2466 - output_1_loss: 0.2091 - val_loss: 0.5202 - val_output_1_loss: 0.4141\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1564 - output_1_loss: 0.1188 - val_loss: 0.4998 - val_output_1_loss: 0.3968\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:04:37,953]\u001b[0m Trial 18 finished with value: 0.023255813953488372 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 3, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 0.07898252596744143, 'bn_momentum': 0.9657998298695998}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 597ms/step - loss: 0.2093 - output_1_loss: 0.1713 - val_loss: 0.4851 - val_output_1_loss: 0.3861\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.3413 - output_1_loss: 0.3029 - val_loss: 0.4722 - val_output_1_loss: 0.3717\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1977 - output_1_loss: 0.1615Epoch 1/100\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.1977 - output_1_loss: 0.1615 - val_loss: 0.4569 - val_output_1_loss: 0.3570\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.1376 - output_1_loss: 0.1037 - val_loss: 0.4330 - val_output_1_loss: 0.3361\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.1714 - output_1_loss: 0.1381 - val_loss: 0.4241 - val_output_1_loss: 0.3251\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.1387 - output_1_loss: 0.1070 - val_loss: 0.4108 - val_output_1_loss: 0.3134\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.2365 - output_1_loss: 0.2057 - val_loss: 0.3907 - val_output_1_loss: 0.3006\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.1331 - output_1_loss: 0.0992 - val_loss: 0.3666 - val_output_1_loss: 0.2780\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.1425 - output_1_loss: 0.1115 - val_loss: 0.3524 - val_output_1_loss: 0.2643\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.2566 - output_1_loss: 0.2246 - val_loss: 0.3413 - val_output_1_loss: 0.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.1676 - output_1_loss: 0.1380 - val_loss: 0.3312 - val_output_1_loss: 0.2439\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.4489 - output_1_loss: 0.4234 - val_loss: 0.3263 - val_output_1_loss: 0.2415\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.1911 - output_1_loss: 0.1598 - val_loss: 0.3245 - val_output_1_loss: 0.2380\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.1261 - output_1_loss: 0.0968 - val_loss: 0.3189 - val_output_1_loss: 0.2343\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.1227 - output_1_loss: 0.0912 - val_loss: 0.3051 - val_output_1_loss: 0.2205\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.1515 - output_1_loss: 0.1177 - val_loss: 0.2977 - val_output_1_loss: 0.2146\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.1092 - output_1_loss: 0.0806 - val_loss: 0.2824 - val_output_1_loss: 0.1995\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.1558 - output_1_loss: 0.1228 - val_loss: 0.2722 - val_output_1_loss: 0.1866\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.1458 - output_1_loss: 0.1113 - val_loss: 0.2656 - val_output_1_loss: 0.1821\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.1317 - output_1_loss: 0.0979 - val_loss: 0.2516 - val_output_1_loss: 0.1662\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.1393 - output_1_loss: 0.1037 - val_loss: 0.2403 - val_output_1_loss: 0.1557\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.1480 - output_1_loss: 0.1145 - val_loss: 0.2300 - val_output_1_loss: 0.1491\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.1321 - output_1_loss: 0.0994 - val_loss: 0.2268 - val_output_1_loss: 0.1473\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.1184 - output_1_loss: 0.0851 - val_loss: 0.2238 - val_output_1_loss: 0.1402\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.1393 - output_1_loss: 0.1059 - val_loss: 0.2156 - val_output_1_loss: 0.1363\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.1404 - output_1_loss: 0.1099 - val_loss: 0.2142 - val_output_1_loss: 0.1336\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.1155 - output_1_loss: 0.0846 - val_loss: 0.2111 - val_output_1_loss: 0.1302\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.1727 - output_1_loss: 0.1418 - val_loss: 0.2038 - val_output_1_loss: 0.1262\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.1913 - output_1_loss: 0.1612 - val_loss: 0.2037 - val_output_1_loss: 0.1232\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.1462 - output_1_loss: 0.1146 - val_loss: 0.1962 - val_output_1_loss: 0.1159\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1369 - output_1_loss: 0.1025 - val_loss: 0.1923 - val_output_1_loss: 0.1098\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1494 - output_1_loss: 0.1160 - val_loss: 0.1926 - val_output_1_loss: 0.1117\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1120 - output_1_loss: 0.0863 - val_loss: 0.1845 - val_output_1_loss: 0.1047\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1325 - output_1_loss: 0.1043 - val_loss: 0.1838 - val_output_1_loss: 0.1056\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1323 - output_1_loss: 0.1064 - val_loss: 0.1807 - val_output_1_loss: 0.1042\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1079 - output_1_loss: 0.0806 - val_loss: 0.1780 - val_output_1_loss: 0.1026\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1838 - output_1_loss: 0.1619 - val_loss: 0.1694 - val_output_1_loss: 0.1007\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1469 - output_1_loss: 0.1184 - val_loss: 0.1666 - val_output_1_loss: 0.0966\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1124 - output_1_loss: 0.0810 - val_loss: 0.1674 - val_output_1_loss: 0.0957\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1441 - output_1_loss: 0.1082 - val_loss: 0.1676 - val_output_1_loss: 0.0927\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1250 - output_1_loss: 0.0903 - val_loss: 0.1651 - val_output_1_loss: 0.0890\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1543 - output_1_loss: 0.1243 - val_loss: 0.1644 - val_output_1_loss: 0.0861\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1231 - output_1_loss: 0.0949 - val_loss: 0.1624 - val_output_1_loss: 0.0805\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1130 - output_1_loss: 0.0856 - val_loss: 0.1585 - val_output_1_loss: 0.0786\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1233 - output_1_loss: 0.0973 - val_loss: 0.1580 - val_output_1_loss: 0.0786\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.1117 - output_1_loss: 0.0875 - val_loss: 0.1521 - val_output_1_loss: 0.0757\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.1305 - output_1_loss: 0.1067 - val_loss: 0.1511 - val_output_1_loss: 0.0751\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1525 - output_1_loss: 0.1273 - val_loss: 0.1538 - val_output_1_loss: 0.0773\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1547 - output_1_loss: 0.1278 - val_loss: 0.1529 - val_output_1_loss: 0.0767\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1789 - output_1_loss: 0.1525 - val_loss: 0.1538 - val_output_1_loss: 0.0749\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1122 - output_1_loss: 0.0833 - val_loss: 0.1465 - val_output_1_loss: 0.0726\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1503 - output_1_loss: 0.1223 - val_loss: 0.1470 - val_output_1_loss: 0.0728\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1971 - output_1_loss: 0.1759 - val_loss: 0.1437 - val_output_1_loss: 0.0694\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.2138 - output_1_loss: 0.1861 - val_loss: 0.1424 - val_output_1_loss: 0.0700\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.6648 - output_1_loss: 0.6641 - val_loss: 0.6849 - val_output_1_loss: 0.6820\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1355 - output_1_loss: 0.1079 - val_loss: 0.1390 - val_output_1_loss: 0.0680\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6104 - output_1_loss: 0.6097 - val_loss: 0.6722 - val_output_1_loss: 0.6696\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.5139 - output_1_loss: 0.5133 - val_loss: 0.6613 - val_output_1_loss: 0.6589\n",
      "Epoch 81/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.5224 - output_1_loss: 0.5218 - val_loss: 0.6473 - val_output_1_loss: 0.6450\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.2870 - output_1_loss: 0.2606 - val_loss: 0.1364 - val_output_1_loss: 0.0674\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4599 - output_1_loss: 0.4593 - val_loss: 0.6355 - val_output_1_loss: 0.6333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4481 - output_1_loss: 0.4475Epoch 82/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4481 - output_1_loss: 0.4475 - val_loss: 0.6232 - val_output_1_loss: 0.6211\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1336 - output_1_loss: 0.1067 - val_loss: 0.1371 - val_output_1_loss: 0.0676\n",
      "Epoch 83/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1212 - output_1_loss: 0.0907 - val_loss: 0.1365 - val_output_1_loss: 0.0682\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.5388 - output_1_loss: 0.5382 - val_loss: 0.6118 - val_output_1_loss: 0.6100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1666 - output_1_loss: 0.1361Epoch 8/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1666 - output_1_loss: 0.1361 - val_loss: 0.1394 - val_output_1_loss: 0.0678\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3947 - output_1_loss: 0.3941 - val_loss: 0.5956 - val_output_1_loss: 0.5939\n",
      "Epoch 85/100\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2661 - output_1_loss: 0.2334 - val_loss: 0.1379 - val_output_1_loss: 0.0679\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.4313 - output_1_loss: 0.4308 - val_loss: 0.5845 - val_output_1_loss: 0.5827\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.1346 - output_1_loss: 0.1018 - val_loss: 0.1364 - val_output_1_loss: 0.0670\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3433 - output_1_loss: 0.3428 - val_loss: 0.5669 - val_output_1_loss: 0.5652\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4286 - output_1_loss: 0.4281 - val_loss: 0.5521 - val_output_1_loss: 0.5505\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3038 - output_1_loss: 0.3033Epoch 87/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3038 - output_1_loss: 0.3033 - val_loss: 0.5373 - val_output_1_loss: 0.5358\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1147 - output_1_loss: 0.0825 - val_loss: 0.1325 - val_output_1_loss: 0.0666\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2345 - output_1_loss: 0.2340 - val_loss: 0.5220 - val_output_1_loss: 0.5204\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2141 - output_1_loss: 0.1810Epoch 14/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2141 - output_1_loss: 0.1810 - val_loss: 0.1359 - val_output_1_loss: 0.0684\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1998 - output_1_loss: 0.1670 - val_loss: 0.1378 - val_output_1_loss: 0.0665\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.4006 - output_1_loss: 0.4001 - val_loss: 0.5085 - val_output_1_loss: 0.5069\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1816 - output_1_loss: 0.1811Epoch 90/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1816 - output_1_loss: 0.1811 - val_loss: 0.4893 - val_output_1_loss: 0.4878\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1179 - output_1_loss: 0.0832 - val_loss: 0.1400 - val_output_1_loss: 0.0651\n",
      "Epoch 91/100\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1134 - output_1_loss: 0.0788 - val_loss: 0.1441 - val_output_1_loss: 0.0654\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.2095 - output_1_loss: 0.2090 - val_loss: 0.4716 - val_output_1_loss: 0.4702\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.1196 - output_1_loss: 0.0848 - val_loss: 0.1458 - val_output_1_loss: 0.0653\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 0.2963 - output_1_loss: 0.2959 - val_loss: 0.4582 - val_output_1_loss: 0.4569\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.2406 - output_1_loss: 0.2402 - val_loss: 0.4372 - val_output_1_loss: 0.4359\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2918 - output_1_loss: 0.2914 - val_loss: 0.4108 - val_output_1_loss: 0.4096\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1409 - output_1_loss: 0.1405 - val_loss: 0.3863 - val_output_1_loss: 0.3851\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1264 - output_1_loss: 0.1260 - val_loss: 0.3492 - val_output_1_loss: 0.3480\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1608 - output_1_loss: 0.1603 - val_loss: 0.3297 - val_output_1_loss: 0.3286\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:05:09,393]\u001b[0m Trial 19 finished with value: 0.3333333333333333 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 1, 'relaxation_factor': 1.8, 'sparsity_coefficient': 0.04314329396924392, 'bn_momentum': 0.9670172930997484}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.2176 - output_1_loss: 0.2170 - val_loss: 0.3055 - val_output_1_loss: 0.3044\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.2318 - output_1_loss: 0.2312 - val_loss: 0.2960 - val_output_1_loss: 0.2949\n",
      "Epoch 1/100\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1641 - output_1_loss: 0.1636 - val_loss: 0.2889 - val_output_1_loss: 0.2879\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.1531 - output_1_loss: 0.1526 - val_loss: 0.2762 - val_output_1_loss: 0.2754\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.0840 - output_1_loss: 0.0835 - val_loss: 0.2493 - val_output_1_loss: 0.2484\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1439 - output_1_loss: 0.1435 - val_loss: 0.2316 - val_output_1_loss: 0.2307\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1540 - output_1_loss: 0.1536 - val_loss: 0.2284 - val_output_1_loss: 0.2276\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1109 - output_1_loss: 0.1104 - val_loss: 0.2085 - val_output_1_loss: 0.2076\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.1457 - output_1_loss: 0.1453 - val_loss: 0.1936 - val_output_1_loss: 0.1928\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1868 - output_1_loss: 0.1863 - val_loss: 0.1807 - val_output_1_loss: 0.1799\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.2011 - output_1_loss: 0.2007 - val_loss: 0.1797 - val_output_1_loss: 0.1788\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1753 - output_1_loss: 0.1749 - val_loss: 0.1709 - val_output_1_loss: 0.1700\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0889 - output_1_loss: 0.0884 - val_loss: 0.1634 - val_output_1_loss: 0.1625\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.0702 - output_1_loss: 0.0697 - val_loss: 0.1524 - val_output_1_loss: 0.1515\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1269 - output_1_loss: 0.1264 - val_loss: 0.1336 - val_output_1_loss: 0.1327\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0935 - output_1_loss: 0.0930 - val_loss: 0.1070 - val_output_1_loss: 0.1060\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.1454 - output_1_loss: 0.1449 - val_loss: 0.1048 - val_output_1_loss: 0.1040\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0917 - output_1_loss: 0.0912 - val_loss: 0.1009 - val_output_1_loss: 0.0999\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.2412 - output_1_loss: 0.2407 - val_loss: 0.1007 - val_output_1_loss: 0.0998\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1846 - output_1_loss: 0.1841 - val_loss: 0.1006 - val_output_1_loss: 0.0997\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1629 - output_1_loss: 0.1624 - val_loss: 0.1012 - val_output_1_loss: 0.1003\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1581 - output_1_loss: 0.1577 - val_loss: 0.1011 - val_output_1_loss: 0.1002\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1030 - output_1_loss: 0.1026 - val_loss: 0.1006 - val_output_1_loss: 0.0997\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.1694 - output_1_loss: 0.1691 - val_loss: 0.0979 - val_output_1_loss: 0.0970\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.1441 - output_1_loss: 0.1437 - val_loss: 0.0918 - val_output_1_loss: 0.0909\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2104 - output_1_loss: 0.2100 - val_loss: 0.0921 - val_output_1_loss: 0.0912\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1668 - output_1_loss: 0.1663 - val_loss: 0.0957 - val_output_1_loss: 0.0948\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.0766 - output_1_loss: 0.0762 - val_loss: 0.0852 - val_output_1_loss: 0.0843\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.0991 - output_1_loss: 0.0987 - val_loss: 0.0839 - val_output_1_loss: 0.0829\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0981 - output_1_loss: 0.0978 - val_loss: 0.0886 - val_output_1_loss: 0.0876\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1071 - output_1_loss: 0.1068 - val_loss: 0.0910 - val_output_1_loss: 0.0900\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0920 - output_1_loss: 0.0916 - val_loss: 0.0887 - val_output_1_loss: 0.0877\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0906 - output_1_loss: 0.0901 - val_loss: 0.0873 - val_output_1_loss: 0.0863\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.3297 - output_1_loss: 0.3294 - val_loss: 0.0859 - val_output_1_loss: 0.0850\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:05:25,785]\u001b[0m Trial 20 finished with value: 0.25 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 1, 'relaxation_factor': 3.0, 'sparsity_coefficient': 0.0007197172439479281, 'bn_momentum': 0.943503526611746}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.9423 - output_1_loss: 0.9414 - val_loss: 0.6896 - val_output_1_loss: 0.6860\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.8136 - output_1_loss: 0.8127 - val_loss: 0.6816 - val_output_1_loss: 0.6785\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.8538 - output_1_loss: 0.8529 - val_loss: 0.6750 - val_output_1_loss: 0.6720\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.7699 - output_1_loss: 0.7691 - val_loss: 0.6675 - val_output_1_loss: 0.6645\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.7262 - output_1_loss: 0.7253 - val_loss: 0.6606 - val_output_1_loss: 0.6578\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.7247 - output_1_loss: 0.7239 - val_loss: 0.6537 - val_output_1_loss: 0.6510\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.5811 - output_1_loss: 0.5802 - val_loss: 0.6437 - val_output_1_loss: 0.6411\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.5933 - output_1_loss: 0.5925 - val_loss: 0.6347 - val_output_1_loss: 0.6323\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.5689 - output_1_loss: 0.5682 - val_loss: 0.6258 - val_output_1_loss: 0.6234\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.5381 - output_1_loss: 0.5373 - val_loss: 0.6191 - val_output_1_loss: 0.6169\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.6103 - output_1_loss: 0.6096 - val_loss: 0.6094 - val_output_1_loss: 0.6072\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5185 - output_1_loss: 0.5178 - val_loss: 0.6010 - val_output_1_loss: 0.5989\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5188 - output_1_loss: 0.5181 - val_loss: 0.5926 - val_output_1_loss: 0.5905\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3984 - output_1_loss: 0.3977 - val_loss: 0.5799 - val_output_1_loss: 0.5779\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.4534 - output_1_loss: 0.4526 - val_loss: 0.5697 - val_output_1_loss: 0.5678\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.4796 - output_1_loss: 0.4789 - val_loss: 0.5606 - val_output_1_loss: 0.5588\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3837 - output_1_loss: 0.3831 - val_loss: 0.5504 - val_output_1_loss: 0.5486\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5525 - output_1_loss: 0.5518 - val_loss: 0.5407 - val_output_1_loss: 0.5389\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3382 - output_1_loss: 0.3375 - val_loss: 0.5307 - val_output_1_loss: 0.5288\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4640 - output_1_loss: 0.4633 - val_loss: 0.5181 - val_output_1_loss: 0.5163\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3605 - output_1_loss: 0.3598 - val_loss: 0.5061 - val_output_1_loss: 0.5043\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3835 - output_1_loss: 0.3828 - val_loss: 0.4956 - val_output_1_loss: 0.4938\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3760 - output_1_loss: 0.3752 - val_loss: 0.4895 - val_output_1_loss: 0.4878\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3083 - output_1_loss: 0.3075 - val_loss: 0.4804 - val_output_1_loss: 0.4787\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3954 - output_1_loss: 0.3946 - val_loss: 0.4634 - val_output_1_loss: 0.4618\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4649 - output_1_loss: 0.4641 - val_loss: 0.4435 - val_output_1_loss: 0.4419\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2870 - output_1_loss: 0.2862 - val_loss: 0.4406 - val_output_1_loss: 0.4390\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3479 - output_1_loss: 0.3471 - val_loss: 0.4369 - val_output_1_loss: 0.4353\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2644 - output_1_loss: 0.2637 - val_loss: 0.4292 - val_output_1_loss: 0.4277\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3159 - output_1_loss: 0.3152 - val_loss: 0.4062 - val_output_1_loss: 0.4046\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.2893 - output_1_loss: 0.2886 - val_loss: 0.4055 - val_output_1_loss: 0.4040\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3953 - output_1_loss: 0.3947 - val_loss: 0.3913 - val_output_1_loss: 0.3897\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.2988 - output_1_loss: 0.2982 - val_loss: 0.3854 - val_output_1_loss: 0.3838\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.2644 - output_1_loss: 0.2638 - val_loss: 0.3733 - val_output_1_loss: 0.3719\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.2587 - output_1_loss: 0.2581 - val_loss: 0.3622 - val_output_1_loss: 0.3607\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.3338 - output_1_loss: 0.3331 - val_loss: 0.3563 - val_output_1_loss: 0.3548\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2452 - output_1_loss: 0.2447 - val_loss: 0.3460 - val_output_1_loss: 0.3445\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2026 - output_1_loss: 0.2021 - val_loss: 0.3332 - val_output_1_loss: 0.3317\n",
      "1/1 [==============================] - 26s 26s/step - loss: 1.0437 - output_1_loss: 1.0432 - val_loss: 0.6979 - val_output_1_loss: 0.6957\n",
      "Epoch 2/100\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3132 - output_1_loss: 0.3127 - val_loss: 0.3308 - val_output_1_loss: 0.3294\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.0885 - output_1_loss: 1.0880 - val_loss: 0.6930 - val_output_1_loss: 0.6910\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2586 - output_1_loss: 0.2581 - val_loss: 0.3201 - val_output_1_loss: 0.3187\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.0285 - output_1_loss: 1.0280 - val_loss: 0.6919 - val_output_1_loss: 0.6900\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1833 - output_1_loss: 0.1828Epoch 4/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1833 - output_1_loss: 0.1828 - val_loss: 0.3129 - val_output_1_loss: 0.3115\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.9473 - output_1_loss: 0.9468 - val_loss: 0.6898 - val_output_1_loss: 0.6880\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2658 - output_1_loss: 0.2653 - val_loss: 0.3040 - val_output_1_loss: 0.3026\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9624 - output_1_loss: 0.9619Epoch 43/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.9624 - output_1_loss: 0.9619 - val_loss: 0.6858 - val_output_1_loss: 0.6840\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3502 - output_1_loss: 0.3497 - val_loss: 0.2967 - val_output_1_loss: 0.2954\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.8741 - output_1_loss: 0.8736 - val_loss: 0.6835 - val_output_1_loss: 0.6818\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2004 - output_1_loss: 0.2000 - val_loss: 0.2863 - val_output_1_loss: 0.2850\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1928 - output_1_loss: 0.1924 - val_loss: 0.2777 - val_output_1_loss: 0.2764\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.8913 - output_1_loss: 0.8908 - val_loss: 0.6809 - val_output_1_loss: 0.6793\n",
      "Epoch 8/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2743 - output_1_loss: 0.2738 - val_loss: 0.2669 - val_output_1_loss: 0.2657\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.8546 - output_1_loss: 0.8541 - val_loss: 0.6790 - val_output_1_loss: 0.6774\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7785 - output_1_loss: 0.7780Epoch 47/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.7785 - output_1_loss: 0.7780 - val_loss: 0.6772 - val_output_1_loss: 0.6756\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1836 - output_1_loss: 0.1832 - val_loss: 0.2511 - val_output_1_loss: 0.2499\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8399 - output_1_loss: 0.8394Epoch 48/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8399 - output_1_loss: 0.8394 - val_loss: 0.6751 - val_output_1_loss: 0.6736\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1401 - output_1_loss: 0.1397 - val_loss: 0.2393 - val_output_1_loss: 0.2381\n",
      "Epoch 49/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1647 - output_1_loss: 0.1643 - val_loss: 0.2321 - val_output_1_loss: 0.2310\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.8440 - output_1_loss: 0.8435 - val_loss: 0.6727 - val_output_1_loss: 0.6713\n",
      "Epoch 12/100\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1580 - output_1_loss: 0.1576 - val_loss: 0.2269 - val_output_1_loss: 0.2259\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.7783 - output_1_loss: 0.7778 - val_loss: 0.6714 - val_output_1_loss: 0.6700\n",
      "Epoch 51/100\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1477 - output_1_loss: 0.1472 - val_loss: 0.2153 - val_output_1_loss: 0.2143\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7627 - output_1_loss: 0.7622 - val_loss: 0.6682 - val_output_1_loss: 0.6668\n",
      "Epoch 14/100\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1898 - output_1_loss: 0.1894 - val_loss: 0.2088 - val_output_1_loss: 0.2079\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.7273 - output_1_loss: 0.7268 - val_loss: 0.6651 - val_output_1_loss: 0.6637\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2773 - output_1_loss: 0.2769 - val_loss: 0.2081 - val_output_1_loss: 0.2071\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.7428 - output_1_loss: 0.7423 - val_loss: 0.6632 - val_output_1_loss: 0.6619\n",
      "Epoch 16/100\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.7688 - output_1_loss: 0.7683 - val_loss: 0.6615 - val_output_1_loss: 0.6602\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1708 - output_1_loss: 0.1704 - val_loss: 0.2015 - val_output_1_loss: 0.2005\n",
      "Epoch 17/100\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.6960 - output_1_loss: 0.6955 - val_loss: 0.6587 - val_output_1_loss: 0.6574\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2186 - output_1_loss: 0.2181 - val_loss: 0.1979 - val_output_1_loss: 0.1970\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6899 - output_1_loss: 0.6894Epoch 56/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6899 - output_1_loss: 0.6894 - val_loss: 0.6554 - val_output_1_loss: 0.6541\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2237 - output_1_loss: 0.2232 - val_loss: 0.1892 - val_output_1_loss: 0.1883\n",
      "Epoch 57/100\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1879 - output_1_loss: 0.1874 - val_loss: 0.1800 - val_output_1_loss: 0.1791\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6820 - output_1_loss: 0.6815Epoch 58/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.6820 - output_1_loss: 0.6815 - val_loss: 0.6508 - val_output_1_loss: 0.6495\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3263 - output_1_loss: 0.3258 - val_loss: 0.1791 - val_output_1_loss: 0.1783\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.6690 - output_1_loss: 0.6685 - val_loss: 0.6504 - val_output_1_loss: 0.6491\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2345 - output_1_loss: 0.2340 - val_loss: 0.1738 - val_output_1_loss: 0.1730\n",
      "Epoch 60/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0978 - output_1_loss: 0.0973 - val_loss: 0.1713 - val_output_1_loss: 0.1706\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.6915 - output_1_loss: 0.6911 - val_loss: 0.6479 - val_output_1_loss: 0.6466\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1885 - output_1_loss: 0.1880Epoch 22/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1885 - output_1_loss: 0.1880 - val_loss: 0.1653 - val_output_1_loss: 0.1646\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6674 - output_1_loss: 0.6669Epoch 62/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.6674 - output_1_loss: 0.6669 - val_loss: 0.6475 - val_output_1_loss: 0.6463\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1833 - output_1_loss: 0.1827 - val_loss: 0.1651 - val_output_1_loss: 0.1643\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6974 - output_1_loss: 0.6969Epoch 63/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6974 - output_1_loss: 0.6969 - val_loss: 0.6449 - val_output_1_loss: 0.6437\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1597 - output_1_loss: 0.1593 - val_loss: 0.1590 - val_output_1_loss: 0.1583\n",
      "Epoch 64/100\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1704 - output_1_loss: 0.1699 - val_loss: 0.1565 - val_output_1_loss: 0.1557\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.6398 - output_1_loss: 0.6393 - val_loss: 0.6386 - val_output_1_loss: 0.6374\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.2066 - output_1_loss: 0.2061 - val_loss: 0.1569 - val_output_1_loss: 0.1562\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1119 - output_1_loss: 0.1114 - val_loss: 0.1594 - val_output_1_loss: 0.1587\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5878 - output_1_loss: 0.5873 - val_loss: 0.6337 - val_output_1_loss: 0.6325\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1970 - output_1_loss: 0.1964 - val_loss: 0.1588 - val_output_1_loss: 0.1581\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1509 - output_1_loss: 0.1503 - val_loss: 0.1450 - val_output_1_loss: 0.1443\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.6101 - output_1_loss: 0.6096 - val_loss: 0.6321 - val_output_1_loss: 0.6310\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1972 - output_1_loss: 0.1967 - val_loss: 0.1457 - val_output_1_loss: 0.1449\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6041 - output_1_loss: 0.6036Epoch 70/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.6041 - output_1_loss: 0.6036 - val_loss: 0.6281 - val_output_1_loss: 0.6269\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1303 - output_1_loss: 0.1297 - val_loss: 0.1417 - val_output_1_loss: 0.1409\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1869 - output_1_loss: 0.1863 - val_loss: 0.1403 - val_output_1_loss: 0.1394\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.6280 - output_1_loss: 0.6275 - val_loss: 0.6264 - val_output_1_loss: 0.6252\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6088 - output_1_loss: 0.6083Epoch 72/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6088 - output_1_loss: 0.6083 - val_loss: 0.6244 - val_output_1_loss: 0.6233\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1109 - output_1_loss: 0.1104 - val_loss: 0.1333 - val_output_1_loss: 0.1324\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6260 - output_1_loss: 0.6255Epoch 73/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6260 - output_1_loss: 0.6255 - val_loss: 0.6235 - val_output_1_loss: 0.6224\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1064 - output_1_loss: 0.1058 - val_loss: 0.1249 - val_output_1_loss: 0.1240\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.5813 - output_1_loss: 0.5808 - val_loss: 0.6213 - val_output_1_loss: 0.6202\n",
      "Epoch 32/100\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1779 - output_1_loss: 0.1773 - val_loss: 0.1159 - val_output_1_loss: 0.1150\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5464 - output_1_loss: 0.5459 - val_loss: 0.6171 - val_output_1_loss: 0.6161\n",
      "Epoch 33/100\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5853 - output_1_loss: 0.5848 - val_loss: 0.6133 - val_output_1_loss: 0.6123\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1150 - output_1_loss: 0.1144 - val_loss: 0.1177 - val_output_1_loss: 0.1168\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0842 - output_1_loss: 0.0837Epoch 34/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0842 - output_1_loss: 0.0837 - val_loss: 0.1011 - val_output_1_loss: 0.1002\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6057 - output_1_loss: 0.6052Epoch 77/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.6057 - output_1_loss: 0.6052 - val_loss: 0.6105 - val_output_1_loss: 0.6095\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1118 - output_1_loss: 0.1112 - val_loss: 0.0977 - val_output_1_loss: 0.0969\n",
      "Epoch 78/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1418 - output_1_loss: 0.1413 - val_loss: 0.0985 - val_output_1_loss: 0.0976\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.6013 - output_1_loss: 0.6008 - val_loss: 0.6104 - val_output_1_loss: 0.6094\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0991 - output_1_loss: 0.0986 - val_loss: 0.0946 - val_output_1_loss: 0.0937\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3184 - output_1_loss: 0.3179 - val_loss: 0.1109 - val_output_1_loss: 0.1100\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.5472 - output_1_loss: 0.5467 - val_loss: 0.6027 - val_output_1_loss: 0.6017\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1141 - output_1_loss: 0.1135 - val_loss: 0.0962 - val_output_1_loss: 0.0953\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1300 - output_1_loss: 0.1294 - val_loss: 0.1028 - val_output_1_loss: 0.1019\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5871 - output_1_loss: 0.5866Epoch 83/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2591 - output_1_loss: 0.2585 - val_loss: 0.1021 - val_output_1_loss: 0.1012\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.5871 - output_1_loss: 0.5866 - val_loss: 0.5972 - val_output_1_loss: 0.5962\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2109 - output_1_loss: 0.2103 - val_loss: 0.0920 - val_output_1_loss: 0.0911\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5858 - output_1_loss: 0.5853 - val_loss: 0.5961 - val_output_1_loss: 0.5951\n",
      "Epoch 39/100\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5291 - output_1_loss: 0.5286 - val_loss: 0.5939 - val_output_1_loss: 0.5929\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1167 - output_1_loss: 0.1161 - val_loss: 0.0897 - val_output_1_loss: 0.0888\n",
      "Epoch 86/100\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1178 - output_1_loss: 0.1173 - val_loss: 0.0896 - val_output_1_loss: 0.0887\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.4997 - output_1_loss: 0.4992 - val_loss: 0.5875 - val_output_1_loss: 0.5865\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1651 - output_1_loss: 0.1646 - val_loss: 0.0858 - val_output_1_loss: 0.0850\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1160 - output_1_loss: 0.1155 - val_loss: 0.0883 - val_output_1_loss: 0.0875\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.5589 - output_1_loss: 0.5585 - val_loss: 0.5836 - val_output_1_loss: 0.5826\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1224 - output_1_loss: 0.1219 - val_loss: 0.0840 - val_output_1_loss: 0.0832\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.5262 - output_1_loss: 0.5257 - val_loss: 0.5763 - val_output_1_loss: 0.5753\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.1345 - output_1_loss: 0.1340 - val_loss: 0.0860 - val_output_1_loss: 0.0852\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1767 - output_1_loss: 0.1762 - val_loss: 0.0876 - val_output_1_loss: 0.0868\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1268 - output_1_loss: 0.1263 - val_loss: 0.0869 - val_output_1_loss: 0.0861\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.5176 - output_1_loss: 0.5171 - val_loss: 0.5728 - val_output_1_loss: 0.5718\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1200 - output_1_loss: 0.1194 - val_loss: 0.1153 - val_output_1_loss: 0.1147\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1266 - output_1_loss: 0.1262 - val_loss: 0.1182 - val_output_1_loss: 0.1176\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.5068 - output_1_loss: 0.5063 - val_loss: 0.5636 - val_output_1_loss: 0.5627\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5533 - output_1_loss: 0.5529 - val_loss: 0.5556 - val_output_1_loss: 0.5547\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.4683 - output_1_loss: 0.4679 - val_loss: 0.5479 - val_output_1_loss: 0.5470\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5058 - output_1_loss: 0.5053 - val_loss: 0.5398 - val_output_1_loss: 0.5389\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4940 - output_1_loss: 0.4936 - val_loss: 0.5290 - val_output_1_loss: 0.5282\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4987 - output_1_loss: 0.4983 - val_loss: 0.5268 - val_output_1_loss: 0.5260\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4873 - output_1_loss: 0.4868 - val_loss: 0.5338 - val_output_1_loss: 0.5330\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:06:07,427]\u001b[0m Trial 21 finished with value: 0.043478260869565216 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 4, 'relaxation_factor': 3.0, 'sparsity_coefficient': 0.0008897387443439486, 'bn_momentum': 0.9407586161338476}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 442ms/step - loss: 0.4201 - output_1_loss: 0.4196 - val_loss: 0.5351 - val_output_1_loss: 0.5343\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4651 - output_1_loss: 0.4646 - val_loss: 0.5420 - val_output_1_loss: 0.5412\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4772 - output_1_loss: 0.4767 - val_loss: 0.5414 - val_output_1_loss: 0.5407\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.4520 - output_1_loss: 0.4516 - val_loss: 0.5335 - val_output_1_loss: 0.5328\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:06:12,932]\u001b[0m Trial 22 finished with value: 0.07692307692307693 and parameters: {'feature_dim': 32, 'n_step': 6, 'n_shared': 0, 'relaxation_factor': 2.2, 'sparsity_coefficient': 0.000463665967757629, 'bn_momentum': 0.9374389322891754}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.8617 - output_1_loss: 0.8617 - val_loss: 0.6823 - val_output_1_loss: 0.6820\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.7184 - output_1_loss: 0.7184 - val_loss: 0.6732 - val_output_1_loss: 0.6730\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6051 - output_1_loss: 0.6051 - val_loss: 0.6622 - val_output_1_loss: 0.6620\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3558 - output_1_loss: 0.3557 - val_loss: 0.6459 - val_output_1_loss: 0.6457\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2245 - output_1_loss: 0.2245 - val_loss: 0.6154 - val_output_1_loss: 0.6152\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.1349 - output_1_loss: 0.1348 - val_loss: 0.5791 - val_output_1_loss: 0.5790\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.1009 - output_1_loss: 0.1008 - val_loss: 0.5305 - val_output_1_loss: 0.5304\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0997 - output_1_loss: 0.0996 - val_loss: 0.4634 - val_output_1_loss: 0.4632\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0927 - output_1_loss: 0.0926 - val_loss: 0.3988 - val_output_1_loss: 0.3987\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0933 - output_1_loss: 0.0932 - val_loss: 0.3340 - val_output_1_loss: 0.3339\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1027 - output_1_loss: 0.1027 - val_loss: 0.2917 - val_output_1_loss: 0.2915\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1099 - output_1_loss: 0.1099 - val_loss: 0.2646 - val_output_1_loss: 0.2645\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0839 - output_1_loss: 0.0838 - val_loss: 0.2286 - val_output_1_loss: 0.2285\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.9011 - output_1_loss: 0.9010 - val_loss: 0.6938 - val_output_1_loss: 0.6936\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0747 - output_1_loss: 0.0747 - val_loss: 0.2069 - val_output_1_loss: 0.2068\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0693 - output_1_loss: 0.0693 - val_loss: 0.1878 - val_output_1_loss: 0.1876\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0625 - output_1_loss: 0.0624 - val_loss: 0.1740 - val_output_1_loss: 0.1738\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0578 - output_1_loss: 0.0578 - val_loss: 0.1653 - val_output_1_loss: 0.1651\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0580 - output_1_loss: 0.0580 - val_loss: 0.1536 - val_output_1_loss: 0.1535\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0542 - output_1_loss: 0.0541 - val_loss: 0.1457 - val_output_1_loss: 0.1456\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0513 - output_1_loss: 0.0512 - val_loss: 0.1429 - val_output_1_loss: 0.1428\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0495 - output_1_loss: 0.0495 - val_loss: 0.1421 - val_output_1_loss: 0.1420\n",
      "Epoch 22/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0692 - output_1_loss: 0.0691 - val_loss: 0.1432 - val_output_1_loss: 0.1431\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0521 - output_1_loss: 0.0520 - val_loss: 0.1451 - val_output_1_loss: 0.1450\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0523 - output_1_loss: 0.0522 - val_loss: 0.1462 - val_output_1_loss: 0.1461\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.9381 - output_1_loss: 0.9380 - val_loss: 0.6912 - val_output_1_loss: 0.6909\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0479 - output_1_loss: 0.0478 - val_loss: 0.1418 - val_output_1_loss: 0.1417\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.8712 - output_1_loss: 0.8711 - val_loss: 0.6880 - val_output_1_loss: 0.6878\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0613 - output_1_loss: 0.0613Epoch 4/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0613 - output_1_loss: 0.0613 - val_loss: 0.1391 - val_output_1_loss: 0.1389\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0539 - output_1_loss: 0.0539 - val_loss: 0.1434 - val_output_1_loss: 0.1433\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0484 - output_1_loss: 0.0484 - val_loss: 0.1479 - val_output_1_loss: 0.1478\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.8756 - output_1_loss: 0.8755 - val_loss: 0.6870 - val_output_1_loss: 0.6868\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0549 - output_1_loss: 0.0549 - val_loss: 0.1512 - val_output_1_loss: 0.1511\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8341 - output_1_loss: 0.8340 - val_loss: 0.6801 - val_output_1_loss: 0.6799\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0511 - output_1_loss: 0.0511Epoch 6/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0511 - output_1_loss: 0.0511 - val_loss: 0.1511 - val_output_1_loss: 0.1510\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0426 - output_1_loss: 0.0426 - val_loss: 0.1452 - val_output_1_loss: 0.1450\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.8260 - output_1_loss: 0.8259 - val_loss: 0.6787 - val_output_1_loss: 0.6785\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.7973 - output_1_loss: 0.7972 - val_loss: 0.6766 - val_output_1_loss: 0.6764\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.7895 - output_1_loss: 0.7895 - val_loss: 0.6726 - val_output_1_loss: 0.6724\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.7758 - output_1_loss: 0.7758 - val_loss: 0.6714 - val_output_1_loss: 0.6712\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.7449 - output_1_loss: 0.7448 - val_loss: 0.6657 - val_output_1_loss: 0.6655\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:06:48,038]\u001b[0m Trial 24 finished with value: 0.06666666666666667 and parameters: {'feature_dim': 512, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 2.6, 'sparsity_coefficient': 4.130547677311622e-05, 'bn_momentum': 0.9190223934912535}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.7284 - output_1_loss: 0.7283 - val_loss: 0.6624 - val_output_1_loss: 0.6623\n",
      "Epoch 12/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.7128 - output_1_loss: 0.7127 - val_loss: 0.6618 - val_output_1_loss: 0.6616\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.7198 - output_1_loss: 0.7197 - val_loss: 0.6597 - val_output_1_loss: 0.6595\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.6545 - output_1_loss: 0.6544 - val_loss: 0.6586 - val_output_1_loss: 0.6585\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.6712 - output_1_loss: 0.6711 - val_loss: 0.6560 - val_output_1_loss: 0.6558\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.6703 - output_1_loss: 0.6703 - val_loss: 0.6542 - val_output_1_loss: 0.6540\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.6606 - output_1_loss: 0.6606 - val_loss: 0.6504 - val_output_1_loss: 0.6502\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.6422 - output_1_loss: 0.6421 - val_loss: 0.6484 - val_output_1_loss: 0.6482\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6964 - output_1_loss: 0.6963 - val_loss: 0.6465 - val_output_1_loss: 0.6463\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6484 - output_1_loss: 0.6483 - val_loss: 0.6428 - val_output_1_loss: 0.6427\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.6434 - output_1_loss: 0.6433 - val_loss: 0.6425 - val_output_1_loss: 0.6423\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.6164 - output_1_loss: 0.6164 - val_loss: 0.6372 - val_output_1_loss: 0.6370\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.6487 - output_1_loss: 0.6486 - val_loss: 0.6312 - val_output_1_loss: 0.6310\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.5883 - output_1_loss: 0.5882 - val_loss: 0.6252 - val_output_1_loss: 0.6250\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.5675 - output_1_loss: 0.5675 - val_loss: 0.6160 - val_output_1_loss: 0.6159\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.5842 - output_1_loss: 0.5842 - val_loss: 0.6143 - val_output_1_loss: 0.6141\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5624 - output_1_loss: 0.5624 - val_loss: 0.6170 - val_output_1_loss: 0.6168\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.5531 - output_1_loss: 0.5530 - val_loss: 0.6148 - val_output_1_loss: 0.6146\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.5630 - output_1_loss: 0.5629 - val_loss: 0.6115 - val_output_1_loss: 0.6113\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.5467 - output_1_loss: 0.5466 - val_loss: 0.6097 - val_output_1_loss: 0.6096\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.5286 - output_1_loss: 0.5286 - val_loss: 0.6017 - val_output_1_loss: 0.6016\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.5159 - output_1_loss: 0.5158 - val_loss: 0.5937 - val_output_1_loss: 0.5936\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.5212 - output_1_loss: 0.5211 - val_loss: 0.5886 - val_output_1_loss: 0.5885\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.5127 - output_1_loss: 0.5126 - val_loss: 0.5778 - val_output_1_loss: 0.5777\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.4763 - output_1_loss: 0.4762 - val_loss: 0.5706 - val_output_1_loss: 0.5705\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.5496 - output_1_loss: 0.5495 - val_loss: 0.5686 - val_output_1_loss: 0.5684\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.4826 - output_1_loss: 0.4825 - val_loss: 0.5601 - val_output_1_loss: 0.5600\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.5045 - output_1_loss: 0.5044 - val_loss: 0.5479 - val_output_1_loss: 0.5478\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.4824 - output_1_loss: 0.4823 - val_loss: 0.5395 - val_output_1_loss: 0.5394\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4314 - output_1_loss: 0.4313 - val_loss: 0.5282 - val_output_1_loss: 0.5281\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.4634 - output_1_loss: 0.4633 - val_loss: 0.5183 - val_output_1_loss: 0.5182\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.4753 - output_1_loss: 0.4753 - val_loss: 0.5097 - val_output_1_loss: 0.5096\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.5023 - output_1_loss: 0.5023 - val_loss: 0.4834 - val_output_1_loss: 0.4833\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4138 - output_1_loss: 0.4137 - val_loss: 0.4844 - val_output_1_loss: 0.4843\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4517 - output_1_loss: 0.4516 - val_loss: 0.4945 - val_output_1_loss: 0.4944\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.3927 - output_1_loss: 0.3926 - val_loss: 0.4831 - val_output_1_loss: 0.4830\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.4384 - output_1_loss: 0.4383 - val_loss: 0.4735 - val_output_1_loss: 0.4734\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.4422 - output_1_loss: 0.4422 - val_loss: 0.4723 - val_output_1_loss: 0.4722\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.4177 - output_1_loss: 0.4177 - val_loss: 0.4847 - val_output_1_loss: 0.4846\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.4291 - output_1_loss: 0.4291 - val_loss: 0.4671 - val_output_1_loss: 0.4670\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.3925 - output_1_loss: 0.3924 - val_loss: 0.4597 - val_output_1_loss: 0.4596\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.4738 - output_1_loss: 0.4737 - val_loss: 0.4443 - val_output_1_loss: 0.4442\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.4343 - output_1_loss: 0.4342 - val_loss: 0.4433 - val_output_1_loss: 0.4432\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4325 - output_1_loss: 0.4324 - val_loss: 0.4440 - val_output_1_loss: 0.4439\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3099 - output_1_loss: 0.3099 - val_loss: 0.4457 - val_output_1_loss: 0.4456\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.3911 - output_1_loss: 0.3911 - val_loss: 0.4401 - val_output_1_loss: 0.4400\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.3417 - output_1_loss: 0.3416 - val_loss: 0.4155 - val_output_1_loss: 0.4154\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3534 - output_1_loss: 0.3534 - val_loss: 0.4190 - val_output_1_loss: 0.4189\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.3460 - output_1_loss: 0.3459 - val_loss: 0.3956 - val_output_1_loss: 0.3955\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.3039 - output_1_loss: 0.3038 - val_loss: 0.3790 - val_output_1_loss: 0.3789\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.3978 - output_1_loss: 0.3978 - val_loss: 0.3766 - val_output_1_loss: 0.3765\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2998 - output_1_loss: 0.2998 - val_loss: 0.3782 - val_output_1_loss: 0.3782\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.2723 - output_1_loss: 0.2722 - val_loss: 0.3618 - val_output_1_loss: 0.3617\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.3829 - output_1_loss: 0.3829 - val_loss: 0.3475 - val_output_1_loss: 0.3474\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3434 - output_1_loss: 0.3433 - val_loss: 0.3439 - val_output_1_loss: 0.3438\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3672 - output_1_loss: 0.3671 - val_loss: 0.3529 - val_output_1_loss: 0.3528\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3553 - output_1_loss: 0.3552 - val_loss: 0.3593 - val_output_1_loss: 0.3593\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2958 - output_1_loss: 0.2957 - val_loss: 0.3488 - val_output_1_loss: 0.3487\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.3103 - output_1_loss: 0.3103 - val_loss: 0.3347 - val_output_1_loss: 0.3346\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.2919 - output_1_loss: 0.2919 - val_loss: 0.3252 - val_output_1_loss: 0.3251\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.3251 - output_1_loss: 0.3250 - val_loss: 0.3047 - val_output_1_loss: 0.3046\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2287 - output_1_loss: 0.2287 - val_loss: 0.2976 - val_output_1_loss: 0.2975\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.2875 - output_1_loss: 0.2874 - val_loss: 0.2926 - val_output_1_loss: 0.2925\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.2655 - output_1_loss: 0.2654 - val_loss: 0.2902 - val_output_1_loss: 0.2901\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2896 - output_1_loss: 0.2896 - val_loss: 0.2758 - val_output_1_loss: 0.2757\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3040 - output_1_loss: 0.3040 - val_loss: 0.2839 - val_output_1_loss: 0.2838\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2623 - output_1_loss: 0.2623 - val_loss: 0.2585 - val_output_1_loss: 0.2585\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2375 - output_1_loss: 0.2374 - val_loss: 0.2527 - val_output_1_loss: 0.2526\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2183 - output_1_loss: 0.2182 - val_loss: 0.2559 - val_output_1_loss: 0.2559\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2066 - output_1_loss: 0.2066 - val_loss: 0.2456 - val_output_1_loss: 0.2455\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2224 - output_1_loss: 0.2223 - val_loss: 0.2521 - val_output_1_loss: 0.2521\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2004 - output_1_loss: 0.2004 - val_loss: 0.2835 - val_output_1_loss: 0.2835\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.2484 - output_1_loss: 0.2483 - val_loss: 0.2834 - val_output_1_loss: 0.2834\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2595 - output_1_loss: 0.2595 - val_loss: 0.2237 - val_output_1_loss: 0.2236\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2116 - output_1_loss: 0.2115 - val_loss: 0.2170 - val_output_1_loss: 0.2170\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2432 - output_1_loss: 0.2432 - val_loss: 0.2149 - val_output_1_loss: 0.2148\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2062 - output_1_loss: 0.2061 - val_loss: 0.2076 - val_output_1_loss: 0.2075\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.2002 - output_1_loss: 0.2002 - val_loss: 0.1862 - val_output_1_loss: 0.1861\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.2368 - output_1_loss: 0.2367 - val_loss: 0.1811 - val_output_1_loss: 0.1811\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3052 - output_1_loss: 0.3051 - val_loss: 0.1686 - val_output_1_loss: 0.1685\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.3044 - output_1_loss: 0.3044 - val_loss: 0.1954 - val_output_1_loss: 0.1953\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1863 - output_1_loss: 0.1862 - val_loss: 0.1993 - val_output_1_loss: 0.1992\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1950 - output_1_loss: 0.1949 - val_loss: 0.1895 - val_output_1_loss: 0.1894\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2156 - output_1_loss: 0.2155 - val_loss: 0.1942 - val_output_1_loss: 0.1941\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1801 - output_1_loss: 0.1800 - val_loss: 0.1852 - val_output_1_loss: 0.1851\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:07:22,547]\u001b[0m Trial 23 finished with value: 0.25 and parameters: {'feature_dim': 32, 'n_step': 6, 'n_shared': 0, 'relaxation_factor': 2.1, 'sparsity_coefficient': 5.9463880860714254e-05, 'bn_momentum': 0.9157997310757688}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 40s 40s/step - loss: 0.8680 - output_1_loss: 0.8680 - val_loss: 0.6867 - val_output_1_loss: 0.6867\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.7211 - output_1_loss: 0.7211 - val_loss: 0.6825 - val_output_1_loss: 0.6825\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.7033 - output_1_loss: 0.7033 - val_loss: 0.6777 - val_output_1_loss: 0.6777\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.6846 - output_1_loss: 0.6846 - val_loss: 0.6720 - val_output_1_loss: 0.6720\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.6733 - output_1_loss: 0.6733 - val_loss: 0.6663 - val_output_1_loss: 0.6663\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.6694 - output_1_loss: 0.6694 - val_loss: 0.6623 - val_output_1_loss: 0.6623\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6642 - output_1_loss: 0.6642 - val_loss: 0.6565 - val_output_1_loss: 0.6565\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 0.6061 - output_1_loss: 0.6061 - val_loss: 0.6512 - val_output_1_loss: 0.6512\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.5943 - output_1_loss: 0.5943 - val_loss: 0.6446 - val_output_1_loss: 0.6446\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5880 - output_1_loss: 0.5880 - val_loss: 0.6395 - val_output_1_loss: 0.6395\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5668 - output_1_loss: 0.5668 - val_loss: 0.6349 - val_output_1_loss: 0.6349\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.5469 - output_1_loss: 0.5469 - val_loss: 0.6275 - val_output_1_loss: 0.6275\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5085 - output_1_loss: 0.5085 - val_loss: 0.6200 - val_output_1_loss: 0.6200\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.4932 - output_1_loss: 0.4932 - val_loss: 0.6133 - val_output_1_loss: 0.6133\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.5906 - output_1_loss: 0.5906 - val_loss: 0.6093 - val_output_1_loss: 0.6093\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.4661 - output_1_loss: 0.4661 - val_loss: 0.6030 - val_output_1_loss: 0.6030\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.3562 - output_1_loss: 0.3562 - val_loss: 0.5954 - val_output_1_loss: 0.5954\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 0.4288 - output_1_loss: 0.4288 - val_loss: 0.5878 - val_output_1_loss: 0.5878\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.4165 - output_1_loss: 0.4165 - val_loss: 0.5798 - val_output_1_loss: 0.5798\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.4588 - output_1_loss: 0.4588 - val_loss: 0.5764 - val_output_1_loss: 0.5763\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.4259 - output_1_loss: 0.4259 - val_loss: 0.5702 - val_output_1_loss: 0.5702\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.4180 - output_1_loss: 0.4180 - val_loss: 0.5629 - val_output_1_loss: 0.5629\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.3747 - output_1_loss: 0.3747 - val_loss: 0.5561 - val_output_1_loss: 0.5561\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.3997 - output_1_loss: 0.3997 - val_loss: 0.5475 - val_output_1_loss: 0.5475\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.3580 - output_1_loss: 0.3580 - val_loss: 0.5425 - val_output_1_loss: 0.5425\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 0.3976 - output_1_loss: 0.3976 - val_loss: 0.5362 - val_output_1_loss: 0.5362\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.4160 - output_1_loss: 0.4160 - val_loss: 0.5291 - val_output_1_loss: 0.5291\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3874 - output_1_loss: 0.3874 - val_loss: 0.5211 - val_output_1_loss: 0.5211\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 0.3726 - output_1_loss: 0.3726 - val_loss: 0.5146 - val_output_1_loss: 0.5146\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.2815 - output_1_loss: 0.2815 - val_loss: 0.5072 - val_output_1_loss: 0.5072\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.4166 - output_1_loss: 0.4166 - val_loss: 0.4994 - val_output_1_loss: 0.4994\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.2558 - output_1_loss: 0.2558 - val_loss: 0.4931 - val_output_1_loss: 0.4931\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.3713 - output_1_loss: 0.3713 - val_loss: 0.4848 - val_output_1_loss: 0.4848\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.3307 - output_1_loss: 0.3307 - val_loss: 0.4778 - val_output_1_loss: 0.4778\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.2801 - output_1_loss: 0.2801 - val_loss: 0.4706 - val_output_1_loss: 0.4706\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.2606 - output_1_loss: 0.2606 - val_loss: 0.4634 - val_output_1_loss: 0.4634\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.2541 - output_1_loss: 0.2541 - val_loss: 0.4558 - val_output_1_loss: 0.4558\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2493 - output_1_loss: 0.2493 - val_loss: 0.4515 - val_output_1_loss: 0.4515\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2658 - output_1_loss: 0.2658 - val_loss: 0.4430 - val_output_1_loss: 0.4430\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2290 - output_1_loss: 0.2290 - val_loss: 0.4363 - val_output_1_loss: 0.4363\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2645 - output_1_loss: 0.2645 - val_loss: 0.4295 - val_output_1_loss: 0.4295\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3506 - output_1_loss: 0.3506 - val_loss: 0.4238 - val_output_1_loss: 0.4238\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.2799 - output_1_loss: 0.2799 - val_loss: 0.4162 - val_output_1_loss: 0.4162\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1923 - output_1_loss: 0.1923 - val_loss: 0.4070 - val_output_1_loss: 0.4070\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2305 - output_1_loss: 0.2305 - val_loss: 0.4040 - val_output_1_loss: 0.4040\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2023 - output_1_loss: 0.2023 - val_loss: 0.3963 - val_output_1_loss: 0.3963\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2249 - output_1_loss: 0.2249 - val_loss: 0.3861 - val_output_1_loss: 0.3861\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.2237 - output_1_loss: 0.2237 - val_loss: 0.3709 - val_output_1_loss: 0.3709\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2371 - output_1_loss: 0.2371 - val_loss: 0.3687 - val_output_1_loss: 0.3687\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1476 - output_1_loss: 0.1476 - val_loss: 0.3682 - val_output_1_loss: 0.3681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1924 - output_1_loss: 0.1924 - val_loss: 0.3622 - val_output_1_loss: 0.3622\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1491 - output_1_loss: 0.1491 - val_loss: 0.3553 - val_output_1_loss: 0.3553\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1439 - output_1_loss: 0.1439 - val_loss: 0.3483 - val_output_1_loss: 0.3483\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2127 - output_1_loss: 0.2127 - val_loss: 0.3427 - val_output_1_loss: 0.3427\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2031 - output_1_loss: 0.2031 - val_loss: 0.3387 - val_output_1_loss: 0.3387\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1638 - output_1_loss: 0.1638 - val_loss: 0.3316 - val_output_1_loss: 0.3316\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1549 - output_1_loss: 0.1549 - val_loss: 0.3246 - val_output_1_loss: 0.3246\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1133 - output_1_loss: 0.1133 - val_loss: 0.3154 - val_output_1_loss: 0.3154\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7528 - output_1_loss: 0.7528Epoch 59/100\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.1810 - output_1_loss: 0.1810 - val_loss: 0.3101 - val_output_1_loss: 0.3101\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1840 - output_1_loss: 0.1840 - val_loss: 0.3034 - val_output_1_loss: 0.3034\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.1325 - output_1_loss: 0.1325 - val_loss: 0.2992 - val_output_1_loss: 0.2992\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1455 - output_1_loss: 0.1455 - val_loss: 0.2932 - val_output_1_loss: 0.2932\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.2143 - output_1_loss: 0.2143 - val_loss: 0.2891 - val_output_1_loss: 0.2891\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.7528 - output_1_loss: 0.7528 - val_loss: 0.6882 - val_output_1_loss: 0.6882\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.1286 - output_1_loss: 0.1286 - val_loss: 0.2814 - val_output_1_loss: 0.2814\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.7311 - output_1_loss: 0.7311 - val_loss: 0.6828 - val_output_1_loss: 0.6828\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1419 - output_1_loss: 0.1419 - val_loss: 0.2754 - val_output_1_loss: 0.2753\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1672 - output_1_loss: 0.1672Epoch 3/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1672 - output_1_loss: 0.1672 - val_loss: 0.2678 - val_output_1_loss: 0.2678\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.7087 - output_1_loss: 0.7087 - val_loss: 0.6768 - val_output_1_loss: 0.6768\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1684 - output_1_loss: 0.1684 - val_loss: 0.2624 - val_output_1_loss: 0.2624\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.6856 - output_1_loss: 0.6856 - val_loss: 0.6721 - val_output_1_loss: 0.6721\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1330 - output_1_loss: 0.1330 - val_loss: 0.2547 - val_output_1_loss: 0.2547\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0979 - output_1_loss: 0.0979Epoch 5/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0979 - output_1_loss: 0.0979 - val_loss: 0.2506 - val_output_1_loss: 0.2506\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6668 - output_1_loss: 0.6668Epoch 70/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6668 - output_1_loss: 0.6668 - val_loss: 0.6662 - val_output_1_loss: 0.6662\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1568 - output_1_loss: 0.1568Epoch 6/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.1568 - output_1_loss: 0.1568 - val_loss: 0.2499 - val_output_1_loss: 0.2498\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.6569 - output_1_loss: 0.6569 - val_loss: 0.6601 - val_output_1_loss: 0.6601\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1691 - output_1_loss: 0.1691 - val_loss: 0.2441 - val_output_1_loss: 0.2441\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1268 - output_1_loss: 0.1268 - val_loss: 0.2400 - val_output_1_loss: 0.2400\n",
      "Epoch 73/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.6345 - output_1_loss: 0.6345 - val_loss: 0.6541 - val_output_1_loss: 0.6541\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.1001 - output_1_loss: 0.1001 - val_loss: 0.2341 - val_output_1_loss: 0.2341\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.5831 - output_1_loss: 0.5831 - val_loss: 0.6492 - val_output_1_loss: 0.6492\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.2030 - output_1_loss: 0.2030 - val_loss: 0.2311 - val_output_1_loss: 0.2311\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0995 - output_1_loss: 0.0995 - val_loss: 0.2215 - val_output_1_loss: 0.2215\n",
      "Epoch 9/100\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.5537 - output_1_loss: 0.5537 - val_loss: 0.6414 - val_output_1_loss: 0.6414\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.1035 - output_1_loss: 0.1035 - val_loss: 0.2178 - val_output_1_loss: 0.2178\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.5150 - output_1_loss: 0.5150 - val_loss: 0.6347 - val_output_1_loss: 0.6347\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.1042 - output_1_loss: 0.1042 - val_loss: 0.2165 - val_output_1_loss: 0.2165\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5469 - output_1_loss: 0.5469 - val_loss: 0.6303 - val_output_1_loss: 0.6303\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4491 - output_1_loss: 0.4491Epoch 78/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4491 - output_1_loss: 0.4491 - val_loss: 0.6212 - val_output_1_loss: 0.6212\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1036 - output_1_loss: 0.1036Epoch 13/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.1036 - output_1_loss: 0.1036 - val_loss: 0.2095 - val_output_1_loss: 0.2095\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.4983 - output_1_loss: 0.4983 - val_loss: 0.6146 - val_output_1_loss: 0.6146\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1014 - output_1_loss: 0.1014 - val_loss: 0.2057 - val_output_1_loss: 0.2057\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1395 - output_1_loss: 0.1395 - val_loss: 0.2032 - val_output_1_loss: 0.2032\n",
      "Epoch 81/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1330 - output_1_loss: 0.1330 - val_loss: 0.2030 - val_output_1_loss: 0.2030\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4799 - output_1_loss: 0.4799 - val_loss: 0.6099 - val_output_1_loss: 0.6099\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0897 - output_1_loss: 0.0897 - val_loss: 0.1924 - val_output_1_loss: 0.1924\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.4751 - output_1_loss: 0.4751 - val_loss: 0.6039 - val_output_1_loss: 0.6039\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5144 - output_1_loss: 0.5144 - val_loss: 0.6000 - val_output_1_loss: 0.6000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4109 - output_1_loss: 0.4109Epoch 83/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4109 - output_1_loss: 0.4109 - val_loss: 0.5943 - val_output_1_loss: 0.5943\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0903 - output_1_loss: 0.0903 - val_loss: 0.1884 - val_output_1_loss: 0.1884\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.3918 - output_1_loss: 0.3918 - val_loss: 0.5870 - val_output_1_loss: 0.5870\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0849 - output_1_loss: 0.0849 - val_loss: 0.1873 - val_output_1_loss: 0.1873\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4169 - output_1_loss: 0.4169 - val_loss: 0.5801 - val_output_1_loss: 0.5801\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0998 - output_1_loss: 0.0998 - val_loss: 0.1816 - val_output_1_loss: 0.1816\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4258 - output_1_loss: 0.4258 - val_loss: 0.5769 - val_output_1_loss: 0.5769\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4220 - output_1_loss: 0.4220Epoch 86/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.4220 - output_1_loss: 0.4220 - val_loss: 0.5684 - val_output_1_loss: 0.5684\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0969 - output_1_loss: 0.0969 - val_loss: 0.1789 - val_output_1_loss: 0.1789\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4175 - output_1_loss: 0.4175 - val_loss: 0.5622 - val_output_1_loss: 0.5622\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0945 - output_1_loss: 0.0945 - val_loss: 0.1781 - val_output_1_loss: 0.1781\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1022 - output_1_loss: 0.1022 - val_loss: 0.1757 - val_output_1_loss: 0.1757\n",
      "Epoch 89/100\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.4261 - output_1_loss: 0.4261 - val_loss: 0.5579 - val_output_1_loss: 0.5579\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.1105 - output_1_loss: 0.1105 - val_loss: 0.1693 - val_output_1_loss: 0.1693\n",
      "Epoch 90/100\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0981 - output_1_loss: 0.0981 - val_loss: 0.1688 - val_output_1_loss: 0.1688\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.3436 - output_1_loss: 0.3436 - val_loss: 0.5511 - val_output_1_loss: 0.5511\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1076 - output_1_loss: 0.1076 - val_loss: 0.1665 - val_output_1_loss: 0.1665\n",
      "Epoch 25/100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.4228 - output_1_loss: 0.4228 - val_loss: 0.5443 - val_output_1_loss: 0.5443\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0916 - output_1_loss: 0.0916 - val_loss: 0.1627 - val_output_1_loss: 0.1627\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3657 - output_1_loss: 0.3657 - val_loss: 0.5374 - val_output_1_loss: 0.5374\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3707 - output_1_loss: 0.3707Epoch 93/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3707 - output_1_loss: 0.3707 - val_loss: 0.5312 - val_output_1_loss: 0.5312\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.0873 - output_1_loss: 0.0873 - val_loss: 0.1586 - val_output_1_loss: 0.1586\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.2553 - output_1_loss: 0.2553 - val_loss: 0.5233 - val_output_1_loss: 0.5233\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1426 - output_1_loss: 0.1426 - val_loss: 0.1562 - val_output_1_loss: 0.1562\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.3960 - output_1_loss: 0.3960 - val_loss: 0.5163 - val_output_1_loss: 0.5163\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.1680 - output_1_loss: 0.1680 - val_loss: 0.1543 - val_output_1_loss: 0.1543\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.2362 - output_1_loss: 0.2362 - val_loss: 0.5108 - val_output_1_loss: 0.5108\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0883 - output_1_loss: 0.0883 - val_loss: 0.1538 - val_output_1_loss: 0.1538\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2598 - output_1_loss: 0.2598 - val_loss: 0.5075 - val_output_1_loss: 0.5075\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3486 - output_1_loss: 0.3486 - val_loss: 0.5011 - val_output_1_loss: 0.5011\n",
      "Epoch 33/100\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1043 - output_1_loss: 0.1043 - val_loss: 0.1547 - val_output_1_loss: 0.1547\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.3173 - output_1_loss: 0.3173 - val_loss: 0.4947 - val_output_1_loss: 0.4947\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1453 - output_1_loss: 0.1453 - val_loss: 0.1530 - val_output_1_loss: 0.1530\n",
      "Epoch 99/100\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.1375 - output_1_loss: 0.1375 - val_loss: 0.1518 - val_output_1_loss: 0.1518\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3908 - output_1_loss: 0.3908 - val_loss: 0.4884 - val_output_1_loss: 0.4884\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0909 - output_1_loss: 0.0909 - val_loss: 0.1518 - val_output_1_loss: 0.1518\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2657 - output_1_loss: 0.2657 - val_loss: 0.4822 - val_output_1_loss: 0.4822\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.2149 - output_1_loss: 0.2149 - val_loss: 0.4766 - val_output_1_loss: 0.4766\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.3117 - output_1_loss: 0.3117 - val_loss: 0.4702 - val_output_1_loss: 0.4702\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.2400 - output_1_loss: 0.2400 - val_loss: 0.4637 - val_output_1_loss: 0.4637\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.1343 - output_1_loss: 0.1342 - val_loss: 0.4554 - val_output_1_loss: 0.4554\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.1696 - output_1_loss: 0.1696 - val_loss: 0.4488 - val_output_1_loss: 0.4488\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.3343 - output_1_loss: 0.3343 - val_loss: 0.4405 - val_output_1_loss: 0.4405\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1965 - output_1_loss: 0.1965 - val_loss: 0.4336 - val_output_1_loss: 0.4336\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1254 - output_1_loss: 0.1254 - val_loss: 0.4263 - val_output_1_loss: 0.4263\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2133 - output_1_loss: 0.2133 - val_loss: 0.4210 - val_output_1_loss: 0.4210\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:08:15,397]\u001b[0m Trial 25 finished with value: 0.047619047619047616 and parameters: {'feature_dim': 128, 'n_step': 8, 'n_shared': 1, 'relaxation_factor': 2.2, 'sparsity_coefficient': 1.4929655140575546e-06, 'bn_momentum': 0.9881547661463858}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 555ms/step - loss: 0.1928 - output_1_loss: 0.1928 - val_loss: 0.4147 - val_output_1_loss: 0.4147\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.2278 - output_1_loss: 0.2278 - val_loss: 0.4085 - val_output_1_loss: 0.4085\n",
      "Epoch 47/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.1881 - output_1_loss: 0.1881 - val_loss: 0.4016 - val_output_1_loss: 0.4016\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.2248 - output_1_loss: 0.2248 - val_loss: 0.3960 - val_output_1_loss: 0.3960\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.2997 - output_1_loss: 0.2997 - val_loss: 0.3906 - val_output_1_loss: 0.3906\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.1587 - output_1_loss: 0.1587 - val_loss: 0.3840 - val_output_1_loss: 0.3840\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.2053 - output_1_loss: 0.2053 - val_loss: 0.3771 - val_output_1_loss: 0.3771\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.1811 - output_1_loss: 0.1811 - val_loss: 0.3713 - val_output_1_loss: 0.3713\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.1351 - output_1_loss: 0.1351 - val_loss: 0.3648 - val_output_1_loss: 0.3648\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.1646 - output_1_loss: 0.1646 - val_loss: 0.3597 - val_output_1_loss: 0.3597\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.1503 - output_1_loss: 0.1503 - val_loss: 0.3537 - val_output_1_loss: 0.3537\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.2365 - output_1_loss: 0.2365 - val_loss: 0.3487 - val_output_1_loss: 0.3487\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.1214 - output_1_loss: 0.1214 - val_loss: 0.3433 - val_output_1_loss: 0.3433\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.2030 - output_1_loss: 0.2030 - val_loss: 0.3418 - val_output_1_loss: 0.3418\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.1329 - output_1_loss: 0.1329 - val_loss: 0.3337 - val_output_1_loss: 0.3337\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.1779 - output_1_loss: 0.1779 - val_loss: 0.3269 - val_output_1_loss: 0.3269\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.2275 - output_1_loss: 0.2275 - val_loss: 0.3260 - val_output_1_loss: 0.3260\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.2209 - output_1_loss: 0.2209 - val_loss: 0.3189 - val_output_1_loss: 0.3189\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.1154 - output_1_loss: 0.1154 - val_loss: 0.3132 - val_output_1_loss: 0.3132\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1362 - output_1_loss: 0.1362 - val_loss: 0.3096 - val_output_1_loss: 0.3096\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1395 - output_1_loss: 0.1395 - val_loss: 0.3029 - val_output_1_loss: 0.3029\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1432 - output_1_loss: 0.1432 - val_loss: 0.2995 - val_output_1_loss: 0.2995\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1262 - output_1_loss: 0.1262 - val_loss: 0.2904 - val_output_1_loss: 0.2904\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1720 - output_1_loss: 0.1720 - val_loss: 0.2859 - val_output_1_loss: 0.2859\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0934 - output_1_loss: 0.0934 - val_loss: 0.2834 - val_output_1_loss: 0.2834\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1615 - output_1_loss: 0.1615 - val_loss: 0.2787 - val_output_1_loss: 0.2787\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.1727 - output_1_loss: 0.1727 - val_loss: 0.2753 - val_output_1_loss: 0.2753\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 0.1976 - output_1_loss: 0.1976 - val_loss: 0.2714 - val_output_1_loss: 0.2714\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.1316 - output_1_loss: 0.1316 - val_loss: 0.2683 - val_output_1_loss: 0.2683\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2653 - output_1_loss: 0.2653 - val_loss: 0.2649 - val_output_1_loss: 0.2649\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2018 - output_1_loss: 0.2018 - val_loss: 0.2593 - val_output_1_loss: 0.2592\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.8806 - output_1_loss: 0.8425 - val_loss: 0.7950 - val_output_1_loss: 0.6849\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0956 - output_1_loss: 0.0956Epoch 2/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0956 - output_1_loss: 0.0956 - val_loss: 0.2613 - val_output_1_loss: 0.2613\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7577 - output_1_loss: 0.7221 - val_loss: 0.7789 - val_output_1_loss: 0.6763\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7153 - output_1_loss: 0.6795 - val_loss: 0.7631 - val_output_1_loss: 0.6675\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1823 - output_1_loss: 0.1823 - val_loss: 0.2573 - val_output_1_loss: 0.2573\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6059 - output_1_loss: 0.5692 - val_loss: 0.7479 - val_output_1_loss: 0.6583\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0947 - output_1_loss: 0.0947Epoch 5/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0947 - output_1_loss: 0.0947 - val_loss: 0.2535 - val_output_1_loss: 0.2535\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5851 - output_1_loss: 0.5480 - val_loss: 0.7364 - val_output_1_loss: 0.6500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1355 - output_1_loss: 0.1355Epoch 6/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.1355 - output_1_loss: 0.1355 - val_loss: 0.2515 - val_output_1_loss: 0.2515\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4528 - output_1_loss: 0.4170 - val_loss: 0.7244 - val_output_1_loss: 0.6394\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.3727 - output_1_loss: 0.3389 - val_loss: 0.7114 - val_output_1_loss: 0.6281\n",
      "Epoch 80/100\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2464 - output_1_loss: 0.2119 - val_loss: 0.6955 - val_output_1_loss: 0.6144\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0909 - output_1_loss: 0.0909Epoch 9/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1769 - output_1_loss: 0.1458 - val_loss: 0.6771 - val_output_1_loss: 0.5981\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0909 - output_1_loss: 0.0909 - val_loss: 0.2442 - val_output_1_loss: 0.2442\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1198 - output_1_loss: 0.0936 - val_loss: 0.6525 - val_output_1_loss: 0.5760\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0998 - output_1_loss: 0.0757 - val_loss: 0.6239 - val_output_1_loss: 0.5502\n",
      "Epoch 81/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0917 - output_1_loss: 0.0687 - val_loss: 0.5915 - val_output_1_loss: 0.5206\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0862 - output_1_loss: 0.0648 - val_loss: 0.5589 - val_output_1_loss: 0.4905\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0917 - output_1_loss: 0.0917 - val_loss: 0.2372 - val_output_1_loss: 0.2372\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1202 - output_1_loss: 0.1202Epoch 14/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1202 - output_1_loss: 0.1202 - val_loss: 0.2354 - val_output_1_loss: 0.2354\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0845 - output_1_loss: 0.0643 - val_loss: 0.5272 - val_output_1_loss: 0.4606\n",
      "Epoch 15/100\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0819 - output_1_loss: 0.0628 - val_loss: 0.4964 - val_output_1_loss: 0.4313\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0824 - output_1_loss: 0.0642 - val_loss: 0.4672 - val_output_1_loss: 0.4034\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.1186 - output_1_loss: 0.1186 - val_loss: 0.2326 - val_output_1_loss: 0.2326\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0804 - output_1_loss: 0.0627 - val_loss: 0.4401 - val_output_1_loss: 0.3775\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0791 - output_1_loss: 0.0622 - val_loss: 0.4149 - val_output_1_loss: 0.3532\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0771 - output_1_loss: 0.0608Epoch 84/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0771 - output_1_loss: 0.0608 - val_loss: 0.3919 - val_output_1_loss: 0.3308\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1219 - output_1_loss: 0.1219 - val_loss: 0.2325 - val_output_1_loss: 0.2325\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0750 - output_1_loss: 0.0595Epoch 85/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0750 - output_1_loss: 0.0595 - val_loss: 0.3714 - val_output_1_loss: 0.3107\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0966 - output_1_loss: 0.0966 - val_loss: 0.2206 - val_output_1_loss: 0.2206\n",
      "Epoch 86/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1138 - output_1_loss: 0.1138 - val_loss: 0.2237 - val_output_1_loss: 0.2237\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0715 - output_1_loss: 0.0568 - val_loss: 0.3530 - val_output_1_loss: 0.2926\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1181 - output_1_loss: 0.1181Epoch 22/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0674 - output_1_loss: 0.0533 - val_loss: 0.3365 - val_output_1_loss: 0.2766\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1181 - output_1_loss: 0.1181 - val_loss: 0.2201 - val_output_1_loss: 0.2201\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1498 - output_1_loss: 0.1498Epoch 23/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0643 - output_1_loss: 0.0505 - val_loss: 0.3219 - val_output_1_loss: 0.2624\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1498 - output_1_loss: 0.1498 - val_loss: 0.2172 - val_output_1_loss: 0.2171\n",
      "Epoch 24/100\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0627 - output_1_loss: 0.0495 - val_loss: 0.3089 - val_output_1_loss: 0.2498\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0614 - output_1_loss: 0.0487 - val_loss: 0.2973 - val_output_1_loss: 0.2387\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.1177 - output_1_loss: 0.1177 - val_loss: 0.2161 - val_output_1_loss: 0.2161\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0603 - output_1_loss: 0.0482 - val_loss: 0.2869 - val_output_1_loss: 0.2287\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0595 - output_1_loss: 0.0477Epoch 90/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0595 - output_1_loss: 0.0477 - val_loss: 0.2776 - val_output_1_loss: 0.2199\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1302 - output_1_loss: 0.1302 - val_loss: 0.2136 - val_output_1_loss: 0.2136\n",
      "Epoch 91/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0588 - output_1_loss: 0.0473 - val_loss: 0.2693 - val_output_1_loss: 0.2120\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1028 - output_1_loss: 0.1028Epoch 29/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0582 - output_1_loss: 0.0469 - val_loss: 0.2618 - val_output_1_loss: 0.2049\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.1028 - output_1_loss: 0.1028 - val_loss: 0.2111 - val_output_1_loss: 0.2111\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0576 - output_1_loss: 0.0466 - val_loss: 0.2550 - val_output_1_loss: 0.1985\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1185 - output_1_loss: 0.1185 - val_loss: 0.2061 - val_output_1_loss: 0.2061\n",
      "Epoch 93/100\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0569 - output_1_loss: 0.0462 - val_loss: 0.2489 - val_output_1_loss: 0.1927\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1481 - output_1_loss: 0.1481 - val_loss: 0.2023 - val_output_1_loss: 0.2023\n",
      "Epoch 94/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0561 - output_1_loss: 0.0458 - val_loss: 0.2433 - val_output_1_loss: 0.1875\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1578 - output_1_loss: 0.1578 - val_loss: 0.1988 - val_output_1_loss: 0.1988\n",
      "Epoch 95/100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0555 - output_1_loss: 0.0454 - val_loss: 0.2383 - val_output_1_loss: 0.1827\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.1158 - output_1_loss: 0.1158 - val_loss: 0.1955 - val_output_1_loss: 0.1955\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0549 - output_1_loss: 0.0450Epoch 96/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0549 - output_1_loss: 0.0450 - val_loss: 0.2337 - val_output_1_loss: 0.1784\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0543 - output_1_loss: 0.0447 - val_loss: 0.2295 - val_output_1_loss: 0.1745\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0965 - output_1_loss: 0.0965 - val_loss: 0.1930 - val_output_1_loss: 0.1930\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0537 - output_1_loss: 0.0444 - val_loss: 0.2256 - val_output_1_loss: 0.1709\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0532 - output_1_loss: 0.0441Epoch 97/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0532 - output_1_loss: 0.0441 - val_loss: 0.2220 - val_output_1_loss: 0.1675\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1662 - output_1_loss: 0.1662 - val_loss: 0.1893 - val_output_1_loss: 0.1893\n",
      "Epoch 98/100\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0527 - output_1_loss: 0.0439 - val_loss: 0.2187 - val_output_1_loss: 0.1644\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1031 - output_1_loss: 0.1031 - val_loss: 0.1866 - val_output_1_loss: 0.1866\n",
      "Epoch 39/100\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0519 - output_1_loss: 0.0433 - val_loss: 0.2155 - val_output_1_loss: 0.1615\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1057 - output_1_loss: 0.1057 - val_loss: 0.1830 - val_output_1_loss: 0.1830\n",
      "Epoch 100/100\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0512 - output_1_loss: 0.0430 - val_loss: 0.2126 - val_output_1_loss: 0.1587\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0915 - output_1_loss: 0.0915 - val_loss: 0.1798 - val_output_1_loss: 0.1798\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0505 - output_1_loss: 0.0427 - val_loss: 0.2098 - val_output_1_loss: 0.1561\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0499 - output_1_loss: 0.0423 - val_loss: 0.2074 - val_output_1_loss: 0.1538\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0494 - output_1_loss: 0.0419 - val_loss: 0.2050 - val_output_1_loss: 0.1516\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0488 - output_1_loss: 0.0415 - val_loss: 0.2028 - val_output_1_loss: 0.1496\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0483 - output_1_loss: 0.0412 - val_loss: 0.2006 - val_output_1_loss: 0.1477\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0478 - output_1_loss: 0.0408 - val_loss: 0.1985 - val_output_1_loss: 0.1458\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0473 - output_1_loss: 0.0405 - val_loss: 0.1965 - val_output_1_loss: 0.1440\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0468 - output_1_loss: 0.0401 - val_loss: 0.1946 - val_output_1_loss: 0.1424\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0462 - output_1_loss: 0.0396 - val_loss: 0.1928 - val_output_1_loss: 0.1409\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:08:43,210]\u001b[0m Trial 26 finished with value: 0.011235955056179775 and parameters: {'feature_dim': 128, 'n_step': 8, 'n_shared': 1, 'relaxation_factor': 2.2, 'sparsity_coefficient': 1.9321062314538313e-06, 'bn_momentum': 0.9909194985124697}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0456 - output_1_loss: 0.0392 - val_loss: 0.1911 - val_output_1_loss: 0.1395\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0454 - output_1_loss: 0.0391 - val_loss: 0.1895 - val_output_1_loss: 0.1383\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0446 - output_1_loss: 0.0384Epoch 1/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0446 - output_1_loss: 0.0384 - val_loss: 0.1881 - val_output_1_loss: 0.1371\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0443 - output_1_loss: 0.0384 - val_loss: 0.1867 - val_output_1_loss: 0.1360\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0436 - output_1_loss: 0.0378 - val_loss: 0.1855 - val_output_1_loss: 0.1351\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0430 - output_1_loss: 0.0374 - val_loss: 0.1843 - val_output_1_loss: 0.1342\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0433 - output_1_loss: 0.0379 - val_loss: 0.1832 - val_output_1_loss: 0.1334\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0422 - output_1_loss: 0.0368 - val_loss: 0.1821 - val_output_1_loss: 0.1327\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0418 - output_1_loss: 0.0366 - val_loss: 0.1812 - val_output_1_loss: 0.1321\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0414 - output_1_loss: 0.0362 - val_loss: 0.1802 - val_output_1_loss: 0.1315\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0409 - output_1_loss: 0.0360 - val_loss: 0.1793 - val_output_1_loss: 0.1310\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0406 - output_1_loss: 0.0357 - val_loss: 0.1784 - val_output_1_loss: 0.1305\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.0403 - output_1_loss: 0.0355 - val_loss: 0.1776 - val_output_1_loss: 0.1301\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0400 - output_1_loss: 0.0353 - val_loss: 0.1768 - val_output_1_loss: 0.1297\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0398 - output_1_loss: 0.0351 - val_loss: 0.1761 - val_output_1_loss: 0.1294\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0395 - output_1_loss: 0.0349 - val_loss: 0.1755 - val_output_1_loss: 0.1291\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0392 - output_1_loss: 0.0347 - val_loss: 0.1750 - val_output_1_loss: 0.1290\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0389 - output_1_loss: 0.0345 - val_loss: 0.1745 - val_output_1_loss: 0.1290\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0385 - output_1_loss: 0.0342 - val_loss: 0.1743 - val_output_1_loss: 0.1292\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0383 - output_1_loss: 0.0340 - val_loss: 0.1742 - val_output_1_loss: 0.1296\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0380 - output_1_loss: 0.0337 - val_loss: 0.1741 - val_output_1_loss: 0.1300\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0376 - output_1_loss: 0.0334 - val_loss: 0.1740 - val_output_1_loss: 0.1304\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0374 - output_1_loss: 0.0333 - val_loss: 0.1740 - val_output_1_loss: 0.1310\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0368 - output_1_loss: 0.0328 - val_loss: 0.1738 - val_output_1_loss: 0.1314\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0366 - output_1_loss: 0.0326 - val_loss: 0.1735 - val_output_1_loss: 0.1317\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0363 - output_1_loss: 0.0324 - val_loss: 0.1732 - val_output_1_loss: 0.1320\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0361 - output_1_loss: 0.0323 - val_loss: 0.1729 - val_output_1_loss: 0.1323\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0359 - output_1_loss: 0.0322 - val_loss: 0.1724 - val_output_1_loss: 0.1324\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0357 - output_1_loss: 0.0321 - val_loss: 0.1718 - val_output_1_loss: 0.1324\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0356 - output_1_loss: 0.0320 - val_loss: 0.1712 - val_output_1_loss: 0.1324\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0355 - output_1_loss: 0.0319 - val_loss: 0.1705 - val_output_1_loss: 0.1324\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0354 - output_1_loss: 0.0318 - val_loss: 0.1696 - val_output_1_loss: 0.1321\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0355 - output_1_loss: 0.0320 - val_loss: 0.1671 - val_output_1_loss: 0.1302\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0400 - output_1_loss: 0.0363 - val_loss: 0.1651 - val_output_1_loss: 0.1290\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0441 - output_1_loss: 0.0405 - val_loss: 0.1625 - val_output_1_loss: 0.1273\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0429 - output_1_loss: 0.0393 - val_loss: 0.1601 - val_output_1_loss: 0.1256\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0420 - output_1_loss: 0.0385 - val_loss: 0.1582 - val_output_1_loss: 0.1242\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0419 - output_1_loss: 0.0382 - val_loss: 0.1572 - val_output_1_loss: 0.1235\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0421 - output_1_loss: 0.0380 - val_loss: 0.1554 - val_output_1_loss: 0.1222\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0424 - output_1_loss: 0.0381 - val_loss: 0.1529 - val_output_1_loss: 0.1200\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0426 - output_1_loss: 0.0383 - val_loss: 0.1504 - val_output_1_loss: 0.1180\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0421 - output_1_loss: 0.0377 - val_loss: 0.1468 - val_output_1_loss: 0.1150\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0416 - output_1_loss: 0.0372 - val_loss: 0.1427 - val_output_1_loss: 0.1113\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0406 - output_1_loss: 0.0362 - val_loss: 0.1342 - val_output_1_loss: 0.1033\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0400 - output_1_loss: 0.0354 - val_loss: 0.1352 - val_output_1_loss: 0.1046\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0443 - output_1_loss: 0.0398 - val_loss: 0.1353 - val_output_1_loss: 0.1055\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0483 - output_1_loss: 0.0429 - val_loss: 0.1413 - val_output_1_loss: 0.1107\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0516 - output_1_loss: 0.0464 - val_loss: 0.1467 - val_output_1_loss: 0.1159\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0494 - output_1_loss: 0.0434 - val_loss: 0.1492 - val_output_1_loss: 0.1183\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:08:59,515]\u001b[0m Trial 27 finished with value: 1.0 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.7000000000000002, 'sparsity_coefficient': 0.017300412754893708, 'bn_momentum': 0.9609401679600647}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 16s 16s/step - loss: 0.8134 - output_1_loss: 0.8130 - val_loss: 0.6868 - val_output_1_loss: 0.6856\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.7243 - output_1_loss: 0.7239 - val_loss: 0.6798 - val_output_1_loss: 0.6787\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.6493 - output_1_loss: 0.6489 - val_loss: 0.6715 - val_output_1_loss: 0.6705\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.5786 - output_1_loss: 0.5782 - val_loss: 0.6624 - val_output_1_loss: 0.6614\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.5286 - output_1_loss: 0.5282 - val_loss: 0.6537 - val_output_1_loss: 0.6528\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.4265 - output_1_loss: 0.4262 - val_loss: 0.6431 - val_output_1_loss: 0.6422\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.3629 - output_1_loss: 0.3626 - val_loss: 0.6312 - val_output_1_loss: 0.6303\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.3242 - output_1_loss: 0.3238 - val_loss: 0.6196 - val_output_1_loss: 0.6188\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1881 - output_1_loss: 0.1878 - val_loss: 0.6032 - val_output_1_loss: 0.6024\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1775 - output_1_loss: 0.1772 - val_loss: 0.5837 - val_output_1_loss: 0.5830\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1379 - output_1_loss: 0.1377 - val_loss: 0.5612 - val_output_1_loss: 0.5605\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1042 - output_1_loss: 0.1039 - val_loss: 0.5388 - val_output_1_loss: 0.5381\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0928 - output_1_loss: 0.0925 - val_loss: 0.5170 - val_output_1_loss: 0.5163\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0833 - output_1_loss: 0.0830 - val_loss: 0.4949 - val_output_1_loss: 0.4943\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0848 - output_1_loss: 0.0845 - val_loss: 0.4747 - val_output_1_loss: 0.4741\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0810 - output_1_loss: 0.0807 - val_loss: 0.4554 - val_output_1_loss: 0.4547\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.0751 - output_1_loss: 0.0748 - val_loss: 0.4337 - val_output_1_loss: 0.4331\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0694 - output_1_loss: 0.0691 - val_loss: 0.4131 - val_output_1_loss: 0.4125\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0728 - output_1_loss: 0.0726 - val_loss: 0.3944 - val_output_1_loss: 0.3938\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0681 - output_1_loss: 0.0678 - val_loss: 0.3771 - val_output_1_loss: 0.3765\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0665 - output_1_loss: 0.0662 - val_loss: 0.3586 - val_output_1_loss: 0.3581\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0764 - output_1_loss: 0.0761 - val_loss: 0.3430 - val_output_1_loss: 0.3424\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0725 - output_1_loss: 0.0722 - val_loss: 0.3286 - val_output_1_loss: 0.3280\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0689 - output_1_loss: 0.0687 - val_loss: 0.3146 - val_output_1_loss: 0.3141\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.0661 - output_1_loss: 0.0658 - val_loss: 0.3006 - val_output_1_loss: 0.3001\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0630 - output_1_loss: 0.0627 - val_loss: 0.2861 - val_output_1_loss: 0.2856\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0680 - output_1_loss: 0.0677 - val_loss: 0.2722 - val_output_1_loss: 0.2717\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0596 - output_1_loss: 0.0593 - val_loss: 0.2596 - val_output_1_loss: 0.2592\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0633 - output_1_loss: 0.0631 - val_loss: 0.2492 - val_output_1_loss: 0.2488\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.0634 - output_1_loss: 0.0631 - val_loss: 0.2402 - val_output_1_loss: 0.2397\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0632 - output_1_loss: 0.0629 - val_loss: 0.2318 - val_output_1_loss: 0.2313\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0606 - output_1_loss: 0.0604 - val_loss: 0.2239 - val_output_1_loss: 0.2235\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0598 - output_1_loss: 0.0595 - val_loss: 0.2166 - val_output_1_loss: 0.2162\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0592 - output_1_loss: 0.0589 - val_loss: 0.2095 - val_output_1_loss: 0.2091\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0585 - output_1_loss: 0.0582 - val_loss: 0.2029 - val_output_1_loss: 0.2025\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0573 - output_1_loss: 0.0570 - val_loss: 0.1965 - val_output_1_loss: 0.1961\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0561 - output_1_loss: 0.0559 - val_loss: 0.1904 - val_output_1_loss: 0.1900\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0557 - output_1_loss: 0.0554 - val_loss: 0.1850 - val_output_1_loss: 0.1846\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0550 - output_1_loss: 0.0547 - val_loss: 0.1802 - val_output_1_loss: 0.1797\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0546 - output_1_loss: 0.0543 - val_loss: 0.1760 - val_output_1_loss: 0.1755\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0532 - output_1_loss: 0.0529 - val_loss: 0.1719 - val_output_1_loss: 0.1715\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0590 - output_1_loss: 0.0587 - val_loss: 0.1679 - val_output_1_loss: 0.1675\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0521 - output_1_loss: 0.0519 - val_loss: 0.1649 - val_output_1_loss: 0.1644\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0545 - output_1_loss: 0.0542 - val_loss: 0.1626 - val_output_1_loss: 0.1622\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0536 - output_1_loss: 0.0532 - val_loss: 0.1607 - val_output_1_loss: 0.1602\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0675 - output_1_loss: 0.0671 - val_loss: 0.1599 - val_output_1_loss: 0.1595\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0656 - output_1_loss: 0.0653 - val_loss: 0.1576 - val_output_1_loss: 0.1571\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0617 - output_1_loss: 0.0614 - val_loss: 0.1580 - val_output_1_loss: 0.1575\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0553 - output_1_loss: 0.0550 - val_loss: 0.1551 - val_output_1_loss: 0.1547\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0540 - output_1_loss: 0.0537 - val_loss: 0.1525 - val_output_1_loss: 0.1520\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0541 - output_1_loss: 0.0538 - val_loss: 0.1499 - val_output_1_loss: 0.1494\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7018 - output_1_loss: 0.6712Epoch 52/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0488 - output_1_loss: 0.0486 - val_loss: 0.1474 - val_output_1_loss: 0.1469\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0472 - output_1_loss: 0.0470 - val_loss: 0.1445 - val_output_1_loss: 0.1440\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.0479 - output_1_loss: 0.0476 - val_loss: 0.1420 - val_output_1_loss: 0.1415\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0458 - output_1_loss: 0.0456 - val_loss: 0.1398 - val_output_1_loss: 0.1393\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0479 - output_1_loss: 0.0476 - val_loss: 0.1378 - val_output_1_loss: 0.1373\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0476 - output_1_loss: 0.0474 - val_loss: 0.1368 - val_output_1_loss: 0.1362\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0466 - output_1_loss: 0.0464 - val_loss: 0.1356 - val_output_1_loss: 0.1351\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0452 - output_1_loss: 0.0450 - val_loss: 0.1337 - val_output_1_loss: 0.1332\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0445 - output_1_loss: 0.0443 - val_loss: 0.1317 - val_output_1_loss: 0.1311\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.7018 - output_1_loss: 0.6712 - val_loss: 0.7818 - val_output_1_loss: 0.6836\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0440 - output_1_loss: 0.0437 - val_loss: 0.1297 - val_output_1_loss: 0.1291\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0437 - output_1_loss: 0.0434 - val_loss: 0.1275 - val_output_1_loss: 0.1270\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0435 - output_1_loss: 0.0432 - val_loss: 0.1253 - val_output_1_loss: 0.1247\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0432 - output_1_loss: 0.0429 - val_loss: 0.1233 - val_output_1_loss: 0.1227\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0428 - output_1_loss: 0.0425 - val_loss: 0.1215 - val_output_1_loss: 0.1209\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0426 - output_1_loss: 0.0424 - val_loss: 0.1196 - val_output_1_loss: 0.1190\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0423 - output_1_loss: 0.0420 - val_loss: 0.1177 - val_output_1_loss: 0.1171\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0420 - output_1_loss: 0.0418 - val_loss: 0.1159 - val_output_1_loss: 0.1153\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0420 - output_1_loss: 0.0417 - val_loss: 0.1141 - val_output_1_loss: 0.1136\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0419 - output_1_loss: 0.0417 - val_loss: 0.1126 - val_output_1_loss: 0.1121\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0416 - output_1_loss: 0.0413 - val_loss: 0.1114 - val_output_1_loss: 0.1109\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0412 - output_1_loss: 0.0410 - val_loss: 0.1101 - val_output_1_loss: 0.1096\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0810 - output_1_loss: 0.0808 - val_loss: 0.1073 - val_output_1_loss: 0.1068\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0500 - output_1_loss: 0.0498 - val_loss: 0.1055 - val_output_1_loss: 0.1050\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0632 - output_1_loss: 0.0630 - val_loss: 0.1036 - val_output_1_loss: 0.1031\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0497 - output_1_loss: 0.0494 - val_loss: 0.1047 - val_output_1_loss: 0.1042\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0531 - output_1_loss: 0.0529 - val_loss: 0.1064 - val_output_1_loss: 0.1059\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0526 - output_1_loss: 0.0524Epoch 2/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0526 - output_1_loss: 0.0524 - val_loss: 0.1091 - val_output_1_loss: 0.1086\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0551 - output_1_loss: 0.0549 - val_loss: 0.1121 - val_output_1_loss: 0.1116\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.6015 - output_1_loss: 0.5717 - val_loss: 0.7673 - val_output_1_loss: 0.6745\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0582 - output_1_loss: 0.0580 - val_loss: 0.1117 - val_output_1_loss: 0.1113\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5815 - output_1_loss: 0.5508 - val_loss: 0.7534 - val_output_1_loss: 0.6659\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.5811 - output_1_loss: 0.5511 - val_loss: 0.7414 - val_output_1_loss: 0.6569\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5439 - output_1_loss: 0.5153 - val_loss: 0.7283 - val_output_1_loss: 0.6467\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:09:24,805]\u001b[0m Trial 28 finished with value: 0.16666666666666666 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 2.5, 'sparsity_coefficient': 0.00019628732891701535, 'bn_momentum': 0.9590069037137885}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 536ms/step - loss: 0.4737 - output_1_loss: 0.4459 - val_loss: 0.7149 - val_output_1_loss: 0.6366\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4187 - output_1_loss: 0.3923Epoch 1/100\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.4187 - output_1_loss: 0.3923 - val_loss: 0.7007 - val_output_1_loss: 0.6244\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.4625 - output_1_loss: 0.4365 - val_loss: 0.6880 - val_output_1_loss: 0.6142\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.3967 - output_1_loss: 0.3687 - val_loss: 0.6754 - val_output_1_loss: 0.6036\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.3377 - output_1_loss: 0.3097 - val_loss: 0.6623 - val_output_1_loss: 0.5919\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.3043 - output_1_loss: 0.2793 - val_loss: 0.6480 - val_output_1_loss: 0.5786\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.3733 - output_1_loss: 0.3485 - val_loss: 0.6372 - val_output_1_loss: 0.5690\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.3572 - output_1_loss: 0.3313 - val_loss: 0.6242 - val_output_1_loss: 0.5571\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.2286 - output_1_loss: 0.2043 - val_loss: 0.6084 - val_output_1_loss: 0.5433\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.3509 - output_1_loss: 0.3277 - val_loss: 0.5962 - val_output_1_loss: 0.5318\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.2864 - output_1_loss: 0.2631 - val_loss: 0.5830 - val_output_1_loss: 0.5194\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.3398 - output_1_loss: 0.3162 - val_loss: 0.5699 - val_output_1_loss: 0.5073\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.2173 - output_1_loss: 0.1935 - val_loss: 0.5532 - val_output_1_loss: 0.4923\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2593 - output_1_loss: 0.2335 - val_loss: 0.5412 - val_output_1_loss: 0.4807\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.2092 - output_1_loss: 0.1863 - val_loss: 0.5252 - val_output_1_loss: 0.4657\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.1477 - output_1_loss: 0.1240 - val_loss: 0.5092 - val_output_1_loss: 0.4505\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1703 - output_1_loss: 0.1503 - val_loss: 0.4900 - val_output_1_loss: 0.4324\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.2038 - output_1_loss: 0.1826 - val_loss: 0.4739 - val_output_1_loss: 0.4171\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1287 - output_1_loss: 0.1094 - val_loss: 0.4557 - val_output_1_loss: 0.3997\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1128 - output_1_loss: 0.0943 - val_loss: 0.4360 - val_output_1_loss: 0.3813\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1113 - output_1_loss: 0.0952 - val_loss: 0.4152 - val_output_1_loss: 0.3620\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.0989 - output_1_loss: 0.0792 - val_loss: 0.3932 - val_output_1_loss: 0.3414\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.1054 - output_1_loss: 0.0858 - val_loss: 0.3786 - val_output_1_loss: 0.3282\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.1672 - output_1_loss: 0.1506 - val_loss: 0.3635 - val_output_1_loss: 0.3144\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0875 - output_1_loss: 0.0716 - val_loss: 0.3487 - val_output_1_loss: 0.3004\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.1487 - output_1_loss: 0.1310 - val_loss: 0.3395 - val_output_1_loss: 0.2913\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.1409 - output_1_loss: 0.1221 - val_loss: 0.3233 - val_output_1_loss: 0.2753\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.0911 - output_1_loss: 0.0733 - val_loss: 0.3108 - val_output_1_loss: 0.2635\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1096 - output_1_loss: 0.0907 - val_loss: 0.2978 - val_output_1_loss: 0.2503\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.1603 - output_1_loss: 0.1407 - val_loss: 0.2871 - val_output_1_loss: 0.2397\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.1183 - output_1_loss: 0.1000 - val_loss: 0.2785 - val_output_1_loss: 0.2311\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.1662 - output_1_loss: 0.1474 - val_loss: 0.2683 - val_output_1_loss: 0.2211\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.1579 - output_1_loss: 0.1401 - val_loss: 0.2605 - val_output_1_loss: 0.2132\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.1090 - output_1_loss: 0.0917 - val_loss: 0.2502 - val_output_1_loss: 0.2037\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1194 - output_1_loss: 0.1001 - val_loss: 0.2413 - val_output_1_loss: 0.1948\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0954 - output_1_loss: 0.0786 - val_loss: 0.2327 - val_output_1_loss: 0.1870\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0998 - output_1_loss: 0.0829 - val_loss: 0.2219 - val_output_1_loss: 0.1766\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1117 - output_1_loss: 0.0933 - val_loss: 0.2150 - val_output_1_loss: 0.1702\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0901 - output_1_loss: 0.0726 - val_loss: 0.2085 - val_output_1_loss: 0.1638\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1291 - output_1_loss: 0.1120 - val_loss: 0.2037 - val_output_1_loss: 0.1591\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2548 - output_1_loss: 0.2361 - val_loss: 0.1991 - val_output_1_loss: 0.1546\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1092 - output_1_loss: 0.0922 - val_loss: 0.1929 - val_output_1_loss: 0.1486\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1072 - output_1_loss: 0.0882 - val_loss: 0.1840 - val_output_1_loss: 0.1395\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1093 - output_1_loss: 0.0895 - val_loss: 0.1799 - val_output_1_loss: 0.1354\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1021 - output_1_loss: 0.0824 - val_loss: 0.1777 - val_output_1_loss: 0.1333\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0994 - output_1_loss: 0.0804 - val_loss: 0.1725 - val_output_1_loss: 0.1282\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1075 - output_1_loss: 0.0871 - val_loss: 0.1678 - val_output_1_loss: 0.1241\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0987 - output_1_loss: 0.0802 - val_loss: 0.1635 - val_output_1_loss: 0.1205\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1099 - output_1_loss: 0.0927 - val_loss: 0.1576 - val_output_1_loss: 0.1147\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2004 - output_1_loss: 0.1838 - val_loss: 0.1590 - val_output_1_loss: 0.1163\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0919 - output_1_loss: 0.0767 - val_loss: 0.1519 - val_output_1_loss: 0.1097\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1021 - output_1_loss: 0.0845 - val_loss: 0.1489 - val_output_1_loss: 0.1071\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1020 - output_1_loss: 0.0843 - val_loss: 0.1452 - val_output_1_loss: 0.1038\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1239 - output_1_loss: 0.1047 - val_loss: 0.1442 - val_output_1_loss: 0.1034\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1267 - output_1_loss: 0.1092 - val_loss: 0.1445 - val_output_1_loss: 0.1042\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2413 - output_1_loss: 0.2251 - val_loss: 0.1443 - val_output_1_loss: 0.1040\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1103 - output_1_loss: 0.0940 - val_loss: 0.1388 - val_output_1_loss: 0.0982\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1068 - output_1_loss: 0.0882 - val_loss: 0.1379 - val_output_1_loss: 0.0971\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7968 - output_1_loss: 0.7670Epoch 64/100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0952 - output_1_loss: 0.0773 - val_loss: 0.1369 - val_output_1_loss: 0.0963\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1005 - output_1_loss: 0.0822 - val_loss: 0.1346 - val_output_1_loss: 0.0941\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.1130 - output_1_loss: 0.0951 - val_loss: 0.1324 - val_output_1_loss: 0.0920\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1036 - output_1_loss: 0.0870 - val_loss: 0.1317 - val_output_1_loss: 0.0914\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0925 - output_1_loss: 0.0769 - val_loss: 0.1289 - val_output_1_loss: 0.0889\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0915 - output_1_loss: 0.0749 - val_loss: 0.1269 - val_output_1_loss: 0.0872\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0907 - output_1_loss: 0.0740 - val_loss: 0.1249 - val_output_1_loss: 0.0856\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0885 - output_1_loss: 0.0705 - val_loss: 0.1234 - val_output_1_loss: 0.0849\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 24s 24s/step - loss: 0.7968 - output_1_loss: 0.7670 - val_loss: 0.7867 - val_output_1_loss: 0.6855\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0919 - output_1_loss: 0.0731 - val_loss: 0.1215 - val_output_1_loss: 0.0841\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.7036 - output_1_loss: 0.6737 - val_loss: 0.7725 - val_output_1_loss: 0.6774\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0944 - output_1_loss: 0.0751Epoch 3/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0944 - output_1_loss: 0.0751 - val_loss: 0.1193 - val_output_1_loss: 0.0827\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.6718 - output_1_loss: 0.6424 - val_loss: 0.7572 - val_output_1_loss: 0.6691\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0973 - output_1_loss: 0.0776 - val_loss: 0.1179 - val_output_1_loss: 0.0816\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6576 - output_1_loss: 0.6293 - val_loss: 0.7439 - val_output_1_loss: 0.6609\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1032 - output_1_loss: 0.0839 - val_loss: 0.1160 - val_output_1_loss: 0.0800\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5675 - output_1_loss: 0.5396 - val_loss: 0.7312 - val_output_1_loss: 0.6521\n",
      "Epoch 6/100\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5225 - output_1_loss: 0.4942 - val_loss: 0.7201 - val_output_1_loss: 0.6437\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1458 - output_1_loss: 0.1262 - val_loss: 0.1145 - val_output_1_loss: 0.0787\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5224 - output_1_loss: 0.4940 - val_loss: 0.7085 - val_output_1_loss: 0.6350\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0971 - output_1_loss: 0.0776 - val_loss: 0.1133 - val_output_1_loss: 0.0772\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.4898 - output_1_loss: 0.4618 - val_loss: 0.6968 - val_output_1_loss: 0.6254\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.1113 - output_1_loss: 0.0935 - val_loss: 0.1102 - val_output_1_loss: 0.0739\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5030 - output_1_loss: 0.4751 - val_loss: 0.6866 - val_output_1_loss: 0.6172\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1083 - output_1_loss: 0.0912 - val_loss: 0.1071 - val_output_1_loss: 0.0710\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4136 - output_1_loss: 0.3874Epoch 80/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.4136 - output_1_loss: 0.3874 - val_loss: 0.6752 - val_output_1_loss: 0.6078\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0968 - output_1_loss: 0.0791 - val_loss: 0.1054 - val_output_1_loss: 0.0695\n",
      "Epoch 81/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0948 - output_1_loss: 0.0786 - val_loss: 0.1056 - val_output_1_loss: 0.0695\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5933 - output_1_loss: 0.5686 - val_loss: 0.6651 - val_output_1_loss: 0.5998\n",
      "Epoch 82/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1556 - output_1_loss: 0.1376 - val_loss: 0.1054 - val_output_1_loss: 0.0697\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3595 - output_1_loss: 0.3339 - val_loss: 0.6540 - val_output_1_loss: 0.5900\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.1203 - output_1_loss: 0.1032 - val_loss: 0.1038 - val_output_1_loss: 0.0684\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3787 - output_1_loss: 0.3509 - val_loss: 0.6457 - val_output_1_loss: 0.5825\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1131 - output_1_loss: 0.0969 - val_loss: 0.1025 - val_output_1_loss: 0.0678\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3599 - output_1_loss: 0.3338 - val_loss: 0.6354 - val_output_1_loss: 0.5735\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0945 - output_1_loss: 0.0787Epoch 15/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0945 - output_1_loss: 0.0787 - val_loss: 0.1010 - val_output_1_loss: 0.0676\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3282 - output_1_loss: 0.2989 - val_loss: 0.6250 - val_output_1_loss: 0.5638\n",
      "Epoch 86/100\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3301 - output_1_loss: 0.3024 - val_loss: 0.6158 - val_output_1_loss: 0.5553\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0888 - output_1_loss: 0.0731 - val_loss: 0.1000 - val_output_1_loss: 0.0674\n",
      "Epoch 17/100\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3361 - output_1_loss: 0.3085 - val_loss: 0.6063 - val_output_1_loss: 0.5466\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0903 - output_1_loss: 0.0748 - val_loss: 0.0993 - val_output_1_loss: 0.0673\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0949 - output_1_loss: 0.0796 - val_loss: 0.0986 - val_output_1_loss: 0.0671\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4088 - output_1_loss: 0.3807 - val_loss: 0.5980 - val_output_1_loss: 0.5389\n",
      "Epoch 19/100\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0913 - output_1_loss: 0.0752 - val_loss: 0.0978 - val_output_1_loss: 0.0669\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.2317 - output_1_loss: 0.2029 - val_loss: 0.5858 - val_output_1_loss: 0.5284\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3128 - output_1_loss: 0.2840 - val_loss: 0.5754 - val_output_1_loss: 0.5187\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0847 - output_1_loss: 0.0703 - val_loss: 0.0963 - val_output_1_loss: 0.0661\n",
      "Epoch 21/100\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0984 - output_1_loss: 0.0827 - val_loss: 0.0946 - val_output_1_loss: 0.0648\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2889 - output_1_loss: 0.2610 - val_loss: 0.5641 - val_output_1_loss: 0.5088\n",
      "Epoch 92/100\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0850 - output_1_loss: 0.0681 - val_loss: 0.0927 - val_output_1_loss: 0.0634\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2254 - output_1_loss: 0.1999 - val_loss: 0.5528 - val_output_1_loss: 0.4983\n",
      "Epoch 93/100\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1064 - output_1_loss: 0.0918 - val_loss: 0.0909 - val_output_1_loss: 0.0623\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1987 - output_1_loss: 0.1728 - val_loss: 0.5417 - val_output_1_loss: 0.4880\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1059 - output_1_loss: 0.0903Epoch 24/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1059 - output_1_loss: 0.0903 - val_loss: 0.0903 - val_output_1_loss: 0.0624\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2315 - output_1_loss: 0.2063 - val_loss: 0.5312 - val_output_1_loss: 0.4778\n",
      "Epoch 25/100\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1698 - output_1_loss: 0.1444 - val_loss: 0.5191 - val_output_1_loss: 0.4649\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1015 - output_1_loss: 0.0860 - val_loss: 0.0900 - val_output_1_loss: 0.0627\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2262 - output_1_loss: 0.1998 - val_loss: 0.5106 - val_output_1_loss: 0.4570\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1086 - output_1_loss: 0.0928 - val_loss: 0.0891 - val_output_1_loss: 0.0624\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2256 - output_1_loss: 0.2002Epoch 97/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.2256 - output_1_loss: 0.2002 - val_loss: 0.5007 - val_output_1_loss: 0.4475\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0764 - output_1_loss: 0.0608 - val_loss: 0.0884 - val_output_1_loss: 0.0623\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1719 - output_1_loss: 0.1487Epoch 98/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1719 - output_1_loss: 0.1487 - val_loss: 0.4885 - val_output_1_loss: 0.4366\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0772 - output_1_loss: 0.0621 - val_loss: 0.0882 - val_output_1_loss: 0.0625\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2391 - output_1_loss: 0.2156Epoch 99/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2391 - output_1_loss: 0.2156 - val_loss: 0.4764 - val_output_1_loss: 0.4254\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0760 - output_1_loss: 0.0610 - val_loss: 0.0868 - val_output_1_loss: 0.0616\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2136 - output_1_loss: 0.1876Epoch 100/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2136 - output_1_loss: 0.1876 - val_loss: 0.4657 - val_output_1_loss: 0.4153\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0859 - output_1_loss: 0.0708 - val_loss: 0.0853 - val_output_1_loss: 0.0605\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1845 - output_1_loss: 0.1568 - val_loss: 0.4594 - val_output_1_loss: 0.4085\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.1571 - output_1_loss: 0.1299 - val_loss: 0.4480 - val_output_1_loss: 0.3974\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1442 - output_1_loss: 0.1177 - val_loss: 0.4305 - val_output_1_loss: 0.3804\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1538 - output_1_loss: 0.1306 - val_loss: 0.4150 - val_output_1_loss: 0.3642\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1553 - output_1_loss: 0.1324 - val_loss: 0.4048 - val_output_1_loss: 0.3543\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1275 - output_1_loss: 0.1026 - val_loss: 0.3975 - val_output_1_loss: 0.3470\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:10:00,040]\u001b[0m Trial 29 finished with value: 1.0 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 2, 'relaxation_factor': 1.6, 'sparsity_coefficient': 0.018050384365139744, 'bn_momentum': 0.9592104224233506}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.1769 - output_1_loss: 0.1526 - val_loss: 0.3842 - val_output_1_loss: 0.3341\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1287 - output_1_loss: 0.1037 - val_loss: 0.3750 - val_output_1_loss: 0.3249\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1414 - output_1_loss: 0.1165Epoch 1/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1414 - output_1_loss: 0.1165 - val_loss: 0.3591 - val_output_1_loss: 0.3089\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1505 - output_1_loss: 0.1258 - val_loss: 0.3442 - val_output_1_loss: 0.2943\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1937 - output_1_loss: 0.1722 - val_loss: 0.3366 - val_output_1_loss: 0.2865\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1720 - output_1_loss: 0.1497 - val_loss: 0.3250 - val_output_1_loss: 0.2756\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.1143 - output_1_loss: 0.0920 - val_loss: 0.3193 - val_output_1_loss: 0.2699\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.0971 - output_1_loss: 0.0798 - val_loss: 0.3083 - val_output_1_loss: 0.2593\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1206 - output_1_loss: 0.0973 - val_loss: 0.2954 - val_output_1_loss: 0.2466\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1083 - output_1_loss: 0.0855 - val_loss: 0.2857 - val_output_1_loss: 0.2371\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1549 - output_1_loss: 0.1326 - val_loss: 0.2766 - val_output_1_loss: 0.2286\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.1608 - output_1_loss: 0.1383 - val_loss: 0.2711 - val_output_1_loss: 0.2226\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.1384 - output_1_loss: 0.1171 - val_loss: 0.2654 - val_output_1_loss: 0.2165\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.0970 - output_1_loss: 0.0798 - val_loss: 0.2595 - val_output_1_loss: 0.2109\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1363 - output_1_loss: 0.1152 - val_loss: 0.2528 - val_output_1_loss: 0.2045\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.1291 - output_1_loss: 0.1089 - val_loss: 0.2470 - val_output_1_loss: 0.1998\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.1261 - output_1_loss: 0.1051 - val_loss: 0.2390 - val_output_1_loss: 0.1921\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1259 - output_1_loss: 0.1066 - val_loss: 0.2310 - val_output_1_loss: 0.1849\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.2179 - output_1_loss: 0.1958 - val_loss: 0.2271 - val_output_1_loss: 0.1818\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1405 - output_1_loss: 0.1190 - val_loss: 0.2226 - val_output_1_loss: 0.1773\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.1552 - output_1_loss: 0.1341 - val_loss: 0.2173 - val_output_1_loss: 0.1722\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1208 - output_1_loss: 0.0993 - val_loss: 0.2109 - val_output_1_loss: 0.1661\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.1328 - output_1_loss: 0.1138 - val_loss: 0.2074 - val_output_1_loss: 0.1627\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1308 - output_1_loss: 0.1118 - val_loss: 0.2067 - val_output_1_loss: 0.1621\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.2086 - output_1_loss: 0.1890 - val_loss: 0.2042 - val_output_1_loss: 0.1593\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.1191 - output_1_loss: 0.0981 - val_loss: 0.2009 - val_output_1_loss: 0.1558\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.1218 - output_1_loss: 0.1031 - val_loss: 0.1954 - val_output_1_loss: 0.1505\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.0889 - output_1_loss: 0.0692 - val_loss: 0.1892 - val_output_1_loss: 0.1443\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0856 - output_1_loss: 0.0647 - val_loss: 0.1842 - val_output_1_loss: 0.1387\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1229 - output_1_loss: 0.1048 - val_loss: 0.1823 - val_output_1_loss: 0.1359\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1028 - output_1_loss: 0.0828 - val_loss: 0.1801 - val_output_1_loss: 0.1338\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.1002 - output_1_loss: 0.0796 - val_loss: 0.1778 - val_output_1_loss: 0.1314\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0947 - output_1_loss: 0.0762 - val_loss: 0.1744 - val_output_1_loss: 0.1283\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0872 - output_1_loss: 0.0687 - val_loss: 0.1722 - val_output_1_loss: 0.1260\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0898 - output_1_loss: 0.0705 - val_loss: 0.1709 - val_output_1_loss: 0.1244\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0877 - output_1_loss: 0.0695 - val_loss: 0.1696 - val_output_1_loss: 0.1226\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0950 - output_1_loss: 0.0782 - val_loss: 0.1657 - val_output_1_loss: 0.1181\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1324 - output_1_loss: 0.1152 - val_loss: 0.1650 - val_output_1_loss: 0.1173\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1059 - output_1_loss: 0.0885 - val_loss: 0.1628 - val_output_1_loss: 0.1146\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1095 - output_1_loss: 0.0911 - val_loss: 0.1630 - val_output_1_loss: 0.1145\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1560 - output_1_loss: 0.1372 - val_loss: 0.1619 - val_output_1_loss: 0.1130\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0981 - output_1_loss: 0.0803 - val_loss: 0.1606 - val_output_1_loss: 0.1115\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.1260 - output_1_loss: 0.1092 - val_loss: 0.1599 - val_output_1_loss: 0.1109\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1826 - output_1_loss: 0.1655 - val_loss: 0.1590 - val_output_1_loss: 0.1104\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1233 - output_1_loss: 0.1041 - val_loss: 0.1594 - val_output_1_loss: 0.1108\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1039 - output_1_loss: 0.0846 - val_loss: 0.1602 - val_output_1_loss: 0.1114\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1060 - output_1_loss: 0.0867 - val_loss: 0.1591 - val_output_1_loss: 0.1100\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.1150 - output_1_loss: 0.0940 - val_loss: 0.1590 - val_output_1_loss: 0.1098\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.1078 - output_1_loss: 0.0889 - val_loss: 0.1579 - val_output_1_loss: 0.1087\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1171 - output_1_loss: 0.0989 - val_loss: 0.1576 - val_output_1_loss: 0.1090\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.1085 - output_1_loss: 0.0929 - val_loss: 0.1545 - val_output_1_loss: 0.1062\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0889 - output_1_loss: 0.0728 - val_loss: 0.1521 - val_output_1_loss: 0.1043\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1075 - output_1_loss: 0.0894 - val_loss: 0.1499 - val_output_1_loss: 0.1027\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0950 - output_1_loss: 0.0789 - val_loss: 0.1492 - val_output_1_loss: 0.1023\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1052 - output_1_loss: 0.0871 - val_loss: 0.1474 - val_output_1_loss: 0.1013\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1288 - output_1_loss: 0.1072 - val_loss: 0.1473 - val_output_1_loss: 0.1017\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1237 - output_1_loss: 0.1037 - val_loss: 0.1462 - val_output_1_loss: 0.1013\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.1186 - output_1_loss: 0.0978 - val_loss: 0.1439 - val_output_1_loss: 0.1001\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0954 - output_1_loss: 0.0767 - val_loss: 0.1414 - val_output_1_loss: 0.0985\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1023 - output_1_loss: 0.0848 - val_loss: 0.1379 - val_output_1_loss: 0.0960\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.7025 - output_1_loss: 0.6757 - val_loss: 0.7722 - val_output_1_loss: 0.6846\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.1688 - output_1_loss: 0.1514 - val_loss: 0.1379 - val_output_1_loss: 0.0966\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.6374 - output_1_loss: 0.6103 - val_loss: 0.7584 - val_output_1_loss: 0.6764\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.1190 - output_1_loss: 0.1012 - val_loss: 0.1368 - val_output_1_loss: 0.0956\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.5778 - output_1_loss: 0.5490 - val_loss: 0.7455 - val_output_1_loss: 0.6674\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1250 - output_1_loss: 0.1079 - val_loss: 0.1341 - val_output_1_loss: 0.0932\n",
      "Epoch 100/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5564 - output_1_loss: 0.5279 - val_loss: 0.7340 - val_output_1_loss: 0.6579\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1533 - output_1_loss: 0.1371 - val_loss: 0.1314 - val_output_1_loss: 0.0915\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4711 - output_1_loss: 0.4441 - val_loss: 0.7211 - val_output_1_loss: 0.6480\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.4412 - output_1_loss: 0.4168 - val_loss: 0.7088 - val_output_1_loss: 0.6387\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.4647 - output_1_loss: 0.4389 - val_loss: 0.6968 - val_output_1_loss: 0.6282\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.4180 - output_1_loss: 0.3925 - val_loss: 0.6848 - val_output_1_loss: 0.6184\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3962 - output_1_loss: 0.3728 - val_loss: 0.6711 - val_output_1_loss: 0.6073\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3385 - output_1_loss: 0.3156 - val_loss: 0.6594 - val_output_1_loss: 0.5971\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3588 - output_1_loss: 0.3349 - val_loss: 0.6459 - val_output_1_loss: 0.5856\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:10:27,684]\u001b[0m Trial 30 finished with value: 0.07142857142857142 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 2, 'relaxation_factor': 1.6, 'sparsity_coefficient': 0.018412906111727707, 'bn_momentum': 0.9758301587323598}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 480ms/step - loss: 0.3153 - output_1_loss: 0.2923 - val_loss: 0.6299 - val_output_1_loss: 0.5730\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.3705 - output_1_loss: 0.3487 - val_loss: 0.6170 - val_output_1_loss: 0.5614\n",
      "Epoch 1/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.3015 - output_1_loss: 0.2796 - val_loss: 0.6033 - val_output_1_loss: 0.5486\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.2198 - output_1_loss: 0.1996 - val_loss: 0.5852 - val_output_1_loss: 0.5322\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.2324 - output_1_loss: 0.2104 - val_loss: 0.5715 - val_output_1_loss: 0.5198\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.2494 - output_1_loss: 0.2282 - val_loss: 0.5601 - val_output_1_loss: 0.5088\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.3321 - output_1_loss: 0.3104 - val_loss: 0.5437 - val_output_1_loss: 0.4932\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1823 - output_1_loss: 0.1617 - val_loss: 0.5292 - val_output_1_loss: 0.4788\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.2125 - output_1_loss: 0.1901 - val_loss: 0.5146 - val_output_1_loss: 0.4647\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.2516 - output_1_loss: 0.2310 - val_loss: 0.5026 - val_output_1_loss: 0.4527\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1548 - output_1_loss: 0.1337 - val_loss: 0.4834 - val_output_1_loss: 0.4348\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1898 - output_1_loss: 0.1679 - val_loss: 0.4720 - val_output_1_loss: 0.4237\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1249 - output_1_loss: 0.1033 - val_loss: 0.4532 - val_output_1_loss: 0.4053\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.1316 - output_1_loss: 0.1092 - val_loss: 0.4316 - val_output_1_loss: 0.3840\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1065 - output_1_loss: 0.0851 - val_loss: 0.4098 - val_output_1_loss: 0.3633\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1537 - output_1_loss: 0.1323 - val_loss: 0.3903 - val_output_1_loss: 0.3431\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1437 - output_1_loss: 0.1215 - val_loss: 0.3697 - val_output_1_loss: 0.3211\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1122 - output_1_loss: 0.0895 - val_loss: 0.3519 - val_output_1_loss: 0.3034\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1155 - output_1_loss: 0.0904 - val_loss: 0.3311 - val_output_1_loss: 0.2831\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1432 - output_1_loss: 0.1181 - val_loss: 0.3170 - val_output_1_loss: 0.2698\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1505 - output_1_loss: 0.1251 - val_loss: 0.3015 - val_output_1_loss: 0.2549\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1065 - output_1_loss: 0.0818 - val_loss: 0.2867 - val_output_1_loss: 0.2406\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.1768 - output_1_loss: 0.1544 - val_loss: 0.2817 - val_output_1_loss: 0.2375\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.1220 - output_1_loss: 0.1000 - val_loss: 0.2730 - val_output_1_loss: 0.2306\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.1428 - output_1_loss: 0.1209 - val_loss: 0.2673 - val_output_1_loss: 0.2250\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1550 - output_1_loss: 0.1351 - val_loss: 0.2600 - val_output_1_loss: 0.2178\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1322 - output_1_loss: 0.1107 - val_loss: 0.2511 - val_output_1_loss: 0.2086\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.1337 - output_1_loss: 0.1111 - val_loss: 0.2404 - val_output_1_loss: 0.1978\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.1447 - output_1_loss: 0.1222 - val_loss: 0.2325 - val_output_1_loss: 0.1890\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1269 - output_1_loss: 0.1042 - val_loss: 0.2219 - val_output_1_loss: 0.1786\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.2133 - output_1_loss: 0.1905 - val_loss: 0.2186 - val_output_1_loss: 0.1753\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.1855 - output_1_loss: 0.1631 - val_loss: 0.2167 - val_output_1_loss: 0.1734\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.1370 - output_1_loss: 0.1144 - val_loss: 0.2114 - val_output_1_loss: 0.1685\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.1277 - output_1_loss: 0.1070 - val_loss: 0.2060 - val_output_1_loss: 0.1639\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.1212 - output_1_loss: 0.1008 - val_loss: 0.1974 - val_output_1_loss: 0.1559\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0995 - output_1_loss: 0.0797 - val_loss: 0.1897 - val_output_1_loss: 0.1486\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.0976 - output_1_loss: 0.0775 - val_loss: 0.1835 - val_output_1_loss: 0.1425\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1041 - output_1_loss: 0.0841 - val_loss: 0.1796 - val_output_1_loss: 0.1382\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1201 - output_1_loss: 0.1009 - val_loss: 0.1763 - val_output_1_loss: 0.1349\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0966 - output_1_loss: 0.0789 - val_loss: 0.1716 - val_output_1_loss: 0.1304\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0969 - output_1_loss: 0.0793 - val_loss: 0.1676 - val_output_1_loss: 0.1272\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0922 - output_1_loss: 0.0745 - val_loss: 0.1634 - val_output_1_loss: 0.1237\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1221 - output_1_loss: 0.1042 - val_loss: 0.1600 - val_output_1_loss: 0.1209\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.1139 - output_1_loss: 0.0961 - val_loss: 0.1565 - val_output_1_loss: 0.1182\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0966 - output_1_loss: 0.0783 - val_loss: 0.1530 - val_output_1_loss: 0.1151\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0921 - output_1_loss: 0.0744 - val_loss: 0.1509 - val_output_1_loss: 0.1133\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0855 - output_1_loss: 0.0675 - val_loss: 0.1486 - val_output_1_loss: 0.1112\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0932 - output_1_loss: 0.0752 - val_loss: 0.1471 - val_output_1_loss: 0.1096\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0878 - output_1_loss: 0.0703 - val_loss: 0.1455 - val_output_1_loss: 0.1079\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0974 - output_1_loss: 0.0801 - val_loss: 0.1440 - val_output_1_loss: 0.1063\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0918 - output_1_loss: 0.0755 - val_loss: 0.1429 - val_output_1_loss: 0.1050\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0897 - output_1_loss: 0.0733 - val_loss: 0.1416 - val_output_1_loss: 0.1036\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0905 - output_1_loss: 0.0740 - val_loss: 0.1404 - val_output_1_loss: 0.1024\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1033 - output_1_loss: 0.0862 - val_loss: 0.1393 - val_output_1_loss: 0.1012\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0949 - output_1_loss: 0.0783 - val_loss: 0.1381 - val_output_1_loss: 0.1002\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1010 - output_1_loss: 0.0847 - val_loss: 0.1364 - val_output_1_loss: 0.0987\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0924 - output_1_loss: 0.0764 - val_loss: 0.1348 - val_output_1_loss: 0.0972\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0805 - output_1_loss: 0.0649 - val_loss: 0.1337 - val_output_1_loss: 0.0958\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0826 - output_1_loss: 0.0671 - val_loss: 0.1325 - val_output_1_loss: 0.0944\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0777 - output_1_loss: 0.0614 - val_loss: 0.1315 - val_output_1_loss: 0.0931\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0776 - output_1_loss: 0.0614 - val_loss: 0.1309 - val_output_1_loss: 0.0923\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0929 - output_1_loss: 0.0768 - val_loss: 0.1308 - val_output_1_loss: 0.0921\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0856 - output_1_loss: 0.0702 - val_loss: 0.1299 - val_output_1_loss: 0.0912\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9524 - output_1_loss: 0.9343Epoch 75/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0804 - output_1_loss: 0.0650 - val_loss: 0.1294 - val_output_1_loss: 0.0908\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0795 - output_1_loss: 0.0641 - val_loss: 0.1288 - val_output_1_loss: 0.0904\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.0797 - output_1_loss: 0.0649 - val_loss: 0.1277 - val_output_1_loss: 0.0894\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0753 - output_1_loss: 0.0606 - val_loss: 0.1271 - val_output_1_loss: 0.0890\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0761 - output_1_loss: 0.0618 - val_loss: 0.1263 - val_output_1_loss: 0.0887\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0760 - output_1_loss: 0.0619 - val_loss: 0.1257 - val_output_1_loss: 0.0885\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0737 - output_1_loss: 0.0597 - val_loss: 0.1252 - val_output_1_loss: 0.0884\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1162 - output_1_loss: 0.1025 - val_loss: 0.1246 - val_output_1_loss: 0.0883\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0830 - output_1_loss: 0.0692 - val_loss: 0.1234 - val_output_1_loss: 0.0876\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.9524 - output_1_loss: 0.9343 - val_loss: 0.7507 - val_output_1_loss: 0.6865\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1119 - output_1_loss: 0.0965 - val_loss: 0.1225 - val_output_1_loss: 0.0869\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0875 - output_1_loss: 0.0738 - val_loss: 0.1212 - val_output_1_loss: 0.0859\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0947 - output_1_loss: 0.0806 - val_loss: 0.1201 - val_output_1_loss: 0.0849\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1151 - output_1_loss: 0.0998 - val_loss: 0.1191 - val_output_1_loss: 0.0842\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0899 - output_1_loss: 0.0748 - val_loss: 0.1175 - val_output_1_loss: 0.0831\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0851 - output_1_loss: 0.0714 - val_loss: 0.1167 - val_output_1_loss: 0.0827\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0804 - output_1_loss: 0.0663 - val_loss: 0.1161 - val_output_1_loss: 0.0823\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0783 - output_1_loss: 0.0639 - val_loss: 0.1155 - val_output_1_loss: 0.0818\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0775 - output_1_loss: 0.0630Epoch 2/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0775 - output_1_loss: 0.0630 - val_loss: 0.1152 - val_output_1_loss: 0.0816\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.9039 - output_1_loss: 0.8858 - val_loss: 0.7388 - val_output_1_loss: 0.6790\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0781 - output_1_loss: 0.0637 - val_loss: 0.1146 - val_output_1_loss: 0.0810\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8922 - output_1_loss: 0.8737Epoch 94/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.8922 - output_1_loss: 0.8737 - val_loss: 0.7282 - val_output_1_loss: 0.6711\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0775 - output_1_loss: 0.0636 - val_loss: 0.1138 - val_output_1_loss: 0.0803\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.8052 - output_1_loss: 0.7863 - val_loss: 0.7182 - val_output_1_loss: 0.6638\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0778 - output_1_loss: 0.0644 - val_loss: 0.1131 - val_output_1_loss: 0.0798\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0763 - output_1_loss: 0.0620 - val_loss: 0.1128 - val_output_1_loss: 0.0795\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.7382 - output_1_loss: 0.7199 - val_loss: 0.7091 - val_output_1_loss: 0.6568\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0892 - output_1_loss: 0.0755 - val_loss: 0.1123 - val_output_1_loss: 0.0791\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.6495 - output_1_loss: 0.6329 - val_loss: 0.6997 - val_output_1_loss: 0.6495\n",
      "Epoch 98/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0692 - output_1_loss: 0.0558 - val_loss: 0.1115 - val_output_1_loss: 0.0783\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.6198 - output_1_loss: 0.6035 - val_loss: 0.6901 - val_output_1_loss: 0.6411\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0663 - output_1_loss: 0.0530Epoch 8/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0663 - output_1_loss: 0.0530 - val_loss: 0.1104 - val_output_1_loss: 0.0773\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.6132 - output_1_loss: 0.5978 - val_loss: 0.6799 - val_output_1_loss: 0.6327\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0646 - output_1_loss: 0.0518Epoch 9/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0646 - output_1_loss: 0.0518 - val_loss: 0.1096 - val_output_1_loss: 0.0769\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.6330 - output_1_loss: 0.6164 - val_loss: 0.6703 - val_output_1_loss: 0.6240\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.5930 - output_1_loss: 0.5778 - val_loss: 0.6604 - val_output_1_loss: 0.6161\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.5528 - output_1_loss: 0.5363 - val_loss: 0.6514 - val_output_1_loss: 0.6076\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5265 - output_1_loss: 0.5108 - val_loss: 0.6409 - val_output_1_loss: 0.5979\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5064 - output_1_loss: 0.4909 - val_loss: 0.6315 - val_output_1_loss: 0.5888\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4417 - output_1_loss: 0.4272 - val_loss: 0.6218 - val_output_1_loss: 0.5797\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3772 - output_1_loss: 0.3624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:11:01,917]\u001b[0m Trial 31 finished with value: 0.09090909090909091 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 2, 'relaxation_factor': 1.6, 'sparsity_coefficient': 0.016160917850315284, 'bn_momentum': 0.968996705704612}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.3772 - output_1_loss: 0.3624 - val_loss: 0.6111 - val_output_1_loss: 0.5695\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4437 - output_1_loss: 0.4280Epoch 1/100\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.4437 - output_1_loss: 0.4280 - val_loss: 0.6019 - val_output_1_loss: 0.5613\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.3901 - output_1_loss: 0.3748 - val_loss: 0.5930 - val_output_1_loss: 0.5522\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.3204 - output_1_loss: 0.3054 - val_loss: 0.5809 - val_output_1_loss: 0.5414\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.3298 - output_1_loss: 0.3163 - val_loss: 0.5681 - val_output_1_loss: 0.5293\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.3510 - output_1_loss: 0.3362 - val_loss: 0.5573 - val_output_1_loss: 0.5188\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.4140 - output_1_loss: 0.3984 - val_loss: 0.5477 - val_output_1_loss: 0.5091\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.3185 - output_1_loss: 0.3045 - val_loss: 0.5339 - val_output_1_loss: 0.4953\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.3523 - output_1_loss: 0.3363 - val_loss: 0.5235 - val_output_1_loss: 0.4854\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.3319 - output_1_loss: 0.3158 - val_loss: 0.5132 - val_output_1_loss: 0.4751\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2727 - output_1_loss: 0.2561 - val_loss: 0.5024 - val_output_1_loss: 0.4648\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2906 - output_1_loss: 0.2731 - val_loss: 0.4922 - val_output_1_loss: 0.4549\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.1949 - output_1_loss: 0.1794 - val_loss: 0.4763 - val_output_1_loss: 0.4390\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.3317 - output_1_loss: 0.3180 - val_loss: 0.4683 - val_output_1_loss: 0.4313\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.2278 - output_1_loss: 0.2114 - val_loss: 0.4547 - val_output_1_loss: 0.4181\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.2627 - output_1_loss: 0.2480 - val_loss: 0.4434 - val_output_1_loss: 0.4077\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.3504 - output_1_loss: 0.3357 - val_loss: 0.4358 - val_output_1_loss: 0.4003\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.2326 - output_1_loss: 0.2190 - val_loss: 0.4251 - val_output_1_loss: 0.3899\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1393 - output_1_loss: 0.1249 - val_loss: 0.4043 - val_output_1_loss: 0.3693\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1391 - output_1_loss: 0.1242 - val_loss: 0.3852 - val_output_1_loss: 0.3510\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.1404 - output_1_loss: 0.1266 - val_loss: 0.3627 - val_output_1_loss: 0.3289\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.1241 - output_1_loss: 0.1098 - val_loss: 0.3413 - val_output_1_loss: 0.3082\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.1949 - output_1_loss: 0.1806 - val_loss: 0.3262 - val_output_1_loss: 0.2938\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2111 - output_1_loss: 0.1975 - val_loss: 0.3196 - val_output_1_loss: 0.2876\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.1454 - output_1_loss: 0.1316 - val_loss: 0.3122 - val_output_1_loss: 0.2803\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2335 - output_1_loss: 0.2197 - val_loss: 0.3078 - val_output_1_loss: 0.2756\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2561 - output_1_loss: 0.2418 - val_loss: 0.3015 - val_output_1_loss: 0.2695\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.1783 - output_1_loss: 0.1633 - val_loss: 0.2931 - val_output_1_loss: 0.2613\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.1523 - output_1_loss: 0.1363 - val_loss: 0.2874 - val_output_1_loss: 0.2554\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.1960 - output_1_loss: 0.1807 - val_loss: 0.2829 - val_output_1_loss: 0.2505\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.1570 - output_1_loss: 0.1431 - val_loss: 0.2743 - val_output_1_loss: 0.2420\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.2707 - output_1_loss: 0.2565 - val_loss: 0.2657 - val_output_1_loss: 0.2331\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.1198 - output_1_loss: 0.1057 - val_loss: 0.2521 - val_output_1_loss: 0.2201\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.1264 - output_1_loss: 0.1128 - val_loss: 0.2428 - val_output_1_loss: 0.2113\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.2278 - output_1_loss: 0.2147 - val_loss: 0.2399 - val_output_1_loss: 0.2084\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1874 - output_1_loss: 0.1739 - val_loss: 0.2358 - val_output_1_loss: 0.2046\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0997 - output_1_loss: 0.0865 - val_loss: 0.2284 - val_output_1_loss: 0.1974\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1184 - output_1_loss: 0.1057 - val_loss: 0.2223 - val_output_1_loss: 0.1918\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1403 - output_1_loss: 0.1270 - val_loss: 0.2178 - val_output_1_loss: 0.1878\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1738 - output_1_loss: 0.1617 - val_loss: 0.2154 - val_output_1_loss: 0.1859\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2088 - output_1_loss: 0.1963 - val_loss: 0.2089 - val_output_1_loss: 0.1801\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1443 - output_1_loss: 0.1302 - val_loss: 0.2034 - val_output_1_loss: 0.1747\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3688 - output_1_loss: 0.3536 - val_loss: 0.2036 - val_output_1_loss: 0.1750\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2742 - output_1_loss: 0.2612 - val_loss: 0.2017 - val_output_1_loss: 0.1743\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1304 - output_1_loss: 0.1167 - val_loss: 0.1971 - val_output_1_loss: 0.1704\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1069 - output_1_loss: 0.0941 - val_loss: 0.1896 - val_output_1_loss: 0.1632\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1270 - output_1_loss: 0.1134 - val_loss: 0.1872 - val_output_1_loss: 0.1607\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1246 - output_1_loss: 0.1107 - val_loss: 0.1790 - val_output_1_loss: 0.1529\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1327 - output_1_loss: 0.1188 - val_loss: 0.1714 - val_output_1_loss: 0.1457\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1580 - output_1_loss: 0.1441 - val_loss: 0.1697 - val_output_1_loss: 0.1442\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1065 - output_1_loss: 0.0929 - val_loss: 0.1669 - val_output_1_loss: 0.1417\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1236 - output_1_loss: 0.1114 - val_loss: 0.1623 - val_output_1_loss: 0.1374\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1389 - output_1_loss: 0.1258 - val_loss: 0.1605 - val_output_1_loss: 0.1358\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0996 - output_1_loss: 0.0862 - val_loss: 0.1569 - val_output_1_loss: 0.1321\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1104 - output_1_loss: 0.0967 - val_loss: 0.1519 - val_output_1_loss: 0.1269\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.0973 - output_1_loss: 0.0847 - val_loss: 0.1467 - val_output_1_loss: 0.1215\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.0954 - output_1_loss: 0.0835 - val_loss: 0.1426 - val_output_1_loss: 0.1172\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.0897 - output_1_loss: 0.0775 - val_loss: 0.1389 - val_output_1_loss: 0.1138\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0888 - output_1_loss: 0.0770 - val_loss: 0.1351 - val_output_1_loss: 0.1102\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1326 - output_1_loss: 0.1205 - val_loss: 0.1308 - val_output_1_loss: 0.1060\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1188 - output_1_loss: 0.1066 - val_loss: 0.1269 - val_output_1_loss: 0.1022\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1087 - output_1_loss: 0.0965 - val_loss: 0.1233 - val_output_1_loss: 0.0989\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0793 - output_1_loss: 0.0673 - val_loss: 0.1201 - val_output_1_loss: 0.0960\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.7062 - output_1_loss: 0.7013 - val_loss: 0.7001 - val_output_1_loss: 0.6847\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0929 - output_1_loss: 0.0809 - val_loss: 0.1180 - val_output_1_loss: 0.0943\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0976 - output_1_loss: 0.0857 - val_loss: 0.1152 - val_output_1_loss: 0.0918\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0977 - output_1_loss: 0.0858 - val_loss: 0.1129 - val_output_1_loss: 0.0896\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1095 - output_1_loss: 0.0973 - val_loss: 0.1115 - val_output_1_loss: 0.0884\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1526 - output_1_loss: 0.1400 - val_loss: 0.1096 - val_output_1_loss: 0.0867\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0959 - output_1_loss: 0.0832 - val_loss: 0.1087 - val_output_1_loss: 0.0860\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1190 - output_1_loss: 0.1060 - val_loss: 0.1087 - val_output_1_loss: 0.0862\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1114 - output_1_loss: 0.0987 - val_loss: 0.1095 - val_output_1_loss: 0.0867\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1005 - output_1_loss: 0.0869 - val_loss: 0.1109 - val_output_1_loss: 0.0880\n",
      "Epoch 87/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1225 - output_1_loss: 0.1093 - val_loss: 0.1112 - val_output_1_loss: 0.0883\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0994 - output_1_loss: 0.0872 - val_loss: 0.1124 - val_output_1_loss: 0.0893\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.6470 - output_1_loss: 0.6421 - val_loss: 0.6904 - val_output_1_loss: 0.6760\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.5926 - output_1_loss: 0.5878 - val_loss: 0.6812 - val_output_1_loss: 0.6676\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.5562 - output_1_loss: 0.5515 - val_loss: 0.6715 - val_output_1_loss: 0.6585\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.5110 - output_1_loss: 0.5065 - val_loss: 0.6617 - val_output_1_loss: 0.6492\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4901 - output_1_loss: 0.4854 - val_loss: 0.6527 - val_output_1_loss: 0.6405\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5286 - output_1_loss: 0.5239 - val_loss: 0.6428 - val_output_1_loss: 0.6307\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4903 - output_1_loss: 0.4856 - val_loss: 0.6327 - val_output_1_loss: 0.6208\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:11:33,720]\u001b[0m Trial 32 finished with value: 0.2 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 0.012353734826356048, 'bn_momentum': 0.9598655030322786}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 524ms/step - loss: 0.3699 - output_1_loss: 0.3650 - val_loss: 0.6210 - val_output_1_loss: 0.6093\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3976 - output_1_loss: 0.3928Epoch 1/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.3976 - output_1_loss: 0.3928 - val_loss: 0.6106 - val_output_1_loss: 0.5990\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.3696 - output_1_loss: 0.3649 - val_loss: 0.5995 - val_output_1_loss: 0.5880\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.3121 - output_1_loss: 0.3071 - val_loss: 0.5871 - val_output_1_loss: 0.5756\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.3142 - output_1_loss: 0.3095 - val_loss: 0.5747 - val_output_1_loss: 0.5636\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.3381 - output_1_loss: 0.3334 - val_loss: 0.5636 - val_output_1_loss: 0.5526\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2539 - output_1_loss: 0.2491 - val_loss: 0.5494 - val_output_1_loss: 0.5383\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.3309 - output_1_loss: 0.3264 - val_loss: 0.5377 - val_output_1_loss: 0.5266\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.2891 - output_1_loss: 0.2845 - val_loss: 0.5249 - val_output_1_loss: 0.5140\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2492 - output_1_loss: 0.2446 - val_loss: 0.5116 - val_output_1_loss: 0.5008\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.1768 - output_1_loss: 0.1723 - val_loss: 0.4963 - val_output_1_loss: 0.4858\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.2711 - output_1_loss: 0.2666 - val_loss: 0.4840 - val_output_1_loss: 0.4735\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.2261 - output_1_loss: 0.2214 - val_loss: 0.4694 - val_output_1_loss: 0.4590\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2503 - output_1_loss: 0.2459 - val_loss: 0.4570 - val_output_1_loss: 0.4467\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.2104 - output_1_loss: 0.2064 - val_loss: 0.4440 - val_output_1_loss: 0.4337\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.2134 - output_1_loss: 0.2093 - val_loss: 0.4307 - val_output_1_loss: 0.4206\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2836 - output_1_loss: 0.2794 - val_loss: 0.4177 - val_output_1_loss: 0.4076\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.1459 - output_1_loss: 0.1417 - val_loss: 0.4038 - val_output_1_loss: 0.3938\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.2395 - output_1_loss: 0.2353 - val_loss: 0.3902 - val_output_1_loss: 0.3805\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.2087 - output_1_loss: 0.2046 - val_loss: 0.3723 - val_output_1_loss: 0.3628\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.2356 - output_1_loss: 0.2314 - val_loss: 0.3596 - val_output_1_loss: 0.3502\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1765 - output_1_loss: 0.1727 - val_loss: 0.3444 - val_output_1_loss: 0.3351\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1376 - output_1_loss: 0.1336 - val_loss: 0.3292 - val_output_1_loss: 0.3200\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1478 - output_1_loss: 0.1438 - val_loss: 0.3208 - val_output_1_loss: 0.3116\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1855 - output_1_loss: 0.1812 - val_loss: 0.3120 - val_output_1_loss: 0.3029\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1628 - output_1_loss: 0.1585 - val_loss: 0.3001 - val_output_1_loss: 0.2909\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0990 - output_1_loss: 0.0946 - val_loss: 0.2806 - val_output_1_loss: 0.2714\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.1340 - output_1_loss: 0.1293 - val_loss: 0.2714 - val_output_1_loss: 0.2622\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.1293 - output_1_loss: 0.1250 - val_loss: 0.2578 - val_output_1_loss: 0.2488\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.1065 - output_1_loss: 0.1021 - val_loss: 0.2412 - val_output_1_loss: 0.2321\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.1498 - output_1_loss: 0.1454 - val_loss: 0.2319 - val_output_1_loss: 0.2230\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.1355 - output_1_loss: 0.1310 - val_loss: 0.2245 - val_output_1_loss: 0.2157\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.1040 - output_1_loss: 0.0997 - val_loss: 0.2122 - val_output_1_loss: 0.2035\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.1355 - output_1_loss: 0.1308 - val_loss: 0.2015 - val_output_1_loss: 0.1928\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.0898 - output_1_loss: 0.0851 - val_loss: 0.1933 - val_output_1_loss: 0.1846\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.1159 - output_1_loss: 0.1111 - val_loss: 0.1890 - val_output_1_loss: 0.1804\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.1478 - output_1_loss: 0.1429 - val_loss: 0.1825 - val_output_1_loss: 0.1738\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.1646 - output_1_loss: 0.1598 - val_loss: 0.1764 - val_output_1_loss: 0.1677\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.1714 - output_1_loss: 0.1669 - val_loss: 0.1712 - val_output_1_loss: 0.1625\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.0911 - output_1_loss: 0.0867 - val_loss: 0.1633 - val_output_1_loss: 0.1545\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.1209 - output_1_loss: 0.1164 - val_loss: 0.1597 - val_output_1_loss: 0.1509\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.1575 - output_1_loss: 0.1531 - val_loss: 0.1570 - val_output_1_loss: 0.1482\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.1100 - output_1_loss: 0.1056 - val_loss: 0.1537 - val_output_1_loss: 0.1450\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.1368 - output_1_loss: 0.1328 - val_loss: 0.1444 - val_output_1_loss: 0.1357\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.1339 - output_1_loss: 0.1297 - val_loss: 0.1439 - val_output_1_loss: 0.1353\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.1561 - output_1_loss: 0.1521 - val_loss: 0.1400 - val_output_1_loss: 0.1314\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1233 - output_1_loss: 0.1194 - val_loss: 0.1365 - val_output_1_loss: 0.1280\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1361 - output_1_loss: 0.1319 - val_loss: 0.1354 - val_output_1_loss: 0.1269\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1078 - output_1_loss: 0.1039 - val_loss: 0.1319 - val_output_1_loss: 0.1234\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.1095 - output_1_loss: 0.1057 - val_loss: 0.1318 - val_output_1_loss: 0.1234\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2191 - output_1_loss: 0.2151 - val_loss: 0.1327 - val_output_1_loss: 0.1243\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0883 - output_1_loss: 0.0842 - val_loss: 0.1310 - val_output_1_loss: 0.1226\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0963 - output_1_loss: 0.0922 - val_loss: 0.1271 - val_output_1_loss: 0.1188\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1044 - output_1_loss: 0.1005 - val_loss: 0.1255 - val_output_1_loss: 0.1172\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1031 - output_1_loss: 0.0992 - val_loss: 0.1207 - val_output_1_loss: 0.1124\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0806 - output_1_loss: 0.0768 - val_loss: 0.1171 - val_output_1_loss: 0.1088\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1483 - output_1_loss: 0.1446 - val_loss: 0.1128 - val_output_1_loss: 0.1047\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1038 - output_1_loss: 0.0997 - val_loss: 0.1102 - val_output_1_loss: 0.1020\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1103 - output_1_loss: 0.1059 - val_loss: 0.1097 - val_output_1_loss: 0.1016\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1448 - output_1_loss: 0.1407 - val_loss: 0.1077 - val_output_1_loss: 0.0996\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1070 - output_1_loss: 0.1031 - val_loss: 0.1041 - val_output_1_loss: 0.0961\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0826 - output_1_loss: 0.0784 - val_loss: 0.0997 - val_output_1_loss: 0.0918\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1840 - output_1_loss: 0.1799 - val_loss: 0.1002 - val_output_1_loss: 0.0924\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2117 - output_1_loss: 0.2074 - val_loss: 0.0999 - val_output_1_loss: 0.0921\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1830 - output_1_loss: 0.1787 - val_loss: 0.0957 - val_output_1_loss: 0.0879\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1765 - output_1_loss: 0.1722 - val_loss: 0.0933 - val_output_1_loss: 0.0856\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0909 - output_1_loss: 0.0866 - val_loss: 0.0919 - val_output_1_loss: 0.0843\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0965 - output_1_loss: 0.0921 - val_loss: 0.0931 - val_output_1_loss: 0.0855\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1170 - output_1_loss: 0.1128 - val_loss: 0.0878 - val_output_1_loss: 0.0803\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0972 - output_1_loss: 0.0926 - val_loss: 0.0873 - val_output_1_loss: 0.0798\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0956 - output_1_loss: 0.0916 - val_loss: 0.0882 - val_output_1_loss: 0.0807\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1013 - output_1_loss: 0.0973 - val_loss: 0.0883 - val_output_1_loss: 0.0808\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1023 - output_1_loss: 0.0985 - val_loss: 0.0855 - val_output_1_loss: 0.0781\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0855 - output_1_loss: 0.0816 - val_loss: 0.0857 - val_output_1_loss: 0.0782\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1090 - output_1_loss: 0.1052 - val_loss: 0.0847 - val_output_1_loss: 0.0773\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1212 - output_1_loss: 0.1173 - val_loss: 0.0844 - val_output_1_loss: 0.0770\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0994 - output_1_loss: 0.0953 - val_loss: 0.0810 - val_output_1_loss: 0.0737\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0871 - output_1_loss: 0.0827 - val_loss: 0.0777 - val_output_1_loss: 0.0705\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0789 - output_1_loss: 0.0743 - val_loss: 0.0782 - val_output_1_loss: 0.0709\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0864 - output_1_loss: 0.0819 - val_loss: 0.0786 - val_output_1_loss: 0.0713\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0968 - output_1_loss: 0.0923 - val_loss: 0.0774 - val_output_1_loss: 0.0702\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1244 - output_1_loss: 0.1202 - val_loss: 0.0774 - val_output_1_loss: 0.0702\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1549 - output_1_loss: 0.1506 - val_loss: 0.0817 - val_output_1_loss: 0.0746\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1106 - output_1_loss: 0.1061 - val_loss: 0.0837 - val_output_1_loss: 0.0766\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1144 - output_1_loss: 0.1097 - val_loss: 0.0830 - val_output_1_loss: 0.0759\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0802 - output_1_loss: 0.0756 - val_loss: 0.0865 - val_output_1_loss: 0.0794\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0986 - output_1_loss: 0.0941 - val_loss: 0.0839 - val_output_1_loss: 0.0769\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:12:12,834]\u001b[0m Trial 33 finished with value: 0.125 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 2, 'relaxation_factor': 1.3, 'sparsity_coefficient': 0.0027647938303586024, 'bn_momentum': 0.9495039673551249}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 39s 39s/step - loss: 0.7622 - output_1_loss: 0.7562 - val_loss: 0.7044 - val_output_1_loss: 0.6852\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.6957 - output_1_loss: 0.6898 - val_loss: 0.6950 - val_output_1_loss: 0.6768\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.6487 - output_1_loss: 0.6427 - val_loss: 0.6850 - val_output_1_loss: 0.6675\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.5645 - output_1_loss: 0.5586 - val_loss: 0.6742 - val_output_1_loss: 0.6573\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.5828 - output_1_loss: 0.5769 - val_loss: 0.6652 - val_output_1_loss: 0.6488\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5558 - output_1_loss: 0.5499 - val_loss: 0.6558 - val_output_1_loss: 0.6398\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.5595 - output_1_loss: 0.5535 - val_loss: 0.6466 - val_output_1_loss: 0.6308\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.4585 - output_1_loss: 0.4526 - val_loss: 0.6352 - val_output_1_loss: 0.6198\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 0.4684 - output_1_loss: 0.4628 - val_loss: 0.6239 - val_output_1_loss: 0.6089\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.4399 - output_1_loss: 0.4341 - val_loss: 0.6138 - val_output_1_loss: 0.5990\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 0.4483 - output_1_loss: 0.4423 - val_loss: 0.6028 - val_output_1_loss: 0.5882\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.4808 - output_1_loss: 0.4751 - val_loss: 0.5916 - val_output_1_loss: 0.5772\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.3820 - output_1_loss: 0.3763 - val_loss: 0.5800 - val_output_1_loss: 0.5659\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.3545 - output_1_loss: 0.3492 - val_loss: 0.5680 - val_output_1_loss: 0.5541\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.3383 - output_1_loss: 0.3329 - val_loss: 0.5564 - val_output_1_loss: 0.5427\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 0.4196 - output_1_loss: 0.4143 - val_loss: 0.5458 - val_output_1_loss: 0.5324\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.3317 - output_1_loss: 0.3265 - val_loss: 0.5352 - val_output_1_loss: 0.5220\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.3006 - output_1_loss: 0.2955 - val_loss: 0.5240 - val_output_1_loss: 0.5110\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.2244 - output_1_loss: 0.2192 - val_loss: 0.5098 - val_output_1_loss: 0.4970\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.3002 - output_1_loss: 0.2948 - val_loss: 0.4978 - val_output_1_loss: 0.4849\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.2859 - output_1_loss: 0.2806 - val_loss: 0.4854 - val_output_1_loss: 0.4726\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.2607 - output_1_loss: 0.2553 - val_loss: 0.4740 - val_output_1_loss: 0.4614\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2509 - output_1_loss: 0.2456 - val_loss: 0.4623 - val_output_1_loss: 0.4500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1911 - output_1_loss: 0.1858 - val_loss: 0.4479 - val_output_1_loss: 0.4356\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2019 - output_1_loss: 0.1965 - val_loss: 0.4350 - val_output_1_loss: 0.4227\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.2294 - output_1_loss: 0.2241 - val_loss: 0.4230 - val_output_1_loss: 0.4107\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.2001 - output_1_loss: 0.1947 - val_loss: 0.4099 - val_output_1_loss: 0.3976\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2096 - output_1_loss: 0.2039 - val_loss: 0.3980 - val_output_1_loss: 0.3855\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1989 - output_1_loss: 0.1935 - val_loss: 0.3863 - val_output_1_loss: 0.3738\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.2224 - output_1_loss: 0.2167 - val_loss: 0.3731 - val_output_1_loss: 0.3607\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.2078 - output_1_loss: 0.2022 - val_loss: 0.3626 - val_output_1_loss: 0.3503\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.2284 - output_1_loss: 0.2229 - val_loss: 0.3487 - val_output_1_loss: 0.3364\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1727 - output_1_loss: 0.1668 - val_loss: 0.3358 - val_output_1_loss: 0.3236\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1930 - output_1_loss: 0.1872 - val_loss: 0.3282 - val_output_1_loss: 0.3160\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1528 - output_1_loss: 0.1466 - val_loss: 0.3180 - val_output_1_loss: 0.3059\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1629 - output_1_loss: 0.1568 - val_loss: 0.3074 - val_output_1_loss: 0.2952\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1781 - output_1_loss: 0.1719 - val_loss: 0.2965 - val_output_1_loss: 0.2844\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.1167 - output_1_loss: 0.1106 - val_loss: 0.2845 - val_output_1_loss: 0.2725\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1523 - output_1_loss: 0.1465 - val_loss: 0.2741 - val_output_1_loss: 0.2620\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1451 - output_1_loss: 0.1390 - val_loss: 0.2653 - val_output_1_loss: 0.2532\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.3085 - output_1_loss: 0.3025 - val_loss: 0.2564 - val_output_1_loss: 0.2445\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8040 - output_1_loss: 0.8019Epoch 42/100\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 0.1919 - output_1_loss: 0.1859 - val_loss: 0.2502 - val_output_1_loss: 0.2383\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.1529 - output_1_loss: 0.1469 - val_loss: 0.2471 - val_output_1_loss: 0.2353\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.1648 - output_1_loss: 0.1585 - val_loss: 0.2426 - val_output_1_loss: 0.2309\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.1284 - output_1_loss: 0.1224 - val_loss: 0.2361 - val_output_1_loss: 0.2244\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.2616 - output_1_loss: 0.2556 - val_loss: 0.2302 - val_output_1_loss: 0.2185\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1260 - output_1_loss: 0.1201 - val_loss: 0.2219 - val_output_1_loss: 0.2103\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1253 - output_1_loss: 0.1195 - val_loss: 0.2152 - val_output_1_loss: 0.2036\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.8040 - output_1_loss: 0.8019 - val_loss: 0.6892 - val_output_1_loss: 0.6813\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.1581 - output_1_loss: 0.1523 - val_loss: 0.2116 - val_output_1_loss: 0.2001\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.7321 - output_1_loss: 0.7302 - val_loss: 0.6769 - val_output_1_loss: 0.6697\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.1158 - output_1_loss: 0.1101 - val_loss: 0.2067 - val_output_1_loss: 0.1953\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6095 - output_1_loss: 0.6077 - val_loss: 0.6629 - val_output_1_loss: 0.6562\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1608 - output_1_loss: 0.1550Epoch 4/100\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.1608 - output_1_loss: 0.1550 - val_loss: 0.1984 - val_output_1_loss: 0.1871\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5709 - output_1_loss: 0.5692 - val_loss: 0.6495 - val_output_1_loss: 0.6432\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1232 - output_1_loss: 0.1173Epoch 5/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.1232 - output_1_loss: 0.1173 - val_loss: 0.1976 - val_output_1_loss: 0.1866\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.6251 - output_1_loss: 0.6235 - val_loss: 0.6359 - val_output_1_loss: 0.6299\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4891 - output_1_loss: 0.4875Epoch 53/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.4891 - output_1_loss: 0.4875 - val_loss: 0.6195 - val_output_1_loss: 0.6139\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.0921 - output_1_loss: 0.0866 - val_loss: 0.1876 - val_output_1_loss: 0.1765\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.4772 - output_1_loss: 0.4757 - val_loss: 0.6064 - val_output_1_loss: 0.6012\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1042 - output_1_loss: 0.0986Epoch 8/100\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.1042 - output_1_loss: 0.0986 - val_loss: 0.1809 - val_output_1_loss: 0.1699\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.4443 - output_1_loss: 0.4428 - val_loss: 0.5952 - val_output_1_loss: 0.5902\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1175 - output_1_loss: 0.1113 - val_loss: 0.1768 - val_output_1_loss: 0.1658\n",
      "Epoch 9/100\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.3537 - output_1_loss: 0.3520 - val_loss: 0.5789 - val_output_1_loss: 0.5742\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.1023 - output_1_loss: 0.0968 - val_loss: 0.1721 - val_output_1_loss: 0.1611\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3399 - output_1_loss: 0.3384Epoch 57/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.3399 - output_1_loss: 0.3384 - val_loss: 0.5614 - val_output_1_loss: 0.5566\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0936 - output_1_loss: 0.0878 - val_loss: 0.1680 - val_output_1_loss: 0.1571\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1322 - output_1_loss: 0.1266Epoch 11/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1322 - output_1_loss: 0.1266 - val_loss: 0.1694 - val_output_1_loss: 0.1585\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1676 - output_1_loss: 0.1620 - val_loss: 0.1682 - val_output_1_loss: 0.1572\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.3487 - output_1_loss: 0.3470 - val_loss: 0.5482 - val_output_1_loss: 0.5435\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.1707 - output_1_loss: 0.1654 - val_loss: 0.1652 - val_output_1_loss: 0.1542\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.2947 - output_1_loss: 0.2931 - val_loss: 0.5298 - val_output_1_loss: 0.5250\n",
      "Epoch 13/100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.3005 - output_1_loss: 0.2989 - val_loss: 0.5149 - val_output_1_loss: 0.5103\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1291 - output_1_loss: 0.1240 - val_loss: 0.1665 - val_output_1_loss: 0.1556\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1362 - output_1_loss: 0.1305 - val_loss: 0.1652 - val_output_1_loss: 0.1543\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.3060 - output_1_loss: 0.3043 - val_loss: 0.4971 - val_output_1_loss: 0.4926\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1313 - output_1_loss: 0.1260 - val_loss: 0.1587 - val_output_1_loss: 0.1478\n",
      "Epoch 15/100\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.2590 - output_1_loss: 0.2573 - val_loss: 0.4800 - val_output_1_loss: 0.4754\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1370 - output_1_loss: 0.1313 - val_loss: 0.1558 - val_output_1_loss: 0.1449\n",
      "Epoch 16/100\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.2397 - output_1_loss: 0.2380 - val_loss: 0.4596 - val_output_1_loss: 0.4551\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.2162 - output_1_loss: 0.2106 - val_loss: 0.1445 - val_output_1_loss: 0.1337\n",
      "Epoch 17/100\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.3139 - output_1_loss: 0.3122 - val_loss: 0.4493 - val_output_1_loss: 0.4448\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.1217 - output_1_loss: 0.1161 - val_loss: 0.1392 - val_output_1_loss: 0.1284\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.2987 - output_1_loss: 0.2972 - val_loss: 0.4275 - val_output_1_loss: 0.4231\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0931 - output_1_loss: 0.0873 - val_loss: 0.1419 - val_output_1_loss: 0.1312\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1012 - output_1_loss: 0.0957Epoch 19/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.1012 - output_1_loss: 0.0957 - val_loss: 0.1384 - val_output_1_loss: 0.1277\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.3428 - output_1_loss: 0.3409 - val_loss: 0.4129 - val_output_1_loss: 0.4085\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2329 - output_1_loss: 0.2311Epoch 69/100\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.2329 - output_1_loss: 0.2311 - val_loss: 0.3960 - val_output_1_loss: 0.3919\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.1506 - output_1_loss: 0.1449 - val_loss: 0.1356 - val_output_1_loss: 0.1249\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.2278 - output_1_loss: 0.2261 - val_loss: 0.3764 - val_output_1_loss: 0.3722\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1250 - output_1_loss: 0.1194Epoch 22/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1250 - output_1_loss: 0.1194 - val_loss: 0.1365 - val_output_1_loss: 0.1259\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1112 - output_1_loss: 0.1056 - val_loss: 0.1369 - val_output_1_loss: 0.1265\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.2128 - output_1_loss: 0.2110 - val_loss: 0.3626 - val_output_1_loss: 0.3584\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1955 - output_1_loss: 0.1937 - val_loss: 0.3464 - val_output_1_loss: 0.3423\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.1128 - output_1_loss: 0.1071 - val_loss: 0.1334 - val_output_1_loss: 0.1231\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0868 - output_1_loss: 0.0812Epoch 24/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0868 - output_1_loss: 0.0812 - val_loss: 0.1253 - val_output_1_loss: 0.1150\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1544 - output_1_loss: 0.1527 - val_loss: 0.3183 - val_output_1_loss: 0.3143\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1006 - output_1_loss: 0.0950 - val_loss: 0.1236 - val_output_1_loss: 0.1135\n",
      "Epoch 25/100\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1514 - output_1_loss: 0.1495 - val_loss: 0.3106 - val_output_1_loss: 0.3067\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0934 - output_1_loss: 0.0877 - val_loss: 0.1193 - val_output_1_loss: 0.1091\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0926 - output_1_loss: 0.0870Epoch 26/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.0926 - output_1_loss: 0.0870 - val_loss: 0.1137 - val_output_1_loss: 0.1035\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1407 - output_1_loss: 0.1390 - val_loss: 0.2935 - val_output_1_loss: 0.2897\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1939 - output_1_loss: 0.1883 - val_loss: 0.1187 - val_output_1_loss: 0.1086\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1070 - output_1_loss: 0.1016 - val_loss: 0.1204 - val_output_1_loss: 0.1103\n",
      "Epoch 79/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1006 - output_1_loss: 0.0949 - val_loss: 0.1172 - val_output_1_loss: 0.1071\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.2189 - output_1_loss: 0.2171 - val_loss: 0.2730 - val_output_1_loss: 0.2693\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.1562 - output_1_loss: 0.1505 - val_loss: 0.1190 - val_output_1_loss: 0.1090\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1546 - output_1_loss: 0.1527 - val_loss: 0.2671 - val_output_1_loss: 0.2635\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1272 - output_1_loss: 0.1216Epoch 29/100\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.1272 - output_1_loss: 0.1216 - val_loss: 0.1239 - val_output_1_loss: 0.1140\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.1339 - output_1_loss: 0.1322 - val_loss: 0.2558 - val_output_1_loss: 0.2521\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.2170 - output_1_loss: 0.2152 - val_loss: 0.2502 - val_output_1_loss: 0.2467\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.0849 - output_1_loss: 0.0834 - val_loss: 0.2182 - val_output_1_loss: 0.2148\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.1223 - output_1_loss: 0.1207 - val_loss: 0.2051 - val_output_1_loss: 0.2019\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.1816 - output_1_loss: 0.1798 - val_loss: 0.2031 - val_output_1_loss: 0.2000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.2211 - output_1_loss: 0.2193 - val_loss: 0.1921 - val_output_1_loss: 0.1889\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:12:59,325]\u001b[0m Trial 34 finished with value: 0.25 and parameters: {'feature_dim': 256, 'n_step': 9, 'n_shared': 3, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.003576562663922608, 'bn_momentum': 0.9495679718298294}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 740ms/step - loss: 0.1748 - output_1_loss: 0.1729 - val_loss: 0.1854 - val_output_1_loss: 0.1822\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2734 - output_1_loss: 0.2716 - val_loss: 0.1759 - val_output_1_loss: 0.1726\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1772 - output_1_loss: 0.1756Epoch 1/100\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 0.1772 - output_1_loss: 0.1756 - val_loss: 0.1742 - val_output_1_loss: 0.1709\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 0.1831 - output_1_loss: 0.1815 - val_loss: 0.1709 - val_output_1_loss: 0.1676\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.0983 - output_1_loss: 0.0966 - val_loss: 0.1626 - val_output_1_loss: 0.1594\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.1454 - output_1_loss: 0.1437 - val_loss: 0.1624 - val_output_1_loss: 0.1592\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.1132 - output_1_loss: 0.1115 - val_loss: 0.1568 - val_output_1_loss: 0.1536\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.1263 - output_1_loss: 0.1245 - val_loss: 0.1509 - val_output_1_loss: 0.1478\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.2393 - output_1_loss: 0.2373 - val_loss: 0.1483 - val_output_1_loss: 0.1451\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 0.1061 - output_1_loss: 0.1039 - val_loss: 0.1451 - val_output_1_loss: 0.1420\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1227 - output_1_loss: 0.1209 - val_loss: 0.1515 - val_output_1_loss: 0.1484\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.1586 - output_1_loss: 0.1567 - val_loss: 0.1437 - val_output_1_loss: 0.1404\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.1025 - output_1_loss: 0.1007 - val_loss: 0.1356 - val_output_1_loss: 0.1325\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1363 - output_1_loss: 0.1346 - val_loss: 0.1369 - val_output_1_loss: 0.1338\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1416 - output_1_loss: 0.1398 - val_loss: 0.1540 - val_output_1_loss: 0.1510\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1113 - output_1_loss: 0.1094 - val_loss: 0.1594 - val_output_1_loss: 0.1566\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1051 - output_1_loss: 0.1032 - val_loss: 0.1516 - val_output_1_loss: 0.1487\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1100 - output_1_loss: 0.1081 - val_loss: 0.1493 - val_output_1_loss: 0.1463\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:13:13,875]\u001b[0m Trial 35 finished with value: 0.012658227848101266 and parameters: {'feature_dim': 512, 'n_step': 7, 'n_shared': 3, 'relaxation_factor': 1.8, 'sparsity_coefficient': 0.0018421263573759196, 'bn_momentum': 0.9316697471389155}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.7271 - output_1_loss: 0.7172 - val_loss: 0.7119 - val_output_1_loss: 0.6808\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.6347 - output_1_loss: 0.6256 - val_loss: 0.6964 - val_output_1_loss: 0.6678\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.5364 - output_1_loss: 0.5262 - val_loss: 0.6807 - val_output_1_loss: 0.6533\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.4421 - output_1_loss: 0.4326 - val_loss: 0.6586 - val_output_1_loss: 0.6328\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4157 - output_1_loss: 0.4062 - val_loss: 0.6392 - val_output_1_loss: 0.6148\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.3500 - output_1_loss: 0.3409 - val_loss: 0.6187 - val_output_1_loss: 0.5959\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.4259 - output_1_loss: 0.4169 - val_loss: 0.6022 - val_output_1_loss: 0.5804\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.4445 - output_1_loss: 0.4361 - val_loss: 0.5820 - val_output_1_loss: 0.5610\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4337 - output_1_loss: 0.4255 - val_loss: 0.5466 - val_output_1_loss: 0.5261\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.1476 - output_1_loss: 0.1388 - val_loss: 0.5143 - val_output_1_loss: 0.4944\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2395 - output_1_loss: 0.2303 - val_loss: 0.4887 - val_output_1_loss: 0.4692\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1413 - output_1_loss: 0.1326 - val_loss: 0.4272 - val_output_1_loss: 0.4080\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.1396 - output_1_loss: 0.1310 - val_loss: 0.3736 - val_output_1_loss: 0.3550\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.1655 - output_1_loss: 0.1578 - val_loss: 0.3226 - val_output_1_loss: 0.3046\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1115 - output_1_loss: 0.1025 - val_loss: 0.2892 - val_output_1_loss: 0.2715\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.1084 - output_1_loss: 0.0992 - val_loss: 0.2538 - val_output_1_loss: 0.2365\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0974 - output_1_loss: 0.0885 - val_loss: 0.2246 - val_output_1_loss: 0.2075\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1386 - output_1_loss: 0.1297 - val_loss: 0.2045 - val_output_1_loss: 0.1876\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0921 - output_1_loss: 0.0832 - val_loss: 0.1869 - val_output_1_loss: 0.1702\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0805 - output_1_loss: 0.0729 - val_loss: 0.1740 - val_output_1_loss: 0.1576\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0836 - output_1_loss: 0.0757 - val_loss: 0.1624 - val_output_1_loss: 0.1461\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0779 - output_1_loss: 0.0703 - val_loss: 0.1527 - val_output_1_loss: 0.1365\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0798 - output_1_loss: 0.0723 - val_loss: 0.1455 - val_output_1_loss: 0.1293\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0766 - output_1_loss: 0.0697 - val_loss: 0.1380 - val_output_1_loss: 0.1221\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0726 - output_1_loss: 0.0655 - val_loss: 0.1304 - val_output_1_loss: 0.1148\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0719 - output_1_loss: 0.0646 - val_loss: 0.1235 - val_output_1_loss: 0.1081\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0688 - output_1_loss: 0.0615 - val_loss: 0.1186 - val_output_1_loss: 0.1032\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0691 - output_1_loss: 0.0617 - val_loss: 0.1149 - val_output_1_loss: 0.0996\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9748 - output_1_loss: 0.9593Epoch 29/100\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0725 - output_1_loss: 0.0649 - val_loss: 0.1115 - val_output_1_loss: 0.0963\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 0.0662 - output_1_loss: 0.0589 - val_loss: 0.1092 - val_output_1_loss: 0.0940\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0693 - output_1_loss: 0.0615 - val_loss: 0.1066 - val_output_1_loss: 0.0915\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0639 - output_1_loss: 0.0563 - val_loss: 0.1045 - val_output_1_loss: 0.0894\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1205 - output_1_loss: 0.1127 - val_loss: 0.1022 - val_output_1_loss: 0.0870\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.9748 - output_1_loss: 0.9593 - val_loss: 0.7453 - val_output_1_loss: 0.6910\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0766 - output_1_loss: 0.0690 - val_loss: 0.1000 - val_output_1_loss: 0.0847\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0728 - output_1_loss: 0.0656 - val_loss: 0.0984 - val_output_1_loss: 0.0830\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0671 - output_1_loss: 0.0597 - val_loss: 0.0967 - val_output_1_loss: 0.0814\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0675 - output_1_loss: 0.0604 - val_loss: 0.0948 - val_output_1_loss: 0.0795\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0649 - output_1_loss: 0.0578 - val_loss: 0.0933 - val_output_1_loss: 0.0782\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0628 - output_1_loss: 0.0561 - val_loss: 0.0916 - val_output_1_loss: 0.0766\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0599 - output_1_loss: 0.0536 - val_loss: 0.0901 - val_output_1_loss: 0.0754\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0627 - output_1_loss: 0.0563 - val_loss: 0.0886 - val_output_1_loss: 0.0741\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0688 - output_1_loss: 0.0624 - val_loss: 0.0878 - val_output_1_loss: 0.0736\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0642 - output_1_loss: 0.0580Epoch 2/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0642 - output_1_loss: 0.0580 - val_loss: 0.0863 - val_output_1_loss: 0.0723\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8716 - output_1_loss: 0.8552Epoch 44/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8716 - output_1_loss: 0.8552 - val_loss: 0.7395 - val_output_1_loss: 0.6882\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0645 - output_1_loss: 0.0584 - val_loss: 0.0850 - val_output_1_loss: 0.0712\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.8688 - output_1_loss: 0.8525 - val_loss: 0.7345 - val_output_1_loss: 0.6853\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.8497 - output_1_loss: 0.8327 - val_loss: 0.7296 - val_output_1_loss: 0.6821\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0624 - output_1_loss: 0.0563 - val_loss: 0.0838 - val_output_1_loss: 0.0702\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8063 - output_1_loss: 0.7895 - val_loss: 0.7257 - val_output_1_loss: 0.6796\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7989 - output_1_loss: 0.7824 - val_loss: 0.7213 - val_output_1_loss: 0.6768\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7658 - output_1_loss: 0.7486Epoch 46/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7658 - output_1_loss: 0.7486 - val_loss: 0.7171 - val_output_1_loss: 0.6737\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0617 - output_1_loss: 0.0557 - val_loss: 0.0824 - val_output_1_loss: 0.0690\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7594 - output_1_loss: 0.7434Epoch 47/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.7594 - output_1_loss: 0.7434 - val_loss: 0.7129 - val_output_1_loss: 0.6708\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0667 - output_1_loss: 0.0600 - val_loss: 0.0811 - val_output_1_loss: 0.0678\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.7386 - output_1_loss: 0.7222 - val_loss: 0.7091 - val_output_1_loss: 0.6679\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0682 - output_1_loss: 0.0621 - val_loss: 0.0799 - val_output_1_loss: 0.0668\n",
      "Epoch 10/100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.7372 - output_1_loss: 0.7202 - val_loss: 0.7055 - val_output_1_loss: 0.6651\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0700 - output_1_loss: 0.0639 - val_loss: 0.0791 - val_output_1_loss: 0.0661\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.7117 - output_1_loss: 0.6958 - val_loss: 0.7021 - val_output_1_loss: 0.6623\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0648 - output_1_loss: 0.0592 - val_loss: 0.0787 - val_output_1_loss: 0.0657\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6702 - output_1_loss: 0.6545Epoch 51/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.6702 - output_1_loss: 0.6545 - val_loss: 0.6979 - val_output_1_loss: 0.6587\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0705 - output_1_loss: 0.0650 - val_loss: 0.0783 - val_output_1_loss: 0.0654\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.6505 - output_1_loss: 0.6362 - val_loss: 0.6927 - val_output_1_loss: 0.6542\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0670 - output_1_loss: 0.0615 - val_loss: 0.0782 - val_output_1_loss: 0.0656\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0671 - output_1_loss: 0.0615 - val_loss: 0.0786 - val_output_1_loss: 0.0664\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.6197 - output_1_loss: 0.6057 - val_loss: 0.6882 - val_output_1_loss: 0.6503\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0628 - output_1_loss: 0.0572 - val_loss: 0.0784 - val_output_1_loss: 0.0664\n",
      "Epoch 15/100\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0646 - output_1_loss: 0.0588 - val_loss: 0.0791 - val_output_1_loss: 0.0671\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.6321 - output_1_loss: 0.6178 - val_loss: 0.6831 - val_output_1_loss: 0.6465\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0625 - output_1_loss: 0.0569 - val_loss: 0.0788 - val_output_1_loss: 0.0669\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0610 - output_1_loss: 0.0550 - val_loss: 0.0783 - val_output_1_loss: 0.0664\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.6265 - output_1_loss: 0.6123 - val_loss: 0.6776 - val_output_1_loss: 0.6425\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.6247 - output_1_loss: 0.6099 - val_loss: 0.6731 - val_output_1_loss: 0.6388\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.6235 - output_1_loss: 0.6089 - val_loss: 0.6691 - val_output_1_loss: 0.6354\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.5868 - output_1_loss: 0.5719 - val_loss: 0.6652 - val_output_1_loss: 0.6321\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5482 - output_1_loss: 0.5332 - val_loss: 0.6609 - val_output_1_loss: 0.6281\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5925 - output_1_loss: 0.5770 - val_loss: 0.6576 - val_output_1_loss: 0.6253\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5491 - output_1_loss: 0.5337 - val_loss: 0.6537 - val_output_1_loss: 0.6217\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.5355 - output_1_loss: 0.5200 - val_loss: 0.6486 - val_output_1_loss: 0.6169\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:13:43,686]\u001b[0m Trial 36 finished with value: 0.03333333333333333 and parameters: {'feature_dim': 512, 'n_step': 4, 'n_shared': 2, 'relaxation_factor': 1.9, 'sparsity_coefficient': 0.005900181853728779, 'bn_momentum': 0.9321997628472821}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 411ms/step - loss: 0.5477 - output_1_loss: 0.5325 - val_loss: 0.6448 - val_output_1_loss: 0.6129\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5350 - output_1_loss: 0.5199Epoch 1/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5350 - output_1_loss: 0.5199 - val_loss: 0.6413 - val_output_1_loss: 0.6097\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5393 - output_1_loss: 0.5241 - val_loss: 0.6365 - val_output_1_loss: 0.6054\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.4993 - output_1_loss: 0.4843 - val_loss: 0.6320 - val_output_1_loss: 0.6012\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.4807 - output_1_loss: 0.4660 - val_loss: 0.6268 - val_output_1_loss: 0.5964\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.4953 - output_1_loss: 0.4815 - val_loss: 0.6222 - val_output_1_loss: 0.5922\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.4981 - output_1_loss: 0.4835 - val_loss: 0.6190 - val_output_1_loss: 0.5892\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4555 - output_1_loss: 0.4414 - val_loss: 0.6141 - val_output_1_loss: 0.5847\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5308 - output_1_loss: 0.5156 - val_loss: 0.6100 - val_output_1_loss: 0.5809\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.4523 - output_1_loss: 0.4367 - val_loss: 0.6051 - val_output_1_loss: 0.5764\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.4402 - output_1_loss: 0.4252 - val_loss: 0.5994 - val_output_1_loss: 0.5710\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.4106 - output_1_loss: 0.3948 - val_loss: 0.5928 - val_output_1_loss: 0.5650\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.4433 - output_1_loss: 0.4272 - val_loss: 0.5868 - val_output_1_loss: 0.5593\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.4353 - output_1_loss: 0.4198 - val_loss: 0.5821 - val_output_1_loss: 0.5545\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3990 - output_1_loss: 0.3840 - val_loss: 0.5745 - val_output_1_loss: 0.5474\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3760 - output_1_loss: 0.3604 - val_loss: 0.5685 - val_output_1_loss: 0.5419\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3422 - output_1_loss: 0.3280 - val_loss: 0.5626 - val_output_1_loss: 0.5367\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2923 - output_1_loss: 0.2780 - val_loss: 0.5566 - val_output_1_loss: 0.5311\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2523 - output_1_loss: 0.2384 - val_loss: 0.5503 - val_output_1_loss: 0.5252\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3470 - output_1_loss: 0.3330 - val_loss: 0.5458 - val_output_1_loss: 0.5208\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3011 - output_1_loss: 0.2880 - val_loss: 0.5405 - val_output_1_loss: 0.5156\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.3036 - output_1_loss: 0.2906 - val_loss: 0.5346 - val_output_1_loss: 0.5098\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2465 - output_1_loss: 0.2336 - val_loss: 0.5276 - val_output_1_loss: 0.5033\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2145 - output_1_loss: 0.2020 - val_loss: 0.5197 - val_output_1_loss: 0.4956\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1908 - output_1_loss: 0.1782 - val_loss: 0.5118 - val_output_1_loss: 0.4880\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1722 - output_1_loss: 0.1596 - val_loss: 0.5039 - val_output_1_loss: 0.4802\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1559 - output_1_loss: 0.1433 - val_loss: 0.4943 - val_output_1_loss: 0.4707\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1563 - output_1_loss: 0.1434 - val_loss: 0.4833 - val_output_1_loss: 0.4598\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1298 - output_1_loss: 0.1168 - val_loss: 0.4705 - val_output_1_loss: 0.4473\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2280 - output_1_loss: 0.2153 - val_loss: 0.4605 - val_output_1_loss: 0.4374\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1803 - output_1_loss: 0.1682 - val_loss: 0.4485 - val_output_1_loss: 0.4257\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.1079 - output_1_loss: 0.0959 - val_loss: 0.4313 - val_output_1_loss: 0.4090\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1032 - output_1_loss: 0.0913 - val_loss: 0.4144 - val_output_1_loss: 0.3925\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0990 - output_1_loss: 0.0872 - val_loss: 0.3972 - val_output_1_loss: 0.3758\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0958 - output_1_loss: 0.0841 - val_loss: 0.3804 - val_output_1_loss: 0.3593\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.7036 - output_1_loss: 0.7027 - val_loss: 0.6911 - val_output_1_loss: 0.6892\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0944 - output_1_loss: 0.0827 - val_loss: 0.3646 - val_output_1_loss: 0.3439\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.6443 - output_1_loss: 0.6434 - val_loss: 0.6872 - val_output_1_loss: 0.6854\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0926 - output_1_loss: 0.0809 - val_loss: 0.3488 - val_output_1_loss: 0.3286\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0909 - output_1_loss: 0.0794Epoch 3/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0909 - output_1_loss: 0.0794 - val_loss: 0.3337 - val_output_1_loss: 0.3140\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6108 - output_1_loss: 0.6099 - val_loss: 0.6838 - val_output_1_loss: 0.6821\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5205 - output_1_loss: 0.5196Epoch 62/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5205 - output_1_loss: 0.5196 - val_loss: 0.6802 - val_output_1_loss: 0.6786\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4727 - output_1_loss: 0.4718 - val_loss: 0.6756 - val_output_1_loss: 0.6740\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0900 - output_1_loss: 0.0785 - val_loss: 0.3193 - val_output_1_loss: 0.2999\n",
      "Epoch 63/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4272 - output_1_loss: 0.4264 - val_loss: 0.6709 - val_output_1_loss: 0.6693\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0906 - output_1_loss: 0.0792 - val_loss: 0.3059 - val_output_1_loss: 0.2868\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.3467 - output_1_loss: 0.3458 - val_loss: 0.6647 - val_output_1_loss: 0.6632\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0872 - output_1_loss: 0.0758Epoch 8/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2851 - output_1_loss: 0.2843 - val_loss: 0.6568 - val_output_1_loss: 0.6553\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0872 - output_1_loss: 0.0758 - val_loss: 0.2929 - val_output_1_loss: 0.2741\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2333 - output_1_loss: 0.2325 - val_loss: 0.6477 - val_output_1_loss: 0.6462\n",
      "Epoch 65/100\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1916 - output_1_loss: 0.1907 - val_loss: 0.6377 - val_output_1_loss: 0.6362\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0849 - output_1_loss: 0.0735 - val_loss: 0.2795 - val_output_1_loss: 0.2612\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1632 - output_1_loss: 0.1624Epoch 66/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1632 - output_1_loss: 0.1624 - val_loss: 0.6265 - val_output_1_loss: 0.6250\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0963 - output_1_loss: 0.0849Epoch 12/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0963 - output_1_loss: 0.0849 - val_loss: 0.2661 - val_output_1_loss: 0.2481\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1439 - output_1_loss: 0.1431 - val_loss: 0.6146 - val_output_1_loss: 0.6132\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1274 - output_1_loss: 0.1267 - val_loss: 0.6027 - val_output_1_loss: 0.6014\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1164 - output_1_loss: 0.1050 - val_loss: 0.2534 - val_output_1_loss: 0.2357\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1085 - output_1_loss: 0.1077 - val_loss: 0.5905 - val_output_1_loss: 0.5891\n",
      "Epoch 68/100\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0948 - output_1_loss: 0.0941 - val_loss: 0.5778 - val_output_1_loss: 0.5765\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0882 - output_1_loss: 0.0767 - val_loss: 0.2423 - val_output_1_loss: 0.2249\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0863 - output_1_loss: 0.0856 - val_loss: 0.5649 - val_output_1_loss: 0.5635\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0754 - output_1_loss: 0.0747Epoch 69/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0754 - output_1_loss: 0.0747 - val_loss: 0.5528 - val_output_1_loss: 0.5515\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0695 - output_1_loss: 0.0688 - val_loss: 0.5413 - val_output_1_loss: 0.5400\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0884 - output_1_loss: 0.0765 - val_loss: 0.2318 - val_output_1_loss: 0.2146\n",
      "Epoch 70/100\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0644 - output_1_loss: 0.0637 - val_loss: 0.5302 - val_output_1_loss: 0.5289\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0871 - output_1_loss: 0.0753 - val_loss: 0.2222 - val_output_1_loss: 0.2051\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0595 - output_1_loss: 0.0588 - val_loss: 0.5191 - val_output_1_loss: 0.5178\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0869 - output_1_loss: 0.0752 - val_loss: 0.2136 - val_output_1_loss: 0.1966\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0855 - output_1_loss: 0.0739Epoch 21/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0855 - output_1_loss: 0.0739 - val_loss: 0.2055 - val_output_1_loss: 0.1887\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0551 - output_1_loss: 0.0544 - val_loss: 0.5081 - val_output_1_loss: 0.5068\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0849 - output_1_loss: 0.0733Epoch 22/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0519 - output_1_loss: 0.0512 - val_loss: 0.4971 - val_output_1_loss: 0.4958\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0849 - output_1_loss: 0.0733 - val_loss: 0.1982 - val_output_1_loss: 0.1815\n",
      "Epoch 74/100\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0489 - output_1_loss: 0.0482 - val_loss: 0.4865 - val_output_1_loss: 0.4852\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0840 - output_1_loss: 0.0724 - val_loss: 0.1917 - val_output_1_loss: 0.1751\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0462 - output_1_loss: 0.0456 - val_loss: 0.4763 - val_output_1_loss: 0.4750\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0435 - output_1_loss: 0.0428 - val_loss: 0.4666 - val_output_1_loss: 0.4654\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0826 - output_1_loss: 0.0711 - val_loss: 0.1857 - val_output_1_loss: 0.1691\n",
      "Epoch 26/100\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0417 - output_1_loss: 0.0410 - val_loss: 0.4577 - val_output_1_loss: 0.4565\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0816 - output_1_loss: 0.0701 - val_loss: 0.1801 - val_output_1_loss: 0.1635\n",
      "Epoch 27/100\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0398 - output_1_loss: 0.0391 - val_loss: 0.4496 - val_output_1_loss: 0.4483\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0807 - output_1_loss: 0.0693 - val_loss: 0.1749 - val_output_1_loss: 0.1584\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0381 - output_1_loss: 0.0374 - val_loss: 0.4418 - val_output_1_loss: 0.4406\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1218 - output_1_loss: 0.1104 - val_loss: 0.1701 - val_output_1_loss: 0.1537\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0368 - output_1_loss: 0.0361 - val_loss: 0.4340 - val_output_1_loss: 0.4328\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0349 - output_1_loss: 0.0342 - val_loss: 0.4265 - val_output_1_loss: 0.4254\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0829 - output_1_loss: 0.0713 - val_loss: 0.1662 - val_output_1_loss: 0.1499\n",
      "Epoch 31/100\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0333 - output_1_loss: 0.0327 - val_loss: 0.4192 - val_output_1_loss: 0.4181\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0876 - output_1_loss: 0.0760 - val_loss: 0.1635 - val_output_1_loss: 0.1473\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0323 - output_1_loss: 0.0316 - val_loss: 0.4121 - val_output_1_loss: 0.4109\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0305 - output_1_loss: 0.0299Epoch 81/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0305 - output_1_loss: 0.0299 - val_loss: 0.4056 - val_output_1_loss: 0.4045\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0855 - output_1_loss: 0.0735Epoch 34/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0855 - output_1_loss: 0.0735 - val_loss: 0.1623 - val_output_1_loss: 0.1463\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0295 - output_1_loss: 0.0288 - val_loss: 0.3997 - val_output_1_loss: 0.3985\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0285 - output_1_loss: 0.0279Epoch 82/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0285 - output_1_loss: 0.0279 - val_loss: 0.3939 - val_output_1_loss: 0.3928\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1073 - output_1_loss: 0.0951Epoch 36/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1073 - output_1_loss: 0.0951 - val_loss: 0.1627 - val_output_1_loss: 0.1469\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0271 - output_1_loss: 0.0264 - val_loss: 0.3884 - val_output_1_loss: 0.3873\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0261 - output_1_loss: 0.0254 - val_loss: 0.3830 - val_output_1_loss: 0.3819\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0886 - output_1_loss: 0.0763 - val_loss: 0.1588 - val_output_1_loss: 0.1430\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0247 - output_1_loss: 0.0241 - val_loss: 0.3777 - val_output_1_loss: 0.3766\n",
      "Epoch 84/100\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0239 - output_1_loss: 0.0233 - val_loss: 0.3727 - val_output_1_loss: 0.3716\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0869 - output_1_loss: 0.0750 - val_loss: 0.1558 - val_output_1_loss: 0.1404\n",
      "Epoch 85/100\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0232 - output_1_loss: 0.0225 - val_loss: 0.3684 - val_output_1_loss: 0.3673\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1047 - output_1_loss: 0.0922 - val_loss: 0.1539 - val_output_1_loss: 0.1387\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0221 - output_1_loss: 0.0215 - val_loss: 0.3649 - val_output_1_loss: 0.3638\n",
      "Epoch 86/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0214 - output_1_loss: 0.0208 - val_loss: 0.3621 - val_output_1_loss: 0.3610\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0866 - output_1_loss: 0.0750 - val_loss: 0.1497 - val_output_1_loss: 0.1349\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0206 - output_1_loss: 0.0200 - val_loss: 0.3597 - val_output_1_loss: 0.3587\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0900 - output_1_loss: 0.0779 - val_loss: 0.1472 - val_output_1_loss: 0.1324\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0197 - output_1_loss: 0.0191 - val_loss: 0.3574 - val_output_1_loss: 0.3564\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0920 - output_1_loss: 0.0803 - val_loss: 0.1451 - val_output_1_loss: 0.1304\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0192 - output_1_loss: 0.0186 - val_loss: 0.3552 - val_output_1_loss: 0.3541\n",
      "Epoch 89/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0187 - output_1_loss: 0.0181 - val_loss: 0.3531 - val_output_1_loss: 0.3521\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0894 - output_1_loss: 0.0780 - val_loss: 0.1449 - val_output_1_loss: 0.1301\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0181 - output_1_loss: 0.0175 - val_loss: 0.3514 - val_output_1_loss: 0.3503\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0807 - output_1_loss: 0.0695 - val_loss: 0.1429 - val_output_1_loss: 0.1282\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0175 - output_1_loss: 0.0169Epoch 91/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0175 - output_1_loss: 0.0169 - val_loss: 0.3500 - val_output_1_loss: 0.3489\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0877 - output_1_loss: 0.0763 - val_loss: 0.1416 - val_output_1_loss: 0.1269\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0169 - output_1_loss: 0.0163 - val_loss: 0.3485 - val_output_1_loss: 0.3475\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0163 - output_1_loss: 0.0156 - val_loss: 0.3471 - val_output_1_loss: 0.3461\n",
      "Epoch 51/100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0158 - output_1_loss: 0.0151 - val_loss: 0.3459 - val_output_1_loss: 0.3448\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1188 - output_1_loss: 0.1074 - val_loss: 0.1392 - val_output_1_loss: 0.1245\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0152 - output_1_loss: 0.0146 - val_loss: 0.3449 - val_output_1_loss: 0.3439\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0146 - output_1_loss: 0.0140 - val_loss: 0.3442 - val_output_1_loss: 0.3431\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1218 - output_1_loss: 0.1104 - val_loss: 0.1360 - val_output_1_loss: 0.1214\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0141 - output_1_loss: 0.0135 - val_loss: 0.3435 - val_output_1_loss: 0.3424\n",
      "Epoch 55/100\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0135 - output_1_loss: 0.0129 - val_loss: 0.3427 - val_output_1_loss: 0.3416\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0788 - output_1_loss: 0.0673 - val_loss: 0.1319 - val_output_1_loss: 0.1174\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0870 - output_1_loss: 0.0755 - val_loss: 0.1284 - val_output_1_loss: 0.1140\n",
      "Epoch 56/100\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0131 - output_1_loss: 0.0125 - val_loss: 0.3419 - val_output_1_loss: 0.3409\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1334 - output_1_loss: 0.1219 - val_loss: 0.1263 - val_output_1_loss: 0.1119\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0126 - output_1_loss: 0.0120 - val_loss: 0.3413 - val_output_1_loss: 0.3403\n",
      "Epoch 58/100\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0121 - output_1_loss: 0.0115 - val_loss: 0.3409 - val_output_1_loss: 0.3398\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0854 - output_1_loss: 0.0741 - val_loss: 0.1225 - val_output_1_loss: 0.1082\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0832 - output_1_loss: 0.0720 - val_loss: 0.1189 - val_output_1_loss: 0.1046\n",
      "Epoch 59/100\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0116 - output_1_loss: 0.0111 - val_loss: 0.3404 - val_output_1_loss: 0.3394\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0825 - output_1_loss: 0.0711 - val_loss: 0.1166 - val_output_1_loss: 0.1024\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0113 - output_1_loss: 0.0107 - val_loss: 0.3401 - val_output_1_loss: 0.3391\n",
      "Epoch 100/100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0109 - output_1_loss: 0.0103 - val_loss: 0.3397 - val_output_1_loss: 0.3387\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0819 - output_1_loss: 0.0704 - val_loss: 0.1145 - val_output_1_loss: 0.1003\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0107 - output_1_loss: 0.0101 - val_loss: 0.3396 - val_output_1_loss: 0.3386\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0103 - output_1_loss: 0.0097 - val_loss: 0.3393 - val_output_1_loss: 0.3383\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0098 - output_1_loss: 0.0092 - val_loss: 0.3388 - val_output_1_loss: 0.3379\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0092 - output_1_loss: 0.0087 - val_loss: 0.3382 - val_output_1_loss: 0.3373\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0090 - output_1_loss: 0.0084 - val_loss: 0.3376 - val_output_1_loss: 0.3366\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0087 - output_1_loss: 0.0081 - val_loss: 0.3368 - val_output_1_loss: 0.3358\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0085 - output_1_loss: 0.0080 - val_loss: 0.3359 - val_output_1_loss: 0.3349\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0082 - output_1_loss: 0.0076 - val_loss: 0.3348 - val_output_1_loss: 0.3339\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0077 - output_1_loss: 0.0071 - val_loss: 0.3335 - val_output_1_loss: 0.3325\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0072 - output_1_loss: 0.0066 - val_loss: 0.3318 - val_output_1_loss: 0.3309\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:14:06,745]\u001b[0m Trial 37 finished with value: 0.058823529411764705 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 2, 'relaxation_factor': 1.9, 'sparsity_coefficient': 0.009320032915613771, 'bn_momentum': 0.9574678918876702}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0067 - output_1_loss: 0.0061 - val_loss: 0.3300 - val_output_1_loss: 0.3290\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0069 - output_1_loss: 0.0063 - val_loss: 0.3281 - val_output_1_loss: 0.3272\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0058 - output_1_loss: 0.0053 - val_loss: 0.3262 - val_output_1_loss: 0.3252\n",
      "Epoch 1/100\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0056 - output_1_loss: 0.0050 - val_loss: 0.3242 - val_output_1_loss: 0.3233\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0054 - output_1_loss: 0.0048 - val_loss: 0.3222 - val_output_1_loss: 0.3213\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0051 - output_1_loss: 0.0046 - val_loss: 0.3202 - val_output_1_loss: 0.3193\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0048 - output_1_loss: 0.0043 - val_loss: 0.3179 - val_output_1_loss: 0.3170\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0046 - output_1_loss: 0.0040 - val_loss: 0.3154 - val_output_1_loss: 0.3145\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0043 - output_1_loss: 0.0038 - val_loss: 0.3128 - val_output_1_loss: 0.3119\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0042 - output_1_loss: 0.0036 - val_loss: 0.3100 - val_output_1_loss: 0.3091\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0040 - output_1_loss: 0.0035 - val_loss: 0.3071 - val_output_1_loss: 0.3062\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0038 - output_1_loss: 0.0033 - val_loss: 0.3041 - val_output_1_loss: 0.3033\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0037 - output_1_loss: 0.0031 - val_loss: 0.3010 - val_output_1_loss: 0.3002\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0035 - output_1_loss: 0.0030 - val_loss: 0.2979 - val_output_1_loss: 0.2970\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0034 - output_1_loss: 0.0029 - val_loss: 0.2946 - val_output_1_loss: 0.2938\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0033 - output_1_loss: 0.0028 - val_loss: 0.2912 - val_output_1_loss: 0.2904\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0032 - output_1_loss: 0.0027 - val_loss: 0.2876 - val_output_1_loss: 0.2868\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0031 - output_1_loss: 0.0025 - val_loss: 0.2837 - val_output_1_loss: 0.2829\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0030 - output_1_loss: 0.0024 - val_loss: 0.2794 - val_output_1_loss: 0.2786\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - output_1_loss: 0.0024 - val_loss: 0.2749 - val_output_1_loss: 0.2741\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0028 - output_1_loss: 0.0023 - val_loss: 0.2703 - val_output_1_loss: 0.2695\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0027 - output_1_loss: 0.0022 - val_loss: 0.2656 - val_output_1_loss: 0.2648\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0027 - output_1_loss: 0.0021 - val_loss: 0.2607 - val_output_1_loss: 0.2599\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0026 - output_1_loss: 0.0021 - val_loss: 0.2557 - val_output_1_loss: 0.2549\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0025 - output_1_loss: 0.0020 - val_loss: 0.2505 - val_output_1_loss: 0.2497\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0025 - output_1_loss: 0.0020 - val_loss: 0.2452 - val_output_1_loss: 0.2444\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0024 - output_1_loss: 0.0019 - val_loss: 0.2397 - val_output_1_loss: 0.2389\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0024 - output_1_loss: 0.0019 - val_loss: 0.2340 - val_output_1_loss: 0.2332\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0023 - output_1_loss: 0.0018 - val_loss: 0.2282 - val_output_1_loss: 0.2274\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:14:15,573]\u001b[0m Trial 38 finished with value: 0.5 and parameters: {'feature_dim': 64, 'n_step': 2, 'n_shared': 1, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0002213123732917068, 'bn_momentum': 0.955778675300332}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.6628 - output_1_loss: 0.6618 - val_loss: 0.6882 - val_output_1_loss: 0.6860\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5123 - output_1_loss: 0.5113 - val_loss: 0.6802 - val_output_1_loss: 0.6781\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.3572 - output_1_loss: 0.3562 - val_loss: 0.6680 - val_output_1_loss: 0.6661\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2331 - output_1_loss: 0.2321 - val_loss: 0.6501 - val_output_1_loss: 0.6483\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1028 - output_1_loss: 0.1020 - val_loss: 0.6232 - val_output_1_loss: 0.6215\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0680 - output_1_loss: 0.0672 - val_loss: 0.5950 - val_output_1_loss: 0.5933\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0524 - output_1_loss: 0.0515 - val_loss: 0.5610 - val_output_1_loss: 0.5593\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0431 - output_1_loss: 0.0422 - val_loss: 0.5251 - val_output_1_loss: 0.5235\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0362 - output_1_loss: 0.0354 - val_loss: 0.4907 - val_output_1_loss: 0.4891\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0334 - output_1_loss: 0.0326 - val_loss: 0.4603 - val_output_1_loss: 0.4588\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0302 - output_1_loss: 0.0294 - val_loss: 0.4341 - val_output_1_loss: 0.4327\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0254 - output_1_loss: 0.0246 - val_loss: 0.4098 - val_output_1_loss: 0.4084\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0223 - output_1_loss: 0.0214 - val_loss: 0.3875 - val_output_1_loss: 0.3861\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0183 - output_1_loss: 0.0175 - val_loss: 0.3677 - val_output_1_loss: 0.3663\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0158 - output_1_loss: 0.0150 - val_loss: 0.3514 - val_output_1_loss: 0.3501\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0132 - output_1_loss: 0.0124 - val_loss: 0.3358 - val_output_1_loss: 0.3345\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0111 - output_1_loss: 0.0103 - val_loss: 0.3202 - val_output_1_loss: 0.3189\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0091 - output_1_loss: 0.0083 - val_loss: 0.3056 - val_output_1_loss: 0.3043\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0075 - output_1_loss: 0.0067 - val_loss: 0.2920 - val_output_1_loss: 0.2907\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0064 - output_1_loss: 0.0056 - val_loss: 0.2794 - val_output_1_loss: 0.2781\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0051 - output_1_loss: 0.0043 - val_loss: 0.2680 - val_output_1_loss: 0.2667\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0045 - output_1_loss: 0.0037 - val_loss: 0.2577 - val_output_1_loss: 0.2565\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0040 - output_1_loss: 0.0032 - val_loss: 0.2482 - val_output_1_loss: 0.2469\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0033 - output_1_loss: 0.0025 - val_loss: 0.2390 - val_output_1_loss: 0.2377\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0030 - output_1_loss: 0.0022 - val_loss: 0.2300 - val_output_1_loss: 0.2288\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0026 - output_1_loss: 0.0018 - val_loss: 0.2214 - val_output_1_loss: 0.2202\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0024 - output_1_loss: 0.0016 - val_loss: 0.2130 - val_output_1_loss: 0.2117\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0022 - output_1_loss: 0.0014 - val_loss: 0.2048 - val_output_1_loss: 0.2036\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0020 - output_1_loss: 0.0012 - val_loss: 0.1968 - val_output_1_loss: 0.1956\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0018 - output_1_loss: 0.0010 - val_loss: 0.1890 - val_output_1_loss: 0.1878\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0017 - output_1_loss: 9.0540e-04 - val_loss: 0.1815 - val_output_1_loss: 0.1803\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0016 - output_1_loss: 8.0689e-04 - val_loss: 0.1742 - val_output_1_loss: 0.1730\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0015 - output_1_loss: 7.2507e-04 - val_loss: 0.1672 - val_output_1_loss: 0.1660\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0014 - output_1_loss: 6.4205e-04 - val_loss: 0.1606 - val_output_1_loss: 0.1594\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.0013 - output_1_loss: 5.7811e-04 - val_loss: 0.1544 - val_output_1_loss: 0.1532\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0013 - output_1_loss: 5.2627e-04 - val_loss: 0.1485 - val_output_1_loss: 0.1473\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0012 - output_1_loss: 4.8122e-04 - val_loss: 0.1430 - val_output_1_loss: 0.1418\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0012 - output_1_loss: 4.3894e-04 - val_loss: 0.1378 - val_output_1_loss: 0.1366\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0012 - output_1_loss: 4.0305e-04 - val_loss: 0.1329 - val_output_1_loss: 0.1317\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0011 - output_1_loss: 3.7185e-04 - val_loss: 0.1283 - val_output_1_loss: 0.1271\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0011 - output_1_loss: 3.4484e-04 - val_loss: 0.1239 - val_output_1_loss: 0.1227\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0011 - output_1_loss: 3.2096e-04 - val_loss: 0.1197 - val_output_1_loss: 0.1186\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0011 - output_1_loss: 2.9948e-04 - val_loss: 0.1158 - val_output_1_loss: 0.1147\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0010 - output_1_loss: 2.7932e-04 - val_loss: 0.1121 - val_output_1_loss: 0.1109\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0010 - output_1_loss: 2.6132e-04 - val_loss: 0.1086 - val_output_1_loss: 0.1074\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 9.8972e-04 - output_1_loss: 2.4596e-04 - val_loss: 0.1052 - val_output_1_loss: 0.1041\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 9.7360e-04 - output_1_loss: 2.3256e-04 - val_loss: 0.1020 - val_output_1_loss: 0.1009\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 9.5857e-04 - output_1_loss: 2.2030e-04 - val_loss: 0.0990 - val_output_1_loss: 0.0979\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 9.3392e-04 - output_1_loss: 1.9835e-04 - val_loss: 0.0961 - val_output_1_loss: 0.0950\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 9.0977e-04 - output_1_loss: 1.7699e-04 - val_loss: 0.0932 - val_output_1_loss: 0.0921\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0116 - output_1_loss: 0.0109 - val_loss: 0.0908 - val_output_1_loss: 0.0897\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0266 - output_1_loss: 0.0259 - val_loss: 0.0887 - val_output_1_loss: 0.0876\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0110 - output_1_loss: 0.0102 - val_loss: 0.0868 - val_output_1_loss: 0.0856\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0100 - output_1_loss: 0.0092 - val_loss: 0.0860 - val_output_1_loss: 0.0849\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0114 - output_1_loss: 0.0106 - val_loss: 0.0850 - val_output_1_loss: 0.0839\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0192 - output_1_loss: 0.0184 - val_loss: 0.0848 - val_output_1_loss: 0.0836\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0112 - output_1_loss: 0.0104 - val_loss: 0.0854 - val_output_1_loss: 0.0843\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0106 - output_1_loss: 0.0097 - val_loss: 0.0856 - val_output_1_loss: 0.0845\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0097 - output_1_loss: 0.0088 - val_loss: 0.0855 - val_output_1_loss: 0.0844\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - output_1_loss: 0.0080 - val_loss: 0.0857 - val_output_1_loss: 0.0846\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0081 - output_1_loss: 0.0073 - val_loss: 0.0865 - val_output_1_loss: 0.0854\n",
      "1/1 [==============================] - 1s 853ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:14:35,770]\u001b[0m Trial 39 finished with value: 0.125 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 1, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00026794163512046924, 'bn_momentum': 0.9444012196463457}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.7985 - output_1_loss: 0.7262Epoch 1/100\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.7985 - output_1_loss: 0.7262 - val_loss: 0.8991 - val_output_1_loss: 0.6846\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.8014 - output_1_loss: 0.7309 - val_loss: 0.8768 - val_output_1_loss: 0.6755\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.7038 - output_1_loss: 0.6340 - val_loss: 0.8581 - val_output_1_loss: 0.6654\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.7423 - output_1_loss: 0.6753 - val_loss: 0.8427 - val_output_1_loss: 0.6567\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.6280 - output_1_loss: 0.5583 - val_loss: 0.8259 - val_output_1_loss: 0.6471\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.6142 - output_1_loss: 0.5465 - val_loss: 0.8098 - val_output_1_loss: 0.6372\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.6110 - output_1_loss: 0.5455 - val_loss: 0.7962 - val_output_1_loss: 0.6282\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.5038 - output_1_loss: 0.4391 - val_loss: 0.7811 - val_output_1_loss: 0.6172\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.4949 - output_1_loss: 0.4288 - val_loss: 0.7665 - val_output_1_loss: 0.6073\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.4716 - output_1_loss: 0.4032 - val_loss: 0.7520 - val_output_1_loss: 0.5968\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.4716 - output_1_loss: 0.4042 - val_loss: 0.7369 - val_output_1_loss: 0.5858\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.4591 - output_1_loss: 0.3926 - val_loss: 0.7231 - val_output_1_loss: 0.5759\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.4756 - output_1_loss: 0.4089 - val_loss: 0.7093 - val_output_1_loss: 0.5652\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.4704 - output_1_loss: 0.3993 - val_loss: 0.6966 - val_output_1_loss: 0.5544\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.3872 - output_1_loss: 0.3161 - val_loss: 0.6845 - val_output_1_loss: 0.5428\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.4943 - output_1_loss: 0.4215 - val_loss: 0.6723 - val_output_1_loss: 0.5318\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.3696 - output_1_loss: 0.2986 - val_loss: 0.6589 - val_output_1_loss: 0.5194\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.3692 - output_1_loss: 0.3011 - val_loss: 0.6439 - val_output_1_loss: 0.5085\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.3382 - output_1_loss: 0.2646 - val_loss: 0.6302 - val_output_1_loss: 0.4956\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3953 - output_1_loss: 0.3264 - val_loss: 0.6168 - val_output_1_loss: 0.4842\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.2972 - output_1_loss: 0.2269 - val_loss: 0.6040 - val_output_1_loss: 0.4719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3724 - output_1_loss: 0.2992 - val_loss: 0.5941 - val_output_1_loss: 0.4615\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.3019 - output_1_loss: 0.2313 - val_loss: 0.5852 - val_output_1_loss: 0.4527\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.4174 - output_1_loss: 0.3471 - val_loss: 0.5723 - val_output_1_loss: 0.4416\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.3427 - output_1_loss: 0.2761 - val_loss: 0.5602 - val_output_1_loss: 0.4303\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 0.3791 - output_1_loss: 0.3127 - val_loss: 0.5466 - val_output_1_loss: 0.4188\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.2175 - output_1_loss: 0.1541 - val_loss: 0.5310 - val_output_1_loss: 0.4053\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.2546 - output_1_loss: 0.1947 - val_loss: 0.5179 - val_output_1_loss: 0.3939\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.2787 - output_1_loss: 0.2166 - val_loss: 0.5068 - val_output_1_loss: 0.3841\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.3049 - output_1_loss: 0.2425 - val_loss: 0.4966 - val_output_1_loss: 0.3751\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.4108 - output_1_loss: 0.3462 - val_loss: 0.4868 - val_output_1_loss: 0.3664\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.2144 - output_1_loss: 0.1513 - val_loss: 0.4732 - val_output_1_loss: 0.3548\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.3798 - output_1_loss: 0.3150 - val_loss: 0.4639 - val_output_1_loss: 0.3462\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.2180 - output_1_loss: 0.1615 - val_loss: 0.4538 - val_output_1_loss: 0.3362\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.2536 - output_1_loss: 0.1957 - val_loss: 0.4383 - val_output_1_loss: 0.3214\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.2637 - output_1_loss: 0.2064 - val_loss: 0.4293 - val_output_1_loss: 0.3138\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1712 - output_1_loss: 0.1140 - val_loss: 0.4132 - val_output_1_loss: 0.2979\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.1984 - output_1_loss: 0.1408 - val_loss: 0.3998 - val_output_1_loss: 0.2852\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1451 - output_1_loss: 0.0905 - val_loss: 0.3840 - val_output_1_loss: 0.2702\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1524 - output_1_loss: 0.0964 - val_loss: 0.3701 - val_output_1_loss: 0.2567\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1411 - output_1_loss: 0.0875 - val_loss: 0.3564 - val_output_1_loss: 0.2433\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1356 - output_1_loss: 0.0816 - val_loss: 0.3423 - val_output_1_loss: 0.2305\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1384 - output_1_loss: 0.0846 - val_loss: 0.3277 - val_output_1_loss: 0.2167\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1601 - output_1_loss: 0.1046 - val_loss: 0.3152 - val_output_1_loss: 0.2050\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1497 - output_1_loss: 0.0959 - val_loss: 0.3019 - val_output_1_loss: 0.1926\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1400 - output_1_loss: 0.0891 - val_loss: 0.2889 - val_output_1_loss: 0.1807\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3233 - output_1_loss: 0.2670 - val_loss: 0.2793 - val_output_1_loss: 0.1718\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.1740 - output_1_loss: 0.1144 - val_loss: 0.2705 - val_output_1_loss: 0.1643\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1624 - output_1_loss: 0.1027 - val_loss: 0.2634 - val_output_1_loss: 0.1577\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1414 - output_1_loss: 0.0824 - val_loss: 0.2583 - val_output_1_loss: 0.1525\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1455 - output_1_loss: 0.0854 - val_loss: 0.2497 - val_output_1_loss: 0.1441\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1580 - output_1_loss: 0.0980 - val_loss: 0.2452 - val_output_1_loss: 0.1407\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1388 - output_1_loss: 0.0816 - val_loss: 0.2380 - val_output_1_loss: 0.1348\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1512 - output_1_loss: 0.0953 - val_loss: 0.2313 - val_output_1_loss: 0.1286\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1362 - output_1_loss: 0.0801 - val_loss: 0.2273 - val_output_1_loss: 0.1248\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1298 - output_1_loss: 0.0771 - val_loss: 0.2220 - val_output_1_loss: 0.1195\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1215 - output_1_loss: 0.0710 - val_loss: 0.2188 - val_output_1_loss: 0.1169\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1458 - output_1_loss: 0.0946 - val_loss: 0.2178 - val_output_1_loss: 0.1167\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1323 - output_1_loss: 0.0803 - val_loss: 0.2143 - val_output_1_loss: 0.1141\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1444 - output_1_loss: 0.0920 - val_loss: 0.2110 - val_output_1_loss: 0.1117\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1199 - output_1_loss: 0.0688 - val_loss: 0.2062 - val_output_1_loss: 0.1080\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1225 - output_1_loss: 0.0705 - val_loss: 0.2029 - val_output_1_loss: 0.1050\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1222 - output_1_loss: 0.0702 - val_loss: 0.1995 - val_output_1_loss: 0.1017\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1403 - output_1_loss: 0.0854 - val_loss: 0.1957 - val_output_1_loss: 0.0984\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1314 - output_1_loss: 0.0785 - val_loss: 0.1939 - val_output_1_loss: 0.0973\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1273 - output_1_loss: 0.0748 - val_loss: 0.1921 - val_output_1_loss: 0.0963\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1302 - output_1_loss: 0.0773 - val_loss: 0.1890 - val_output_1_loss: 0.0944\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1619 - output_1_loss: 0.1082 - val_loss: 0.1868 - val_output_1_loss: 0.0933\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1331 - output_1_loss: 0.0795 - val_loss: 0.1834 - val_output_1_loss: 0.0913\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1342 - output_1_loss: 0.0810 - val_loss: 0.1804 - val_output_1_loss: 0.0894\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2077 - output_1_loss: 0.1522 - val_loss: 0.1762 - val_output_1_loss: 0.0871\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1361 - output_1_loss: 0.0827 - val_loss: 0.1713 - val_output_1_loss: 0.0840\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1269 - output_1_loss: 0.0732 - val_loss: 0.1682 - val_output_1_loss: 0.0823\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0037 - output_1_loss: 1.0029Epoch 74/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.1311 - output_1_loss: 0.0778 - val_loss: 0.1675 - val_output_1_loss: 0.0830\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1534 - output_1_loss: 0.1015 - val_loss: 0.1674 - val_output_1_loss: 0.0839\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1330 - output_1_loss: 0.0814 - val_loss: 0.1688 - val_output_1_loss: 0.0861\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1261 - output_1_loss: 0.0764 - val_loss: 0.1699 - val_output_1_loss: 0.0885\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1246 - output_1_loss: 0.0747 - val_loss: 0.1700 - val_output_1_loss: 0.0902\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1215 - output_1_loss: 0.0729 - val_loss: 0.1685 - val_output_1_loss: 0.0901\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1201 - output_1_loss: 0.0734 - val_loss: 0.1647 - val_output_1_loss: 0.0878\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1183 - output_1_loss: 0.0725 - val_loss: 0.1605 - val_output_1_loss: 0.0853\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2368 - output_1_loss: 0.1898 - val_loss: 0.1588 - val_output_1_loss: 0.0847\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1307 - output_1_loss: 0.0854 - val_loss: 0.1578 - val_output_1_loss: 0.0843\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1139 - output_1_loss: 0.0674 - val_loss: 0.1569 - val_output_1_loss: 0.0840\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1127 - output_1_loss: 0.0660 - val_loss: 0.1567 - val_output_1_loss: 0.0842\n",
      "1/1 [==============================] - 35s 35s/step - loss: 1.0037 - output_1_loss: 1.0029 - val_loss: 0.6949 - val_output_1_loss: 0.6909\n",
      "Epoch 2/100\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1121 - output_1_loss: 0.0657 - val_loss: 0.1556 - val_output_1_loss: 0.0834\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.8607 - output_1_loss: 0.8599 - val_loss: 0.6906 - val_output_1_loss: 0.6869\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1274 - output_1_loss: 0.0813 - val_loss: 0.1549 - val_output_1_loss: 0.0831\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.8488 - output_1_loss: 0.8480 - val_loss: 0.6869 - val_output_1_loss: 0.6834\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1063 - output_1_loss: 0.0614 - val_loss: 0.1543 - val_output_1_loss: 0.0830\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1150 - output_1_loss: 0.0700 - val_loss: 0.1537 - val_output_1_loss: 0.0827\n",
      "Epoch 90/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1087 - output_1_loss: 0.0631 - val_loss: 0.1535 - val_output_1_loss: 0.0825\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8346 - output_1_loss: 0.8337Epoch 91/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1051 - output_1_loss: 0.0608 - val_loss: 0.1512 - val_output_1_loss: 0.0807\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.8346 - output_1_loss: 0.8337 - val_loss: 0.6812 - val_output_1_loss: 0.6780\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1010 - output_1_loss: 0.0576 - val_loss: 0.1487 - val_output_1_loss: 0.0792\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1018 - output_1_loss: 0.0593Epoch 5/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1018 - output_1_loss: 0.0593 - val_loss: 0.1464 - val_output_1_loss: 0.0779\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0995 - output_1_loss: 0.0582 - val_loss: 0.1442 - val_output_1_loss: 0.0768\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.8295 - output_1_loss: 0.8286 - val_loss: 0.6728 - val_output_1_loss: 0.6697\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0998 - output_1_loss: 0.0603 - val_loss: 0.1415 - val_output_1_loss: 0.0756\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0960 - output_1_loss: 0.0580Epoch 6/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0960 - output_1_loss: 0.0580 - val_loss: 0.1391 - val_output_1_loss: 0.0748\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0967 - output_1_loss: 0.0600 - val_loss: 0.1367 - val_output_1_loss: 0.0739\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.7570 - output_1_loss: 0.7561 - val_loss: 0.6668 - val_output_1_loss: 0.6637\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0922 - output_1_loss: 0.0564 - val_loss: 0.1345 - val_output_1_loss: 0.0731\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0894 - output_1_loss: 0.0544Epoch 7/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0894 - output_1_loss: 0.0544 - val_loss: 0.1315 - val_output_1_loss: 0.0710\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.7295 - output_1_loss: 0.7287 - val_loss: 0.6636 - val_output_1_loss: 0.6607\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0896 - output_1_loss: 0.0550 - val_loss: 0.1282 - val_output_1_loss: 0.0688\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.6923 - output_1_loss: 0.6913 - val_loss: 0.6589 - val_output_1_loss: 0.6561\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.6930 - output_1_loss: 0.6921 - val_loss: 0.6537 - val_output_1_loss: 0.6511\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.6370 - output_1_loss: 0.6362 - val_loss: 0.6478 - val_output_1_loss: 0.6452\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.6246 - output_1_loss: 0.6237 - val_loss: 0.6437 - val_output_1_loss: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:15:17,238]\u001b[0m Trial 40 finished with value: 1.0 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 1.4, 'sparsity_coefficient': 0.03757950284574927, 'bn_momentum': 0.945069457379541}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.6061 - output_1_loss: 0.6052 - val_loss: 0.6384 - val_output_1_loss: 0.6358\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5845 - output_1_loss: 0.5837Epoch 1/100\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.5845 - output_1_loss: 0.5837 - val_loss: 0.6332 - val_output_1_loss: 0.6308\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.6184 - output_1_loss: 0.6175 - val_loss: 0.6286 - val_output_1_loss: 0.6263\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.5486 - output_1_loss: 0.5477 - val_loss: 0.6235 - val_output_1_loss: 0.6212\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.5711 - output_1_loss: 0.5702 - val_loss: 0.6178 - val_output_1_loss: 0.6156\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.5553 - output_1_loss: 0.5545 - val_loss: 0.6164 - val_output_1_loss: 0.6141\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.5566 - output_1_loss: 0.5559 - val_loss: 0.6057 - val_output_1_loss: 0.6035\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5118 - output_1_loss: 0.5111 - val_loss: 0.6071 - val_output_1_loss: 0.6049\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.5062 - output_1_loss: 0.5054 - val_loss: 0.5960 - val_output_1_loss: 0.5938\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.4972 - output_1_loss: 0.4965 - val_loss: 0.5957 - val_output_1_loss: 0.5934\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.4639 - output_1_loss: 0.4632 - val_loss: 0.5905 - val_output_1_loss: 0.5883\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.5015 - output_1_loss: 0.5008 - val_loss: 0.5826 - val_output_1_loss: 0.5806\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.3792 - output_1_loss: 0.3785 - val_loss: 0.5772 - val_output_1_loss: 0.5752\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.4763 - output_1_loss: 0.4756 - val_loss: 0.5714 - val_output_1_loss: 0.5695\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.4311 - output_1_loss: 0.4304 - val_loss: 0.5664 - val_output_1_loss: 0.5645\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.3767 - output_1_loss: 0.3761 - val_loss: 0.5590 - val_output_1_loss: 0.5570\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.4780 - output_1_loss: 0.4773 - val_loss: 0.5531 - val_output_1_loss: 0.5512\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.3778 - output_1_loss: 0.3771 - val_loss: 0.5502 - val_output_1_loss: 0.5481\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.3890 - output_1_loss: 0.3883 - val_loss: 0.5431 - val_output_1_loss: 0.5410\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.4240 - output_1_loss: 0.4233 - val_loss: 0.5365 - val_output_1_loss: 0.5347\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.3006 - output_1_loss: 0.2999 - val_loss: 0.5309 - val_output_1_loss: 0.5290\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3578 - output_1_loss: 0.3572 - val_loss: 0.5244 - val_output_1_loss: 0.5227\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.4220 - output_1_loss: 0.4212 - val_loss: 0.5184 - val_output_1_loss: 0.5167\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.3732 - output_1_loss: 0.3725 - val_loss: 0.5133 - val_output_1_loss: 0.5116\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3848 - output_1_loss: 0.3842 - val_loss: 0.5074 - val_output_1_loss: 0.5057\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.4035 - output_1_loss: 0.4028 - val_loss: 0.5010 - val_output_1_loss: 0.4991\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.3392 - output_1_loss: 0.3385 - val_loss: 0.4930 - val_output_1_loss: 0.4911\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.3599 - output_1_loss: 0.3593 - val_loss: 0.4846 - val_output_1_loss: 0.4829\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2702 - output_1_loss: 0.2695 - val_loss: 0.4768 - val_output_1_loss: 0.4750\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3629 - output_1_loss: 0.3622 - val_loss: 0.4719 - val_output_1_loss: 0.4702\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3386 - output_1_loss: 0.3379 - val_loss: 0.4650 - val_output_1_loss: 0.4634\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3568 - output_1_loss: 0.3562 - val_loss: 0.4573 - val_output_1_loss: 0.4558\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3799 - output_1_loss: 0.3792 - val_loss: 0.4510 - val_output_1_loss: 0.4494\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2064 - output_1_loss: 0.2058 - val_loss: 0.4414 - val_output_1_loss: 0.4400\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3264 - output_1_loss: 0.3259 - val_loss: 0.4352 - val_output_1_loss: 0.4339\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2442 - output_1_loss: 0.2435 - val_loss: 0.4267 - val_output_1_loss: 0.4253\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3417 - output_1_loss: 0.3411 - val_loss: 0.4216 - val_output_1_loss: 0.4201\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3093 - output_1_loss: 0.3088 - val_loss: 0.4159 - val_output_1_loss: 0.4144\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3000 - output_1_loss: 0.2994 - val_loss: 0.4087 - val_output_1_loss: 0.4074\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2636 - output_1_loss: 0.2629 - val_loss: 0.4018 - val_output_1_loss: 0.4006\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2064 - output_1_loss: 0.2058 - val_loss: 0.3939 - val_output_1_loss: 0.3928\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2763 - output_1_loss: 0.2757 - val_loss: 0.3872 - val_output_1_loss: 0.3860\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.2762 - output_1_loss: 0.2755 - val_loss: 0.3818 - val_output_1_loss: 0.3805\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.2864 - output_1_loss: 0.2858 - val_loss: 0.3754 - val_output_1_loss: 0.3742\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2978 - output_1_loss: 0.2972 - val_loss: 0.3713 - val_output_1_loss: 0.3700\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.2440 - output_1_loss: 0.2434 - val_loss: 0.3622 - val_output_1_loss: 0.3609\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.8676 - output_1_loss: 0.8003 - val_loss: 0.9093 - val_output_1_loss: 0.6856\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1772 - output_1_loss: 0.1764 - val_loss: 0.3558 - val_output_1_loss: 0.3543\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2596 - output_1_loss: 0.2589 - val_loss: 0.3525 - val_output_1_loss: 0.3509\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3148 - output_1_loss: 0.3141 - val_loss: 0.3493 - val_output_1_loss: 0.3477\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1490 - output_1_loss: 0.1483 - val_loss: 0.3393 - val_output_1_loss: 0.3377\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1932 - output_1_loss: 0.1925 - val_loss: 0.3329 - val_output_1_loss: 0.3313\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1972 - output_1_loss: 0.1965 - val_loss: 0.3246 - val_output_1_loss: 0.3230\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.2519 - output_1_loss: 0.2512 - val_loss: 0.3185 - val_output_1_loss: 0.3170\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2238 - output_1_loss: 0.2232 - val_loss: 0.3122 - val_output_1_loss: 0.3108\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1066 - output_1_loss: 0.1059 - val_loss: 0.3000 - val_output_1_loss: 0.2986\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1874 - output_1_loss: 0.1867 - val_loss: 0.2961 - val_output_1_loss: 0.2948\n",
      "Epoch 68/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.8041 - output_1_loss: 0.7332 - val_loss: 0.8891 - val_output_1_loss: 0.6770\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1694 - output_1_loss: 0.1688 - val_loss: 0.2909 - val_output_1_loss: 0.2897\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.7702 - output_1_loss: 0.6926 - val_loss: 0.8733 - val_output_1_loss: 0.6685\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6680 - output_1_loss: 0.5957 - val_loss: 0.8544 - val_output_1_loss: 0.6592\n",
      "Epoch 5/100\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.6721 - output_1_loss: 0.5999 - val_loss: 0.8384 - val_output_1_loss: 0.6518\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.1242 - output_1_loss: 0.1236 - val_loss: 0.2794 - val_output_1_loss: 0.2780\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6469 - output_1_loss: 0.5717Epoch 70/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6469 - output_1_loss: 0.5717 - val_loss: 0.8226 - val_output_1_loss: 0.6440\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1477 - output_1_loss: 0.1471Epoch 7/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1477 - output_1_loss: 0.1471 - val_loss: 0.2735 - val_output_1_loss: 0.2723\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6073 - output_1_loss: 0.5336 - val_loss: 0.8075 - val_output_1_loss: 0.6350\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.5399 - output_1_loss: 0.4770 - val_loss: 0.7939 - val_output_1_loss: 0.6273\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5887 - output_1_loss: 0.5206Epoch 71/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.5887 - output_1_loss: 0.5206 - val_loss: 0.7793 - val_output_1_loss: 0.6181\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1521 - output_1_loss: 0.1514 - val_loss: 0.2657 - val_output_1_loss: 0.2643\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5231 - output_1_loss: 0.4510Epoch 72/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5231 - output_1_loss: 0.4510 - val_loss: 0.7660 - val_output_1_loss: 0.6082\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4529 - output_1_loss: 0.3865 - val_loss: 0.7515 - val_output_1_loss: 0.5984\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.1631 - output_1_loss: 0.1626 - val_loss: 0.2626 - val_output_1_loss: 0.2612\n",
      "Epoch 73/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4379 - output_1_loss: 0.3677 - val_loss: 0.7371 - val_output_1_loss: 0.5893\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.1959 - output_1_loss: 0.1953 - val_loss: 0.2519 - val_output_1_loss: 0.2507\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5149 - output_1_loss: 0.4467 - val_loss: 0.7248 - val_output_1_loss: 0.5806\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1778 - output_1_loss: 0.1772 - val_loss: 0.2507 - val_output_1_loss: 0.2495\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4172 - output_1_loss: 0.3537 - val_loss: 0.7134 - val_output_1_loss: 0.5718\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3737 - output_1_loss: 0.3073 - val_loss: 0.6990 - val_output_1_loss: 0.5618\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1947 - output_1_loss: 0.1940 - val_loss: 0.2451 - val_output_1_loss: 0.2439\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2713 - output_1_loss: 0.2092 - val_loss: 0.6830 - val_output_1_loss: 0.5494\n",
      "Epoch 76/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2036 - output_1_loss: 0.2029 - val_loss: 0.2483 - val_output_1_loss: 0.2470\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.2758 - output_1_loss: 0.2146 - val_loss: 0.6705 - val_output_1_loss: 0.5386\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1324 - output_1_loss: 0.1317 - val_loss: 0.2348 - val_output_1_loss: 0.2336\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1385 - output_1_loss: 0.1378 - val_loss: 0.2321 - val_output_1_loss: 0.2310\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2007 - output_1_loss: 0.1445Epoch 79/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2007 - output_1_loss: 0.1445 - val_loss: 0.6561 - val_output_1_loss: 0.5252\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2426 - output_1_loss: 0.1834 - val_loss: 0.6445 - val_output_1_loss: 0.5141\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.1108 - output_1_loss: 0.1102 - val_loss: 0.2261 - val_output_1_loss: 0.2250\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2859 - output_1_loss: 0.2278 - val_loss: 0.6349 - val_output_1_loss: 0.5045\n",
      "Epoch 80/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2654 - output_1_loss: 0.2060 - val_loss: 0.6220 - val_output_1_loss: 0.4926\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.1953 - output_1_loss: 0.1947 - val_loss: 0.2239 - val_output_1_loss: 0.2228\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2274 - output_1_loss: 0.1686 - val_loss: 0.6095 - val_output_1_loss: 0.4828\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.2027 - output_1_loss: 0.2021 - val_loss: 0.2262 - val_output_1_loss: 0.2250\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3268 - output_1_loss: 0.2663 - val_loss: 0.5972 - val_output_1_loss: 0.4744\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1755 - output_1_loss: 0.1748 - val_loss: 0.2204 - val_output_1_loss: 0.2194\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.1569 - output_1_loss: 0.1024 - val_loss: 0.5763 - val_output_1_loss: 0.4566\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.1781 - output_1_loss: 0.1774 - val_loss: 0.2145 - val_output_1_loss: 0.2135\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1330 - output_1_loss: 0.0830 - val_loss: 0.5563 - val_output_1_loss: 0.4401\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2634 - output_1_loss: 0.2628Epoch 26/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.2634 - output_1_loss: 0.2628 - val_loss: 0.2126 - val_output_1_loss: 0.2115\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2291 - output_1_loss: 0.1803 - val_loss: 0.5385 - val_output_1_loss: 0.4256\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1401 - output_1_loss: 0.0923 - val_loss: 0.5164 - val_output_1_loss: 0.4070\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1295 - output_1_loss: 0.0830Epoch 85/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1295 - output_1_loss: 0.0830 - val_loss: 0.4961 - val_output_1_loss: 0.3889\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1371 - output_1_loss: 0.1366Epoch 29/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1371 - output_1_loss: 0.1366 - val_loss: 0.2017 - val_output_1_loss: 0.2005\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1277 - output_1_loss: 0.0839Epoch 86/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1277 - output_1_loss: 0.0839 - val_loss: 0.4749 - val_output_1_loss: 0.3700\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.2034 - output_1_loss: 0.1584 - val_loss: 0.4603 - val_output_1_loss: 0.3571\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1070 - output_1_loss: 0.1066 - val_loss: 0.1956 - val_output_1_loss: 0.1944\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1186 - output_1_loss: 0.0731 - val_loss: 0.4378 - val_output_1_loss: 0.3366\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.1430 - output_1_loss: 0.1424 - val_loss: 0.1769 - val_output_1_loss: 0.1757\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1217 - output_1_loss: 0.0745 - val_loss: 0.4234 - val_output_1_loss: 0.3228\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1073 - output_1_loss: 0.1066 - val_loss: 0.1906 - val_output_1_loss: 0.1895\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1247 - output_1_loss: 0.0785 - val_loss: 0.4064 - val_output_1_loss: 0.3064\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1641 - output_1_loss: 0.1635 - val_loss: 0.2044 - val_output_1_loss: 0.2033\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1268 - output_1_loss: 0.0799 - val_loss: 0.3890 - val_output_1_loss: 0.2893\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1360 - output_1_loss: 0.1355 - val_loss: 0.1972 - val_output_1_loss: 0.1960\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1421 - output_1_loss: 0.0929 - val_loss: 0.3783 - val_output_1_loss: 0.2777\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1434 - output_1_loss: 0.1428 - val_loss: 0.1783 - val_output_1_loss: 0.1772\n",
      "Epoch 92/100\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.1359 - output_1_loss: 0.1353 - val_loss: 0.1850 - val_output_1_loss: 0.1838\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.1441 - output_1_loss: 0.0963 - val_loss: 0.3658 - val_output_1_loss: 0.2647\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1900 - output_1_loss: 0.1393 - val_loss: 0.3589 - val_output_1_loss: 0.2589\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1454 - output_1_loss: 0.0947 - val_loss: 0.3489 - val_output_1_loss: 0.2503\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.1556 - output_1_loss: 0.1105 - val_loss: 0.3382 - val_output_1_loss: 0.2408\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1415 - output_1_loss: 0.0942 - val_loss: 0.3211 - val_output_1_loss: 0.2252\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.1308 - output_1_loss: 0.0822 - val_loss: 0.3053 - val_output_1_loss: 0.2110\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1537 - output_1_loss: 0.1057 - val_loss: 0.2973 - val_output_1_loss: 0.2037\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1420 - output_1_loss: 0.0966 - val_loss: 0.2852 - val_output_1_loss: 0.1920\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1460 - output_1_loss: 0.0996 - val_loss: 0.2808 - val_output_1_loss: 0.1879\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1328 - output_1_loss: 0.0907 - val_loss: 0.2719 - val_output_1_loss: 0.1801\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1198 - output_1_loss: 0.0803 - val_loss: 0.2579 - val_output_1_loss: 0.1687\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1367 - output_1_loss: 0.0988 - val_loss: 0.2436 - val_output_1_loss: 0.1576\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1268 - output_1_loss: 0.0923 - val_loss: 0.2356 - val_output_1_loss: 0.1524\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:15:55,389]\u001b[0m Trial 41 finished with value: 0.03125 and parameters: {'feature_dim': 128, 'n_step': 8, 'n_shared': 2, 'relaxation_factor': 2.6, 'sparsity_coefficient': 0.0013184105653449912, 'bn_momentum': 0.9712582125605377}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.1308 - output_1_loss: 0.0964 - val_loss: 0.2311 - val_output_1_loss: 0.1498\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.1244 - output_1_loss: 0.0900 - val_loss: 0.2245 - val_output_1_loss: 0.1454\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1170 - output_1_loss: 0.0802Epoch 1/100\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.1170 - output_1_loss: 0.0802 - val_loss: 0.2176 - val_output_1_loss: 0.1392\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.1242 - output_1_loss: 0.0842 - val_loss: 0.2163 - val_output_1_loss: 0.1368\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1208 - output_1_loss: 0.0782 - val_loss: 0.2117 - val_output_1_loss: 0.1317\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1830 - output_1_loss: 0.1431 - val_loss: 0.2082 - val_output_1_loss: 0.1268\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.1200 - output_1_loss: 0.0759 - val_loss: 0.2071 - val_output_1_loss: 0.1231\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1109 - output_1_loss: 0.0672 - val_loss: 0.2053 - val_output_1_loss: 0.1194\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.1131 - output_1_loss: 0.0713 - val_loss: 0.1997 - val_output_1_loss: 0.1140\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.1300 - output_1_loss: 0.0895 - val_loss: 0.1941 - val_output_1_loss: 0.1096\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.1540 - output_1_loss: 0.1094 - val_loss: 0.1921 - val_output_1_loss: 0.1095\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.1609 - output_1_loss: 0.1174 - val_loss: 0.1884 - val_output_1_loss: 0.1078\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.1142 - output_1_loss: 0.0726 - val_loss: 0.1812 - val_output_1_loss: 0.1036\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.1263 - output_1_loss: 0.0860 - val_loss: 0.1773 - val_output_1_loss: 0.1020\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.1684 - output_1_loss: 0.1278 - val_loss: 0.1745 - val_output_1_loss: 0.1005\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1246 - output_1_loss: 0.0853 - val_loss: 0.1727 - val_output_1_loss: 0.0999\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1212 - output_1_loss: 0.0833 - val_loss: 0.1727 - val_output_1_loss: 0.1007\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1236 - output_1_loss: 0.0845 - val_loss: 0.1721 - val_output_1_loss: 0.1004\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1129 - output_1_loss: 0.0729 - val_loss: 0.1726 - val_output_1_loss: 0.1009\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1293 - output_1_loss: 0.0904 - val_loss: 0.1738 - val_output_1_loss: 0.1021\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1206 - output_1_loss: 0.0823 - val_loss: 0.1751 - val_output_1_loss: 0.1036\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1115 - output_1_loss: 0.0743 - val_loss: 0.1728 - val_output_1_loss: 0.1019\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1561 - output_1_loss: 0.1197 - val_loss: 0.1697 - val_output_1_loss: 0.0998\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1142 - output_1_loss: 0.0761 - val_loss: 0.1637 - val_output_1_loss: 0.0944\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1219 - output_1_loss: 0.0843 - val_loss: 0.1591 - val_output_1_loss: 0.0911\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.1101 - output_1_loss: 0.0754 - val_loss: 0.1540 - val_output_1_loss: 0.0874\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.1051 - output_1_loss: 0.0710 - val_loss: 0.1528 - val_output_1_loss: 0.0867\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1047 - output_1_loss: 0.0693 - val_loss: 0.1520 - val_output_1_loss: 0.0862\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.1077 - output_1_loss: 0.0719 - val_loss: 0.1495 - val_output_1_loss: 0.0842\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1098 - output_1_loss: 0.0732 - val_loss: 0.1508 - val_output_1_loss: 0.0864\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1144 - output_1_loss: 0.0783 - val_loss: 0.1508 - val_output_1_loss: 0.0879\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1072 - output_1_loss: 0.0718 - val_loss: 0.1480 - val_output_1_loss: 0.0864\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1044 - output_1_loss: 0.0694 - val_loss: 0.1472 - val_output_1_loss: 0.0862\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.1026 - output_1_loss: 0.0697 - val_loss: 0.1459 - val_output_1_loss: 0.0849\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.1290 - output_1_loss: 0.0971 - val_loss: 0.1442 - val_output_1_loss: 0.0835\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0972 - output_1_loss: 0.0665 - val_loss: 0.1432 - val_output_1_loss: 0.0823\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.1157 - output_1_loss: 0.0843 - val_loss: 0.1419 - val_output_1_loss: 0.0815\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1069 - output_1_loss: 0.0770 - val_loss: 0.1408 - val_output_1_loss: 0.0811\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0978 - output_1_loss: 0.0723 - val_loss: 0.1388 - val_output_1_loss: 0.0797\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0891 - output_1_loss: 0.0638 - val_loss: 0.1374 - val_output_1_loss: 0.0790\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0889 - output_1_loss: 0.0648 - val_loss: 0.1361 - val_output_1_loss: 0.0785\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0959 - output_1_loss: 0.0651 - val_loss: 0.1360 - val_output_1_loss: 0.0801\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0887 - output_1_loss: 0.0626 - val_loss: 0.1356 - val_output_1_loss: 0.0807\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0847 - output_1_loss: 0.0619 - val_loss: 0.1314 - val_output_1_loss: 0.0778\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0835 - output_1_loss: 0.0617 - val_loss: 0.1239 - val_output_1_loss: 0.0715\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0903 - output_1_loss: 0.0690 - val_loss: 0.1186 - val_output_1_loss: 0.0671\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0904 - output_1_loss: 0.0693 - val_loss: 0.1138 - val_output_1_loss: 0.0636\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0897 - output_1_loss: 0.0686 - val_loss: 0.1117 - val_output_1_loss: 0.0624\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0882 - output_1_loss: 0.0674 - val_loss: 0.1110 - val_output_1_loss: 0.0629\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0867 - output_1_loss: 0.0661 - val_loss: 0.1108 - val_output_1_loss: 0.0640\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0851 - output_1_loss: 0.0645 - val_loss: 0.1099 - val_output_1_loss: 0.0640\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0845 - output_1_loss: 0.0639 - val_loss: 0.1087 - val_output_1_loss: 0.0641\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:16:16,377]\u001b[0m Trial 42 finished with value: 0.09090909090909091 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 0.0411157457092957, 'bn_momentum': 0.9456768823733765}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 24s 24s/step - loss: 0.7304 - output_1_loss: 0.6798 - val_loss: 0.8428 - val_output_1_loss: 0.6850\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.6831 - output_1_loss: 0.6319 - val_loss: 0.8249 - val_output_1_loss: 0.6764\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.6922 - output_1_loss: 0.6409 - val_loss: 0.8073 - val_output_1_loss: 0.6686\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.5743 - output_1_loss: 0.5241 - val_loss: 0.7914 - val_output_1_loss: 0.6598\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.6196 - output_1_loss: 0.5726 - val_loss: 0.7776 - val_output_1_loss: 0.6505\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.5822 - output_1_loss: 0.5361 - val_loss: 0.7648 - val_output_1_loss: 0.6411\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.5425 - output_1_loss: 0.4960 - val_loss: 0.7518 - val_output_1_loss: 0.6315\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.4956 - output_1_loss: 0.4488 - val_loss: 0.7392 - val_output_1_loss: 0.6215\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.4113 - output_1_loss: 0.3664 - val_loss: 0.7269 - val_output_1_loss: 0.6112\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.5225 - output_1_loss: 0.4803 - val_loss: 0.7133 - val_output_1_loss: 0.6010\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.4443 - output_1_loss: 0.4031 - val_loss: 0.7005 - val_output_1_loss: 0.5899\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3824 - output_1_loss: 0.3387 - val_loss: 0.6858 - val_output_1_loss: 0.5785\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.4836 - output_1_loss: 0.4403 - val_loss: 0.6729 - val_output_1_loss: 0.5683\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3392 - output_1_loss: 0.2964 - val_loss: 0.6599 - val_output_1_loss: 0.5583\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3892 - output_1_loss: 0.3431 - val_loss: 0.6479 - val_output_1_loss: 0.5473\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.3728 - output_1_loss: 0.3282 - val_loss: 0.6361 - val_output_1_loss: 0.5371\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.3864 - output_1_loss: 0.3462 - val_loss: 0.6239 - val_output_1_loss: 0.5264\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.3112 - output_1_loss: 0.2728 - val_loss: 0.6123 - val_output_1_loss: 0.5151\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.3305 - output_1_loss: 0.2883 - val_loss: 0.5968 - val_output_1_loss: 0.5027\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.3259 - output_1_loss: 0.2848 - val_loss: 0.5841 - val_output_1_loss: 0.4920\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.1985 - output_1_loss: 0.1591 - val_loss: 0.5696 - val_output_1_loss: 0.4792\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.2127 - output_1_loss: 0.1729 - val_loss: 0.5553 - val_output_1_loss: 0.4658\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.3201 - output_1_loss: 0.2807 - val_loss: 0.5424 - val_output_1_loss: 0.4546\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.2662 - output_1_loss: 0.2278 - val_loss: 0.5272 - val_output_1_loss: 0.4414\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.2676 - output_1_loss: 0.2295 - val_loss: 0.5155 - val_output_1_loss: 0.4310\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1991 - output_1_loss: 0.1612 - val_loss: 0.5007 - val_output_1_loss: 0.4170\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.2664 - output_1_loss: 0.2306 - val_loss: 0.4891 - val_output_1_loss: 0.4044\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.2142 - output_1_loss: 0.1791 - val_loss: 0.4761 - val_output_1_loss: 0.3916\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.2125 - output_1_loss: 0.1763 - val_loss: 0.4638 - val_output_1_loss: 0.3793\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.2059 - output_1_loss: 0.1726 - val_loss: 0.4511 - val_output_1_loss: 0.3674\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1959 - output_1_loss: 0.1596 - val_loss: 0.4369 - val_output_1_loss: 0.3535\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1893 - output_1_loss: 0.1542 - val_loss: 0.4255 - val_output_1_loss: 0.3428\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.2101 - output_1_loss: 0.1762 - val_loss: 0.4158 - val_output_1_loss: 0.3334\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1921 - output_1_loss: 0.1584 - val_loss: 0.4045 - val_output_1_loss: 0.3235\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1758 - output_1_loss: 0.1410 - val_loss: 0.3935 - val_output_1_loss: 0.3137\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1399 - output_1_loss: 0.1060 - val_loss: 0.3810 - val_output_1_loss: 0.3026\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1430 - output_1_loss: 0.1091 - val_loss: 0.3643 - val_output_1_loss: 0.2871\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1352 - output_1_loss: 0.1063 - val_loss: 0.3511 - val_output_1_loss: 0.2750\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1214 - output_1_loss: 0.0905 - val_loss: 0.3386 - val_output_1_loss: 0.2629\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1016 - output_1_loss: 0.0710 - val_loss: 0.3207 - val_output_1_loss: 0.2448\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1357 - output_1_loss: 0.1062 - val_loss: 0.3095 - val_output_1_loss: 0.2333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1230 - output_1_loss: 0.0948 - val_loss: 0.2987 - val_output_1_loss: 0.2225\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1230 - output_1_loss: 0.0947 - val_loss: 0.2852 - val_output_1_loss: 0.2096\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1060 - output_1_loss: 0.0780 - val_loss: 0.2735 - val_output_1_loss: 0.1986\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1027 - output_1_loss: 0.0742 - val_loss: 0.2639 - val_output_1_loss: 0.1895\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1021 - output_1_loss: 0.0751 - val_loss: 0.2550 - val_output_1_loss: 0.1807\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0967 - output_1_loss: 0.0702 - val_loss: 0.2461 - val_output_1_loss: 0.1720\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0934 - output_1_loss: 0.0663 - val_loss: 0.2369 - val_output_1_loss: 0.1628\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0926 - output_1_loss: 0.0634 - val_loss: 0.2269 - val_output_1_loss: 0.1528\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7506 - output_1_loss: 0.7083Epoch 50/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0922 - output_1_loss: 0.0619 - val_loss: 0.2197 - val_output_1_loss: 0.1453\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1047 - output_1_loss: 0.0731 - val_loss: 0.2136 - val_output_1_loss: 0.1388\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0987 - output_1_loss: 0.0694 - val_loss: 0.2080 - val_output_1_loss: 0.1329\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0983 - output_1_loss: 0.0703 - val_loss: 0.2032 - val_output_1_loss: 0.1279\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0923 - output_1_loss: 0.0659 - val_loss: 0.1977 - val_output_1_loss: 0.1224\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0946 - output_1_loss: 0.0678 - val_loss: 0.1920 - val_output_1_loss: 0.1168\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.7506 - output_1_loss: 0.7083 - val_loss: 0.8216 - val_output_1_loss: 0.6849\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.0870 - output_1_loss: 0.0619 - val_loss: 0.1857 - val_output_1_loss: 0.1110\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7180 - output_1_loss: 0.6708 - val_loss: 0.8052 - val_output_1_loss: 0.6752\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0946 - output_1_loss: 0.0700Epoch 3/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0946 - output_1_loss: 0.0700 - val_loss: 0.1800 - val_output_1_loss: 0.1064\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6783 - output_1_loss: 0.6355 - val_loss: 0.7868 - val_output_1_loss: 0.6667\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1031 - output_1_loss: 0.0785Epoch 4/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1031 - output_1_loss: 0.0785 - val_loss: 0.1763 - val_output_1_loss: 0.1032\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6168 - output_1_loss: 0.5717Epoch 59/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6168 - output_1_loss: 0.5717 - val_loss: 0.7721 - val_output_1_loss: 0.6576\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1082 - output_1_loss: 0.0824 - val_loss: 0.1718 - val_output_1_loss: 0.1005\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5859 - output_1_loss: 0.5421 - val_loss: 0.7570 - val_output_1_loss: 0.6475\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0945 - output_1_loss: 0.0707 - val_loss: 0.1671 - val_output_1_loss: 0.0974\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.6134 - output_1_loss: 0.5706 - val_loss: 0.7433 - val_output_1_loss: 0.6378\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0929 - output_1_loss: 0.0701 - val_loss: 0.1639 - val_output_1_loss: 0.0951\n",
      "Epoch 62/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6112 - output_1_loss: 0.5691 - val_loss: 0.7309 - val_output_1_loss: 0.6282\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0932 - output_1_loss: 0.0703 - val_loss: 0.1617 - val_output_1_loss: 0.0929\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5120 - output_1_loss: 0.4701Epoch 63/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5120 - output_1_loss: 0.4701 - val_loss: 0.7185 - val_output_1_loss: 0.6182\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0931 - output_1_loss: 0.0715 - val_loss: 0.1601 - val_output_1_loss: 0.0915\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.5950 - output_1_loss: 0.5509 - val_loss: 0.7070 - val_output_1_loss: 0.6087\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0913 - output_1_loss: 0.0698 - val_loss: 0.1586 - val_output_1_loss: 0.0902\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4818 - output_1_loss: 0.4427Epoch 65/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.4818 - output_1_loss: 0.4427 - val_loss: 0.6951 - val_output_1_loss: 0.5985\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0874 - output_1_loss: 0.0663 - val_loss: 0.1571 - val_output_1_loss: 0.0891\n",
      "Epoch 66/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4536 - output_1_loss: 0.4157 - val_loss: 0.6837 - val_output_1_loss: 0.5879\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0866 - output_1_loss: 0.0654 - val_loss: 0.1560 - val_output_1_loss: 0.0885\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0851 - output_1_loss: 0.0642Epoch 12/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0851 - output_1_loss: 0.0642 - val_loss: 0.1543 - val_output_1_loss: 0.0877\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5029 - output_1_loss: 0.4630Epoch 68/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5029 - output_1_loss: 0.4630 - val_loss: 0.6717 - val_output_1_loss: 0.5768\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0831 - output_1_loss: 0.0625 - val_loss: 0.1521 - val_output_1_loss: 0.0867\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5814 - output_1_loss: 0.5442Epoch 69/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5814 - output_1_loss: 0.5442 - val_loss: 0.6582 - val_output_1_loss: 0.5668\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0805 - output_1_loss: 0.0606 - val_loss: 0.1505 - val_output_1_loss: 0.0858\n",
      "Epoch 70/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0779 - output_1_loss: 0.0583 - val_loss: 0.1491 - val_output_1_loss: 0.0849\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.4641 - output_1_loss: 0.4268 - val_loss: 0.6471 - val_output_1_loss: 0.5573\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0756 - output_1_loss: 0.0566 - val_loss: 0.1476 - val_output_1_loss: 0.0839\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4201 - output_1_loss: 0.3833 - val_loss: 0.6348 - val_output_1_loss: 0.5462\n",
      "Epoch 16/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0746 - output_1_loss: 0.0563 - val_loss: 0.1461 - val_output_1_loss: 0.0830\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3222 - output_1_loss: 0.2851 - val_loss: 0.6227 - val_output_1_loss: 0.5339\n",
      "Epoch 73/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0753 - output_1_loss: 0.0572 - val_loss: 0.1449 - val_output_1_loss: 0.0827\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.3557 - output_1_loss: 0.3188 - val_loss: 0.6099 - val_output_1_loss: 0.5225\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0736 - output_1_loss: 0.0559Epoch 18/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0736 - output_1_loss: 0.0559 - val_loss: 0.1436 - val_output_1_loss: 0.0824\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3008 - output_1_loss: 0.2617Epoch 75/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3008 - output_1_loss: 0.2617 - val_loss: 0.5968 - val_output_1_loss: 0.5101\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0728 - output_1_loss: 0.0552 - val_loss: 0.1423 - val_output_1_loss: 0.0820\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3998 - output_1_loss: 0.3598Epoch 76/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3998 - output_1_loss: 0.3598 - val_loss: 0.5845 - val_output_1_loss: 0.4988\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0720 - output_1_loss: 0.0548 - val_loss: 0.1411 - val_output_1_loss: 0.0818\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3062 - output_1_loss: 0.2675 - val_loss: 0.5712 - val_output_1_loss: 0.4863\n",
      "Epoch 77/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2477 - output_1_loss: 0.2100 - val_loss: 0.5576 - val_output_1_loss: 0.4737\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0707 - output_1_loss: 0.0538 - val_loss: 0.1402 - val_output_1_loss: 0.0820\n",
      "Epoch 78/100\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2706 - output_1_loss: 0.2395 - val_loss: 0.5441 - val_output_1_loss: 0.4609\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0698 - output_1_loss: 0.0530 - val_loss: 0.1392 - val_output_1_loss: 0.0819\n",
      "Epoch 79/100\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0692 - output_1_loss: 0.0525 - val_loss: 0.1379 - val_output_1_loss: 0.0816\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2329 - output_1_loss: 0.1988Epoch 80/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.2329 - output_1_loss: 0.1988 - val_loss: 0.5312 - val_output_1_loss: 0.4489\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0686 - output_1_loss: 0.0520 - val_loss: 0.1365 - val_output_1_loss: 0.0812\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3042 - output_1_loss: 0.2699 - val_loss: 0.5199 - val_output_1_loss: 0.4373\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0675 - output_1_loss: 0.0511 - val_loss: 0.1351 - val_output_1_loss: 0.0807\n",
      "Epoch 82/100\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0669 - output_1_loss: 0.0506 - val_loss: 0.1336 - val_output_1_loss: 0.0801\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2431 - output_1_loss: 0.2089 - val_loss: 0.5044 - val_output_1_loss: 0.4228\n",
      "Epoch 83/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0663 - output_1_loss: 0.0503 - val_loss: 0.1323 - val_output_1_loss: 0.0797\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.1951 - output_1_loss: 0.1640 - val_loss: 0.4890 - val_output_1_loss: 0.4084\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0655 - output_1_loss: 0.0497Epoch 27/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0655 - output_1_loss: 0.0497 - val_loss: 0.1314 - val_output_1_loss: 0.0795\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2735 - output_1_loss: 0.2381 - val_loss: 0.4789 - val_output_1_loss: 0.3980\n",
      "Epoch 28/100\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1961 - output_1_loss: 0.1602 - val_loss: 0.4646 - val_output_1_loss: 0.3842\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0647 - output_1_loss: 0.0491 - val_loss: 0.1306 - val_output_1_loss: 0.0794\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2230 - output_1_loss: 0.1855Epoch 86/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2230 - output_1_loss: 0.1855 - val_loss: 0.4509 - val_output_1_loss: 0.3712\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0642 - output_1_loss: 0.0487 - val_loss: 0.1301 - val_output_1_loss: 0.0793\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1953 - output_1_loss: 0.1594Epoch 87/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1953 - output_1_loss: 0.1594 - val_loss: 0.4364 - val_output_1_loss: 0.3583\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0634 - output_1_loss: 0.0483 - val_loss: 0.1291 - val_output_1_loss: 0.0789\n",
      "Epoch 31/100\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2830 - output_1_loss: 0.2469 - val_loss: 0.4253 - val_output_1_loss: 0.3479\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0630 - output_1_loss: 0.0479 - val_loss: 0.1284 - val_output_1_loss: 0.0787\n",
      "Epoch 89/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0635 - output_1_loss: 0.0485 - val_loss: 0.1296 - val_output_1_loss: 0.0803\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1948 - output_1_loss: 0.1569 - val_loss: 0.4116 - val_output_1_loss: 0.3350\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0625 - output_1_loss: 0.0482 - val_loss: 0.1307 - val_output_1_loss: 0.0818\n",
      "Epoch 91/100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0616 - output_1_loss: 0.0474 - val_loss: 0.1308 - val_output_1_loss: 0.0823\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.2135 - output_1_loss: 0.1781 - val_loss: 0.3988 - val_output_1_loss: 0.3231\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0611 - output_1_loss: 0.0470 - val_loss: 0.1305 - val_output_1_loss: 0.0824\n",
      "Epoch 34/100\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0607 - output_1_loss: 0.0468 - val_loss: 0.1302 - val_output_1_loss: 0.0825\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1957 - output_1_loss: 0.1600 - val_loss: 0.3853 - val_output_1_loss: 0.3109\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.3039 - output_1_loss: 0.2665 - val_loss: 0.3741 - val_output_1_loss: 0.3001\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.2715 - output_1_loss: 0.2336 - val_loss: 0.3634 - val_output_1_loss: 0.2895\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2078 - output_1_loss: 0.1707 - val_loss: 0.3536 - val_output_1_loss: 0.2790\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1811 - output_1_loss: 0.1443 - val_loss: 0.3439 - val_output_1_loss: 0.2692\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:16:51,947]\u001b[0m Trial 43 finished with value: 0.05263157894736842 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 0.028923383708785364, 'bn_momentum': 0.9622295977585122}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1857 - output_1_loss: 0.1500 - val_loss: 0.3352 - val_output_1_loss: 0.2601\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1434 - output_1_loss: 0.1078Epoch 1/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.1434 - output_1_loss: 0.1078 - val_loss: 0.3237 - val_output_1_loss: 0.2488\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.1892 - output_1_loss: 0.1533 - val_loss: 0.3165 - val_output_1_loss: 0.2419\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1781 - output_1_loss: 0.1418 - val_loss: 0.3073 - val_output_1_loss: 0.2335\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1736 - output_1_loss: 0.1376 - val_loss: 0.2957 - val_output_1_loss: 0.2223\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1534 - output_1_loss: 0.1170 - val_loss: 0.2847 - val_output_1_loss: 0.2117\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1213 - output_1_loss: 0.0854 - val_loss: 0.2775 - val_output_1_loss: 0.2044\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.1582 - output_1_loss: 0.1179 - val_loss: 0.2714 - val_output_1_loss: 0.1976\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.1692 - output_1_loss: 0.1299 - val_loss: 0.2603 - val_output_1_loss: 0.1868\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.1771 - output_1_loss: 0.1385 - val_loss: 0.2536 - val_output_1_loss: 0.1804\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1983 - output_1_loss: 0.1617 - val_loss: 0.2488 - val_output_1_loss: 0.1760\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.1580 - output_1_loss: 0.1191 - val_loss: 0.2446 - val_output_1_loss: 0.1716\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1245 - output_1_loss: 0.0873 - val_loss: 0.2343 - val_output_1_loss: 0.1616\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1396 - output_1_loss: 0.1034 - val_loss: 0.2277 - val_output_1_loss: 0.1552\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1955 - output_1_loss: 0.1608 - val_loss: 0.2238 - val_output_1_loss: 0.1516\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1685 - output_1_loss: 0.1362 - val_loss: 0.2169 - val_output_1_loss: 0.1448\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1711 - output_1_loss: 0.1347 - val_loss: 0.2119 - val_output_1_loss: 0.1395\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1209 - output_1_loss: 0.0839 - val_loss: 0.2060 - val_output_1_loss: 0.1338\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1204 - output_1_loss: 0.0833 - val_loss: 0.1991 - val_output_1_loss: 0.1271\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1093 - output_1_loss: 0.0724 - val_loss: 0.1941 - val_output_1_loss: 0.1221\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1177 - output_1_loss: 0.0818 - val_loss: 0.1891 - val_output_1_loss: 0.1169\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.1084 - output_1_loss: 0.0742 - val_loss: 0.1860 - val_output_1_loss: 0.1141\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.1034 - output_1_loss: 0.0715 - val_loss: 0.1850 - val_output_1_loss: 0.1135\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.1011 - output_1_loss: 0.0710 - val_loss: 0.1821 - val_output_1_loss: 0.1113\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1127 - output_1_loss: 0.0836 - val_loss: 0.1784 - val_output_1_loss: 0.1080\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.1096 - output_1_loss: 0.0807 - val_loss: 0.1738 - val_output_1_loss: 0.1037\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.0837 - output_1_loss: 0.0555 - val_loss: 0.1692 - val_output_1_loss: 0.0995\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0957 - output_1_loss: 0.0686 - val_loss: 0.1653 - val_output_1_loss: 0.0960\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.0858 - output_1_loss: 0.0585 - val_loss: 0.1624 - val_output_1_loss: 0.0935\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.0851 - output_1_loss: 0.0572 - val_loss: 0.1582 - val_output_1_loss: 0.0900\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.0808 - output_1_loss: 0.0545 - val_loss: 0.1550 - val_output_1_loss: 0.0877\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0793 - output_1_loss: 0.0523 - val_loss: 0.1529 - val_output_1_loss: 0.0866\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.0749 - output_1_loss: 0.0492 - val_loss: 0.1501 - val_output_1_loss: 0.0848\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.0998 - output_1_loss: 0.0739 - val_loss: 0.1478 - val_output_1_loss: 0.0832\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.1069 - output_1_loss: 0.0781 - val_loss: 0.1473 - val_output_1_loss: 0.0829\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0998 - output_1_loss: 0.0687 - val_loss: 0.1465 - val_output_1_loss: 0.0823\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1260 - output_1_loss: 0.0968 - val_loss: 0.1455 - val_output_1_loss: 0.0821\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0957 - output_1_loss: 0.0680 - val_loss: 0.1435 - val_output_1_loss: 0.0802\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1008 - output_1_loss: 0.0714 - val_loss: 0.1423 - val_output_1_loss: 0.0793\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0901 - output_1_loss: 0.0609 - val_loss: 0.1416 - val_output_1_loss: 0.0788\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0906 - output_1_loss: 0.0610 - val_loss: 0.1408 - val_output_1_loss: 0.0780\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2194 - output_1_loss: 0.1878 - val_loss: 0.1402 - val_output_1_loss: 0.0770\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1133 - output_1_loss: 0.0846 - val_loss: 0.1396 - val_output_1_loss: 0.0763\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1120 - output_1_loss: 0.0818 - val_loss: 0.1367 - val_output_1_loss: 0.0739\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1264 - output_1_loss: 0.0960 - val_loss: 0.1357 - val_output_1_loss: 0.0732\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.1059 - output_1_loss: 0.0755 - val_loss: 0.1374 - val_output_1_loss: 0.0749\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1191 - output_1_loss: 0.0882 - val_loss: 0.1389 - val_output_1_loss: 0.0765\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0985 - output_1_loss: 0.0679 - val_loss: 0.1383 - val_output_1_loss: 0.0757\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1115 - output_1_loss: 0.0809 - val_loss: 0.1387 - val_output_1_loss: 0.0759\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1347 - output_1_loss: 0.1026 - val_loss: 0.1391 - val_output_1_loss: 0.0765\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:17:13,977]\u001b[0m Trial 44 finished with value: 0.25 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 4, 'relaxation_factor': 1.4, 'sparsity_coefficient': 0.024004409895286342, 'bn_momentum': 0.9630692210334412}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.8593 - output_1_loss: 0.8450 - val_loss: 0.7307 - val_output_1_loss: 0.6855\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.8261 - output_1_loss: 0.8113 - val_loss: 0.7200 - val_output_1_loss: 0.6775\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.7243 - output_1_loss: 0.7098 - val_loss: 0.7091 - val_output_1_loss: 0.6690\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.7448 - output_1_loss: 0.7300 - val_loss: 0.7001 - val_output_1_loss: 0.6613\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.6634 - output_1_loss: 0.6481 - val_loss: 0.6911 - val_output_1_loss: 0.6539\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.6523 - output_1_loss: 0.6378 - val_loss: 0.6827 - val_output_1_loss: 0.6462\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.6000 - output_1_loss: 0.5850 - val_loss: 0.6735 - val_output_1_loss: 0.6377\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.5771 - output_1_loss: 0.5620 - val_loss: 0.6647 - val_output_1_loss: 0.6295\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.5390 - output_1_loss: 0.5247 - val_loss: 0.6548 - val_output_1_loss: 0.6200\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5189 - output_1_loss: 0.5039 - val_loss: 0.6456 - val_output_1_loss: 0.6116\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5123 - output_1_loss: 0.4973 - val_loss: 0.6361 - val_output_1_loss: 0.6025\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.5595 - output_1_loss: 0.5447 - val_loss: 0.6268 - val_output_1_loss: 0.5937\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.4970 - output_1_loss: 0.4824 - val_loss: 0.6170 - val_output_1_loss: 0.5845\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.5230 - output_1_loss: 0.5091 - val_loss: 0.6077 - val_output_1_loss: 0.5755\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.4847 - output_1_loss: 0.4707 - val_loss: 0.5983 - val_output_1_loss: 0.5667\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.4130 - output_1_loss: 0.3990 - val_loss: 0.5885 - val_output_1_loss: 0.5573\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.4406 - output_1_loss: 0.4276 - val_loss: 0.5789 - val_output_1_loss: 0.5478\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.3821 - output_1_loss: 0.3682 - val_loss: 0.5700 - val_output_1_loss: 0.5391\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.3707 - output_1_loss: 0.3564 - val_loss: 0.5606 - val_output_1_loss: 0.5297\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.3905 - output_1_loss: 0.3775 - val_loss: 0.5515 - val_output_1_loss: 0.5207\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.4026 - output_1_loss: 0.3889 - val_loss: 0.5428 - val_output_1_loss: 0.5121\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.4008 - output_1_loss: 0.3882 - val_loss: 0.5336 - val_output_1_loss: 0.5030\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.3082 - output_1_loss: 0.2958 - val_loss: 0.5249 - val_output_1_loss: 0.4948\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.3153 - output_1_loss: 0.3023 - val_loss: 0.5160 - val_output_1_loss: 0.4862\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.3551 - output_1_loss: 0.3417 - val_loss: 0.5048 - val_output_1_loss: 0.4752\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.2488 - output_1_loss: 0.2359 - val_loss: 0.4949 - val_output_1_loss: 0.4656\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3359 - output_1_loss: 0.3228 - val_loss: 0.4856 - val_output_1_loss: 0.4564\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.2776 - output_1_loss: 0.2644 - val_loss: 0.4742 - val_output_1_loss: 0.4453\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3424 - output_1_loss: 0.3290 - val_loss: 0.4655 - val_output_1_loss: 0.4367\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.2981 - output_1_loss: 0.2852 - val_loss: 0.4554 - val_output_1_loss: 0.4268\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.2036 - output_1_loss: 0.1903 - val_loss: 0.4429 - val_output_1_loss: 0.4144\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1733 - output_1_loss: 0.1607 - val_loss: 0.4330 - val_output_1_loss: 0.4045\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1891 - output_1_loss: 0.1768 - val_loss: 0.4242 - val_output_1_loss: 0.3959\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2315 - output_1_loss: 0.2187 - val_loss: 0.4153 - val_output_1_loss: 0.3875\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1581 - output_1_loss: 0.1445 - val_loss: 0.4022 - val_output_1_loss: 0.3746\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1817 - output_1_loss: 0.1685 - val_loss: 0.3917 - val_output_1_loss: 0.3643\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1645 - output_1_loss: 0.1513 - val_loss: 0.3772 - val_output_1_loss: 0.3501\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2514 - output_1_loss: 0.2386 - val_loss: 0.3705 - val_output_1_loss: 0.3439\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1658 - output_1_loss: 0.1536 - val_loss: 0.3585 - val_output_1_loss: 0.3327\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1516 - output_1_loss: 0.1384 - val_loss: 0.3489 - val_output_1_loss: 0.3232\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2291 - output_1_loss: 0.2160 - val_loss: 0.3430 - val_output_1_loss: 0.3173\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1257 - output_1_loss: 0.1131 - val_loss: 0.3329 - val_output_1_loss: 0.3074\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1929 - output_1_loss: 0.1798 - val_loss: 0.3292 - val_output_1_loss: 0.3038\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1294 - output_1_loss: 0.1158 - val_loss: 0.3159 - val_output_1_loss: 0.2907\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1709 - output_1_loss: 0.1571 - val_loss: 0.3055 - val_output_1_loss: 0.2805\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1811 - output_1_loss: 0.1675 - val_loss: 0.2989 - val_output_1_loss: 0.2737\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7817 - output_1_loss: 0.7700Epoch 47/100\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.1979 - output_1_loss: 0.1853 - val_loss: 0.2922 - val_output_1_loss: 0.2672\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.1876 - output_1_loss: 0.1745 - val_loss: 0.2836 - val_output_1_loss: 0.2586\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1616 - output_1_loss: 0.1481 - val_loss: 0.2767 - val_output_1_loss: 0.2520\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.1370 - output_1_loss: 0.1242 - val_loss: 0.2725 - val_output_1_loss: 0.2478\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1314 - output_1_loss: 0.1188 - val_loss: 0.2626 - val_output_1_loss: 0.2381\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1455 - output_1_loss: 0.1333 - val_loss: 0.2554 - val_output_1_loss: 0.2308\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1328 - output_1_loss: 0.1201 - val_loss: 0.2503 - val_output_1_loss: 0.2256\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.7817 - output_1_loss: 0.7700 - val_loss: 0.7192 - val_output_1_loss: 0.6845\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2047 - output_1_loss: 0.1925 - val_loss: 0.2470 - val_output_1_loss: 0.2222\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1547 - output_1_loss: 0.1424 - val_loss: 0.2408 - val_output_1_loss: 0.2161\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.6923 - output_1_loss: 0.6811 - val_loss: 0.7088 - val_output_1_loss: 0.6765\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1368 - output_1_loss: 0.1237 - val_loss: 0.2344 - val_output_1_loss: 0.2098\n",
      "Epoch 3/100\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1288 - output_1_loss: 0.1164 - val_loss: 0.2294 - val_output_1_loss: 0.2050\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.6804 - output_1_loss: 0.6692 - val_loss: 0.6991 - val_output_1_loss: 0.6679\n",
      "Epoch 58/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6066 - output_1_loss: 0.5959 - val_loss: 0.6882 - val_output_1_loss: 0.6586\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1595 - output_1_loss: 0.1476 - val_loss: 0.2181 - val_output_1_loss: 0.1940\n",
      "Epoch 5/100\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1081 - output_1_loss: 0.0960 - val_loss: 0.2109 - val_output_1_loss: 0.1870\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.5985 - output_1_loss: 0.5882 - val_loss: 0.6778 - val_output_1_loss: 0.6494\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1589 - output_1_loss: 0.1472 - val_loss: 0.2075 - val_output_1_loss: 0.1837\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5695 - output_1_loss: 0.5593 - val_loss: 0.6679 - val_output_1_loss: 0.6406\n",
      "Epoch 7/100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4890 - output_1_loss: 0.4785 - val_loss: 0.6564 - val_output_1_loss: 0.6299\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1361 - output_1_loss: 0.1237 - val_loss: 0.2046 - val_output_1_loss: 0.1809\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1579 - output_1_loss: 0.1456 - val_loss: 0.1994 - val_output_1_loss: 0.1758\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.5089 - output_1_loss: 0.4981 - val_loss: 0.6462 - val_output_1_loss: 0.6203\n",
      "Epoch 9/100\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5047 - output_1_loss: 0.4942 - val_loss: 0.6361 - val_output_1_loss: 0.6107\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1398 - output_1_loss: 0.1275 - val_loss: 0.1931 - val_output_1_loss: 0.1696\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4428 - output_1_loss: 0.4327Epoch 64/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4428 - output_1_loss: 0.4327 - val_loss: 0.6263 - val_output_1_loss: 0.6014\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1528 - output_1_loss: 0.1405 - val_loss: 0.1885 - val_output_1_loss: 0.1651\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4991 - output_1_loss: 0.4887Epoch 65/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4991 - output_1_loss: 0.4887 - val_loss: 0.6166 - val_output_1_loss: 0.5921\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1234 - output_1_loss: 0.1108 - val_loss: 0.1863 - val_output_1_loss: 0.1630\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.4522 - output_1_loss: 0.4414 - val_loss: 0.6058 - val_output_1_loss: 0.5817\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1268 - output_1_loss: 0.1145Epoch 13/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1268 - output_1_loss: 0.1145 - val_loss: 0.1835 - val_output_1_loss: 0.1602\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4209 - output_1_loss: 0.4105 - val_loss: 0.5951 - val_output_1_loss: 0.5715\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3894 - output_1_loss: 0.3792 - val_loss: 0.5835 - val_output_1_loss: 0.5605\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0969 - output_1_loss: 0.0846 - val_loss: 0.1800 - val_output_1_loss: 0.1569\n",
      "Epoch 68/100\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3858 - output_1_loss: 0.3751 - val_loss: 0.5729 - val_output_1_loss: 0.5504\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1509 - output_1_loss: 0.1380 - val_loss: 0.1756 - val_output_1_loss: 0.1525\n",
      "Epoch 16/100\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3573 - output_1_loss: 0.3469 - val_loss: 0.5621 - val_output_1_loss: 0.5399\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1890 - output_1_loss: 0.1775 - val_loss: 0.1735 - val_output_1_loss: 0.1506\n",
      "Epoch 70/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1055 - output_1_loss: 0.0936 - val_loss: 0.1709 - val_output_1_loss: 0.1480\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3498 - output_1_loss: 0.3393 - val_loss: 0.5519 - val_output_1_loss: 0.5298\n",
      "Epoch 18/100\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2592 - output_1_loss: 0.2490 - val_loss: 0.5401 - val_output_1_loss: 0.5180\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1413 - output_1_loss: 0.1296 - val_loss: 0.1705 - val_output_1_loss: 0.1477\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1199 - output_1_loss: 0.1091 - val_loss: 0.1628 - val_output_1_loss: 0.1402\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3869 - output_1_loss: 0.3767 - val_loss: 0.5304 - val_output_1_loss: 0.5087\n",
      "Epoch 20/100\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3297 - output_1_loss: 0.3196 - val_loss: 0.5191 - val_output_1_loss: 0.4976\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1076 - output_1_loss: 0.0970 - val_loss: 0.1615 - val_output_1_loss: 0.1390\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4109 - output_1_loss: 0.4009 - val_loss: 0.5082 - val_output_1_loss: 0.4869\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1247 - output_1_loss: 0.1142 - val_loss: 0.1533 - val_output_1_loss: 0.1311\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.2837 - output_1_loss: 0.2743 - val_loss: 0.4982 - val_output_1_loss: 0.4771\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.1114 - output_1_loss: 0.1007 - val_loss: 0.1473 - val_output_1_loss: 0.1252\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3002 - output_1_loss: 0.2911Epoch 76/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3002 - output_1_loss: 0.2911 - val_loss: 0.4864 - val_output_1_loss: 0.4657\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1226 - output_1_loss: 0.1120 - val_loss: 0.1449 - val_output_1_loss: 0.1230\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3822 - output_1_loss: 0.3730 - val_loss: 0.4772 - val_output_1_loss: 0.4568\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1593 - output_1_loss: 0.1481Epoch 25/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1593 - output_1_loss: 0.1481 - val_loss: 0.1425 - val_output_1_loss: 0.1206\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1293 - output_1_loss: 0.1186 - val_loss: 0.1433 - val_output_1_loss: 0.1216\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.2191 - output_1_loss: 0.2097 - val_loss: 0.4646 - val_output_1_loss: 0.4446\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2491 - output_1_loss: 0.2392 - val_loss: 0.4517 - val_output_1_loss: 0.4317\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1158 - output_1_loss: 0.1053 - val_loss: 0.1423 - val_output_1_loss: 0.1207\n",
      "Epoch 27/100\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1410 - output_1_loss: 0.1308 - val_loss: 0.1430 - val_output_1_loss: 0.1216\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.2922 - output_1_loss: 0.2825 - val_loss: 0.4393 - val_output_1_loss: 0.4194\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1084 - output_1_loss: 0.0981Epoch 28/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1084 - output_1_loss: 0.0981 - val_loss: 0.1449 - val_output_1_loss: 0.1238\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1173 - output_1_loss: 0.1072 - val_loss: 0.1446 - val_output_1_loss: 0.1237\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.2987 - output_1_loss: 0.2894 - val_loss: 0.4270 - val_output_1_loss: 0.4074\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.2184 - output_1_loss: 0.2080 - val_loss: 0.1422 - val_output_1_loss: 0.1216\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.2364 - output_1_loss: 0.2274 - val_loss: 0.4146 - val_output_1_loss: 0.3951\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1191 - output_1_loss: 0.1083 - val_loss: 0.1449 - val_output_1_loss: 0.1245\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1241 - output_1_loss: 0.1134 - val_loss: 0.1485 - val_output_1_loss: 0.1284\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.2131 - output_1_loss: 0.2043 - val_loss: 0.4039 - val_output_1_loss: 0.3847\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1144 - output_1_loss: 0.1039 - val_loss: 0.1462 - val_output_1_loss: 0.1264\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.2681 - output_1_loss: 0.2589 - val_loss: 0.3927 - val_output_1_loss: 0.3736\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0975 - output_1_loss: 0.0875Epoch 32/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0975 - output_1_loss: 0.0875 - val_loss: 0.1380 - val_output_1_loss: 0.1183\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1918 - output_1_loss: 0.1823 - val_loss: 0.3835 - val_output_1_loss: 0.3644\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1160 - output_1_loss: 0.1053Epoch 33/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1160 - output_1_loss: 0.1053 - val_loss: 0.1347 - val_output_1_loss: 0.1151\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2090 - output_1_loss: 0.2000Epoch 89/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1038 - output_1_loss: 0.0927 - val_loss: 0.1444 - val_output_1_loss: 0.1247\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2090 - output_1_loss: 0.2000 - val_loss: 0.3726 - val_output_1_loss: 0.3536\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1080 - output_1_loss: 0.0978 - val_loss: 0.1418 - val_output_1_loss: 0.1223\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1910 - output_1_loss: 0.1811Epoch 91/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1184 - output_1_loss: 0.1081 - val_loss: 0.1355 - val_output_1_loss: 0.1162\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.1910 - output_1_loss: 0.1811 - val_loss: 0.3622 - val_output_1_loss: 0.3432\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1551 - output_1_loss: 0.1446 - val_loss: 0.1269 - val_output_1_loss: 0.1079\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1040 - output_1_loss: 0.0937Epoch 35/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1040 - output_1_loss: 0.0937 - val_loss: 0.1210 - val_output_1_loss: 0.1021\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1646 - output_1_loss: 0.1544 - val_loss: 0.3511 - val_output_1_loss: 0.3322\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.1123 - output_1_loss: 0.1025 - val_loss: 0.1259 - val_output_1_loss: 0.1073\n",
      "Epoch 95/100\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0840 - output_1_loss: 0.0744 - val_loss: 0.1276 - val_output_1_loss: 0.1091\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2045 - output_1_loss: 0.1944Epoch 96/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.2045 - output_1_loss: 0.1944 - val_loss: 0.3416 - val_output_1_loss: 0.3225\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1008 - output_1_loss: 0.0911Epoch 37/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1008 - output_1_loss: 0.0911 - val_loss: 0.1290 - val_output_1_loss: 0.1106\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.1961 - output_1_loss: 0.1856 - val_loss: 0.3312 - val_output_1_loss: 0.3122\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1403 - output_1_loss: 0.1306 - val_loss: 0.1201 - val_output_1_loss: 0.1016\n",
      "Epoch 38/100\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2677 - output_1_loss: 0.2568 - val_loss: 0.3232 - val_output_1_loss: 0.3042\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1042 - output_1_loss: 0.0944 - val_loss: 0.1118 - val_output_1_loss: 0.0934\n",
      "Epoch 99/100\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1192 - output_1_loss: 0.1093 - val_loss: 0.1108 - val_output_1_loss: 0.0926\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1264 - output_1_loss: 0.1157 - val_loss: 0.3128 - val_output_1_loss: 0.2936\n",
      "Epoch 40/100\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.2174 - output_1_loss: 0.2066 - val_loss: 0.3062 - val_output_1_loss: 0.2870\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1071 - output_1_loss: 0.0970 - val_loss: 0.1078 - val_output_1_loss: 0.0899\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1628 - output_1_loss: 0.1525 - val_loss: 0.2954 - val_output_1_loss: 0.2763\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.1917 - output_1_loss: 0.1805 - val_loss: 0.2880 - val_output_1_loss: 0.2692\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1420 - output_1_loss: 0.1319 - val_loss: 0.2799 - val_output_1_loss: 0.2613\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1768 - output_1_loss: 0.1667 - val_loss: 0.2724 - val_output_1_loss: 0.2537\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2557 - output_1_loss: 0.2453 - val_loss: 0.2629 - val_output_1_loss: 0.2444\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:17:55,121]\u001b[0m Trial 45 finished with value: 0.04 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 4, 'relaxation_factor': 1.3, 'sparsity_coefficient': 0.00812796456212252, 'bn_momentum': 0.952852861505258}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.1554 - output_1_loss: 0.1452 - val_loss: 0.2509 - val_output_1_loss: 0.2326\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1946 - output_1_loss: 0.1850 - val_loss: 0.2439 - val_output_1_loss: 0.2257\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2415 - output_1_loss: 0.2317Epoch 1/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.2415 - output_1_loss: 0.2317 - val_loss: 0.2388 - val_output_1_loss: 0.2207\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.1446 - output_1_loss: 0.1346 - val_loss: 0.2355 - val_output_1_loss: 0.2176\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.1727 - output_1_loss: 0.1623 - val_loss: 0.2304 - val_output_1_loss: 0.2125\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.1221 - output_1_loss: 0.1124 - val_loss: 0.2258 - val_output_1_loss: 0.2078\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.2023 - output_1_loss: 0.1930 - val_loss: 0.2209 - val_output_1_loss: 0.2031\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1145 - output_1_loss: 0.1046 - val_loss: 0.2129 - val_output_1_loss: 0.1949\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1627 - output_1_loss: 0.1533 - val_loss: 0.2088 - val_output_1_loss: 0.1910\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1206 - output_1_loss: 0.1110 - val_loss: 0.2030 - val_output_1_loss: 0.1852\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.3356 - output_1_loss: 0.3257 - val_loss: 0.2003 - val_output_1_loss: 0.1823\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.2027 - output_1_loss: 0.1927 - val_loss: 0.1987 - val_output_1_loss: 0.1808\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.1582 - output_1_loss: 0.1483 - val_loss: 0.1936 - val_output_1_loss: 0.1757\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1380 - output_1_loss: 0.1282 - val_loss: 0.1870 - val_output_1_loss: 0.1690\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1241 - output_1_loss: 0.1149 - val_loss: 0.1789 - val_output_1_loss: 0.1612\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.1177 - output_1_loss: 0.1082 - val_loss: 0.1766 - val_output_1_loss: 0.1590\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1759 - output_1_loss: 0.1668 - val_loss: 0.1752 - val_output_1_loss: 0.1577\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2621 - output_1_loss: 0.2531 - val_loss: 0.1728 - val_output_1_loss: 0.1556\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.1658 - output_1_loss: 0.1567 - val_loss: 0.1697 - val_output_1_loss: 0.1527\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.1050 - output_1_loss: 0.0963 - val_loss: 0.1679 - val_output_1_loss: 0.1510\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.1172 - output_1_loss: 0.1084 - val_loss: 0.1640 - val_output_1_loss: 0.1472\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.1165 - output_1_loss: 0.1087 - val_loss: 0.1611 - val_output_1_loss: 0.1444\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.1834 - output_1_loss: 0.1757 - val_loss: 0.1589 - val_output_1_loss: 0.1424\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.1188 - output_1_loss: 0.1116 - val_loss: 0.1578 - val_output_1_loss: 0.1416\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.1258 - output_1_loss: 0.1184 - val_loss: 0.1570 - val_output_1_loss: 0.1410\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.1296 - output_1_loss: 0.1230 - val_loss: 0.1549 - val_output_1_loss: 0.1392\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0909 - output_1_loss: 0.0839 - val_loss: 0.1532 - val_output_1_loss: 0.1377\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0947 - output_1_loss: 0.0877 - val_loss: 0.1534 - val_output_1_loss: 0.1382\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0845 - output_1_loss: 0.0775 - val_loss: 0.1472 - val_output_1_loss: 0.1322\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0852 - output_1_loss: 0.0782 - val_loss: 0.1423 - val_output_1_loss: 0.1274\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.1311 - output_1_loss: 0.1241 - val_loss: 0.1380 - val_output_1_loss: 0.1232\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0999 - output_1_loss: 0.0927 - val_loss: 0.1363 - val_output_1_loss: 0.1216\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1413 - output_1_loss: 0.1341 - val_loss: 0.1357 - val_output_1_loss: 0.1212\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1113 - output_1_loss: 0.1037 - val_loss: 0.1346 - val_output_1_loss: 0.1202\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1056 - output_1_loss: 0.0980 - val_loss: 0.1323 - val_output_1_loss: 0.1178\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1088 - output_1_loss: 0.1014 - val_loss: 0.1293 - val_output_1_loss: 0.1149\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1852 - output_1_loss: 0.1775 - val_loss: 0.1288 - val_output_1_loss: 0.1142\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1828 - output_1_loss: 0.1751 - val_loss: 0.1287 - val_output_1_loss: 0.1143\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1422 - output_1_loss: 0.1342 - val_loss: 0.1267 - val_output_1_loss: 0.1125\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1474 - output_1_loss: 0.1395 - val_loss: 0.1249 - val_output_1_loss: 0.1108\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1173 - output_1_loss: 0.1101 - val_loss: 0.1329 - val_output_1_loss: 0.1191\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1319 - output_1_loss: 0.1247 - val_loss: 0.1236 - val_output_1_loss: 0.1100\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1169 - output_1_loss: 0.1104 - val_loss: 0.1200 - val_output_1_loss: 0.1067\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9989 - output_1_loss: 0.8317Epoch 89/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.1291 - output_1_loss: 0.1225 - val_loss: 0.1117 - val_output_1_loss: 0.0987\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0846 - output_1_loss: 0.0786 - val_loss: 0.1075 - val_output_1_loss: 0.0948\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1164 - output_1_loss: 0.1103 - val_loss: 0.1100 - val_output_1_loss: 0.0973\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0790 - output_1_loss: 0.0728 - val_loss: 0.1084 - val_output_1_loss: 0.0956\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.9989 - output_1_loss: 0.8317 - val_loss: 1.2169 - val_output_1_loss: 0.6850\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0946 - output_1_loss: 0.0886 - val_loss: 0.1018 - val_output_1_loss: 0.0892\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9078 - output_1_loss: 0.7370Epoch 94/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.9078 - output_1_loss: 0.7370 - val_loss: 1.1798 - val_output_1_loss: 0.6759\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1139 - output_1_loss: 0.1079 - val_loss: 0.0970 - val_output_1_loss: 0.0845\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.8119 - output_1_loss: 0.6531 - val_loss: 1.1408 - val_output_1_loss: 0.6684\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0934 - output_1_loss: 0.0874 - val_loss: 0.0934 - val_output_1_loss: 0.0811\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8387 - output_1_loss: 0.6719 - val_loss: 1.1080 - val_output_1_loss: 0.6594\n",
      "Epoch 5/100\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1139 - output_1_loss: 0.1076 - val_loss: 0.0991 - val_output_1_loss: 0.0871\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.7576 - output_1_loss: 0.5902 - val_loss: 1.0799 - val_output_1_loss: 0.6499\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0945 - output_1_loss: 0.0873Epoch 6/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0945 - output_1_loss: 0.0873 - val_loss: 0.0988 - val_output_1_loss: 0.0869\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7460 - output_1_loss: 0.5768 - val_loss: 1.0534 - val_output_1_loss: 0.6404\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1171 - output_1_loss: 0.1099 - val_loss: 0.0958 - val_output_1_loss: 0.0840\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1057 - output_1_loss: 0.0985Epoch 7/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1057 - output_1_loss: 0.0985 - val_loss: 0.0899 - val_output_1_loss: 0.0782\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7442 - output_1_loss: 0.5847 - val_loss: 1.0273 - val_output_1_loss: 0.6325\n",
      "Epoch 8/100\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6928 - output_1_loss: 0.5345 - val_loss: 1.0010 - val_output_1_loss: 0.6245\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1739 - output_1_loss: 0.1667 - val_loss: 0.0841 - val_output_1_loss: 0.0725\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6657 - output_1_loss: 0.5208 - val_loss: 0.9810 - val_output_1_loss: 0.6155\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.6166 - output_1_loss: 0.4676 - val_loss: 0.9581 - val_output_1_loss: 0.6044\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5587 - output_1_loss: 0.4106 - val_loss: 0.9350 - val_output_1_loss: 0.5935\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.5147 - output_1_loss: 0.3726 - val_loss: 0.9135 - val_output_1_loss: 0.5806\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4108 - output_1_loss: 0.2765 - val_loss: 0.8903 - val_output_1_loss: 0.5682\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4480 - output_1_loss: 0.3208 - val_loss: 0.8677 - val_output_1_loss: 0.5562\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.3721 - output_1_loss: 0.2455 - val_loss: 0.8446 - val_output_1_loss: 0.5412\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3814 - output_1_loss: 0.2516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:18:18,214]\u001b[0m Trial 46 finished with value: 0.043478260869565216 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 4, 'relaxation_factor': 1.3, 'sparsity_coefficient': 0.006213479594020745, 'bn_momentum': 0.9504921780251541}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.3814 - output_1_loss: 0.2516 - val_loss: 0.8257 - val_output_1_loss: 0.5275\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.3363 - output_1_loss: 0.2073 - val_loss: 0.8107 - val_output_1_loss: 0.5132\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2812 - output_1_loss: 0.1541Epoch 1/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.2812 - output_1_loss: 0.1541 - val_loss: 0.7850 - val_output_1_loss: 0.4917\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.2401 - output_1_loss: 0.1113 - val_loss: 0.7474 - val_output_1_loss: 0.4649\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.2206 - output_1_loss: 0.1009 - val_loss: 0.7101 - val_output_1_loss: 0.4376\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.2131 - output_1_loss: 0.0870 - val_loss: 0.6688 - val_output_1_loss: 0.4070\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.2019 - output_1_loss: 0.0875 - val_loss: 0.6260 - val_output_1_loss: 0.3770\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.1949 - output_1_loss: 0.0855 - val_loss: 0.5855 - val_output_1_loss: 0.3435\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.1863 - output_1_loss: 0.0784 - val_loss: 0.5500 - val_output_1_loss: 0.3131\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1830 - output_1_loss: 0.0721 - val_loss: 0.5150 - val_output_1_loss: 0.2837\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1795 - output_1_loss: 0.0837 - val_loss: 0.4824 - val_output_1_loss: 0.2590\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.1659 - output_1_loss: 0.0727 - val_loss: 0.4539 - val_output_1_loss: 0.2380\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1549 - output_1_loss: 0.0698 - val_loss: 0.4249 - val_output_1_loss: 0.2173\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1586 - output_1_loss: 0.0744 - val_loss: 0.4026 - val_output_1_loss: 0.2004\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1578 - output_1_loss: 0.0708 - val_loss: 0.3851 - val_output_1_loss: 0.1863\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1638 - output_1_loss: 0.0799 - val_loss: 0.3683 - val_output_1_loss: 0.1723\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1497 - output_1_loss: 0.0658 - val_loss: 0.3559 - val_output_1_loss: 0.1618\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.1528 - output_1_loss: 0.0711 - val_loss: 0.3462 - val_output_1_loss: 0.1534\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.1552 - output_1_loss: 0.0737 - val_loss: 0.3367 - val_output_1_loss: 0.1448\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.1413 - output_1_loss: 0.0642 - val_loss: 0.3271 - val_output_1_loss: 0.1363\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.1372 - output_1_loss: 0.0613 - val_loss: 0.3178 - val_output_1_loss: 0.1289\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.1390 - output_1_loss: 0.0624 - val_loss: 0.3097 - val_output_1_loss: 0.1227\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1424 - output_1_loss: 0.0601 - val_loss: 0.3041 - val_output_1_loss: 0.1190\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.1335 - output_1_loss: 0.0590 - val_loss: 0.2974 - val_output_1_loss: 0.1139\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.1294 - output_1_loss: 0.0581 - val_loss: 0.2928 - val_output_1_loss: 0.1110\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.1264 - output_1_loss: 0.0580 - val_loss: 0.2888 - val_output_1_loss: 0.1082\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1287 - output_1_loss: 0.0628 - val_loss: 0.2855 - val_output_1_loss: 0.1059\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1337 - output_1_loss: 0.0662 - val_loss: 0.2839 - val_output_1_loss: 0.1051\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1317 - output_1_loss: 0.0628 - val_loss: 0.2813 - val_output_1_loss: 0.1023\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1294 - output_1_loss: 0.0657 - val_loss: 0.2784 - val_output_1_loss: 0.0996\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1218 - output_1_loss: 0.0621 - val_loss: 0.2756 - val_output_1_loss: 0.0972\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1197 - output_1_loss: 0.0624 - val_loss: 0.2725 - val_output_1_loss: 0.0950\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1157 - output_1_loss: 0.0613 - val_loss: 0.2686 - val_output_1_loss: 0.0926\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1129 - output_1_loss: 0.0616 - val_loss: 0.2654 - val_output_1_loss: 0.0912\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1102 - output_1_loss: 0.0600 - val_loss: 0.2626 - val_output_1_loss: 0.0902\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1094 - output_1_loss: 0.0610 - val_loss: 0.2596 - val_output_1_loss: 0.0892\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1083 - output_1_loss: 0.0610 - val_loss: 0.2565 - val_output_1_loss: 0.0883\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1073 - output_1_loss: 0.0608 - val_loss: 0.2529 - val_output_1_loss: 0.0872\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1057 - output_1_loss: 0.0607 - val_loss: 0.2496 - val_output_1_loss: 0.0864\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1044 - output_1_loss: 0.0605 - val_loss: 0.2452 - val_output_1_loss: 0.0853\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1047 - output_1_loss: 0.0618 - val_loss: 0.2408 - val_output_1_loss: 0.0843\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7331 - output_1_loss: 0.7329Epoch 57/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.1040 - output_1_loss: 0.0622 - val_loss: 0.2368 - val_output_1_loss: 0.0837\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.1019 - output_1_loss: 0.0601 - val_loss: 0.2326 - val_output_1_loss: 0.0825\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.1009 - output_1_loss: 0.0599 - val_loss: 0.2284 - val_output_1_loss: 0.0814\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0995 - output_1_loss: 0.0598 - val_loss: 0.2244 - val_output_1_loss: 0.0804\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0981 - output_1_loss: 0.0599 - val_loss: 0.2206 - val_output_1_loss: 0.0797\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0973 - output_1_loss: 0.0599 - val_loss: 0.2164 - val_output_1_loss: 0.0791\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0970 - output_1_loss: 0.0604 - val_loss: 0.2114 - val_output_1_loss: 0.0779\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.7331 - output_1_loss: 0.7329 - val_loss: 0.6900 - val_output_1_loss: 0.6894\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1009 - output_1_loss: 0.0656 - val_loss: 0.2068 - val_output_1_loss: 0.0771\n",
      "Epoch 65/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7213 - output_1_loss: 0.7211 - val_loss: 0.6862 - val_output_1_loss: 0.6856\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0935 - output_1_loss: 0.0596 - val_loss: 0.2019 - val_output_1_loss: 0.0762\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0921 - output_1_loss: 0.0596Epoch 3/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0921 - output_1_loss: 0.0596 - val_loss: 0.1974 - val_output_1_loss: 0.0751\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6959 - output_1_loss: 0.6957 - val_loss: 0.6833 - val_output_1_loss: 0.6827\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6842 - output_1_loss: 0.6841Epoch 67/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.6842 - output_1_loss: 0.6841 - val_loss: 0.6789 - val_output_1_loss: 0.6783\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0911 - output_1_loss: 0.0595 - val_loss: 0.1929 - val_output_1_loss: 0.0740\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6826 - output_1_loss: 0.6825Epoch 68/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6826 - output_1_loss: 0.6825 - val_loss: 0.6742 - val_output_1_loss: 0.6737\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0899 - output_1_loss: 0.0595Epoch 6/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0899 - output_1_loss: 0.0595 - val_loss: 0.1881 - val_output_1_loss: 0.0729\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6647 - output_1_loss: 0.6645 - val_loss: 0.6698 - val_output_1_loss: 0.6693\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0886 - output_1_loss: 0.0593 - val_loss: 0.1835 - val_output_1_loss: 0.0718\n",
      "Epoch 70/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0882 - output_1_loss: 0.0593 - val_loss: 0.1789 - val_output_1_loss: 0.0706\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6332 - output_1_loss: 0.6330 - val_loss: 0.6637 - val_output_1_loss: 0.6632\n",
      "Epoch 71/100\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0877 - output_1_loss: 0.0593 - val_loss: 0.1746 - val_output_1_loss: 0.0694\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6581 - output_1_loss: 0.6579 - val_loss: 0.6610 - val_output_1_loss: 0.6605\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0872 - output_1_loss: 0.0593 - val_loss: 0.1704 - val_output_1_loss: 0.0682\n",
      "Epoch 9/100\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0868 - output_1_loss: 0.0592 - val_loss: 0.1663 - val_output_1_loss: 0.0671\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6406 - output_1_loss: 0.6404 - val_loss: 0.6566 - val_output_1_loss: 0.6562\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6082 - output_1_loss: 0.6081 - val_loss: 0.6512 - val_output_1_loss: 0.6508\n",
      "Epoch 74/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0866 - output_1_loss: 0.0591 - val_loss: 0.1628 - val_output_1_loss: 0.0663\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5408 - output_1_loss: 0.5406 - val_loss: 0.6468 - val_output_1_loss: 0.6463\n",
      "Epoch 75/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0862 - output_1_loss: 0.0590 - val_loss: 0.1596 - val_output_1_loss: 0.0657\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6210 - output_1_loss: 0.6208 - val_loss: 0.6424 - val_output_1_loss: 0.6419\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5609 - output_1_loss: 0.5607Epoch 76/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.5609 - output_1_loss: 0.5607 - val_loss: 0.6370 - val_output_1_loss: 0.6366\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0857 - output_1_loss: 0.0589Epoch 14/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0857 - output_1_loss: 0.0589 - val_loss: 0.1567 - val_output_1_loss: 0.0654\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.5118 - output_1_loss: 0.5116 - val_loss: 0.6322 - val_output_1_loss: 0.6318\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0854 - output_1_loss: 0.0588 - val_loss: 0.1545 - val_output_1_loss: 0.0655\n",
      "Epoch 78/100\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0873 - output_1_loss: 0.0610 - val_loss: 0.1525 - val_output_1_loss: 0.0660\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5673 - output_1_loss: 0.5671 - val_loss: 0.6279 - val_output_1_loss: 0.6274\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0897 - output_1_loss: 0.0635 - val_loss: 0.1508 - val_output_1_loss: 0.0668\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.5223 - output_1_loss: 0.5221 - val_loss: 0.6235 - val_output_1_loss: 0.6231\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5208 - output_1_loss: 0.5206Epoch 80/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5208 - output_1_loss: 0.5206 - val_loss: 0.6188 - val_output_1_loss: 0.6184\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0903 - output_1_loss: 0.0641 - val_loss: 0.1497 - val_output_1_loss: 0.0680\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0877 - output_1_loss: 0.0618Epoch 18/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0877 - output_1_loss: 0.0618 - val_loss: 0.1486 - val_output_1_loss: 0.0691\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.5166 - output_1_loss: 0.5164 - val_loss: 0.6127 - val_output_1_loss: 0.6123\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0851 - output_1_loss: 0.0595Epoch 19/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0851 - output_1_loss: 0.0595 - val_loss: 0.1483 - val_output_1_loss: 0.0704\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4757 - output_1_loss: 0.4755 - val_loss: 0.6067 - val_output_1_loss: 0.6063\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0852 - output_1_loss: 0.0599 - val_loss: 0.1485 - val_output_1_loss: 0.0722\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0846 - output_1_loss: 0.0595 - val_loss: 0.1499 - val_output_1_loss: 0.0751\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5458 - output_1_loss: 0.5456 - val_loss: 0.6030 - val_output_1_loss: 0.6026\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0832 - output_1_loss: 0.0583 - val_loss: 0.1509 - val_output_1_loss: 0.0776\n",
      "Epoch 86/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0830 - output_1_loss: 0.0583 - val_loss: 0.1496 - val_output_1_loss: 0.0781\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5136 - output_1_loss: 0.5134Epoch 87/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5136 - output_1_loss: 0.5134 - val_loss: 0.5983 - val_output_1_loss: 0.5979\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0828 - output_1_loss: 0.0582 - val_loss: 0.1492 - val_output_1_loss: 0.0790\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.5503 - output_1_loss: 0.5501 - val_loss: 0.5927 - val_output_1_loss: 0.5924\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.5135 - output_1_loss: 0.5133 - val_loss: 0.5866 - val_output_1_loss: 0.5862\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.4146 - output_1_loss: 0.4144 - val_loss: 0.5800 - val_output_1_loss: 0.5796\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4709 - output_1_loss: 0.4708 - val_loss: 0.5730 - val_output_1_loss: 0.5727\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4303 - output_1_loss: 0.4301 - val_loss: 0.5652 - val_output_1_loss: 0.5649\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.3841 - output_1_loss: 0.3839 - val_loss: 0.5591 - val_output_1_loss: 0.5587\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3997 - output_1_loss: 0.3996 - val_loss: 0.5533 - val_output_1_loss: 0.5530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:18:43,205]\u001b[0m Trial 47 finished with value: 0.04 and parameters: {'feature_dim': 256, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 1.7000000000000002, 'sparsity_coefficient': 0.09268119552420263, 'bn_momentum': 0.9361504222784504}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3806 - output_1_loss: 0.3804 - val_loss: 0.5514 - val_output_1_loss: 0.5510\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.4337 - output_1_loss: 0.4335 - val_loss: 0.5471 - val_output_1_loss: 0.5467\n",
      "Epoch 1/100\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.3717 - output_1_loss: 0.3716 - val_loss: 0.5385 - val_output_1_loss: 0.5382\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4429 - output_1_loss: 0.4427 - val_loss: 0.5309 - val_output_1_loss: 0.5306\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.3424 - output_1_loss: 0.3422 - val_loss: 0.5220 - val_output_1_loss: 0.5217\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.3613 - output_1_loss: 0.3611 - val_loss: 0.5147 - val_output_1_loss: 0.5144\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.2875 - output_1_loss: 0.2873 - val_loss: 0.5097 - val_output_1_loss: 0.5094\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.2541 - output_1_loss: 0.2539 - val_loss: 0.5028 - val_output_1_loss: 0.5025\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.3230 - output_1_loss: 0.3229 - val_loss: 0.4960 - val_output_1_loss: 0.4957\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.3449 - output_1_loss: 0.3448 - val_loss: 0.4883 - val_output_1_loss: 0.4879\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.3224 - output_1_loss: 0.3222 - val_loss: 0.4766 - val_output_1_loss: 0.4763\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.2903 - output_1_loss: 0.2901 - val_loss: 0.4674 - val_output_1_loss: 0.4671\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.3305 - output_1_loss: 0.3303 - val_loss: 0.4614 - val_output_1_loss: 0.4611\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.3416 - output_1_loss: 0.3414 - val_loss: 0.4493 - val_output_1_loss: 0.4490\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.2559 - output_1_loss: 0.2557 - val_loss: 0.4385 - val_output_1_loss: 0.4383\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.2978 - output_1_loss: 0.2976 - val_loss: 0.4298 - val_output_1_loss: 0.4295\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.3644 - output_1_loss: 0.3642 - val_loss: 0.4229 - val_output_1_loss: 0.4226\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3560 - output_1_loss: 0.3558 - val_loss: 0.4188 - val_output_1_loss: 0.4185\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.2825 - output_1_loss: 0.2823 - val_loss: 0.4099 - val_output_1_loss: 0.4097\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.2991 - output_1_loss: 0.2989 - val_loss: 0.4022 - val_output_1_loss: 0.4019\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.2284 - output_1_loss: 0.2282 - val_loss: 0.3952 - val_output_1_loss: 0.3950\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.2215 - output_1_loss: 0.2214 - val_loss: 0.3862 - val_output_1_loss: 0.3859\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.1769 - output_1_loss: 0.1767 - val_loss: 0.3723 - val_output_1_loss: 0.3721\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.2011 - output_1_loss: 0.2009 - val_loss: 0.3618 - val_output_1_loss: 0.3615\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2017 - output_1_loss: 0.2015 - val_loss: 0.3542 - val_output_1_loss: 0.3540\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2042 - output_1_loss: 0.2041 - val_loss: 0.3449 - val_output_1_loss: 0.3447\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1788 - output_1_loss: 0.1786 - val_loss: 0.3367 - val_output_1_loss: 0.3365\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1993 - output_1_loss: 0.1991 - val_loss: 0.3281 - val_output_1_loss: 0.3279\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1886 - output_1_loss: 0.1884 - val_loss: 0.3212 - val_output_1_loss: 0.3209\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1351 - output_1_loss: 0.1349 - val_loss: 0.3119 - val_output_1_loss: 0.3116\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1715 - output_1_loss: 0.1713 - val_loss: 0.2990 - val_output_1_loss: 0.2988\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1371 - output_1_loss: 0.1369 - val_loss: 0.2871 - val_output_1_loss: 0.2868\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.1641 - output_1_loss: 0.1639 - val_loss: 0.2777 - val_output_1_loss: 0.2774\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.1948 - output_1_loss: 0.1946 - val_loss: 0.2704 - val_output_1_loss: 0.2701\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.1651 - output_1_loss: 0.1649 - val_loss: 0.2661 - val_output_1_loss: 0.2658\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1605 - output_1_loss: 0.1603 - val_loss: 0.2526 - val_output_1_loss: 0.2524\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.1383 - output_1_loss: 0.1381 - val_loss: 0.2474 - val_output_1_loss: 0.2471\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.1430 - output_1_loss: 0.1428 - val_loss: 0.2466 - val_output_1_loss: 0.2464\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.1280 - output_1_loss: 0.1278 - val_loss: 0.2431 - val_output_1_loss: 0.2429\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.1310 - output_1_loss: 0.1308 - val_loss: 0.2389 - val_output_1_loss: 0.2387\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1304 - output_1_loss: 0.1302 - val_loss: 0.2294 - val_output_1_loss: 0.2292\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1132 - output_1_loss: 0.1130 - val_loss: 0.2250 - val_output_1_loss: 0.2247\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.1130 - output_1_loss: 0.1129 - val_loss: 0.2130 - val_output_1_loss: 0.2128\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1231 - output_1_loss: 0.1229 - val_loss: 0.1958 - val_output_1_loss: 0.1956\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0811 - output_1_loss: 0.0810 - val_loss: 0.1783 - val_output_1_loss: 0.1781\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0917 - output_1_loss: 0.0916 - val_loss: 0.1598 - val_output_1_loss: 0.1596\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0852 - output_1_loss: 0.0850 - val_loss: 0.1509 - val_output_1_loss: 0.1507\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0956 - output_1_loss: 0.0954 - val_loss: 0.1426 - val_output_1_loss: 0.1424\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0889 - output_1_loss: 0.0887 - val_loss: 0.1376 - val_output_1_loss: 0.1374\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1233 - output_1_loss: 0.1231 - val_loss: 0.1311 - val_output_1_loss: 0.1309\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1139 - output_1_loss: 0.1137 - val_loss: 0.1252 - val_output_1_loss: 0.1250\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1039 - output_1_loss: 0.1037 - val_loss: 0.1261 - val_output_1_loss: 0.1259\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2063 - output_1_loss: 0.2061 - val_loss: 0.1121 - val_output_1_loss: 0.1119\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1085 - output_1_loss: 0.1083 - val_loss: 0.1069 - val_output_1_loss: 0.1067\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0907 - output_1_loss: 0.0906 - val_loss: 0.0933 - val_output_1_loss: 0.0931\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0796 - output_1_loss: 0.0794 - val_loss: 0.0955 - val_output_1_loss: 0.0953\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0752 - output_1_loss: 0.0750 - val_loss: 0.0915 - val_output_1_loss: 0.0914\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0803 - output_1_loss: 0.0802 - val_loss: 0.0851 - val_output_1_loss: 0.0849\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0793 - output_1_loss: 0.0791 - val_loss: 0.0831 - val_output_1_loss: 0.0829\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0801 - output_1_loss: 0.0800 - val_loss: 0.0726 - val_output_1_loss: 0.0725\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0835 - output_1_loss: 0.0833 - val_loss: 0.0711 - val_output_1_loss: 0.0709\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0818 - output_1_loss: 0.0816 - val_loss: 0.0783 - val_output_1_loss: 0.0781\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0931 - output_1_loss: 0.0930 - val_loss: 0.0789 - val_output_1_loss: 0.0787\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0888 - output_1_loss: 0.0886 - val_loss: 0.0772 - val_output_1_loss: 0.0770\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0863 - output_1_loss: 0.0861 - val_loss: 0.0759 - val_output_1_loss: 0.0757\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0839 - output_1_loss: 0.0837 - val_loss: 0.0732 - val_output_1_loss: 0.0730\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:19:07,574]\u001b[0m Trial 48 finished with value: 0.3333333333333333 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.0001142856870839636, 'bn_momentum': 0.9368077202589293}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 31s 31s/step - loss: 0.7127 - output_1_loss: 0.7126 - val_loss: 0.6882 - val_output_1_loss: 0.6878\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6735 - output_1_loss: 0.5746Epoch 2/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6735 - output_1_loss: 0.5746 - val_loss: 0.9748 - val_output_1_loss: 0.6830\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.7101 - output_1_loss: 0.7100 - val_loss: 0.6854 - val_output_1_loss: 0.6850\n",
      "Epoch 3/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.6284 - output_1_loss: 0.5186 - val_loss: 0.9481 - val_output_1_loss: 0.6730\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.6633 - output_1_loss: 0.6633 - val_loss: 0.6823 - val_output_1_loss: 0.6820\n",
      "Epoch 4/100\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6012 - output_1_loss: 0.4975 - val_loss: 0.9248 - val_output_1_loss: 0.6630\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.7196 - output_1_loss: 0.7195 - val_loss: 0.6778 - val_output_1_loss: 0.6775\n",
      "Epoch 5/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6688 - output_1_loss: 0.5542 - val_loss: 0.9064 - val_output_1_loss: 0.6529\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.6208 - output_1_loss: 0.6207 - val_loss: 0.6731 - val_output_1_loss: 0.6728\n",
      "Epoch 6/100\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4993 - output_1_loss: 0.3862 - val_loss: 0.8892 - val_output_1_loss: 0.6420\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.6775 - output_1_loss: 0.6774 - val_loss: 0.6687 - val_output_1_loss: 0.6684\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4314 - output_1_loss: 0.3373 - val_loss: 0.8678 - val_output_1_loss: 0.6298\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.6360 - output_1_loss: 0.6359 - val_loss: 0.6635 - val_output_1_loss: 0.6632\n",
      "Epoch 8/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2970 - output_1_loss: 0.2109 - val_loss: 0.8448 - val_output_1_loss: 0.6165\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.5672 - output_1_loss: 0.5672 - val_loss: 0.6596 - val_output_1_loss: 0.6593\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2233 - output_1_loss: 0.1397 - val_loss: 0.8205 - val_output_1_loss: 0.6021\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1800 - output_1_loss: 0.1005 - val_loss: 0.7995 - val_output_1_loss: 0.5882\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1558 - output_1_loss: 0.0922Epoch 9/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1558 - output_1_loss: 0.0922 - val_loss: 0.7780 - val_output_1_loss: 0.5713\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6059 - output_1_loss: 0.6058 - val_loss: 0.6545 - val_output_1_loss: 0.6543\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1333 - output_1_loss: 0.0743 - val_loss: 0.7592 - val_output_1_loss: 0.5554\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.5522 - output_1_loss: 0.5521 - val_loss: 0.6493 - val_output_1_loss: 0.6491\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1298 - output_1_loss: 0.0716 - val_loss: 0.7368 - val_output_1_loss: 0.5385\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1200 - output_1_loss: 0.0656 - val_loss: 0.7132 - val_output_1_loss: 0.5216\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1185 - output_1_loss: 0.0667Epoch 11/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1185 - output_1_loss: 0.0667 - val_loss: 0.6886 - val_output_1_loss: 0.5040\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1677 - output_1_loss: 0.1206 - val_loss: 0.6656 - val_output_1_loss: 0.4875\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5539 - output_1_loss: 0.5538 - val_loss: 0.6451 - val_output_1_loss: 0.6448\n",
      "Epoch 12/100\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1225 - output_1_loss: 0.0791 - val_loss: 0.6450 - val_output_1_loss: 0.4737\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.5275 - output_1_loss: 0.5274 - val_loss: 0.6405 - val_output_1_loss: 0.6403\n",
      "Epoch 13/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1379 - output_1_loss: 0.0959 - val_loss: 0.6272 - val_output_1_loss: 0.4615\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5718 - output_1_loss: 0.5717 - val_loss: 0.6359 - val_output_1_loss: 0.6357\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1046 - output_1_loss: 0.0653 - val_loss: 0.6097 - val_output_1_loss: 0.4494\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1026 - output_1_loss: 0.0652 - val_loss: 0.5921 - val_output_1_loss: 0.4366\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5015 - output_1_loss: 0.5014 - val_loss: 0.6324 - val_output_1_loss: 0.6321\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4916 - output_1_loss: 0.4915Epoch 20/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4916 - output_1_loss: 0.4915 - val_loss: 0.6274 - val_output_1_loss: 0.6271\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0982 - output_1_loss: 0.0627 - val_loss: 0.5755 - val_output_1_loss: 0.4237\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5133 - output_1_loss: 0.5132 - val_loss: 0.6232 - val_output_1_loss: 0.6229\n",
      "Epoch 17/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0918 - output_1_loss: 0.0581 - val_loss: 0.5589 - val_output_1_loss: 0.4106\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5983 - output_1_loss: 0.5982 - val_loss: 0.6176 - val_output_1_loss: 0.6173\n",
      "Epoch 18/100\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0889 - output_1_loss: 0.0563 - val_loss: 0.5427 - val_output_1_loss: 0.3974\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.4927 - output_1_loss: 0.4926 - val_loss: 0.6126 - val_output_1_loss: 0.6124\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0863 - output_1_loss: 0.0556Epoch 19/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0863 - output_1_loss: 0.0556 - val_loss: 0.5281 - val_output_1_loss: 0.3852\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4420 - output_1_loss: 0.4420 - val_loss: 0.6069 - val_output_1_loss: 0.6067\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0836 - output_1_loss: 0.0545Epoch 20/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0836 - output_1_loss: 0.0545 - val_loss: 0.5133 - val_output_1_loss: 0.3730\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4693 - output_1_loss: 0.4692 - val_loss: 0.6029 - val_output_1_loss: 0.6027\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0814 - output_1_loss: 0.0535Epoch 21/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0814 - output_1_loss: 0.0535 - val_loss: 0.4989 - val_output_1_loss: 0.3608\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4455 - output_1_loss: 0.4454 - val_loss: 0.5968 - val_output_1_loss: 0.5966\n",
      "Epoch 22/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0811 - output_1_loss: 0.0541 - val_loss: 0.4844 - val_output_1_loss: 0.3491\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4669 - output_1_loss: 0.4668 - val_loss: 0.5912 - val_output_1_loss: 0.5910\n",
      "Epoch 23/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0826 - output_1_loss: 0.0557 - val_loss: 0.4710 - val_output_1_loss: 0.3380\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.4229 - output_1_loss: 0.4228 - val_loss: 0.5863 - val_output_1_loss: 0.5860\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0846 - output_1_loss: 0.0585Epoch 24/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0846 - output_1_loss: 0.0585 - val_loss: 0.4597 - val_output_1_loss: 0.3278\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0834 - output_1_loss: 0.0583 - val_loss: 0.4492 - val_output_1_loss: 0.3182\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.4775 - output_1_loss: 0.4774 - val_loss: 0.5819 - val_output_1_loss: 0.5817\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4794 - output_1_loss: 0.4793Epoch 30/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4794 - output_1_loss: 0.4793 - val_loss: 0.5754 - val_output_1_loss: 0.5752\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0829 - output_1_loss: 0.0586 - val_loss: 0.4372 - val_output_1_loss: 0.3086\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0823 - output_1_loss: 0.0589Epoch 26/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0823 - output_1_loss: 0.0589 - val_loss: 0.4247 - val_output_1_loss: 0.2992\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0810 - output_1_loss: 0.0586 - val_loss: 0.4121 - val_output_1_loss: 0.2903\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.4358 - output_1_loss: 0.4357 - val_loss: 0.5664 - val_output_1_loss: 0.5662\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0796 - output_1_loss: 0.0580 - val_loss: 0.4000 - val_output_1_loss: 0.2819\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3751 - output_1_loss: 0.3751Epoch 34/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0776 - output_1_loss: 0.0567 - val_loss: 0.3884 - val_output_1_loss: 0.2740\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.3751 - output_1_loss: 0.3751 - val_loss: 0.5605 - val_output_1_loss: 0.5603\n",
      "Epoch 35/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0759 - output_1_loss: 0.0554 - val_loss: 0.3780 - val_output_1_loss: 0.2667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.4734 - output_1_loss: 0.4733 - val_loss: 0.5566 - val_output_1_loss: 0.5563\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0744 - output_1_loss: 0.0544 - val_loss: 0.3685 - val_output_1_loss: 0.2599\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4902 - output_1_loss: 0.4902Epoch 37/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4902 - output_1_loss: 0.4902 - val_loss: 0.5481 - val_output_1_loss: 0.5479\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0747 - output_1_loss: 0.0552 - val_loss: 0.3592 - val_output_1_loss: 0.2534\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0744 - output_1_loss: 0.0554 - val_loss: 0.3498 - val_output_1_loss: 0.2472\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.3171 - output_1_loss: 0.3170 - val_loss: 0.5454 - val_output_1_loss: 0.5452\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0733 - output_1_loss: 0.0548Epoch 31/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0733 - output_1_loss: 0.0548 - val_loss: 0.3419 - val_output_1_loss: 0.2412\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0728 - output_1_loss: 0.0544 - val_loss: 0.3354 - val_output_1_loss: 0.2355\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.4147 - output_1_loss: 0.4147 - val_loss: 0.5368 - val_output_1_loss: 0.5365\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0722 - output_1_loss: 0.0543 - val_loss: 0.3294 - val_output_1_loss: 0.2301\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0718 - output_1_loss: 0.0542 - val_loss: 0.3235 - val_output_1_loss: 0.2246\n",
      "Epoch 43/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0712 - output_1_loss: 0.0539 - val_loss: 0.3179 - val_output_1_loss: 0.2194\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.4234 - output_1_loss: 0.4234 - val_loss: 0.5360 - val_output_1_loss: 0.5358\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0698 - output_1_loss: 0.0534 - val_loss: 0.3125 - val_output_1_loss: 0.2144\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0693 - output_1_loss: 0.0535 - val_loss: 0.3073 - val_output_1_loss: 0.2096\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0688 - output_1_loss: 0.0535Epoch 33/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0688 - output_1_loss: 0.0535 - val_loss: 0.3024 - val_output_1_loss: 0.2049\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3582 - output_1_loss: 0.3581Epoch 47/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.3582 - output_1_loss: 0.3581 - val_loss: 0.5300 - val_output_1_loss: 0.5298\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0681 - output_1_loss: 0.0535 - val_loss: 0.2976 - val_output_1_loss: 0.2005\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0673 - output_1_loss: 0.0531Epoch 34/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0673 - output_1_loss: 0.0531 - val_loss: 0.2929 - val_output_1_loss: 0.1962\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4128 - output_1_loss: 0.4128Epoch 49/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0663 - output_1_loss: 0.0524 - val_loss: 0.2882 - val_output_1_loss: 0.1920\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.4128 - output_1_loss: 0.4128 - val_loss: 0.5226 - val_output_1_loss: 0.5225\n",
      "Epoch 50/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0676 - output_1_loss: 0.0530 - val_loss: 0.2836 - val_output_1_loss: 0.1878\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.3648 - output_1_loss: 0.3648 - val_loss: 0.5165 - val_output_1_loss: 0.5164\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0656 - output_1_loss: 0.0522 - val_loss: 0.2791 - val_output_1_loss: 0.1839\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0657 - output_1_loss: 0.0522Epoch 36/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0657 - output_1_loss: 0.0522 - val_loss: 0.2748 - val_output_1_loss: 0.1801\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0651 - output_1_loss: 0.0517 - val_loss: 0.2706 - val_output_1_loss: 0.1764\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.3572 - output_1_loss: 0.3572 - val_loss: 0.5092 - val_output_1_loss: 0.5090\n",
      "Epoch 37/100\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0644 - output_1_loss: 0.0513 - val_loss: 0.2665 - val_output_1_loss: 0.1727\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.3961 - output_1_loss: 0.3961 - val_loss: 0.5063 - val_output_1_loss: 0.5061\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0637 - output_1_loss: 0.0509 - val_loss: 0.2624 - val_output_1_loss: 0.1691\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0627 - output_1_loss: 0.0504 - val_loss: 0.2584 - val_output_1_loss: 0.1656\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0618 - output_1_loss: 0.0500Epoch 38/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0618 - output_1_loss: 0.0500 - val_loss: 0.2546 - val_output_1_loss: 0.1623\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3619 - output_1_loss: 0.3618 - val_loss: 0.4982 - val_output_1_loss: 0.4980\n",
      "Epoch 39/100\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3449 - output_1_loss: 0.3448 - val_loss: 0.4996 - val_output_1_loss: 0.4994\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0606 - output_1_loss: 0.0497 - val_loss: 0.2509 - val_output_1_loss: 0.1591\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3459 - output_1_loss: 0.3458Epoch 59/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3459 - output_1_loss: 0.3458 - val_loss: 0.4832 - val_output_1_loss: 0.4830\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0605 - output_1_loss: 0.0500 - val_loss: 0.2471 - val_output_1_loss: 0.1558\n",
      "Epoch 60/100\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0604 - output_1_loss: 0.0496 - val_loss: 0.2431 - val_output_1_loss: 0.1524\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3396 - output_1_loss: 0.3395 - val_loss: 0.4767 - val_output_1_loss: 0.4765\n",
      "Epoch 61/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0591 - output_1_loss: 0.0498 - val_loss: 0.2391 - val_output_1_loss: 0.1492\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3089 - output_1_loss: 0.3088 - val_loss: 0.4651 - val_output_1_loss: 0.4649\n",
      "Epoch 43/100\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0591 - output_1_loss: 0.0497 - val_loss: 0.2352 - val_output_1_loss: 0.1461\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.3604 - output_1_loss: 0.3603 - val_loss: 0.4631 - val_output_1_loss: 0.4629\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0589 - output_1_loss: 0.0497 - val_loss: 0.2313 - val_output_1_loss: 0.1431\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0587 - output_1_loss: 0.0496 - val_loss: 0.2276 - val_output_1_loss: 0.1402\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0583 - output_1_loss: 0.0496 - val_loss: 0.2240 - val_output_1_loss: 0.1375\n",
      "Epoch 44/100\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0580 - output_1_loss: 0.0496 - val_loss: 0.2204 - val_output_1_loss: 0.1348\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3227 - output_1_loss: 0.3227 - val_loss: 0.4573 - val_output_1_loss: 0.4572\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3405 - output_1_loss: 0.3404Epoch 67/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3405 - output_1_loss: 0.3404 - val_loss: 0.4580 - val_output_1_loss: 0.4578\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0576 - output_1_loss: 0.0496Epoch 46/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0576 - output_1_loss: 0.0496 - val_loss: 0.2168 - val_output_1_loss: 0.1322\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0573 - output_1_loss: 0.0496 - val_loss: 0.2133 - val_output_1_loss: 0.1297\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.3399 - output_1_loss: 0.3399 - val_loss: 0.4547 - val_output_1_loss: 0.4545\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0569 - output_1_loss: 0.0496 - val_loss: 0.2099 - val_output_1_loss: 0.1272\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0567 - output_1_loss: 0.0496 - val_loss: 0.2064 - val_output_1_loss: 0.1249\n",
      "Epoch 71/100\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0565 - output_1_loss: 0.0496 - val_loss: 0.2030 - val_output_1_loss: 0.1226\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3457 - output_1_loss: 0.3456 - val_loss: 0.4439 - val_output_1_loss: 0.4437\n",
      "Epoch 48/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0564 - output_1_loss: 0.0496 - val_loss: 0.1999 - val_output_1_loss: 0.1205\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2553 - output_1_loss: 0.2552 - val_loss: 0.4389 - val_output_1_loss: 0.4387\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2643 - output_1_loss: 0.2642Epoch 73/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2643 - output_1_loss: 0.2642 - val_loss: 0.4245 - val_output_1_loss: 0.4243\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0562 - output_1_loss: 0.0497 - val_loss: 0.1969 - val_output_1_loss: 0.1183\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0559 - output_1_loss: 0.0497 - val_loss: 0.1939 - val_output_1_loss: 0.1163\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3042 - output_1_loss: 0.3041 - val_loss: 0.4164 - val_output_1_loss: 0.4162\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2927 - output_1_loss: 0.2926Epoch 75/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0565 - output_1_loss: 0.0497 - val_loss: 0.1909 - val_output_1_loss: 0.1142\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.2927 - output_1_loss: 0.2926 - val_loss: 0.4040 - val_output_1_loss: 0.4038\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0556 - output_1_loss: 0.0496 - val_loss: 0.1879 - val_output_1_loss: 0.1123\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2988 - output_1_loss: 0.2987Epoch 77/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.2988 - output_1_loss: 0.2987 - val_loss: 0.4017 - val_output_1_loss: 0.4015\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0555 - output_1_loss: 0.0496 - val_loss: 0.1850 - val_output_1_loss: 0.1104\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2733 - output_1_loss: 0.2733 - val_loss: 0.4025 - val_output_1_loss: 0.4023\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0554 - output_1_loss: 0.0496 - val_loss: 0.1823 - val_output_1_loss: 0.1086\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2698 - output_1_loss: 0.2697Epoch 79/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2698 - output_1_loss: 0.2697 - val_loss: 0.3919 - val_output_1_loss: 0.3917\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0553 - output_1_loss: 0.0496 - val_loss: 0.1798 - val_output_1_loss: 0.1068\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2418 - output_1_loss: 0.2417 - val_loss: 0.3857 - val_output_1_loss: 0.3856\n",
      "Epoch 56/100\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0553 - output_1_loss: 0.0497 - val_loss: 0.1775 - val_output_1_loss: 0.1052\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.2498 - output_1_loss: 0.2497 - val_loss: 0.3803 - val_output_1_loss: 0.3801\n",
      "Epoch 57/100\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0550 - output_1_loss: 0.0496 - val_loss: 0.1752 - val_output_1_loss: 0.1036\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.2532 - output_1_loss: 0.2531 - val_loss: 0.3720 - val_output_1_loss: 0.3718\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0548 - output_1_loss: 0.0496 - val_loss: 0.1730 - val_output_1_loss: 0.1020\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0546 - output_1_loss: 0.0496 - val_loss: 0.1709 - val_output_1_loss: 0.1005\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0554 - output_1_loss: 0.0497 - val_loss: 0.1687 - val_output_1_loss: 0.0991\n",
      "Epoch 58/100\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0545 - output_1_loss: 0.0497 - val_loss: 0.1667 - val_output_1_loss: 0.0977\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.2758 - output_1_loss: 0.2757 - val_loss: 0.3631 - val_output_1_loss: 0.3629\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0546 - output_1_loss: 0.0496Epoch 59/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0546 - output_1_loss: 0.0496 - val_loss: 0.1647 - val_output_1_loss: 0.0964\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2589 - output_1_loss: 0.2588 - val_loss: 0.3549 - val_output_1_loss: 0.3547\n",
      "Epoch 60/100\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0546 - output_1_loss: 0.0496 - val_loss: 0.1627 - val_output_1_loss: 0.0951\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2606 - output_1_loss: 0.2605 - val_loss: 0.3484 - val_output_1_loss: 0.3483\n",
      "Epoch 61/100\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0545 - output_1_loss: 0.0496 - val_loss: 0.1608 - val_output_1_loss: 0.0938\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.3086 - output_1_loss: 0.3085 - val_loss: 0.3400 - val_output_1_loss: 0.3399\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0543 - output_1_loss: 0.0496 - val_loss: 0.1590 - val_output_1_loss: 0.0926\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0543 - output_1_loss: 0.0496 - val_loss: 0.1572 - val_output_1_loss: 0.0915\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1984 - output_1_loss: 0.1983 - val_loss: 0.3343 - val_output_1_loss: 0.3342\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0541 - output_1_loss: 0.0496Epoch 63/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0541 - output_1_loss: 0.0496 - val_loss: 0.1555 - val_output_1_loss: 0.0903\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1503 - output_1_loss: 0.1503 - val_loss: 0.3227 - val_output_1_loss: 0.3226\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0540 - output_1_loss: 0.0496Epoch 64/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0540 - output_1_loss: 0.0496 - val_loss: 0.1537 - val_output_1_loss: 0.0892\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2041 - output_1_loss: 0.2040 - val_loss: 0.3313 - val_output_1_loss: 0.3311\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0539 - output_1_loss: 0.0496 - val_loss: 0.1519 - val_output_1_loss: 0.0882\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0537 - output_1_loss: 0.0496 - val_loss: 0.1502 - val_output_1_loss: 0.0871\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1896 - output_1_loss: 0.1896 - val_loss: 0.3180 - val_output_1_loss: 0.3178\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2029 - output_1_loss: 0.2029Epoch 95/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2029 - output_1_loss: 0.2029 - val_loss: 0.3082 - val_output_1_loss: 0.3081\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0544 - output_1_loss: 0.0497 - val_loss: 0.1486 - val_output_1_loss: 0.0861\n",
      "Epoch 96/100\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0541 - output_1_loss: 0.0496 - val_loss: 0.1472 - val_output_1_loss: 0.0852\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1978 - output_1_loss: 0.1977 - val_loss: 0.3019 - val_output_1_loss: 0.3018\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0545 - output_1_loss: 0.0495Epoch 68/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0545 - output_1_loss: 0.0495 - val_loss: 0.1459 - val_output_1_loss: 0.0842\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0549 - output_1_loss: 0.0495 - val_loss: 0.1448 - val_output_1_loss: 0.0832\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.2057 - output_1_loss: 0.2057 - val_loss: 0.2949 - val_output_1_loss: 0.2948\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1916 - output_1_loss: 0.1915Epoch 99/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1916 - output_1_loss: 0.1915 - val_loss: 0.2844 - val_output_1_loss: 0.2843\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0554 - output_1_loss: 0.0495 - val_loss: 0.1438 - val_output_1_loss: 0.0823\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.2394 - output_1_loss: 0.2393 - val_loss: 0.2941 - val_output_1_loss: 0.2939\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0557 - output_1_loss: 0.0495 - val_loss: 0.1428 - val_output_1_loss: 0.0815\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.1451 - output_1_loss: 0.1451 - val_loss: 0.2814 - val_output_1_loss: 0.2812\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1728 - output_1_loss: 0.1727 - val_loss: 0.2765 - val_output_1_loss: 0.2764\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:19:44,660]\u001b[0m Trial 50 finished with value: 0.16666666666666666 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 2.0, 'sparsity_coefficient': 0.048013501604511746, 'bn_momentum': 0.9805721872556792}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 517ms/step - loss: 0.1487 - output_1_loss: 0.1486 - val_loss: 0.2717 - val_output_1_loss: 0.2716\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3251 - output_1_loss: 0.3250Epoch 1/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.3251 - output_1_loss: 0.3250 - val_loss: 0.2669 - val_output_1_loss: 0.2668\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2206 - output_1_loss: 0.2205 - val_loss: 0.2633 - val_output_1_loss: 0.2631\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.1178 - output_1_loss: 0.1177 - val_loss: 0.2532 - val_output_1_loss: 0.2530\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.1440 - output_1_loss: 0.1440 - val_loss: 0.2502 - val_output_1_loss: 0.2501\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.1772 - output_1_loss: 0.1772 - val_loss: 0.2461 - val_output_1_loss: 0.2459\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.1786 - output_1_loss: 0.1786 - val_loss: 0.2414 - val_output_1_loss: 0.2413\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.1492 - output_1_loss: 0.1491 - val_loss: 0.2302 - val_output_1_loss: 0.2301\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.1166 - output_1_loss: 0.1166 - val_loss: 0.2297 - val_output_1_loss: 0.2295\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.2177 - output_1_loss: 0.2176 - val_loss: 0.2291 - val_output_1_loss: 0.2290\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.1505 - output_1_loss: 0.1504 - val_loss: 0.2204 - val_output_1_loss: 0.2202\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.2633 - output_1_loss: 0.2633 - val_loss: 0.2155 - val_output_1_loss: 0.2153\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1309 - output_1_loss: 0.1308 - val_loss: 0.2114 - val_output_1_loss: 0.2113\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.1404 - output_1_loss: 0.1404 - val_loss: 0.2049 - val_output_1_loss: 0.2048\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.1520 - output_1_loss: 0.1519 - val_loss: 0.2014 - val_output_1_loss: 0.2013\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.1611 - output_1_loss: 0.1610 - val_loss: 0.1930 - val_output_1_loss: 0.1928\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.1344 - output_1_loss: 0.1343 - val_loss: 0.1927 - val_output_1_loss: 0.1926\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1243 - output_1_loss: 0.1243 - val_loss: 0.1876 - val_output_1_loss: 0.1874\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1139 - output_1_loss: 0.1138 - val_loss: 0.1818 - val_output_1_loss: 0.1816\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1545 - output_1_loss: 0.1544 - val_loss: 0.1731 - val_output_1_loss: 0.1730\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1007 - output_1_loss: 0.1006 - val_loss: 0.1713 - val_output_1_loss: 0.1711\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.1735 - output_1_loss: 0.1734 - val_loss: 0.1674 - val_output_1_loss: 0.1673\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.1949 - output_1_loss: 0.1949 - val_loss: 0.1667 - val_output_1_loss: 0.1666\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1046 - output_1_loss: 0.1045 - val_loss: 0.1674 - val_output_1_loss: 0.1673\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.1095 - output_1_loss: 0.1094 - val_loss: 0.1603 - val_output_1_loss: 0.1601\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.1063 - output_1_loss: 0.1063 - val_loss: 0.1489 - val_output_1_loss: 0.1487\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.0855 - output_1_loss: 0.0854 - val_loss: 0.1451 - val_output_1_loss: 0.1449\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.0964 - output_1_loss: 0.0963 - val_loss: 0.1375 - val_output_1_loss: 0.1373\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:20:05,345]\u001b[0m Trial 49 finished with value: 0.017857142857142856 and parameters: {'feature_dim': 64, 'n_step': 7, 'n_shared': 2, 'relaxation_factor': 2.0, 'sparsity_coefficient': 9.078886847707381e-05, 'bn_momentum': 0.9721382281424404}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.6180 - output_1_loss: 0.6180 - val_loss: 0.6822 - val_output_1_loss: 0.6821\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6417 - output_1_loss: 0.6417 - val_loss: 0.6886 - val_output_1_loss: 0.6885\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6362 - output_1_loss: 0.6362 - val_loss: 0.6854 - val_output_1_loss: 0.6853\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6289 - output_1_loss: 0.6289 - val_loss: 0.6810 - val_output_1_loss: 0.6809\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6123 - output_1_loss: 0.6123 - val_loss: 0.6757 - val_output_1_loss: 0.6756\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5655 - output_1_loss: 0.5654 - val_loss: 0.6706 - val_output_1_loss: 0.6705\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5834 - output_1_loss: 0.5833 - val_loss: 0.6658 - val_output_1_loss: 0.6657\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5458 - output_1_loss: 0.5458 - val_loss: 0.6601 - val_output_1_loss: 0.6600\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5691 - output_1_loss: 0.5691 - val_loss: 0.6541 - val_output_1_loss: 0.6540\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4920 - output_1_loss: 0.4920 - val_loss: 0.6483 - val_output_1_loss: 0.6482\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5197 - output_1_loss: 0.5197 - val_loss: 0.6433 - val_output_1_loss: 0.6432\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4812 - output_1_loss: 0.4812 - val_loss: 0.6376 - val_output_1_loss: 0.6375\n",
      "Epoch 12/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5068 - output_1_loss: 0.5068 - val_loss: 0.6326 - val_output_1_loss: 0.6325\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4268 - output_1_loss: 0.4268 - val_loss: 0.6275 - val_output_1_loss: 0.6274\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5925 - output_1_loss: 0.5924 - val_loss: 0.6716 - val_output_1_loss: 0.6715\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3833 - output_1_loss: 0.3832 - val_loss: 0.6222 - val_output_1_loss: 0.6221\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.6118 - output_1_loss: 0.6118 - val_loss: 0.6596 - val_output_1_loss: 0.6596\n",
      "Epoch 15/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3464 - output_1_loss: 0.3464 - val_loss: 0.6161 - val_output_1_loss: 0.6160\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5057 - output_1_loss: 0.5057 - val_loss: 0.6457 - val_output_1_loss: 0.6456\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3187 - output_1_loss: 0.3187 - val_loss: 0.6093 - val_output_1_loss: 0.6093\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2731 - output_1_loss: 0.2731 - val_loss: 0.6012 - val_output_1_loss: 0.6011\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2265 - output_1_loss: 0.2264Epoch 5/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2265 - output_1_loss: 0.2264 - val_loss: 0.5930 - val_output_1_loss: 0.5929\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5621 - output_1_loss: 0.5621 - val_loss: 0.6359 - val_output_1_loss: 0.6359\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1998 - output_1_loss: 0.1998Epoch 6/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1998 - output_1_loss: 0.1998 - val_loss: 0.5825 - val_output_1_loss: 0.5824\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5936 - output_1_loss: 0.5936Epoch 20/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5936 - output_1_loss: 0.5936 - val_loss: 0.6316 - val_output_1_loss: 0.6315\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1781 - output_1_loss: 0.1781Epoch 7/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1781 - output_1_loss: 0.1781 - val_loss: 0.5716 - val_output_1_loss: 0.5715\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1605 - output_1_loss: 0.1605 - val_loss: 0.5594 - val_output_1_loss: 0.5593\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.4423 - output_1_loss: 0.4423 - val_loss: 0.6176 - val_output_1_loss: 0.6176\n",
      "Epoch 8/100\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1424 - output_1_loss: 0.1424 - val_loss: 0.5461 - val_output_1_loss: 0.5460\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.5299 - output_1_loss: 0.5298 - val_loss: 0.6019 - val_output_1_loss: 0.6018\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4921 - output_1_loss: 0.4920Epoch 23/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1313 - output_1_loss: 0.1313 - val_loss: 0.5321 - val_output_1_loss: 0.5320\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.4921 - output_1_loss: 0.4920 - val_loss: 0.5910 - val_output_1_loss: 0.5910\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4360 - output_1_loss: 0.4360Epoch 24/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4360 - output_1_loss: 0.4360 - val_loss: 0.5798 - val_output_1_loss: 0.5797\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1222 - output_1_loss: 0.1221 - val_loss: 0.5178 - val_output_1_loss: 0.5177\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4272 - output_1_loss: 0.4272Epoch 25/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4272 - output_1_loss: 0.4272 - val_loss: 0.5643 - val_output_1_loss: 0.5642\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1139 - output_1_loss: 0.1139Epoch 12/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1139 - output_1_loss: 0.1139 - val_loss: 0.5035 - val_output_1_loss: 0.5034\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3711 - output_1_loss: 0.3711 - val_loss: 0.5526 - val_output_1_loss: 0.5526\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1037 - output_1_loss: 0.1037Epoch 13/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1037 - output_1_loss: 0.1037 - val_loss: 0.4889 - val_output_1_loss: 0.4888\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0971 - output_1_loss: 0.0970 - val_loss: 0.4742 - val_output_1_loss: 0.4741\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.3405 - output_1_loss: 0.3405 - val_loss: 0.5418 - val_output_1_loss: 0.5418\n",
      "Epoch 28/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0922 - output_1_loss: 0.0922 - val_loss: 0.4594 - val_output_1_loss: 0.4594\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.2678 - output_1_loss: 0.2678 - val_loss: 0.5259 - val_output_1_loss: 0.5258\n",
      "Epoch 15/100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0877 - output_1_loss: 0.0877 - val_loss: 0.4447 - val_output_1_loss: 0.4446\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.3161 - output_1_loss: 0.3161 - val_loss: 0.5112 - val_output_1_loss: 0.5112\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0823 - output_1_loss: 0.0823 - val_loss: 0.4300 - val_output_1_loss: 0.4300\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0794 - output_1_loss: 0.0794 - val_loss: 0.4155 - val_output_1_loss: 0.4154\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.4219 - output_1_loss: 0.4219 - val_loss: 0.5052 - val_output_1_loss: 0.5051\n",
      "Epoch 17/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0788 - output_1_loss: 0.0787 - val_loss: 0.4012 - val_output_1_loss: 0.4012\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.4132 - output_1_loss: 0.4132 - val_loss: 0.4977 - val_output_1_loss: 0.4977\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0758 - output_1_loss: 0.0757 - val_loss: 0.3872 - val_output_1_loss: 0.3872\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0731 - output_1_loss: 0.0731 - val_loss: 0.3738 - val_output_1_loss: 0.3738\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.3501 - output_1_loss: 0.3501 - val_loss: 0.4928 - val_output_1_loss: 0.4928\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2718 - output_1_loss: 0.2718Epoch 35/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0706 - output_1_loss: 0.0705 - val_loss: 0.3610 - val_output_1_loss: 0.3610\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.2718 - output_1_loss: 0.2718 - val_loss: 0.4712 - val_output_1_loss: 0.4711\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0682 - output_1_loss: 0.0682 - val_loss: 0.3489 - val_output_1_loss: 0.3488\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3176 - output_1_loss: 0.3176Epoch 37/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.3176 - output_1_loss: 0.3176 - val_loss: 0.4587 - val_output_1_loss: 0.4587\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0665 - output_1_loss: 0.0665 - val_loss: 0.3371 - val_output_1_loss: 0.3370\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0648 - output_1_loss: 0.0648 - val_loss: 0.3258 - val_output_1_loss: 0.3257\n",
      "Epoch 39/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0631 - output_1_loss: 0.0631 - val_loss: 0.3149 - val_output_1_loss: 0.3148\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3510 - output_1_loss: 0.3510 - val_loss: 0.4354 - val_output_1_loss: 0.4354\n",
      "Epoch 22/100\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0618 - output_1_loss: 0.0618 - val_loss: 0.3042 - val_output_1_loss: 0.3042\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3136 - output_1_loss: 0.3136 - val_loss: 0.4245 - val_output_1_loss: 0.4244\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4810 - output_1_loss: 0.4810Epoch 41/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0604 - output_1_loss: 0.0604 - val_loss: 0.2942 - val_output_1_loss: 0.2941\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.4810 - output_1_loss: 0.4810 - val_loss: 0.4134 - val_output_1_loss: 0.4134\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0592 - output_1_loss: 0.0592 - val_loss: 0.2847 - val_output_1_loss: 0.2847\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.2190 - output_1_loss: 0.2190 - val_loss: 0.3945 - val_output_1_loss: 0.3945\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0585 - output_1_loss: 0.0585 - val_loss: 0.2758 - val_output_1_loss: 0.2757\n",
      "Epoch 25/100\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0582 - output_1_loss: 0.0582 - val_loss: 0.2674 - val_output_1_loss: 0.2674\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.3457 - output_1_loss: 0.3457 - val_loss: 0.3833 - val_output_1_loss: 0.3833\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0571 - output_1_loss: 0.0571 - val_loss: 0.2597 - val_output_1_loss: 0.2596\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2289 - output_1_loss: 0.2289Epoch 46/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.2289 - output_1_loss: 0.2289 - val_loss: 0.3699 - val_output_1_loss: 0.3699\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0554 - output_1_loss: 0.0554 - val_loss: 0.2525 - val_output_1_loss: 0.2524\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2880 - output_1_loss: 0.2880Epoch 47/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2880 - output_1_loss: 0.2880 - val_loss: 0.3593 - val_output_1_loss: 0.3593\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0555 - output_1_loss: 0.0554 - val_loss: 0.2457 - val_output_1_loss: 0.2457\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2387 - output_1_loss: 0.2387 - val_loss: 0.3456 - val_output_1_loss: 0.3456\n",
      "Epoch 29/100\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0539 - output_1_loss: 0.0538 - val_loss: 0.2395 - val_output_1_loss: 0.2394\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1910 - output_1_loss: 0.1910 - val_loss: 0.3325 - val_output_1_loss: 0.3325\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0533 - output_1_loss: 0.0533 - val_loss: 0.2338 - val_output_1_loss: 0.2338\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0527 - output_1_loss: 0.0527 - val_loss: 0.2285 - val_output_1_loss: 0.2285\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0519 - output_1_loss: 0.0519 - val_loss: 0.2235 - val_output_1_loss: 0.2235\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0511 - output_1_loss: 0.0510Epoch 30/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0511 - output_1_loss: 0.0510 - val_loss: 0.2188 - val_output_1_loss: 0.2188\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1545 - output_1_loss: 0.1545 - val_loss: 0.3201 - val_output_1_loss: 0.3201\n",
      "Epoch 31/100\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0505 - output_1_loss: 0.0504 - val_loss: 0.2142 - val_output_1_loss: 0.2142\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.2026 - output_1_loss: 0.2026 - val_loss: 0.3079 - val_output_1_loss: 0.3079\n",
      "Epoch 32/100\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0497 - output_1_loss: 0.0497 - val_loss: 0.2099 - val_output_1_loss: 0.2099\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1844 - output_1_loss: 0.1843 - val_loss: 0.2971 - val_output_1_loss: 0.2970\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0492 - output_1_loss: 0.0492 - val_loss: 0.2058 - val_output_1_loss: 0.2058\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1874 - output_1_loss: 0.1874 - val_loss: 0.2834 - val_output_1_loss: 0.2834\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0486 - output_1_loss: 0.0486 - val_loss: 0.2017 - val_output_1_loss: 0.2017\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0480 - output_1_loss: 0.0480 - val_loss: 0.1976 - val_output_1_loss: 0.1975\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0475 - output_1_loss: 0.0475 - val_loss: 0.1936 - val_output_1_loss: 0.1935\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0469 - output_1_loss: 0.0469 - val_loss: 0.1898 - val_output_1_loss: 0.1898\n",
      "Epoch 60/100\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0464 - output_1_loss: 0.0464 - val_loss: 0.1863 - val_output_1_loss: 0.1863\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1777 - output_1_loss: 0.1777 - val_loss: 0.2741 - val_output_1_loss: 0.2741\n",
      "Epoch 61/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0458 - output_1_loss: 0.0458 - val_loss: 0.1831 - val_output_1_loss: 0.1830\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2222 - output_1_loss: 0.2222 - val_loss: 0.2676 - val_output_1_loss: 0.2675\n",
      "Epoch 36/100\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0452 - output_1_loss: 0.0452 - val_loss: 0.1797 - val_output_1_loss: 0.1797\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.1005 - output_1_loss: 0.1005 - val_loss: 0.2471 - val_output_1_loss: 0.2471\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0447 - output_1_loss: 0.0447 - val_loss: 0.1762 - val_output_1_loss: 0.1762\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0443 - output_1_loss: 0.0442 - val_loss: 0.1728 - val_output_1_loss: 0.1727\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0438 - output_1_loss: 0.0437 - val_loss: 0.1695 - val_output_1_loss: 0.1695\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0433 - output_1_loss: 0.0433Epoch 37/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0433 - output_1_loss: 0.0433 - val_loss: 0.1664 - val_output_1_loss: 0.1664\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0428 - output_1_loss: 0.0428 - val_loss: 0.1635 - val_output_1_loss: 0.1634\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1703 - output_1_loss: 0.1703 - val_loss: 0.2390 - val_output_1_loss: 0.2390\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0424 - output_1_loss: 0.0424 - val_loss: 0.1609 - val_output_1_loss: 0.1608\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1881 - output_1_loss: 0.1881Epoch 69/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1881 - output_1_loss: 0.1881 - val_loss: 0.2355 - val_output_1_loss: 0.2355\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0421 - output_1_loss: 0.0420Epoch 39/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0421 - output_1_loss: 0.0420 - val_loss: 0.1585 - val_output_1_loss: 0.1584\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0416 - output_1_loss: 0.0416 - val_loss: 0.1562 - val_output_1_loss: 0.1562\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.2267 - output_1_loss: 0.2267 - val_loss: 0.2200 - val_output_1_loss: 0.2200\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0412 - output_1_loss: 0.0412 - val_loss: 0.1538 - val_output_1_loss: 0.1537\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1722 - output_1_loss: 0.1722Epoch 72/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1722 - output_1_loss: 0.1722 - val_loss: 0.2087 - val_output_1_loss: 0.2086\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0409 - output_1_loss: 0.0408 - val_loss: 0.1516 - val_output_1_loss: 0.1516\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0405 - output_1_loss: 0.0405 - val_loss: 0.1494 - val_output_1_loss: 0.1494\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.1172 - output_1_loss: 0.1172 - val_loss: 0.1993 - val_output_1_loss: 0.1993\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1592 - output_1_loss: 0.1592Epoch 74/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1592 - output_1_loss: 0.1592 - val_loss: 0.2030 - val_output_1_loss: 0.2030\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0402 - output_1_loss: 0.0402 - val_loss: 0.1471 - val_output_1_loss: 0.1470\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1862 - output_1_loss: 0.1861 - val_loss: 0.1939 - val_output_1_loss: 0.1938\n",
      "Epoch 44/100\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0398 - output_1_loss: 0.0398 - val_loss: 0.1447 - val_output_1_loss: 0.1446\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.1052 - output_1_loss: 0.1052 - val_loss: 0.1769 - val_output_1_loss: 0.1769\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0393 - output_1_loss: 0.0393 - val_loss: 0.1424 - val_output_1_loss: 0.1423\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0388 - output_1_loss: 0.0388 - val_loss: 0.1404 - val_output_1_loss: 0.1403\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0383 - output_1_loss: 0.0383 - val_loss: 0.1385 - val_output_1_loss: 0.1384\n",
      "Epoch 45/100\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3441 - output_1_loss: 0.3441 - val_loss: 0.1978 - val_output_1_loss: 0.1978\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0379 - output_1_loss: 0.0379 - val_loss: 0.1366 - val_output_1_loss: 0.1366\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2563 - output_1_loss: 0.2563Epoch 80/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.2563 - output_1_loss: 0.2563 - val_loss: 0.1720 - val_output_1_loss: 0.1720\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0378 - output_1_loss: 0.0377 - val_loss: 0.1350 - val_output_1_loss: 0.1350\n",
      "Epoch 81/100\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0375 - output_1_loss: 0.0374 - val_loss: 0.1332 - val_output_1_loss: 0.1332\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2174 - output_1_loss: 0.2174 - val_loss: 0.1669 - val_output_1_loss: 0.1669\n",
      "Epoch 82/100\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0370 - output_1_loss: 0.0369 - val_loss: 0.1314 - val_output_1_loss: 0.1314\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1140 - output_1_loss: 0.1140 - val_loss: 0.1593 - val_output_1_loss: 0.1593\n",
      "Epoch 49/100\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0370 - output_1_loss: 0.0369 - val_loss: 0.1298 - val_output_1_loss: 0.1297\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1986 - output_1_loss: 0.1986 - val_loss: 0.1566 - val_output_1_loss: 0.1566\n",
      "Epoch 50/100\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0369 - output_1_loss: 0.0368 - val_loss: 0.1282 - val_output_1_loss: 0.1282\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.1406 - output_1_loss: 0.1406 - val_loss: 0.1507 - val_output_1_loss: 0.1507\n",
      "Epoch 51/100\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.3879 - output_1_loss: 0.3879 - val_loss: 0.1511 - val_output_1_loss: 0.1511\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0361 - output_1_loss: 0.0361 - val_loss: 0.1265 - val_output_1_loss: 0.1265\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.1615 - output_1_loss: 0.1615 - val_loss: 0.1502 - val_output_1_loss: 0.1502\n",
      "Epoch 53/100\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0367 - output_1_loss: 0.0366 - val_loss: 0.1244 - val_output_1_loss: 0.1244\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0999 - output_1_loss: 0.0999 - val_loss: 0.1409 - val_output_1_loss: 0.1409\n",
      "Epoch 54/100\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0368 - output_1_loss: 0.0368 - val_loss: 0.1223 - val_output_1_loss: 0.1223\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.1832 - output_1_loss: 0.1832 - val_loss: 0.1378 - val_output_1_loss: 0.1378\n",
      "Epoch 55/100\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0374 - output_1_loss: 0.0374 - val_loss: 0.1200 - val_output_1_loss: 0.1200\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0901 - output_1_loss: 0.0901 - val_loss: 0.1269 - val_output_1_loss: 0.1269\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0351 - output_1_loss: 0.0351 - val_loss: 0.1178 - val_output_1_loss: 0.1178\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1267 - output_1_loss: 0.1267 - val_loss: 0.1248 - val_output_1_loss: 0.1248\n",
      "Epoch 57/100\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0352 - output_1_loss: 0.0352 - val_loss: 0.1156 - val_output_1_loss: 0.1156\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0358 - output_1_loss: 0.0358 - val_loss: 0.1134 - val_output_1_loss: 0.1134\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.1106 - output_1_loss: 0.1106 - val_loss: 0.1179 - val_output_1_loss: 0.1179\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0357 - output_1_loss: 0.0357 - val_loss: 0.1107 - val_output_1_loss: 0.1107\n",
      "Epoch 93/100\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0352 - output_1_loss: 0.0351 - val_loss: 0.1079 - val_output_1_loss: 0.1079\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.2227 - output_1_loss: 0.2227 - val_loss: 0.1161 - val_output_1_loss: 0.1161\n",
      "Epoch 59/100\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1875 - output_1_loss: 0.1875 - val_loss: 0.1250 - val_output_1_loss: 0.1250\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0343 - output_1_loss: 0.0342 - val_loss: 0.1055 - val_output_1_loss: 0.1054\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1142 - output_1_loss: 0.1142Epoch 95/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1142 - output_1_loss: 0.1142 - val_loss: 0.1176 - val_output_1_loss: 0.1176\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0340 - output_1_loss: 0.0340 - val_loss: 0.1028 - val_output_1_loss: 0.1028\n",
      "Epoch 96/100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0338 - output_1_loss: 0.0338 - val_loss: 0.1002 - val_output_1_loss: 0.1002\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.1919 - output_1_loss: 0.1919 - val_loss: 0.1153 - val_output_1_loss: 0.1152\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0334 - output_1_loss: 0.0334 - val_loss: 0.0977 - val_output_1_loss: 0.0977\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.2967 - output_1_loss: 0.2967 - val_loss: 0.1341 - val_output_1_loss: 0.1341\n",
      "Epoch 63/100\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0330 - output_1_loss: 0.0329 - val_loss: 0.0956 - val_output_1_loss: 0.0955\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1324 - output_1_loss: 0.1324 - val_loss: 0.1140 - val_output_1_loss: 0.1140\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0325 - output_1_loss: 0.0325 - val_loss: 0.0943 - val_output_1_loss: 0.0943\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0323 - output_1_loss: 0.0323 - val_loss: 0.0933 - val_output_1_loss: 0.0932\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.1694 - output_1_loss: 0.1694 - val_loss: 0.1125 - val_output_1_loss: 0.1124\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0840 - output_1_loss: 0.0840 - val_loss: 0.1088 - val_output_1_loss: 0.1087\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1095 - output_1_loss: 0.1095 - val_loss: 0.1082 - val_output_1_loss: 0.1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:20:43,855]\u001b[0m Trial 52 finished with value: 0.07692307692307693 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 2.3, 'sparsity_coefficient': 1.8435418548054585e-05, 'bn_momentum': 0.9549050086079555}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.1363 - output_1_loss: 0.1363 - val_loss: 0.1011 - val_output_1_loss: 0.1010\n",
      "Epoch 68/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.1511 - output_1_loss: 0.1511 - val_loss: 0.1001 - val_output_1_loss: 0.1001\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.0747 - output_1_loss: 0.0747 - val_loss: 0.0940 - val_output_1_loss: 0.0940\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0994 - output_1_loss: 0.0994 - val_loss: 0.0983 - val_output_1_loss: 0.0983\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.1209 - output_1_loss: 0.1209 - val_loss: 0.0920 - val_output_1_loss: 0.0920\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1244 - output_1_loss: 0.1243 - val_loss: 0.0958 - val_output_1_loss: 0.0958\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2471 - output_1_loss: 0.2471 - val_loss: 0.0963 - val_output_1_loss: 0.0963\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1186 - output_1_loss: 0.1186 - val_loss: 0.1003 - val_output_1_loss: 0.1003\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0975 - output_1_loss: 0.0975 - val_loss: 0.1016 - val_output_1_loss: 0.1016\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1444 - output_1_loss: 0.1444 - val_loss: 0.1020 - val_output_1_loss: 0.1020\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:20:51,029]\u001b[0m Trial 51 finished with value: 0.0136986301369863 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 2, 'relaxation_factor': 2.8, 'sparsity_coefficient': 2.2249970627835674e-05, 'bn_momentum': 0.9543205613453708}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.8406 - output_1_loss: 0.8392 - val_loss: 0.6933 - val_output_1_loss: 0.6902\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8584 - output_1_loss: 0.8570 - val_loss: 0.6901 - val_output_1_loss: 0.6870\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7768 - output_1_loss: 0.7754 - val_loss: 0.6868 - val_output_1_loss: 0.6838\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6982 - output_1_loss: 0.6968 - val_loss: 0.6836 - val_output_1_loss: 0.6808\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6861 - output_1_loss: 0.6847 - val_loss: 0.6802 - val_output_1_loss: 0.6774\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6398 - output_1_loss: 0.6383 - val_loss: 0.6763 - val_output_1_loss: 0.6736\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6146 - output_1_loss: 0.6132 - val_loss: 0.6725 - val_output_1_loss: 0.6699\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5787 - output_1_loss: 0.5773 - val_loss: 0.6687 - val_output_1_loss: 0.6661\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5280 - output_1_loss: 0.5266 - val_loss: 0.6641 - val_output_1_loss: 0.6615\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4755 - output_1_loss: 0.4741 - val_loss: 0.6581 - val_output_1_loss: 0.6556\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4097 - output_1_loss: 0.4083 - val_loss: 0.6518 - val_output_1_loss: 0.6493\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3585 - output_1_loss: 0.3571 - val_loss: 0.6443 - val_output_1_loss: 0.6418\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3231 - output_1_loss: 0.3218 - val_loss: 0.6347 - val_output_1_loss: 0.6323\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2986 - output_1_loss: 0.2973 - val_loss: 0.6269 - val_output_1_loss: 0.6246\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2587 - output_1_loss: 0.2574 - val_loss: 0.6151 - val_output_1_loss: 0.6128\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2286 - output_1_loss: 0.2273 - val_loss: 0.6020 - val_output_1_loss: 0.5998\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.1981 - output_1_loss: 0.1969 - val_loss: 0.5883 - val_output_1_loss: 0.5861\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1748 - output_1_loss: 0.1736 - val_loss: 0.5733 - val_output_1_loss: 0.5711\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1541 - output_1_loss: 0.1529 - val_loss: 0.5573 - val_output_1_loss: 0.5551\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1358 - output_1_loss: 0.1346 - val_loss: 0.5408 - val_output_1_loss: 0.5387\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.8559 - output_1_loss: 0.8559 - val_loss: 0.6900 - val_output_1_loss: 0.6899\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1229 - output_1_loss: 0.1217 - val_loss: 0.5241 - val_output_1_loss: 0.5221\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7664 - output_1_loss: 0.7664 - val_loss: 0.6866 - val_output_1_loss: 0.6865\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1125 - output_1_loss: 0.1113 - val_loss: 0.5075 - val_output_1_loss: 0.5055\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7427 - output_1_loss: 0.7427 - val_loss: 0.6846 - val_output_1_loss: 0.6846\n",
      "Epoch 23/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.7516 - output_1_loss: 0.7516 - val_loss: 0.6810 - val_output_1_loss: 0.6810\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1034 - output_1_loss: 0.1023 - val_loss: 0.4911 - val_output_1_loss: 0.4891\n",
      "Epoch 24/100\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7352 - output_1_loss: 0.7352 - val_loss: 0.6783 - val_output_1_loss: 0.6783\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0955 - output_1_loss: 0.0944 - val_loss: 0.4749 - val_output_1_loss: 0.4729\n",
      "Epoch 25/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.6925 - output_1_loss: 0.6925 - val_loss: 0.6770 - val_output_1_loss: 0.6769\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0885 - output_1_loss: 0.0874 - val_loss: 0.4590 - val_output_1_loss: 0.4570\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6888 - output_1_loss: 0.6888 - val_loss: 0.6764 - val_output_1_loss: 0.6764\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0820 - output_1_loss: 0.0810 - val_loss: 0.4433 - val_output_1_loss: 0.4414\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0761 - output_1_loss: 0.0750 - val_loss: 0.4281 - val_output_1_loss: 0.4262\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0711 - output_1_loss: 0.0701Epoch 8/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0711 - output_1_loss: 0.0701 - val_loss: 0.4133 - val_output_1_loss: 0.4115\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6690 - output_1_loss: 0.6690Epoch 29/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.6690 - output_1_loss: 0.6690 - val_loss: 0.6753 - val_output_1_loss: 0.6753\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0667 - output_1_loss: 0.0657Epoch 9/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0667 - output_1_loss: 0.0657 - val_loss: 0.3991 - val_output_1_loss: 0.3973\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6420 - output_1_loss: 0.6420Epoch 30/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.6420 - output_1_loss: 0.6420 - val_loss: 0.6735 - val_output_1_loss: 0.6735\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0626 - output_1_loss: 0.0616 - val_loss: 0.3856 - val_output_1_loss: 0.3839\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6079 - output_1_loss: 0.6079 - val_loss: 0.6705 - val_output_1_loss: 0.6705\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0595 - output_1_loss: 0.0585 - val_loss: 0.3728 - val_output_1_loss: 0.3710\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5732 - output_1_loss: 0.5732 - val_loss: 0.6674 - val_output_1_loss: 0.6673\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5342 - output_1_loss: 0.5342 - val_loss: 0.6643 - val_output_1_loss: 0.6643\n",
      "Epoch 13/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0563 - output_1_loss: 0.0553 - val_loss: 0.3606 - val_output_1_loss: 0.3589\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.5119 - output_1_loss: 0.5119 - val_loss: 0.6606 - val_output_1_loss: 0.6606\n",
      "Epoch 14/100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4835 - output_1_loss: 0.4835 - val_loss: 0.6566 - val_output_1_loss: 0.6566\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0535 - output_1_loss: 0.0525 - val_loss: 0.3493 - val_output_1_loss: 0.3475\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4467 - output_1_loss: 0.4467 - val_loss: 0.6518 - val_output_1_loss: 0.6517\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4088 - output_1_loss: 0.4088Epoch 34/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4088 - output_1_loss: 0.4088 - val_loss: 0.6455 - val_output_1_loss: 0.6454\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0506 - output_1_loss: 0.0496 - val_loss: 0.3385 - val_output_1_loss: 0.3369\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3819 - output_1_loss: 0.3819 - val_loss: 0.6385 - val_output_1_loss: 0.6385\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3515 - output_1_loss: 0.3515Epoch 35/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3515 - output_1_loss: 0.3515 - val_loss: 0.6313 - val_output_1_loss: 0.6313\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0484 - output_1_loss: 0.0474Epoch 19/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0484 - output_1_loss: 0.0474 - val_loss: 0.3284 - val_output_1_loss: 0.3267\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3242 - output_1_loss: 0.3242Epoch 36/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3242 - output_1_loss: 0.3242 - val_loss: 0.6236 - val_output_1_loss: 0.6235\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0464 - output_1_loss: 0.0455 - val_loss: 0.3188 - val_output_1_loss: 0.3172\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3011 - output_1_loss: 0.3011 - val_loss: 0.6158 - val_output_1_loss: 0.6158\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0440 - output_1_loss: 0.0431 - val_loss: 0.3099 - val_output_1_loss: 0.3083\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2773 - output_1_loss: 0.2773 - val_loss: 0.6077 - val_output_1_loss: 0.6077\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2572 - output_1_loss: 0.2572 - val_loss: 0.5992 - val_output_1_loss: 0.5992\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2370 - output_1_loss: 0.2370Epoch 38/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2370 - output_1_loss: 0.2370 - val_loss: 0.5899 - val_output_1_loss: 0.5899\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0424 - output_1_loss: 0.0415 - val_loss: 0.3016 - val_output_1_loss: 0.3000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2205 - output_1_loss: 0.2205Epoch 39/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2205 - output_1_loss: 0.2205 - val_loss: 0.5799 - val_output_1_loss: 0.5798\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0406 - output_1_loss: 0.0397 - val_loss: 0.2939 - val_output_1_loss: 0.2923\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2060 - output_1_loss: 0.2060Epoch 40/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2060 - output_1_loss: 0.2060 - val_loss: 0.5692 - val_output_1_loss: 0.5692\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0393 - output_1_loss: 0.0384Epoch 26/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0393 - output_1_loss: 0.0384 - val_loss: 0.2866 - val_output_1_loss: 0.2850\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1914 - output_1_loss: 0.1914 - val_loss: 0.5578 - val_output_1_loss: 0.5578\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2704 - output_1_loss: 0.2704 - val_loss: 0.5513 - val_output_1_loss: 0.5513\n",
      "Epoch 28/100\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2785 - output_1_loss: 0.2785 - val_loss: 0.5433 - val_output_1_loss: 0.5433\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0378 - output_1_loss: 0.0369 - val_loss: 0.2797 - val_output_1_loss: 0.2782\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2170 - output_1_loss: 0.2170 - val_loss: 0.5347 - val_output_1_loss: 0.5347\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0368 - output_1_loss: 0.0359 - val_loss: 0.2734 - val_output_1_loss: 0.2718\n",
      "Epoch 30/100\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1588 - output_1_loss: 0.1588 - val_loss: 0.5211 - val_output_1_loss: 0.5211\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0358 - output_1_loss: 0.0349 - val_loss: 0.2674 - val_output_1_loss: 0.2659\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1527 - output_1_loss: 0.1527 - val_loss: 0.5075 - val_output_1_loss: 0.5075\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1423 - output_1_loss: 0.1423Epoch 44/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1423 - output_1_loss: 0.1423 - val_loss: 0.4933 - val_output_1_loss: 0.4933\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0347 - output_1_loss: 0.0338 - val_loss: 0.2618 - val_output_1_loss: 0.2603\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1392 - output_1_loss: 0.1392 - val_loss: 0.4793 - val_output_1_loss: 0.4793\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0340 - output_1_loss: 0.0331 - val_loss: 0.2566 - val_output_1_loss: 0.2551\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1287 - output_1_loss: 0.1287 - val_loss: 0.4643 - val_output_1_loss: 0.4643\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1215 - output_1_loss: 0.1215 - val_loss: 0.4494 - val_output_1_loss: 0.4494\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0329 - output_1_loss: 0.0320Epoch 36/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0329 - output_1_loss: 0.0320 - val_loss: 0.2518 - val_output_1_loss: 0.2503\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1155 - output_1_loss: 0.1155 - val_loss: 0.4345 - val_output_1_loss: 0.4345\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0323 - output_1_loss: 0.0314Epoch 37/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0323 - output_1_loss: 0.0314 - val_loss: 0.2474 - val_output_1_loss: 0.2459\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1120 - output_1_loss: 0.1119 - val_loss: 0.4189 - val_output_1_loss: 0.4189\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1064 - output_1_loss: 0.1064 - val_loss: 0.4035 - val_output_1_loss: 0.4034\n",
      "Epoch 48/100\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0312 - output_1_loss: 0.0303 - val_loss: 0.2433 - val_output_1_loss: 0.2419\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1013 - output_1_loss: 0.1013 - val_loss: 0.3881 - val_output_1_loss: 0.3880\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0307 - output_1_loss: 0.0298 - val_loss: 0.2396 - val_output_1_loss: 0.2381\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0298 - output_1_loss: 0.0289Epoch 40/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0298 - output_1_loss: 0.0289 - val_loss: 0.2361 - val_output_1_loss: 0.2347\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0968 - output_1_loss: 0.0968Epoch 51/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0968 - output_1_loss: 0.0968 - val_loss: 0.3725 - val_output_1_loss: 0.3725\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0291 - output_1_loss: 0.0282 - val_loss: 0.2330 - val_output_1_loss: 0.2316\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0924 - output_1_loss: 0.0924 - val_loss: 0.3567 - val_output_1_loss: 0.3567\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0285 - output_1_loss: 0.0276Epoch 42/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0285 - output_1_loss: 0.0276 - val_loss: 0.2302 - val_output_1_loss: 0.2288\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0885 - output_1_loss: 0.0885Epoch 53/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0885 - output_1_loss: 0.0885 - val_loss: 0.3410 - val_output_1_loss: 0.3410\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0276 - output_1_loss: 0.0268 - val_loss: 0.2275 - val_output_1_loss: 0.2262\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0856 - output_1_loss: 0.0856Epoch 54/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0856 - output_1_loss: 0.0856 - val_loss: 0.3255 - val_output_1_loss: 0.3255\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0272 - output_1_loss: 0.0264 - val_loss: 0.2253 - val_output_1_loss: 0.2239\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0827 - output_1_loss: 0.0827 - val_loss: 0.3106 - val_output_1_loss: 0.3106\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0801 - output_1_loss: 0.0801Epoch 55/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0801 - output_1_loss: 0.0801 - val_loss: 0.2963 - val_output_1_loss: 0.2963\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0268 - output_1_loss: 0.0259 - val_loss: 0.2231 - val_output_1_loss: 0.2218\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0770 - output_1_loss: 0.0770 - val_loss: 0.2826 - val_output_1_loss: 0.2826\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0747 - output_1_loss: 0.0747 - val_loss: 0.2699 - val_output_1_loss: 0.2699\n",
      "Epoch 56/100\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0260 - output_1_loss: 0.0252 - val_loss: 0.2212 - val_output_1_loss: 0.2199\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0724 - output_1_loss: 0.0724 - val_loss: 0.2578 - val_output_1_loss: 0.2578\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0707 - output_1_loss: 0.0707 - val_loss: 0.2465 - val_output_1_loss: 0.2465\n",
      "Epoch 57/100\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0258 - output_1_loss: 0.0249 - val_loss: 0.2198 - val_output_1_loss: 0.2185\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0689 - output_1_loss: 0.0689 - val_loss: 0.2356 - val_output_1_loss: 0.2356\n",
      "Epoch 51/100\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0674 - output_1_loss: 0.0673 - val_loss: 0.2252 - val_output_1_loss: 0.2252\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0253 - output_1_loss: 0.0245 - val_loss: 0.2185 - val_output_1_loss: 0.2172\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0658 - output_1_loss: 0.0658 - val_loss: 0.2155 - val_output_1_loss: 0.2155\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0246 - output_1_loss: 0.0237 - val_loss: 0.2175 - val_output_1_loss: 0.2162\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0642 - output_1_loss: 0.0642 - val_loss: 0.2063 - val_output_1_loss: 0.2063\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0246 - output_1_loss: 0.0237 - val_loss: 0.2170 - val_output_1_loss: 0.2157\n",
      "Epoch 54/100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0628 - output_1_loss: 0.0628 - val_loss: 0.1978 - val_output_1_loss: 0.1978\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0239 - output_1_loss: 0.0231 - val_loss: 0.2166 - val_output_1_loss: 0.2153\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0614 - output_1_loss: 0.0614 - val_loss: 0.1899 - val_output_1_loss: 0.1899\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0234 - output_1_loss: 0.0226 - val_loss: 0.2163 - val_output_1_loss: 0.2150\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0231 - output_1_loss: 0.0223 - val_loss: 0.2166 - val_output_1_loss: 0.2153\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0224 - output_1_loss: 0.0216 - val_loss: 0.2172 - val_output_1_loss: 0.2159\n",
      "Epoch 65/100\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0221 - output_1_loss: 0.0213 - val_loss: 0.2178 - val_output_1_loss: 0.2166\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0600 - output_1_loss: 0.0600 - val_loss: 0.1826 - val_output_1_loss: 0.1826\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0218 - output_1_loss: 0.0209 - val_loss: 0.2187 - val_output_1_loss: 0.2175\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0588 - output_1_loss: 0.0587Epoch 67/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0588 - output_1_loss: 0.0587 - val_loss: 0.1759 - val_output_1_loss: 0.1759\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0213 - output_1_loss: 0.0205 - val_loss: 0.2198 - val_output_1_loss: 0.2186\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0575 - output_1_loss: 0.0575 - val_loss: 0.1698 - val_output_1_loss: 0.1698\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0562 - output_1_loss: 0.0562 - val_loss: 0.1642 - val_output_1_loss: 0.1642\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0550 - output_1_loss: 0.0550 - val_loss: 0.1588 - val_output_1_loss: 0.1588\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0538 - output_1_loss: 0.0538 - val_loss: 0.1538 - val_output_1_loss: 0.1538\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0526 - output_1_loss: 0.0526 - val_loss: 0.1489 - val_output_1_loss: 0.1489\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0515 - output_1_loss: 0.0515 - val_loss: 0.1442 - val_output_1_loss: 0.1442\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0504 - output_1_loss: 0.0504 - val_loss: 0.1402 - val_output_1_loss: 0.1402\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0495 - output_1_loss: 0.0495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:21:14,474]\u001b[0m Trial 53 finished with value: 0.2 and parameters: {'feature_dim': 64, 'n_step': 2, 'n_shared': 1, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00037015746017264947, 'bn_momentum': 0.9541398455870448}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0495 - output_1_loss: 0.0495 - val_loss: 0.1360 - val_output_1_loss: 0.1360\n",
      "Epoch 1/100\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0488 - output_1_loss: 0.0488 - val_loss: 0.1318 - val_output_1_loss: 0.1318\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0479 - output_1_loss: 0.0479 - val_loss: 0.1276 - val_output_1_loss: 0.1276\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0467 - output_1_loss: 0.0467 - val_loss: 0.1234 - val_output_1_loss: 0.1233\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0457 - output_1_loss: 0.0457 - val_loss: 0.1191 - val_output_1_loss: 0.1191\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0447 - output_1_loss: 0.0447 - val_loss: 0.1151 - val_output_1_loss: 0.1151\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0438 - output_1_loss: 0.0438 - val_loss: 0.1117 - val_output_1_loss: 0.1117\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0429 - output_1_loss: 0.0429 - val_loss: 0.1087 - val_output_1_loss: 0.1086\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0421 - output_1_loss: 0.0421 - val_loss: 0.1060 - val_output_1_loss: 0.1060\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0413 - output_1_loss: 0.0413 - val_loss: 0.1035 - val_output_1_loss: 0.1034\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0404 - output_1_loss: 0.0404 - val_loss: 0.1012 - val_output_1_loss: 0.1012\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0396 - output_1_loss: 0.0396 - val_loss: 0.0991 - val_output_1_loss: 0.0991\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0389 - output_1_loss: 0.0389 - val_loss: 0.0973 - val_output_1_loss: 0.0973\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0381 - output_1_loss: 0.0381 - val_loss: 0.0957 - val_output_1_loss: 0.0957\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0374 - output_1_loss: 0.0373 - val_loss: 0.0943 - val_output_1_loss: 0.0943\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0366 - output_1_loss: 0.0366 - val_loss: 0.0928 - val_output_1_loss: 0.0928\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0359 - output_1_loss: 0.0359 - val_loss: 0.0916 - val_output_1_loss: 0.0916\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0352 - output_1_loss: 0.0352 - val_loss: 0.0903 - val_output_1_loss: 0.0903\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0345 - output_1_loss: 0.0345 - val_loss: 0.0892 - val_output_1_loss: 0.0892\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0339 - output_1_loss: 0.0339 - val_loss: 0.0883 - val_output_1_loss: 0.0883\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0332 - output_1_loss: 0.0332 - val_loss: 0.0876 - val_output_1_loss: 0.0876\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0324 - output_1_loss: 0.0324 - val_loss: 0.0870 - val_output_1_loss: 0.0870\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0319 - output_1_loss: 0.0319 - val_loss: 0.0867 - val_output_1_loss: 0.0867\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0313 - output_1_loss: 0.0313 - val_loss: 0.0866 - val_output_1_loss: 0.0866\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0306 - output_1_loss: 0.0306 - val_loss: 0.0866 - val_output_1_loss: 0.0866\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0300 - output_1_loss: 0.0300 - val_loss: 0.0865 - val_output_1_loss: 0.0865\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0293 - output_1_loss: 0.0293 - val_loss: 0.0863 - val_output_1_loss: 0.0863\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0286 - output_1_loss: 0.0286 - val_loss: 0.0862 - val_output_1_loss: 0.0861\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0280 - output_1_loss: 0.0279 - val_loss: 0.0861 - val_output_1_loss: 0.0861\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0273 - output_1_loss: 0.0272 - val_loss: 0.0862 - val_output_1_loss: 0.0862\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0265 - output_1_loss: 0.0265 - val_loss: 0.0864 - val_output_1_loss: 0.0864\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0258 - output_1_loss: 0.0258 - val_loss: 0.0864 - val_output_1_loss: 0.0864\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0252 - output_1_loss: 0.0252 - val_loss: 0.0863 - val_output_1_loss: 0.0863\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0247 - output_1_loss: 0.0246 - val_loss: 0.0862 - val_output_1_loss: 0.0862\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:21:25,022]\u001b[0m Trial 54 finished with value: 0.021739130434782608 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 1, 'relaxation_factor': 2.3, 'sparsity_coefficient': 2.871274744724478e-06, 'bn_momentum': 0.9256067047088674}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 19s 19s/step - loss: 0.6847 - output_1_loss: 0.6847 - val_loss: 0.6895 - val_output_1_loss: 0.6894\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.7173 - output_1_loss: 0.7117 - val_loss: 0.7021 - val_output_1_loss: 0.6890\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6337 - output_1_loss: 0.6278 - val_loss: 0.6975 - val_output_1_loss: 0.6849\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5423 - output_1_loss: 0.5366 - val_loss: 0.6919 - val_output_1_loss: 0.6798\n",
      "Epoch 4/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.4271 - output_1_loss: 0.4214 - val_loss: 0.6847 - val_output_1_loss: 0.6729\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6929 - output_1_loss: 0.6929 - val_loss: 0.6881 - val_output_1_loss: 0.6881\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3472 - output_1_loss: 0.3415Epoch 3/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3472 - output_1_loss: 0.3415 - val_loss: 0.6761 - val_output_1_loss: 0.6648\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.6770 - output_1_loss: 0.6770 - val_loss: 0.6861 - val_output_1_loss: 0.6861\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2628 - output_1_loss: 0.2573 - val_loss: 0.6661 - val_output_1_loss: 0.6552\n",
      "Epoch 4/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2107 - output_1_loss: 0.2052 - val_loss: 0.6540 - val_output_1_loss: 0.6433\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6383 - output_1_loss: 0.6383 - val_loss: 0.6831 - val_output_1_loss: 0.6831\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1866 - output_1_loss: 0.1813 - val_loss: 0.6413 - val_output_1_loss: 0.6308\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6287 - output_1_loss: 0.6287 - val_loss: 0.6808 - val_output_1_loss: 0.6808\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1440 - output_1_loss: 0.1388 - val_loss: 0.6272 - val_output_1_loss: 0.6168\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.6259 - output_1_loss: 0.6259 - val_loss: 0.6780 - val_output_1_loss: 0.6779\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1274 - output_1_loss: 0.1222 - val_loss: 0.6120 - val_output_1_loss: 0.6018\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1072 - output_1_loss: 0.1021 - val_loss: 0.5954 - val_output_1_loss: 0.5854\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5900 - output_1_loss: 0.5900 - val_loss: 0.6750 - val_output_1_loss: 0.6750\n",
      "Epoch 8/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0942 - output_1_loss: 0.0893 - val_loss: 0.5777 - val_output_1_loss: 0.5678\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5600 - output_1_loss: 0.5600 - val_loss: 0.6712 - val_output_1_loss: 0.6712\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5428 - output_1_loss: 0.5428 - val_loss: 0.6682 - val_output_1_loss: 0.6682\n",
      "Epoch 10/100\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.4479 - output_1_loss: 0.4479 - val_loss: 0.6645 - val_output_1_loss: 0.6645\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0885 - output_1_loss: 0.0836 - val_loss: 0.5594 - val_output_1_loss: 0.5497\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4639 - output_1_loss: 0.4639 - val_loss: 0.6599 - val_output_1_loss: 0.6599\n",
      "Epoch 12/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4098 - output_1_loss: 0.4098 - val_loss: 0.6530 - val_output_1_loss: 0.6530\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0788 - output_1_loss: 0.0740 - val_loss: 0.5409 - val_output_1_loss: 0.5312\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0721 - output_1_loss: 0.0673 - val_loss: 0.5217 - val_output_1_loss: 0.5122\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0680 - output_1_loss: 0.0633Epoch 13/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0680 - output_1_loss: 0.0633 - val_loss: 0.5023 - val_output_1_loss: 0.4929\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3215 - output_1_loss: 0.3215Epoch 17/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0643 - output_1_loss: 0.0596 - val_loss: 0.4830 - val_output_1_loss: 0.4737\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3215 - output_1_loss: 0.3215 - val_loss: 0.6443 - val_output_1_loss: 0.6443\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0608 - output_1_loss: 0.0562 - val_loss: 0.4639 - val_output_1_loss: 0.4548\n",
      "Epoch 14/100\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0586 - output_1_loss: 0.0540 - val_loss: 0.4452 - val_output_1_loss: 0.4362\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2925 - output_1_loss: 0.2925 - val_loss: 0.6336 - val_output_1_loss: 0.6335\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0563 - output_1_loss: 0.0518 - val_loss: 0.4271 - val_output_1_loss: 0.4181\n",
      "Epoch 21/100\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0545 - output_1_loss: 0.0500 - val_loss: 0.4096 - val_output_1_loss: 0.4008\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2468 - output_1_loss: 0.2468 - val_loss: 0.6212 - val_output_1_loss: 0.6212\n",
      "Epoch 22/100\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0530 - output_1_loss: 0.0485 - val_loss: 0.3928 - val_output_1_loss: 0.3840\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2242 - output_1_loss: 0.2242 - val_loss: 0.6071 - val_output_1_loss: 0.6070\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0521 - output_1_loss: 0.0477 - val_loss: 0.3766 - val_output_1_loss: 0.3679\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2313 - output_1_loss: 0.2313 - val_loss: 0.5949 - val_output_1_loss: 0.5948\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0510 - output_1_loss: 0.0466 - val_loss: 0.3615 - val_output_1_loss: 0.3529\n",
      "Epoch 25/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0496 - output_1_loss: 0.0452 - val_loss: 0.3471 - val_output_1_loss: 0.3386\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2242 - output_1_loss: 0.2241Epoch 26/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.2242 - output_1_loss: 0.2241 - val_loss: 0.5822 - val_output_1_loss: 0.5821\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0493 - output_1_loss: 0.0449Epoch 19/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0493 - output_1_loss: 0.0449 - val_loss: 0.3334 - val_output_1_loss: 0.3250\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2254 - output_1_loss: 0.2254Epoch 27/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2254 - output_1_loss: 0.2254 - val_loss: 0.5700 - val_output_1_loss: 0.5700\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0474 - output_1_loss: 0.0431 - val_loss: 0.3207 - val_output_1_loss: 0.3124\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0477 - output_1_loss: 0.0434 - val_loss: 0.3092 - val_output_1_loss: 0.3010\n",
      "Epoch 29/100\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0490 - output_1_loss: 0.0448 - val_loss: 0.2984 - val_output_1_loss: 0.2903\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2113 - output_1_loss: 0.2112Epoch 30/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2113 - output_1_loss: 0.2112 - val_loss: 0.5577 - val_output_1_loss: 0.5576\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0488 - output_1_loss: 0.0446 - val_loss: 0.2885 - val_output_1_loss: 0.2805\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0472 - output_1_loss: 0.0430 - val_loss: 0.2794 - val_output_1_loss: 0.2715\n",
      "Epoch 32/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0458 - output_1_loss: 0.0416 - val_loss: 0.2712 - val_output_1_loss: 0.2633\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2341 - output_1_loss: 0.2341 - val_loss: 0.5465 - val_output_1_loss: 0.5465\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2197 - output_1_loss: 0.2196 - val_loss: 0.5350 - val_output_1_loss: 0.5349\n",
      "Epoch 33/100\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0445 - output_1_loss: 0.0403 - val_loss: 0.2638 - val_output_1_loss: 0.2560\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1721 - output_1_loss: 0.1721 - val_loss: 0.5168 - val_output_1_loss: 0.5168\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0429 - output_1_loss: 0.0388 - val_loss: 0.2572 - val_output_1_loss: 0.2495\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1551 - output_1_loss: 0.1551 - val_loss: 0.4982 - val_output_1_loss: 0.4982\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0414 - output_1_loss: 0.0373 - val_loss: 0.2513 - val_output_1_loss: 0.2437\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0404 - output_1_loss: 0.0363 - val_loss: 0.2461 - val_output_1_loss: 0.2385\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1305 - output_1_loss: 0.1305 - val_loss: 0.4774 - val_output_1_loss: 0.4774\n",
      "Epoch 26/100\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0397 - output_1_loss: 0.0356 - val_loss: 0.2413 - val_output_1_loss: 0.2338\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1249 - output_1_loss: 0.1249 - val_loss: 0.4561 - val_output_1_loss: 0.4561\n",
      "Epoch 27/100\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0388 - output_1_loss: 0.0347 - val_loss: 0.2369 - val_output_1_loss: 0.2295\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1154 - output_1_loss: 0.1153 - val_loss: 0.4346 - val_output_1_loss: 0.4346\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0378 - output_1_loss: 0.0338 - val_loss: 0.2329 - val_output_1_loss: 0.2255\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0371 - output_1_loss: 0.0331Epoch 28/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0371 - output_1_loss: 0.0331 - val_loss: 0.2292 - val_output_1_loss: 0.2219\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1063 - output_1_loss: 0.1063 - val_loss: 0.4128 - val_output_1_loss: 0.4128\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0365 - output_1_loss: 0.0325 - val_loss: 0.2260 - val_output_1_loss: 0.2188\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0998 - output_1_loss: 0.0998 - val_loss: 0.3913 - val_output_1_loss: 0.3913\n",
      "Epoch 30/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0360 - output_1_loss: 0.0319 - val_loss: 0.2232 - val_output_1_loss: 0.2160\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0948 - output_1_loss: 0.0948 - val_loss: 0.3707 - val_output_1_loss: 0.3706\n",
      "Epoch 31/100\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0914 - output_1_loss: 0.0914 - val_loss: 0.3509 - val_output_1_loss: 0.3509\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0353 - output_1_loss: 0.0313 - val_loss: 0.2207 - val_output_1_loss: 0.2136\n",
      "Epoch 32/100\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0346 - output_1_loss: 0.0306 - val_loss: 0.2185 - val_output_1_loss: 0.2114\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0870 - output_1_loss: 0.0870 - val_loss: 0.3321 - val_output_1_loss: 0.3321\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0827 - output_1_loss: 0.0827 - val_loss: 0.3141 - val_output_1_loss: 0.3141\n",
      "Epoch 45/100\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0340 - output_1_loss: 0.0300 - val_loss: 0.2164 - val_output_1_loss: 0.2094\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0794 - output_1_loss: 0.0794 - val_loss: 0.2971 - val_output_1_loss: 0.2971\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0334 - output_1_loss: 0.0294 - val_loss: 0.2145 - val_output_1_loss: 0.2076\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0762 - output_1_loss: 0.0762 - val_loss: 0.2807 - val_output_1_loss: 0.2807\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0329 - output_1_loss: 0.0290 - val_loss: 0.2127 - val_output_1_loss: 0.2058\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0736 - output_1_loss: 0.0736 - val_loss: 0.2652 - val_output_1_loss: 0.2651\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0323 - output_1_loss: 0.0284 - val_loss: 0.2112 - val_output_1_loss: 0.2043\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0319 - output_1_loss: 0.0279Epoch 37/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0319 - output_1_loss: 0.0279 - val_loss: 0.2098 - val_output_1_loss: 0.2030\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0725 - output_1_loss: 0.0725 - val_loss: 0.2507 - val_output_1_loss: 0.2507\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0313 - output_1_loss: 0.0274 - val_loss: 0.2087 - val_output_1_loss: 0.2019\n",
      "Epoch 38/100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0695 - output_1_loss: 0.0695 - val_loss: 0.2371 - val_output_1_loss: 0.2371\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0305 - output_1_loss: 0.0266 - val_loss: 0.2077 - val_output_1_loss: 0.2010\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0300 - output_1_loss: 0.0261 - val_loss: 0.2068 - val_output_1_loss: 0.2001\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0296 - output_1_loss: 0.0257Epoch 39/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0296 - output_1_loss: 0.0257 - val_loss: 0.2058 - val_output_1_loss: 0.1992\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0674 - output_1_loss: 0.0673Epoch 54/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0674 - output_1_loss: 0.0673 - val_loss: 0.2248 - val_output_1_loss: 0.2248\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0291 - output_1_loss: 0.0252 - val_loss: 0.2048 - val_output_1_loss: 0.1982\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0286 - output_1_loss: 0.0248 - val_loss: 0.2038 - val_output_1_loss: 0.1973\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0655 - output_1_loss: 0.0655Epoch 56/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0655 - output_1_loss: 0.0655 - val_loss: 0.2135 - val_output_1_loss: 0.2135\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0283 - output_1_loss: 0.0245 - val_loss: 0.2029 - val_output_1_loss: 0.1964\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0647 - output_1_loss: 0.0647 - val_loss: 0.2028 - val_output_1_loss: 0.2028\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0623 - output_1_loss: 0.0623 - val_loss: 0.1929 - val_output_1_loss: 0.1929\n",
      "Epoch 57/100\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0279 - output_1_loss: 0.0241 - val_loss: 0.2021 - val_output_1_loss: 0.1956\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0620 - output_1_loss: 0.0620 - val_loss: 0.1838 - val_output_1_loss: 0.1838\n",
      "Epoch 58/100\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0275 - output_1_loss: 0.0238 - val_loss: 0.2013 - val_output_1_loss: 0.1950\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0597 - output_1_loss: 0.0597 - val_loss: 0.1757 - val_output_1_loss: 0.1757\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0272 - output_1_loss: 0.0234 - val_loss: 0.2006 - val_output_1_loss: 0.1943\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0583 - output_1_loss: 0.0583 - val_loss: 0.1683 - val_output_1_loss: 0.1683\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0571 - output_1_loss: 0.0571 - val_loss: 0.1619 - val_output_1_loss: 0.1619\n",
      "Epoch 47/100\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0269 - output_1_loss: 0.0231 - val_loss: 0.1999 - val_output_1_loss: 0.1936\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0561 - output_1_loss: 0.0560 - val_loss: 0.1562 - val_output_1_loss: 0.1562\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0265 - output_1_loss: 0.0228Epoch 48/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0265 - output_1_loss: 0.0228 - val_loss: 0.1991 - val_output_1_loss: 0.1928\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0548 - output_1_loss: 0.0548 - val_loss: 0.1509 - val_output_1_loss: 0.1509\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0262 - output_1_loss: 0.0225 - val_loss: 0.1981 - val_output_1_loss: 0.1920\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0259 - output_1_loss: 0.0222Epoch 49/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0259 - output_1_loss: 0.0222 - val_loss: 0.1971 - val_output_1_loss: 0.1910\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0537 - output_1_loss: 0.0537 - val_loss: 0.1462 - val_output_1_loss: 0.1462\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0256 - output_1_loss: 0.0219 - val_loss: 0.1960 - val_output_1_loss: 0.1899\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0253 - output_1_loss: 0.0216 - val_loss: 0.1949 - val_output_1_loss: 0.1889\n",
      "Epoch 66/100\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0250 - output_1_loss: 0.0213 - val_loss: 0.1941 - val_output_1_loss: 0.1881\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0529 - output_1_loss: 0.0529 - val_loss: 0.1421 - val_output_1_loss: 0.1420\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0246 - output_1_loss: 0.0210 - val_loss: 0.1932 - val_output_1_loss: 0.1873\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0243 - output_1_loss: 0.0207Epoch 51/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0243 - output_1_loss: 0.0207 - val_loss: 0.1922 - val_output_1_loss: 0.1864\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0522 - output_1_loss: 0.0522 - val_loss: 0.1378 - val_output_1_loss: 0.1378\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0240 - output_1_loss: 0.0204 - val_loss: 0.1911 - val_output_1_loss: 0.1854\n",
      "Epoch 52/100\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0238 - output_1_loss: 0.0202 - val_loss: 0.1899 - val_output_1_loss: 0.1842\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0514 - output_1_loss: 0.0514 - val_loss: 0.1339 - val_output_1_loss: 0.1339\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0235 - output_1_loss: 0.0199 - val_loss: 0.1885 - val_output_1_loss: 0.1829\n",
      "Epoch 72/100\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0232 - output_1_loss: 0.0196 - val_loss: 0.1871 - val_output_1_loss: 0.1815\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0501 - output_1_loss: 0.0501 - val_loss: 0.1306 - val_output_1_loss: 0.1306\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0229 - output_1_loss: 0.0194 - val_loss: 0.1855 - val_output_1_loss: 0.1799\n",
      "Epoch 74/100\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0227 - output_1_loss: 0.0191 - val_loss: 0.1838 - val_output_1_loss: 0.1784\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0492 - output_1_loss: 0.0492 - val_loss: 0.1278 - val_output_1_loss: 0.1278\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0224 - output_1_loss: 0.0189 - val_loss: 0.1821 - val_output_1_loss: 0.1766\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0221 - output_1_loss: 0.0186 - val_loss: 0.1802 - val_output_1_loss: 0.1748\n",
      "Epoch 55/100\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0219 - output_1_loss: 0.0183 - val_loss: 0.1782 - val_output_1_loss: 0.1729\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0490 - output_1_loss: 0.0490 - val_loss: 0.1241 - val_output_1_loss: 0.1241\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0216 - output_1_loss: 0.0181 - val_loss: 0.1761 - val_output_1_loss: 0.1709\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0213 - output_1_loss: 0.0178Epoch 56/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0213 - output_1_loss: 0.0178 - val_loss: 0.1740 - val_output_1_loss: 0.1688\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0480 - output_1_loss: 0.0480 - val_loss: 0.1213 - val_output_1_loss: 0.1212\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0211 - output_1_loss: 0.0176 - val_loss: 0.1720 - val_output_1_loss: 0.1668\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0208 - output_1_loss: 0.0174 - val_loss: 0.1702 - val_output_1_loss: 0.1651\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0477 - output_1_loss: 0.0477 - val_loss: 0.1188 - val_output_1_loss: 0.1188\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0206 - output_1_loss: 0.0172 - val_loss: 0.1684 - val_output_1_loss: 0.1633\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0467 - output_1_loss: 0.0467 - val_loss: 0.1165 - val_output_1_loss: 0.1165\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0456 - output_1_loss: 0.0456 - val_loss: 0.1135 - val_output_1_loss: 0.1135\n",
      "Epoch 60/100\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0462 - output_1_loss: 0.0462 - val_loss: 0.1109 - val_output_1_loss: 0.1109\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0204 - output_1_loss: 0.0170 - val_loss: 0.1668 - val_output_1_loss: 0.1618\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0203 - output_1_loss: 0.0168 - val_loss: 0.1653 - val_output_1_loss: 0.1603\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0201 - output_1_loss: 0.0167Epoch 61/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0201 - output_1_loss: 0.0167 - val_loss: 0.1638 - val_output_1_loss: 0.1589\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0444 - output_1_loss: 0.0444Epoch 86/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0444 - output_1_loss: 0.0444 - val_loss: 0.1093 - val_output_1_loss: 0.1093\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0200 - output_1_loss: 0.0165 - val_loss: 0.1624 - val_output_1_loss: 0.1575\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0198 - output_1_loss: 0.0164 - val_loss: 0.1610 - val_output_1_loss: 0.1562\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0442 - output_1_loss: 0.0442 - val_loss: 0.1086 - val_output_1_loss: 0.1086\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0197 - output_1_loss: 0.0163 - val_loss: 0.1598 - val_output_1_loss: 0.1550\n",
      "Epoch 63/100\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0438 - output_1_loss: 0.0438 - val_loss: 0.1089 - val_output_1_loss: 0.1089\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0196 - output_1_loss: 0.0162 - val_loss: 0.1585 - val_output_1_loss: 0.1538\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0430 - output_1_loss: 0.0430 - val_loss: 0.1093 - val_output_1_loss: 0.1093\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0195 - output_1_loss: 0.0161Epoch 65/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0195 - output_1_loss: 0.0161 - val_loss: 0.1574 - val_output_1_loss: 0.1527\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0422 - output_1_loss: 0.0422 - val_loss: 0.1093 - val_output_1_loss: 0.1093\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0450 - output_1_loss: 0.0450 - val_loss: 0.1089 - val_output_1_loss: 0.1089\n",
      "Epoch 67/100\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0194 - output_1_loss: 0.0161 - val_loss: 0.1564 - val_output_1_loss: 0.1517\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0467 - output_1_loss: 0.0467 - val_loss: 0.1077 - val_output_1_loss: 0.1077\n",
      "Epoch 68/100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0193 - output_1_loss: 0.0160 - val_loss: 0.1555 - val_output_1_loss: 0.1509\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0463 - output_1_loss: 0.0463 - val_loss: 0.1056 - val_output_1_loss: 0.1056\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0193 - output_1_loss: 0.0159 - val_loss: 0.1548 - val_output_1_loss: 0.1502\n",
      "Epoch 69/100\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0192 - output_1_loss: 0.0159 - val_loss: 0.1542 - val_output_1_loss: 0.1497\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0458 - output_1_loss: 0.0458 - val_loss: 0.1033 - val_output_1_loss: 0.1033\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0452 - output_1_loss: 0.0452 - val_loss: 0.1012 - val_output_1_loss: 0.1011\n",
      "Epoch 95/100\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0191 - output_1_loss: 0.0158 - val_loss: 0.1535 - val_output_1_loss: 0.1491\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0446 - output_1_loss: 0.0446 - val_loss: 0.0983 - val_output_1_loss: 0.0983\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0190 - output_1_loss: 0.0157Epoch 72/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0190 - output_1_loss: 0.0157 - val_loss: 0.1530 - val_output_1_loss: 0.1486\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0442 - output_1_loss: 0.0442 - val_loss: 0.0966 - val_output_1_loss: 0.0966\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0190 - output_1_loss: 0.0157 - val_loss: 0.1526 - val_output_1_loss: 0.1482\n",
      "Epoch 73/100\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0189 - output_1_loss: 0.0156 - val_loss: 0.1523 - val_output_1_loss: 0.1480\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0437 - output_1_loss: 0.0437 - val_loss: 0.0956 - val_output_1_loss: 0.0956\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0434 - output_1_loss: 0.0434 - val_loss: 0.0947 - val_output_1_loss: 0.0946\n",
      "Epoch 75/100\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0428 - output_1_loss: 0.0427 - val_loss: 0.0939 - val_output_1_loss: 0.0939\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0189 - output_1_loss: 0.0156 - val_loss: 0.1521 - val_output_1_loss: 0.1478\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0188 - output_1_loss: 0.0155 - val_loss: 0.1518 - val_output_1_loss: 0.1475\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0427 - output_1_loss: 0.0427 - val_loss: 0.0937 - val_output_1_loss: 0.0937\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0418 - output_1_loss: 0.0418 - val_loss: 0.0940 - val_output_1_loss: 0.0940\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0418 - output_1_loss: 0.0418 - val_loss: 0.0939 - val_output_1_loss: 0.0939\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0413 - output_1_loss: 0.0413 - val_loss: 0.0928 - val_output_1_loss: 0.0928\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0410 - output_1_loss: 0.0410 - val_loss: 0.0902 - val_output_1_loss: 0.0902\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:21:53,499]\u001b[0m Trial 56 finished with value: 0.05555555555555555 and parameters: {'feature_dim': 64, 'n_step': 2, 'n_shared': 1, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.0015706304951285948, 'bn_momentum': 0.9460363045141679}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0409 - output_1_loss: 0.0409 - val_loss: 0.0886 - val_output_1_loss: 0.0886\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0405 - output_1_loss: 0.0405 - val_loss: 0.0873 - val_output_1_loss: 0.0873\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0404 - output_1_loss: 0.0404Epoch 1/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0404 - output_1_loss: 0.0404 - val_loss: 0.0859 - val_output_1_loss: 0.0858\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0398 - output_1_loss: 0.0398 - val_loss: 0.0849 - val_output_1_loss: 0.0849\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0397 - output_1_loss: 0.0397 - val_loss: 0.0842 - val_output_1_loss: 0.0842\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0393 - output_1_loss: 0.0393 - val_loss: 0.0835 - val_output_1_loss: 0.0835\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0389 - output_1_loss: 0.0389 - val_loss: 0.0829 - val_output_1_loss: 0.0829\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.0388 - output_1_loss: 0.0388 - val_loss: 0.0824 - val_output_1_loss: 0.0824\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0384 - output_1_loss: 0.0384 - val_loss: 0.0821 - val_output_1_loss: 0.0821\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0382 - output_1_loss: 0.0381 - val_loss: 0.0819 - val_output_1_loss: 0.0819\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.0380 - output_1_loss: 0.0380 - val_loss: 0.0815 - val_output_1_loss: 0.0815\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0376 - output_1_loss: 0.0376 - val_loss: 0.0809 - val_output_1_loss: 0.0809\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0377 - output_1_loss: 0.0377 - val_loss: 0.0801 - val_output_1_loss: 0.0801\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0373 - output_1_loss: 0.0373 - val_loss: 0.0787 - val_output_1_loss: 0.0787\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0377 - output_1_loss: 0.0377 - val_loss: 0.0787 - val_output_1_loss: 0.0787\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0367 - output_1_loss: 0.0367 - val_loss: 0.0792 - val_output_1_loss: 0.0792\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0374 - output_1_loss: 0.0374 - val_loss: 0.0788 - val_output_1_loss: 0.0788\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0370 - output_1_loss: 0.0370 - val_loss: 0.0777 - val_output_1_loss: 0.0777\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0361 - output_1_loss: 0.0361 - val_loss: 0.0771 - val_output_1_loss: 0.0771\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0366 - output_1_loss: 0.0366 - val_loss: 0.0774 - val_output_1_loss: 0.0774\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:22:01,250]\u001b[0m Trial 55 finished with value: 0.020833333333333332 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 2.1, 'sparsity_coefficient': 5.948749302724076e-06, 'bn_momentum': 0.9247224460532608}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.9194 - output_1_loss: 0.9183 - val_loss: 0.6977 - val_output_1_loss: 0.6932\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8413 - output_1_loss: 0.8402 - val_loss: 0.6936 - val_output_1_loss: 0.6894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.9077 - output_1_loss: 0.9067 - val_loss: 0.6911 - val_output_1_loss: 0.6870\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.6827 - output_1_loss: 0.6814 - val_loss: 0.6932 - val_output_1_loss: 0.6887\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8457 - output_1_loss: 0.8447 - val_loss: 0.6874 - val_output_1_loss: 0.6834\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.8182 - output_1_loss: 0.8171 - val_loss: 0.6839 - val_output_1_loss: 0.6802\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8332 - output_1_loss: 0.8322 - val_loss: 0.6805 - val_output_1_loss: 0.6769\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8640 - output_1_loss: 0.8630 - val_loss: 0.6779 - val_output_1_loss: 0.6745\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7617 - output_1_loss: 0.7606 - val_loss: 0.6748 - val_output_1_loss: 0.6715\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.8084 - output_1_loss: 0.8073 - val_loss: 0.6734 - val_output_1_loss: 0.6703\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.8139 - output_1_loss: 0.8128 - val_loss: 0.6714 - val_output_1_loss: 0.6683\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.8241 - output_1_loss: 0.8230 - val_loss: 0.6678 - val_output_1_loss: 0.6648\n",
      "Epoch 2/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.7047 - output_1_loss: 0.7036 - val_loss: 0.6890 - val_output_1_loss: 0.6848\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8119 - output_1_loss: 0.8108 - val_loss: 0.6658 - val_output_1_loss: 0.6629\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7256 - output_1_loss: 0.7243 - val_loss: 0.6845 - val_output_1_loss: 0.6804\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6396 - output_1_loss: 0.6383Epoch 13/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.6396 - output_1_loss: 0.6383 - val_loss: 0.6796 - val_output_1_loss: 0.6757\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7711 - output_1_loss: 0.7700 - val_loss: 0.6650 - val_output_1_loss: 0.6621\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7290 - output_1_loss: 0.7279 - val_loss: 0.6645 - val_output_1_loss: 0.6617\n",
      "Epoch 15/100\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.7115 - output_1_loss: 0.7105 - val_loss: 0.6609 - val_output_1_loss: 0.6582\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.6498 - output_1_loss: 0.6486 - val_loss: 0.6748 - val_output_1_loss: 0.6710\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5914 - output_1_loss: 0.5902 - val_loss: 0.6693 - val_output_1_loss: 0.6657\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6193 - output_1_loss: 0.6181Epoch 16/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6193 - output_1_loss: 0.6181 - val_loss: 0.6644 - val_output_1_loss: 0.6609\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7447 - output_1_loss: 0.7436 - val_loss: 0.6574 - val_output_1_loss: 0.6546\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.6036 - output_1_loss: 0.6024 - val_loss: 0.6598 - val_output_1_loss: 0.6564\n",
      "Epoch 17/100\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.7144 - output_1_loss: 0.7133 - val_loss: 0.6543 - val_output_1_loss: 0.6515\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.6073 - output_1_loss: 0.6061 - val_loss: 0.6549 - val_output_1_loss: 0.6515\n",
      "Epoch 10/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5828 - output_1_loss: 0.5815 - val_loss: 0.6501 - val_output_1_loss: 0.6468\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7219 - output_1_loss: 0.7208 - val_loss: 0.6506 - val_output_1_loss: 0.6479\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5245 - output_1_loss: 0.5233Epoch 19/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5245 - output_1_loss: 0.5233 - val_loss: 0.6441 - val_output_1_loss: 0.6408\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.7246 - output_1_loss: 0.7236 - val_loss: 0.6498 - val_output_1_loss: 0.6471\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5136 - output_1_loss: 0.5123 - val_loss: 0.6383 - val_output_1_loss: 0.6351\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6977 - output_1_loss: 0.6966Epoch 13/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6977 - output_1_loss: 0.6966 - val_loss: 0.6465 - val_output_1_loss: 0.6439\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4696 - output_1_loss: 0.4684Epoch 21/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.4696 - output_1_loss: 0.4684 - val_loss: 0.6316 - val_output_1_loss: 0.6285\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.7037 - output_1_loss: 0.7026 - val_loss: 0.6445 - val_output_1_loss: 0.6419\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5481 - output_1_loss: 0.5469 - val_loss: 0.6264 - val_output_1_loss: 0.6233\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.7031 - output_1_loss: 0.7020 - val_loss: 0.6387 - val_output_1_loss: 0.6362\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4972 - output_1_loss: 0.4959Epoch 23/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.4972 - output_1_loss: 0.4959 - val_loss: 0.6198 - val_output_1_loss: 0.6167\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6715 - output_1_loss: 0.6704Epoch 16/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6715 - output_1_loss: 0.6704 - val_loss: 0.6380 - val_output_1_loss: 0.6356\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4660 - output_1_loss: 0.4647 - val_loss: 0.6124 - val_output_1_loss: 0.6093\n",
      "Epoch 17/100\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6690 - output_1_loss: 0.6679 - val_loss: 0.6374 - val_output_1_loss: 0.6350\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.4246 - output_1_loss: 0.4234 - val_loss: 0.6062 - val_output_1_loss: 0.6031\n",
      "Epoch 18/100\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6564 - output_1_loss: 0.6553 - val_loss: 0.6339 - val_output_1_loss: 0.6316\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4804 - output_1_loss: 0.4792 - val_loss: 0.5998 - val_output_1_loss: 0.5967\n",
      "Epoch 19/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.4760 - output_1_loss: 0.4748 - val_loss: 0.5942 - val_output_1_loss: 0.5913\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.6556 - output_1_loss: 0.6545 - val_loss: 0.6316 - val_output_1_loss: 0.6293\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4551 - output_1_loss: 0.4538Epoch 27/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.4551 - output_1_loss: 0.4538 - val_loss: 0.5875 - val_output_1_loss: 0.5846\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6325 - output_1_loss: 0.6314 - val_loss: 0.6256 - val_output_1_loss: 0.6234\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.4335 - output_1_loss: 0.4322 - val_loss: 0.5810 - val_output_1_loss: 0.5782\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6051 - output_1_loss: 0.6040 - val_loss: 0.6230 - val_output_1_loss: 0.6208\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4479 - output_1_loss: 0.4467 - val_loss: 0.5749 - val_output_1_loss: 0.5721\n",
      "Epoch 23/100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6107 - output_1_loss: 0.6096 - val_loss: 0.6211 - val_output_1_loss: 0.6189\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.4570 - output_1_loss: 0.4558 - val_loss: 0.5696 - val_output_1_loss: 0.5668\n",
      "Epoch 24/100\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4055 - output_1_loss: 0.4043 - val_loss: 0.5638 - val_output_1_loss: 0.5610\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5922 - output_1_loss: 0.5911 - val_loss: 0.6174 - val_output_1_loss: 0.6152\n",
      "Epoch 25/100\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3510 - output_1_loss: 0.3498 - val_loss: 0.5568 - val_output_1_loss: 0.5540\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.6064 - output_1_loss: 0.6053 - val_loss: 0.6105 - val_output_1_loss: 0.6084\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4033 - output_1_loss: 0.4021Epoch 32/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4033 - output_1_loss: 0.4021 - val_loss: 0.5505 - val_output_1_loss: 0.5477\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6178 - output_1_loss: 0.6167 - val_loss: 0.6043 - val_output_1_loss: 0.6022\n",
      "Epoch 33/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6118 - output_1_loss: 0.6106 - val_loss: 0.6040 - val_output_1_loss: 0.6019\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3694 - output_1_loss: 0.3683 - val_loss: 0.5440 - val_output_1_loss: 0.5412\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5904 - output_1_loss: 0.5893 - val_loss: 0.5990 - val_output_1_loss: 0.5970\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.3427 - output_1_loss: 0.3415 - val_loss: 0.5370 - val_output_1_loss: 0.5342\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5969 - output_1_loss: 0.5958Epoch 29/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5969 - output_1_loss: 0.5958 - val_loss: 0.5933 - val_output_1_loss: 0.5913\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6230 - output_1_loss: 0.6219 - val_loss: 0.5880 - val_output_1_loss: 0.5860\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.3417 - output_1_loss: 0.3405 - val_loss: 0.5285 - val_output_1_loss: 0.5258\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5699 - output_1_loss: 0.5688 - val_loss: 0.5859 - val_output_1_loss: 0.5839\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3322 - output_1_loss: 0.3310 - val_loss: 0.5215 - val_output_1_loss: 0.5188\n",
      "Epoch 38/100\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.5711 - output_1_loss: 0.5700 - val_loss: 0.5901 - val_output_1_loss: 0.5880\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.2327 - output_1_loss: 0.2316 - val_loss: 0.5084 - val_output_1_loss: 0.5057\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5785 - output_1_loss: 0.5774 - val_loss: 0.5831 - val_output_1_loss: 0.5811\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3213 - output_1_loss: 0.3201Epoch 40/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3213 - output_1_loss: 0.3201 - val_loss: 0.4999 - val_output_1_loss: 0.4972\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5515 - output_1_loss: 0.5505 - val_loss: 0.5675 - val_output_1_loss: 0.5655\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.3612 - output_1_loss: 0.3600 - val_loss: 0.4918 - val_output_1_loss: 0.4892\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5725 - output_1_loss: 0.5713 - val_loss: 0.5565 - val_output_1_loss: 0.5545\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.5911 - output_1_loss: 0.5900 - val_loss: 0.5580 - val_output_1_loss: 0.5561\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.3708 - output_1_loss: 0.3696 - val_loss: 0.4855 - val_output_1_loss: 0.4828\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5141 - output_1_loss: 0.5130 - val_loss: 0.5438 - val_output_1_loss: 0.5419\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.3033 - output_1_loss: 0.3021 - val_loss: 0.4770 - val_output_1_loss: 0.4744\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5347 - output_1_loss: 0.5336 - val_loss: 0.5265 - val_output_1_loss: 0.5246\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.2679 - output_1_loss: 0.2668 - val_loss: 0.4684 - val_output_1_loss: 0.4657\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.5410 - output_1_loss: 0.5399 - val_loss: 0.5095 - val_output_1_loss: 0.5077\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2611 - output_1_loss: 0.2600Epoch 46/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2611 - output_1_loss: 0.2600 - val_loss: 0.4606 - val_output_1_loss: 0.4579\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4802 - output_1_loss: 0.4791 - val_loss: 0.4927 - val_output_1_loss: 0.4909\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2911 - output_1_loss: 0.2899Epoch 47/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2911 - output_1_loss: 0.2899 - val_loss: 0.4528 - val_output_1_loss: 0.4502\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5331 - output_1_loss: 0.5319 - val_loss: 0.4715 - val_output_1_loss: 0.4698\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.3608 - output_1_loss: 0.3597 - val_loss: 0.4450 - val_output_1_loss: 0.4424\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4972 - output_1_loss: 0.4961Epoch 40/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4972 - output_1_loss: 0.4961 - val_loss: 0.4638 - val_output_1_loss: 0.4621\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.3177 - output_1_loss: 0.3166 - val_loss: 0.4373 - val_output_1_loss: 0.4348\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5226 - output_1_loss: 0.5215 - val_loss: 0.4607 - val_output_1_loss: 0.4590\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.2741 - output_1_loss: 0.2729 - val_loss: 0.4286 - val_output_1_loss: 0.4262\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.5281 - output_1_loss: 0.5270 - val_loss: 0.4505 - val_output_1_loss: 0.4488\n",
      "Epoch 42/100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5499 - output_1_loss: 0.5488 - val_loss: 0.4466 - val_output_1_loss: 0.4449\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2751 - output_1_loss: 0.2740 - val_loss: 0.4218 - val_output_1_loss: 0.4193\n",
      "Epoch 52/100\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5264 - output_1_loss: 0.5253 - val_loss: 0.4383 - val_output_1_loss: 0.4367\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2544 - output_1_loss: 0.2532 - val_loss: 0.4122 - val_output_1_loss: 0.4098\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4752 - output_1_loss: 0.4741Epoch 44/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4752 - output_1_loss: 0.4741 - val_loss: 0.4421 - val_output_1_loss: 0.4405\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.4976 - output_1_loss: 0.4966 - val_loss: 0.4505 - val_output_1_loss: 0.4488\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.2545 - output_1_loss: 0.2533 - val_loss: 0.4031 - val_output_1_loss: 0.4007\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4855 - output_1_loss: 0.4845Epoch 45/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4855 - output_1_loss: 0.4845 - val_loss: 0.4713 - val_output_1_loss: 0.4697\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4995 - output_1_loss: 0.4985 - val_loss: 0.4914 - val_output_1_loss: 0.4898\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.2646 - output_1_loss: 0.2634 - val_loss: 0.3947 - val_output_1_loss: 0.3923\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5377 - output_1_loss: 0.5367 - val_loss: 0.4856 - val_output_1_loss: 0.4840\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.2454 - output_1_loss: 0.2442 - val_loss: 0.3874 - val_output_1_loss: 0.3850\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.1907 - output_1_loss: 0.1895 - val_loss: 0.3782 - val_output_1_loss: 0.3758\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.1857 - output_1_loss: 0.1846 - val_loss: 0.3691 - val_output_1_loss: 0.3667\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.2350 - output_1_loss: 0.2339 - val_loss: 0.3631 - val_output_1_loss: 0.3607\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2036 - output_1_loss: 0.2025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:22:48,632]\u001b[0m Trial 58 finished with value: 0.034482758620689655 and parameters: {'feature_dim': 32, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 2.5, 'sparsity_coefficient': 0.0009172046761779756, 'bn_momentum': 0.9147020945110155}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.2036 - output_1_loss: 0.2025 - val_loss: 0.3548 - val_output_1_loss: 0.3525\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.2043 - output_1_loss: 0.2032 - val_loss: 0.3475 - val_output_1_loss: 0.3452\n",
      "Epoch 52/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.2064 - output_1_loss: 0.2053 - val_loss: 0.3400 - val_output_1_loss: 0.3377\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2033 - output_1_loss: 0.2022 - val_loss: 0.3308 - val_output_1_loss: 0.3285\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1779 - output_1_loss: 0.1767 - val_loss: 0.3242 - val_output_1_loss: 0.3219\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.1993 - output_1_loss: 0.1982 - val_loss: 0.3178 - val_output_1_loss: 0.3154\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.1397 - output_1_loss: 0.1386 - val_loss: 0.3092 - val_output_1_loss: 0.3069\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.1564 - output_1_loss: 0.1553 - val_loss: 0.3017 - val_output_1_loss: 0.2993\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.1657 - output_1_loss: 0.1646 - val_loss: 0.2956 - val_output_1_loss: 0.2933\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.1621 - output_1_loss: 0.1610 - val_loss: 0.2887 - val_output_1_loss: 0.2864\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.1927 - output_1_loss: 0.1917 - val_loss: 0.2823 - val_output_1_loss: 0.2800\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.1545 - output_1_loss: 0.1535 - val_loss: 0.2717 - val_output_1_loss: 0.2694\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.1892 - output_1_loss: 0.1882 - val_loss: 0.2617 - val_output_1_loss: 0.2594\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.1237 - output_1_loss: 0.1227 - val_loss: 0.2515 - val_output_1_loss: 0.2493\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.1652 - output_1_loss: 0.1643 - val_loss: 0.2468 - val_output_1_loss: 0.2446\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1392 - output_1_loss: 0.1382 - val_loss: 0.2391 - val_output_1_loss: 0.2368\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1464 - output_1_loss: 0.1455 - val_loss: 0.2303 - val_output_1_loss: 0.2281\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1216 - output_1_loss: 0.1206 - val_loss: 0.2199 - val_output_1_loss: 0.2178\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.1555 - output_1_loss: 0.1546 - val_loss: 0.2120 - val_output_1_loss: 0.2098\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1181 - output_1_loss: 0.1172 - val_loss: 0.2060 - val_output_1_loss: 0.2038\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.1315 - output_1_loss: 0.1307 - val_loss: 0.1999 - val_output_1_loss: 0.1978\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.1263 - output_1_loss: 0.1255 - val_loss: 0.1921 - val_output_1_loss: 0.1899\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.1252 - output_1_loss: 0.1244 - val_loss: 0.1834 - val_output_1_loss: 0.1813\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.1682 - output_1_loss: 0.1672 - val_loss: 0.1822 - val_output_1_loss: 0.1801\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.1288 - output_1_loss: 0.1279 - val_loss: 0.1718 - val_output_1_loss: 0.1697\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.1655 - output_1_loss: 0.1645 - val_loss: 0.1676 - val_output_1_loss: 0.1655\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.1615 - output_1_loss: 0.1606 - val_loss: 0.1662 - val_output_1_loss: 0.1642\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.1011 - output_1_loss: 0.1002 - val_loss: 0.1620 - val_output_1_loss: 0.1600\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.1030 - output_1_loss: 0.1022 - val_loss: 0.1617 - val_output_1_loss: 0.1597\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.1532 - output_1_loss: 0.1522 - val_loss: 0.1545 - val_output_1_loss: 0.1525\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.1024 - output_1_loss: 0.1015 - val_loss: 0.1435 - val_output_1_loss: 0.1415\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.1084 - output_1_loss: 0.1075 - val_loss: 0.1401 - val_output_1_loss: 0.1381\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 0.1430 - output_1_loss: 0.1420 - val_loss: 0.1328 - val_output_1_loss: 0.1308\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1243 - output_1_loss: 0.1232 - val_loss: 0.1336 - val_output_1_loss: 0.1316\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.0986 - output_1_loss: 0.0976 - val_loss: 0.1254 - val_output_1_loss: 0.1234\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0967 - output_1_loss: 0.0956 - val_loss: 0.1262 - val_output_1_loss: 0.1242\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1266 - output_1_loss: 0.1256 - val_loss: 0.1246 - val_output_1_loss: 0.1225\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1257 - output_1_loss: 0.1247 - val_loss: 0.1203 - val_output_1_loss: 0.1182\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0923 - output_1_loss: 0.0913 - val_loss: 0.1202 - val_output_1_loss: 0.1181\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1141 - output_1_loss: 0.1131 - val_loss: 0.1180 - val_output_1_loss: 0.1160\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0903 - output_1_loss: 0.0893 - val_loss: 0.1124 - val_output_1_loss: 0.1104\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1471 - output_1_loss: 0.1462 - val_loss: 0.1158 - val_output_1_loss: 0.1137\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0907 - output_1_loss: 0.0898 - val_loss: 0.1097 - val_output_1_loss: 0.1077\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0994 - output_1_loss: 0.0984 - val_loss: 0.1077 - val_output_1_loss: 0.1057\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0972 - output_1_loss: 0.0962 - val_loss: 0.1021 - val_output_1_loss: 0.1001\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1169 - output_1_loss: 0.1159 - val_loss: 0.0977 - val_output_1_loss: 0.0957\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1203 - output_1_loss: 0.1194 - val_loss: 0.1011 - val_output_1_loss: 0.0991\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0917 - output_1_loss: 0.0909 - val_loss: 0.0934 - val_output_1_loss: 0.0914\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0825 - output_1_loss: 0.0816 - val_loss: 0.0963 - val_output_1_loss: 0.0944\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1018 - output_1_loss: 0.1009 - val_loss: 0.0984 - val_output_1_loss: 0.0965\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1078 - output_1_loss: 0.1069 - val_loss: 0.1015 - val_output_1_loss: 0.0996\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:23:12,680]\u001b[0m Trial 57 finished with value: 0.012658227848101266 and parameters: {'feature_dim': 64, 'n_step': 6, 'n_shared': 1, 'relaxation_factor': 1.6, 'sparsity_coefficient': 0.0008321421871016837, 'bn_momentum': 0.965771584957481}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.7553 - output_1_loss: 0.7553Epoch 1/100\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.7553 - output_1_loss: 0.7553 - val_loss: 0.6876 - val_output_1_loss: 0.6876\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.7560 - output_1_loss: 0.7560 - val_loss: 0.6820 - val_output_1_loss: 0.6820\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.7464 - output_1_loss: 0.7464 - val_loss: 0.6763 - val_output_1_loss: 0.6763\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.6927 - output_1_loss: 0.6927 - val_loss: 0.6709 - val_output_1_loss: 0.6709\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.7514 - output_1_loss: 0.7514 - val_loss: 0.6650 - val_output_1_loss: 0.6650\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.6115 - output_1_loss: 0.6115 - val_loss: 0.6608 - val_output_1_loss: 0.6608\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.5855 - output_1_loss: 0.5855 - val_loss: 0.6557 - val_output_1_loss: 0.6557\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.5676 - output_1_loss: 0.5676 - val_loss: 0.6505 - val_output_1_loss: 0.6505\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.5234 - output_1_loss: 0.5234 - val_loss: 0.6439 - val_output_1_loss: 0.6439\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.5381 - output_1_loss: 0.5381 - val_loss: 0.6374 - val_output_1_loss: 0.6374\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4357 - output_1_loss: 0.4357 - val_loss: 0.6279 - val_output_1_loss: 0.6279\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4681 - output_1_loss: 0.4681 - val_loss: 0.6216 - val_output_1_loss: 0.6216\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.4084 - output_1_loss: 0.4084 - val_loss: 0.6067 - val_output_1_loss: 0.6067\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5008 - output_1_loss: 0.5008 - val_loss: 0.5968 - val_output_1_loss: 0.5968\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4558 - output_1_loss: 0.4558 - val_loss: 0.5918 - val_output_1_loss: 0.5918\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3882 - output_1_loss: 0.3882 - val_loss: 0.5775 - val_output_1_loss: 0.5775\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.4457 - output_1_loss: 0.4457 - val_loss: 0.5673 - val_output_1_loss: 0.5673\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3155 - output_1_loss: 0.3155 - val_loss: 0.5558 - val_output_1_loss: 0.5558\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.8962 - output_1_loss: 0.8814 - val_loss: 0.7206 - val_output_1_loss: 0.6869\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.3158 - output_1_loss: 0.3158 - val_loss: 0.5436 - val_output_1_loss: 0.5436\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3747 - output_1_loss: 0.3747 - val_loss: 0.5337 - val_output_1_loss: 0.5337\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4008 - output_1_loss: 0.4008 - val_loss: 0.5256 - val_output_1_loss: 0.5256\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2830 - output_1_loss: 0.2830 - val_loss: 0.5117 - val_output_1_loss: 0.5117\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3294 - output_1_loss: 0.3294 - val_loss: 0.5027 - val_output_1_loss: 0.5027\n",
      "Epoch 2/100\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7076 - output_1_loss: 0.6921 - val_loss: 0.7125 - val_output_1_loss: 0.6805\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.5054 - output_1_loss: 0.4906 - val_loss: 0.7028 - val_output_1_loss: 0.6721\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.2670 - output_1_loss: 0.2670 - val_loss: 0.4914 - val_output_1_loss: 0.4914\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.3549 - output_1_loss: 0.3408 - val_loss: 0.6882 - val_output_1_loss: 0.6583\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2350 - output_1_loss: 0.2350Epoch 5/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2071 - output_1_loss: 0.1945 - val_loss: 0.6673 - val_output_1_loss: 0.6384\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.2350 - output_1_loss: 0.2350 - val_loss: 0.4805 - val_output_1_loss: 0.4805\n",
      "Epoch 26/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1545 - output_1_loss: 0.1424 - val_loss: 0.6406 - val_output_1_loss: 0.6128\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1234 - output_1_loss: 0.1121 - val_loss: 0.6094 - val_output_1_loss: 0.5826\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.3116 - output_1_loss: 0.3116 - val_loss: 0.4789 - val_output_1_loss: 0.4789\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1031 - output_1_loss: 0.0921 - val_loss: 0.5758 - val_output_1_loss: 0.5499\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0921 - output_1_loss: 0.0816 - val_loss: 0.5414 - val_output_1_loss: 0.5163\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.2573 - output_1_loss: 0.2573 - val_loss: 0.4637 - val_output_1_loss: 0.4637\n",
      "Epoch 10/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0840 - output_1_loss: 0.0739 - val_loss: 0.5068 - val_output_1_loss: 0.4824\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0778 - output_1_loss: 0.0679 - val_loss: 0.4728 - val_output_1_loss: 0.4491\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.2351 - output_1_loss: 0.2351 - val_loss: 0.4409 - val_output_1_loss: 0.4409\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0733 - output_1_loss: 0.0637 - val_loss: 0.4403 - val_output_1_loss: 0.4173\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0700 - output_1_loss: 0.0606 - val_loss: 0.4097 - val_output_1_loss: 0.3872\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.2564 - output_1_loss: 0.2564 - val_loss: 0.4239 - val_output_1_loss: 0.4239\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0680 - output_1_loss: 0.0588 - val_loss: 0.3811 - val_output_1_loss: 0.3592\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0663 - output_1_loss: 0.0573 - val_loss: 0.3548 - val_output_1_loss: 0.3333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0651 - output_1_loss: 0.0563 - val_loss: 0.3306 - val_output_1_loss: 0.3096\n",
      "Epoch 17/100\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0637 - output_1_loss: 0.0550 - val_loss: 0.3086 - val_output_1_loss: 0.2880\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0633 - output_1_loss: 0.0547 - val_loss: 0.2887 - val_output_1_loss: 0.2684\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.2812 - output_1_loss: 0.2812 - val_loss: 0.4033 - val_output_1_loss: 0.4033\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0624 - output_1_loss: 0.0539 - val_loss: 0.2708 - val_output_1_loss: 0.2508\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0615 - output_1_loss: 0.0531 - val_loss: 0.2548 - val_output_1_loss: 0.2352\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.1498 - output_1_loss: 0.1498 - val_loss: 0.3818 - val_output_1_loss: 0.3818\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0640 - output_1_loss: 0.0556Epoch 32/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0640 - output_1_loss: 0.0556 - val_loss: 0.2408 - val_output_1_loss: 0.2214\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0600 - output_1_loss: 0.0518 - val_loss: 0.2281 - val_output_1_loss: 0.2091\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.2747 - output_1_loss: 0.2747 - val_loss: 0.3761 - val_output_1_loss: 0.3761\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0594 - output_1_loss: 0.0513Epoch 33/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0594 - output_1_loss: 0.0513 - val_loss: 0.2169 - val_output_1_loss: 0.1982\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1608 - output_1_loss: 0.1608 - val_loss: 0.3624 - val_output_1_loss: 0.3624\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0595 - output_1_loss: 0.0515Epoch 34/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0595 - output_1_loss: 0.0515 - val_loss: 0.2072 - val_output_1_loss: 0.1887\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1697 - output_1_loss: 0.1697Epoch 25/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0622 - output_1_loss: 0.0542 - val_loss: 0.1985 - val_output_1_loss: 0.1803\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1697 - output_1_loss: 0.1697 - val_loss: 0.3422 - val_output_1_loss: 0.3422\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0616 - output_1_loss: 0.0538 - val_loss: 0.1908 - val_output_1_loss: 0.1728\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2482 - output_1_loss: 0.2482Epoch 27/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0604 - output_1_loss: 0.0528 - val_loss: 0.1839 - val_output_1_loss: 0.1662\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.2482 - output_1_loss: 0.2482 - val_loss: 0.3193 - val_output_1_loss: 0.3193\n",
      "Epoch 36/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0593 - output_1_loss: 0.0519 - val_loss: 0.1777 - val_output_1_loss: 0.1602\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1875 - output_1_loss: 0.1875Epoch 29/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0582 - output_1_loss: 0.0510 - val_loss: 0.1721 - val_output_1_loss: 0.1549\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.1875 - output_1_loss: 0.1875 - val_loss: 0.3130 - val_output_1_loss: 0.3130\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0569 - output_1_loss: 0.0498Epoch 37/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0569 - output_1_loss: 0.0498 - val_loss: 0.1671 - val_output_1_loss: 0.1501\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1261 - output_1_loss: 0.1261 - val_loss: 0.2846 - val_output_1_loss: 0.2846\n",
      "Epoch 38/100\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0554 - output_1_loss: 0.0484 - val_loss: 0.1627 - val_output_1_loss: 0.1459\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1037 - output_1_loss: 0.1037 - val_loss: 0.2792 - val_output_1_loss: 0.2792\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0544 - output_1_loss: 0.0475 - val_loss: 0.1587 - val_output_1_loss: 0.1421\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0534 - output_1_loss: 0.0467 - val_loss: 0.1551 - val_output_1_loss: 0.1388\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0527 - output_1_loss: 0.0461 - val_loss: 0.1521 - val_output_1_loss: 0.1360\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0520 - output_1_loss: 0.0455 - val_loss: 0.1494 - val_output_1_loss: 0.1335\n",
      "Epoch 36/100\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0514 - output_1_loss: 0.0450 - val_loss: 0.1471 - val_output_1_loss: 0.1314\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0509 - output_1_loss: 0.0445 - val_loss: 0.1451 - val_output_1_loss: 0.1296\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2143 - output_1_loss: 0.2143 - val_loss: 0.2727 - val_output_1_loss: 0.2727\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0501 - output_1_loss: 0.0438 - val_loss: 0.1434 - val_output_1_loss: 0.1280\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1266 - output_1_loss: 0.1266Epoch 39/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0493 - output_1_loss: 0.0432 - val_loss: 0.1419 - val_output_1_loss: 0.1267\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.1266 - output_1_loss: 0.1266 - val_loss: 0.2700 - val_output_1_loss: 0.2700\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0487 - output_1_loss: 0.0426 - val_loss: 0.1406 - val_output_1_loss: 0.1256\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0482 - output_1_loss: 0.0421 - val_loss: 0.1395 - val_output_1_loss: 0.1246\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0477 - output_1_loss: 0.0417 - val_loss: 0.1385 - val_output_1_loss: 0.1237\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0472 - output_1_loss: 0.0413Epoch 41/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0472 - output_1_loss: 0.0413 - val_loss: 0.1376 - val_output_1_loss: 0.1230\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0467 - output_1_loss: 0.0409 - val_loss: 0.1368 - val_output_1_loss: 0.1223\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1658 - output_1_loss: 0.1658 - val_loss: 0.2316 - val_output_1_loss: 0.2316\n",
      "Epoch 45/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0462 - output_1_loss: 0.0405 - val_loss: 0.1361 - val_output_1_loss: 0.1218\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0984 - output_1_loss: 0.0984Epoch 46/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0456 - output_1_loss: 0.0400 - val_loss: 0.1356 - val_output_1_loss: 0.1214\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0984 - output_1_loss: 0.0984 - val_loss: 0.2141 - val_output_1_loss: 0.2141\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0452 - output_1_loss: 0.0396 - val_loss: 0.1351 - val_output_1_loss: 0.1210\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0871 - output_1_loss: 0.0871 - val_loss: 0.1904 - val_output_1_loss: 0.1904\n",
      "Epoch 44/100\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0445 - output_1_loss: 0.0391 - val_loss: 0.1347 - val_output_1_loss: 0.1207\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1085 - output_1_loss: 0.1085 - val_loss: 0.1794 - val_output_1_loss: 0.1794\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0440 - output_1_loss: 0.0386 - val_loss: 0.1343 - val_output_1_loss: 0.1204\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0434 - output_1_loss: 0.0381 - val_loss: 0.1339 - val_output_1_loss: 0.1201\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1048 - output_1_loss: 0.1048Epoch 51/100\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 0.1048 - output_1_loss: 0.1048 - val_loss: 0.1730 - val_output_1_loss: 0.1730\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0429 - output_1_loss: 0.0376 - val_loss: 0.1334 - val_output_1_loss: 0.1198\n",
      "Epoch 52/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0423 - output_1_loss: 0.0371 - val_loss: 0.1330 - val_output_1_loss: 0.1196\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1233 - output_1_loss: 0.1233Epoch 53/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0417 - output_1_loss: 0.0365 - val_loss: 0.1326 - val_output_1_loss: 0.1193\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1233 - output_1_loss: 0.1233 - val_loss: 0.1676 - val_output_1_loss: 0.1676\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0411 - output_1_loss: 0.0359 - val_loss: 0.1322 - val_output_1_loss: 0.1191\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0404 - output_1_loss: 0.0353 - val_loss: 0.1317 - val_output_1_loss: 0.1189\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1076 - output_1_loss: 0.1076 - val_loss: 0.1642 - val_output_1_loss: 0.1642\n",
      "Epoch 48/100\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0398 - output_1_loss: 0.0347 - val_loss: 0.1311 - val_output_1_loss: 0.1184\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1045 - output_1_loss: 0.1045Epoch 57/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0392 - output_1_loss: 0.0342 - val_loss: 0.1306 - val_output_1_loss: 0.1181\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1045 - output_1_loss: 0.1045 - val_loss: 0.1383 - val_output_1_loss: 0.1383\n",
      "Epoch 58/100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0386 - output_1_loss: 0.0336 - val_loss: 0.1300 - val_output_1_loss: 0.1176\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0379 - output_1_loss: 0.0330 - val_loss: 0.1292 - val_output_1_loss: 0.1171\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.1010 - output_1_loss: 0.1010 - val_loss: 0.1243 - val_output_1_loss: 0.1243\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0372 - output_1_loss: 0.0323 - val_loss: 0.1284 - val_output_1_loss: 0.1164\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0365 - output_1_loss: 0.0316 - val_loss: 0.1275 - val_output_1_loss: 0.1157\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0989 - output_1_loss: 0.0989 - val_loss: 0.1161 - val_output_1_loss: 0.1161\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0356 - output_1_loss: 0.0308 - val_loss: 0.1265 - val_output_1_loss: 0.1149\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1608 - output_1_loss: 0.1608 - val_loss: 0.1243 - val_output_1_loss: 0.1243\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0347 - output_1_loss: 0.0299 - val_loss: 0.1255 - val_output_1_loss: 0.1141\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1331 - output_1_loss: 0.1331 - val_loss: 0.1239 - val_output_1_loss: 0.1239\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1360 - output_1_loss: 0.1360Epoch 64/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1360 - output_1_loss: 0.1360 - val_loss: 0.1255 - val_output_1_loss: 0.1255\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0337 - output_1_loss: 0.0290 - val_loss: 0.1243 - val_output_1_loss: 0.1131\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1466 - output_1_loss: 0.1466 - val_loss: 0.1218 - val_output_1_loss: 0.1218\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0328 - output_1_loss: 0.0281 - val_loss: 0.1230 - val_output_1_loss: 0.1120\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1533 - output_1_loss: 0.1533Epoch 66/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1533 - output_1_loss: 0.1533 - val_loss: 0.1280 - val_output_1_loss: 0.1280\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0315 - output_1_loss: 0.0270 - val_loss: 0.1216 - val_output_1_loss: 0.1107\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0304 - output_1_loss: 0.0258 - val_loss: 0.1202 - val_output_1_loss: 0.1094\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0293 - output_1_loss: 0.0248 - val_loss: 0.1188 - val_output_1_loss: 0.1082\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0282 - output_1_loss: 0.0239 - val_loss: 0.1173 - val_output_1_loss: 0.1069\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0272 - output_1_loss: 0.0229 - val_loss: 0.1158 - val_output_1_loss: 0.1056\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0262 - output_1_loss: 0.0220 - val_loss: 0.1143 - val_output_1_loss: 0.1043\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0253 - output_1_loss: 0.0211 - val_loss: 0.1130 - val_output_1_loss: 0.1032\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0244 - output_1_loss: 0.0203 - val_loss: 0.1118 - val_output_1_loss: 0.1022\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0236 - output_1_loss: 0.0195 - val_loss: 0.1107 - val_output_1_loss: 0.1012\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0231 - output_1_loss: 0.0190 - val_loss: 0.1097 - val_output_1_loss: 0.1004\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0226 - output_1_loss: 0.0186 - val_loss: 0.1087 - val_output_1_loss: 0.0996\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:23:39,280]\u001b[0m Trial 59 finished with value: 0.06666666666666667 and parameters: {'feature_dim': 128, 'n_step': 6, 'n_shared': 0, 'relaxation_factor': 1.7000000000000002, 'sparsity_coefficient': 6.971480762743128e-07, 'bn_momentum': 0.9079888851720942}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.0222 - output_1_loss: 0.0182 - val_loss: 0.1078 - val_output_1_loss: 0.0989\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0218 - output_1_loss: 0.0179Epoch 1/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0218 - output_1_loss: 0.0179 - val_loss: 0.1068 - val_output_1_loss: 0.0982\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0213 - output_1_loss: 0.0174 - val_loss: 0.1056 - val_output_1_loss: 0.0971\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0208 - output_1_loss: 0.0169 - val_loss: 0.1044 - val_output_1_loss: 0.0961\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0201 - output_1_loss: 0.0163 - val_loss: 0.1029 - val_output_1_loss: 0.0949\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0194 - output_1_loss: 0.0156 - val_loss: 0.1014 - val_output_1_loss: 0.0935\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0185 - output_1_loss: 0.0147 - val_loss: 0.0997 - val_output_1_loss: 0.0921\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0174 - output_1_loss: 0.0137 - val_loss: 0.0982 - val_output_1_loss: 0.0907\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0174 - output_1_loss: 0.0137 - val_loss: 0.0966 - val_output_1_loss: 0.0894\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0153 - output_1_loss: 0.0116 - val_loss: 0.0959 - val_output_1_loss: 0.0889\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0148 - output_1_loss: 0.0111 - val_loss: 0.0951 - val_output_1_loss: 0.0883\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0137 - output_1_loss: 0.0100 - val_loss: 0.0937 - val_output_1_loss: 0.0871\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0138 - output_1_loss: 0.0102 - val_loss: 0.0917 - val_output_1_loss: 0.0853\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0168 - output_1_loss: 0.0132 - val_loss: 0.0914 - val_output_1_loss: 0.0852\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0170 - output_1_loss: 0.0135 - val_loss: 0.0902 - val_output_1_loss: 0.0841\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0155 - output_1_loss: 0.0120 - val_loss: 0.0913 - val_output_1_loss: 0.0853\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0145 - output_1_loss: 0.0110 - val_loss: 0.0928 - val_output_1_loss: 0.0868\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0155 - output_1_loss: 0.0120 - val_loss: 0.0895 - val_output_1_loss: 0.0836\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0169 - output_1_loss: 0.0133 - val_loss: 0.0848 - val_output_1_loss: 0.0791\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0163 - output_1_loss: 0.0128 - val_loss: 0.0803 - val_output_1_loss: 0.0747\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0145 - output_1_loss: 0.0110 - val_loss: 0.0775 - val_output_1_loss: 0.0720\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0131 - output_1_loss: 0.0096 - val_loss: 0.0762 - val_output_1_loss: 0.0708\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0128 - output_1_loss: 0.0094 - val_loss: 0.0754 - val_output_1_loss: 0.0701\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0123 - output_1_loss: 0.0090 - val_loss: 0.0751 - val_output_1_loss: 0.0698\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:23:47,500]\u001b[0m Trial 60 finished with value: 0.02631578947368421 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 1, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.004234637789703783, 'bn_momentum': 0.9404658454241085}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.9647 - output_1_loss: 0.9486 - val_loss: 0.7216 - val_output_1_loss: 0.6863\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.7982 - output_1_loss: 0.7810 - val_loss: 0.7124 - val_output_1_loss: 0.6791\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6996 - output_1_loss: 0.6822 - val_loss: 0.7032 - val_output_1_loss: 0.6717\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.5514 - output_1_loss: 0.5337 - val_loss: 0.6940 - val_output_1_loss: 0.6637\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.4089 - output_1_loss: 0.3916 - val_loss: 0.6845 - val_output_1_loss: 0.6552\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2447 - output_1_loss: 0.2286 - val_loss: 0.6731 - val_output_1_loss: 0.6446\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1657 - output_1_loss: 0.1509 - val_loss: 0.6615 - val_output_1_loss: 0.6336\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1164 - output_1_loss: 0.1026 - val_loss: 0.6489 - val_output_1_loss: 0.6219\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1056 - output_1_loss: 0.0923 - val_loss: 0.6333 - val_output_1_loss: 0.6070\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0803 - output_1_loss: 0.0671 - val_loss: 0.6144 - val_output_1_loss: 0.5888\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0701 - output_1_loss: 0.0568 - val_loss: 0.5917 - val_output_1_loss: 0.5666\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0808 - output_1_loss: 0.0680 - val_loss: 0.5669 - val_output_1_loss: 0.5423\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0628 - output_1_loss: 0.0499 - val_loss: 0.5434 - val_output_1_loss: 0.5192\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0511 - output_1_loss: 0.0385 - val_loss: 0.5196 - val_output_1_loss: 0.4956\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0449 - output_1_loss: 0.0324 - val_loss: 0.4955 - val_output_1_loss: 0.4717\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0433 - output_1_loss: 0.0306 - val_loss: 0.4734 - val_output_1_loss: 0.4499\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0473 - output_1_loss: 0.0339 - val_loss: 0.4461 - val_output_1_loss: 0.4228\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0387 - output_1_loss: 0.0254 - val_loss: 0.4209 - val_output_1_loss: 0.3977\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0372 - output_1_loss: 0.0242 - val_loss: 0.3974 - val_output_1_loss: 0.3744\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0366 - output_1_loss: 0.0237 - val_loss: 0.3752 - val_output_1_loss: 0.3523\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0335 - output_1_loss: 0.0208 - val_loss: 0.3548 - val_output_1_loss: 0.3320\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0311 - output_1_loss: 0.0186 - val_loss: 0.3366 - val_output_1_loss: 0.3139\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0301 - output_1_loss: 0.0178 - val_loss: 0.3210 - val_output_1_loss: 0.2984\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0293 - output_1_loss: 0.0173 - val_loss: 0.3068 - val_output_1_loss: 0.2844\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0282 - output_1_loss: 0.0165 - val_loss: 0.2941 - val_output_1_loss: 0.2719\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0266 - output_1_loss: 0.0152 - val_loss: 0.2826 - val_output_1_loss: 0.2606\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0250 - output_1_loss: 0.0138 - val_loss: 0.2721 - val_output_1_loss: 0.2503\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0233 - output_1_loss: 0.0123 - val_loss: 0.2625 - val_output_1_loss: 0.2409\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0217 - output_1_loss: 0.0109 - val_loss: 0.2537 - val_output_1_loss: 0.2323\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0201 - output_1_loss: 0.0096 - val_loss: 0.2455 - val_output_1_loss: 0.2243\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0187 - output_1_loss: 0.0084 - val_loss: 0.2378 - val_output_1_loss: 0.2169\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0176 - output_1_loss: 0.0076 - val_loss: 0.2304 - val_output_1_loss: 0.2097\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0170 - output_1_loss: 0.0071 - val_loss: 0.2236 - val_output_1_loss: 0.2031\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0165 - output_1_loss: 0.0068 - val_loss: 0.2173 - val_output_1_loss: 0.1971\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0162 - output_1_loss: 0.0067 - val_loss: 0.2114 - val_output_1_loss: 0.1915\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0159 - output_1_loss: 0.0066 - val_loss: 0.2060 - val_output_1_loss: 0.1863\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0157 - output_1_loss: 0.0065 - val_loss: 0.2008 - val_output_1_loss: 0.1814\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0154 - output_1_loss: 0.0065 - val_loss: 0.1961 - val_output_1_loss: 0.1769\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0152 - output_1_loss: 0.0065 - val_loss: 0.1916 - val_output_1_loss: 0.1726\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0150 - output_1_loss: 0.0064 - val_loss: 0.1875 - val_output_1_loss: 0.1687\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 15s 15s/step - loss: 1.0059 - output_1_loss: 1.0057 - val_loss: 0.6855 - val_output_1_loss: 0.6851\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0148 - output_1_loss: 0.0064 - val_loss: 0.1837 - val_output_1_loss: 0.1652\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0145 - output_1_loss: 0.0063 - val_loss: 0.1802 - val_output_1_loss: 0.1619\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0143 - output_1_loss: 0.0063 - val_loss: 0.1769 - val_output_1_loss: 0.1589\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0142 - output_1_loss: 0.0063 - val_loss: 0.1740 - val_output_1_loss: 0.1562\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0140 - output_1_loss: 0.0063 - val_loss: 0.1713 - val_output_1_loss: 0.1537\n",
      "Epoch 2/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0138 - output_1_loss: 0.0063 - val_loss: 0.1688 - val_output_1_loss: 0.1515\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.7860 - output_1_loss: 0.7859 - val_loss: 0.6788 - val_output_1_loss: 0.6783\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0136 - output_1_loss: 0.0063 - val_loss: 0.1666 - val_output_1_loss: 0.1495\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.6507 - output_1_loss: 0.6505 - val_loss: 0.6718 - val_output_1_loss: 0.6714\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0134 - output_1_loss: 0.0062 - val_loss: 0.1646 - val_output_1_loss: 0.1477\n",
      "Epoch 49/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0131 - output_1_loss: 0.0062 - val_loss: 0.1628 - val_output_1_loss: 0.1461\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5318 - output_1_loss: 0.5316 - val_loss: 0.6638 - val_output_1_loss: 0.6634\n",
      "Epoch 50/100\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0129 - output_1_loss: 0.0061 - val_loss: 0.1610 - val_output_1_loss: 0.1445\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3445 - output_1_loss: 0.3443 - val_loss: 0.6512 - val_output_1_loss: 0.6508\n",
      "Epoch 51/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0126 - output_1_loss: 0.0059 - val_loss: 0.1595 - val_output_1_loss: 0.1432\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2854 - output_1_loss: 0.2853 - val_loss: 0.6385 - val_output_1_loss: 0.6381\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2249 - output_1_loss: 0.2247Epoch 52/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2249 - output_1_loss: 0.2247 - val_loss: 0.6218 - val_output_1_loss: 0.6215\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0123 - output_1_loss: 0.0057 - val_loss: 0.1583 - val_output_1_loss: 0.1422\n",
      "Epoch 8/100\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0122 - output_1_loss: 0.0057 - val_loss: 0.1576 - val_output_1_loss: 0.1417\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1293 - output_1_loss: 0.1292 - val_loss: 0.5989 - val_output_1_loss: 0.5986\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0927 - output_1_loss: 0.0925Epoch 54/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0927 - output_1_loss: 0.0925 - val_loss: 0.5694 - val_output_1_loss: 0.5691\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0121 - output_1_loss: 0.0057 - val_loss: 0.1571 - val_output_1_loss: 0.1415\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0738 - output_1_loss: 0.0736 - val_loss: 0.5363 - val_output_1_loss: 0.5360\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0666 - output_1_loss: 0.0665Epoch 55/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0120 - output_1_loss: 0.0056 - val_loss: 0.1568 - val_output_1_loss: 0.1413\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0666 - output_1_loss: 0.0665 - val_loss: 0.5023 - val_output_1_loss: 0.5020\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0118 - output_1_loss: 0.0055 - val_loss: 0.1565 - val_output_1_loss: 0.1413\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0698 - output_1_loss: 0.0697 - val_loss: 0.4721 - val_output_1_loss: 0.4718\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0116 - output_1_loss: 0.0054Epoch 13/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0116 - output_1_loss: 0.0054 - val_loss: 0.1562 - val_output_1_loss: 0.1411\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0825 - output_1_loss: 0.0824 - val_loss: 0.4423 - val_output_1_loss: 0.4420\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0114 - output_1_loss: 0.0053Epoch 14/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0114 - output_1_loss: 0.0053 - val_loss: 0.1559 - val_output_1_loss: 0.1410\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0766 - output_1_loss: 0.0765 - val_loss: 0.4107 - val_output_1_loss: 0.4105\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0113 - output_1_loss: 0.0053Epoch 15/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0113 - output_1_loss: 0.0053 - val_loss: 0.1556 - val_output_1_loss: 0.1410\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0696 - output_1_loss: 0.0694 - val_loss: 0.3844 - val_output_1_loss: 0.3842\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0112 - output_1_loss: 0.0053Epoch 16/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0112 - output_1_loss: 0.0053 - val_loss: 0.1556 - val_output_1_loss: 0.1411\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0110 - output_1_loss: 0.0052 - val_loss: 0.1557 - val_output_1_loss: 0.1415\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.0493 - output_1_loss: 0.0492 - val_loss: 0.3575 - val_output_1_loss: 0.3572\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0109 - output_1_loss: 0.0051 - val_loss: 0.1560 - val_output_1_loss: 0.1420\n",
      "Epoch 63/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0107 - output_1_loss: 0.0050 - val_loss: 0.1565 - val_output_1_loss: 0.1427\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0106 - output_1_loss: 0.0049 - val_loss: 0.1570 - val_output_1_loss: 0.1434\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0449 - output_1_loss: 0.0448 - val_loss: 0.3317 - val_output_1_loss: 0.3315\n",
      "Epoch 65/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0104 - output_1_loss: 0.0049 - val_loss: 0.1573 - val_output_1_loss: 0.1439\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0431 - output_1_loss: 0.0430 - val_loss: 0.3086 - val_output_1_loss: 0.3083\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0490 - output_1_loss: 0.0489 - val_loss: 0.2873 - val_output_1_loss: 0.2870\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0454 - output_1_loss: 0.0453 - val_loss: 0.2681 - val_output_1_loss: 0.2678\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0464 - output_1_loss: 0.0463 - val_loss: 0.2509 - val_output_1_loss: 0.2507\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0433 - output_1_loss: 0.0432 - val_loss: 0.2351 - val_output_1_loss: 0.2348\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:24:09,390]\u001b[0m Trial 61 finished with value: 0.1111111111111111 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 1, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.004370968333180712, 'bn_momentum': 0.9404376066030454}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0459 - output_1_loss: 0.0458 - val_loss: 0.2216 - val_output_1_loss: 0.2213\n",
      "Epoch 1/100\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0460 - output_1_loss: 0.0459 - val_loss: 0.2089 - val_output_1_loss: 0.2087\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0429 - output_1_loss: 0.0428 - val_loss: 0.1980 - val_output_1_loss: 0.1978\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0384 - output_1_loss: 0.0383 - val_loss: 0.1879 - val_output_1_loss: 0.1877\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.0368 - output_1_loss: 0.0367 - val_loss: 0.1785 - val_output_1_loss: 0.1783\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.0390 - output_1_loss: 0.0389 - val_loss: 0.1729 - val_output_1_loss: 0.1727\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.0468 - output_1_loss: 0.0467 - val_loss: 0.1643 - val_output_1_loss: 0.1641\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0385 - output_1_loss: 0.0384 - val_loss: 0.1564 - val_output_1_loss: 0.1562\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0363 - output_1_loss: 0.0362 - val_loss: 0.1492 - val_output_1_loss: 0.1489\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0370 - output_1_loss: 0.0368 - val_loss: 0.1426 - val_output_1_loss: 0.1424\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0347 - output_1_loss: 0.0345 - val_loss: 0.1367 - val_output_1_loss: 0.1364\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0339 - output_1_loss: 0.0338 - val_loss: 0.1315 - val_output_1_loss: 0.1313\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0331 - output_1_loss: 0.0330 - val_loss: 0.1271 - val_output_1_loss: 0.1269\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0317 - output_1_loss: 0.0316 - val_loss: 0.1235 - val_output_1_loss: 0.1233\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0297 - output_1_loss: 0.0296 - val_loss: 0.1207 - val_output_1_loss: 0.1205\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0309 - output_1_loss: 0.0307 - val_loss: 0.1180 - val_output_1_loss: 0.1178\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0329 - output_1_loss: 0.0328 - val_loss: 0.1153 - val_output_1_loss: 0.1151\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0296 - output_1_loss: 0.0295 - val_loss: 0.1129 - val_output_1_loss: 0.1127\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0293 - output_1_loss: 0.0291 - val_loss: 0.1111 - val_output_1_loss: 0.1109\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0326 - output_1_loss: 0.0325 - val_loss: 0.1096 - val_output_1_loss: 0.1094\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0310 - output_1_loss: 0.0309 - val_loss: 0.1082 - val_output_1_loss: 0.1080\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0289 - output_1_loss: 0.0287 - val_loss: 0.1069 - val_output_1_loss: 0.1066\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0278 - output_1_loss: 0.0276 - val_loss: 0.1056 - val_output_1_loss: 0.1054\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0274 - output_1_loss: 0.0273 - val_loss: 0.1044 - val_output_1_loss: 0.1042\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0263 - output_1_loss: 0.0261 - val_loss: 0.1034 - val_output_1_loss: 0.1032\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0256 - output_1_loss: 0.0255 - val_loss: 0.1027 - val_output_1_loss: 0.1025\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0331 - output_1_loss: 0.0330 - val_loss: 0.1011 - val_output_1_loss: 0.1009\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0352 - output_1_loss: 0.0351 - val_loss: 0.1004 - val_output_1_loss: 0.1001\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0313 - output_1_loss: 0.0312 - val_loss: 0.0999 - val_output_1_loss: 0.0996\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1233 - output_1_loss: 0.1232 - val_loss: 0.1002 - val_output_1_loss: 0.1000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0720 - output_1_loss: 0.0719 - val_loss: 0.0999 - val_output_1_loss: 0.0996\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0562 - output_1_loss: 0.0561 - val_loss: 0.0988 - val_output_1_loss: 0.0985\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0591 - output_1_loss: 0.0590 - val_loss: 0.0968 - val_output_1_loss: 0.0965\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0527 - output_1_loss: 0.0526 - val_loss: 0.0948 - val_output_1_loss: 0.0946\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0476 - output_1_loss: 0.0474 - val_loss: 0.0933 - val_output_1_loss: 0.0931\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0510 - output_1_loss: 0.0509 - val_loss: 0.0923 - val_output_1_loss: 0.0920\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0492 - output_1_loss: 0.0490 - val_loss: 0.0916 - val_output_1_loss: 0.0913\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0465 - output_1_loss: 0.0463 - val_loss: 0.0916 - val_output_1_loss: 0.0913\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6655 - output_1_loss: 0.6654 - val_loss: 0.6843 - val_output_1_loss: 0.6838\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5786 - output_1_loss: 0.5784Epoch 61/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0667 - output_1_loss: 0.0666 - val_loss: 0.0926 - val_output_1_loss: 0.0924\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5786 - output_1_loss: 0.5784 - val_loss: 0.6743 - val_output_1_loss: 0.6738\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0531 - output_1_loss: 0.0530 - val_loss: 0.0926 - val_output_1_loss: 0.0923\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0478 - output_1_loss: 0.0477 - val_loss: 0.0918 - val_output_1_loss: 0.0916\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.4292 - output_1_loss: 0.4290 - val_loss: 0.6640 - val_output_1_loss: 0.6636\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0556 - output_1_loss: 0.0555 - val_loss: 0.0911 - val_output_1_loss: 0.0908\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0610 - output_1_loss: 0.0609 - val_loss: 0.0896 - val_output_1_loss: 0.0894\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0577 - output_1_loss: 0.0576Epoch 4/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0577 - output_1_loss: 0.0576 - val_loss: 0.0876 - val_output_1_loss: 0.0874\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2967 - output_1_loss: 0.2965 - val_loss: 0.6505 - val_output_1_loss: 0.6502\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0515 - output_1_loss: 0.0514Epoch 5/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0515 - output_1_loss: 0.0514 - val_loss: 0.0858 - val_output_1_loss: 0.0856\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2577 - output_1_loss: 0.2575 - val_loss: 0.6353 - val_output_1_loss: 0.6349\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0534 - output_1_loss: 0.0533 - val_loss: 0.0841 - val_output_1_loss: 0.0839\n",
      "Epoch 69/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0511 - output_1_loss: 0.0510 - val_loss: 0.0824 - val_output_1_loss: 0.0821\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1156 - output_1_loss: 0.1155 - val_loss: 0.6092 - val_output_1_loss: 0.6089\n",
      "Epoch 70/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0497 - output_1_loss: 0.0496 - val_loss: 0.0807 - val_output_1_loss: 0.0805\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1053 - output_1_loss: 0.1051 - val_loss: 0.5801 - val_output_1_loss: 0.5798\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0957 - output_1_loss: 0.0956Epoch 71/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0957 - output_1_loss: 0.0956 - val_loss: 0.5523 - val_output_1_loss: 0.5519\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0458 - output_1_loss: 0.0457 - val_loss: 0.0791 - val_output_1_loss: 0.0789\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0928 - output_1_loss: 0.0927Epoch 72/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0928 - output_1_loss: 0.0927 - val_loss: 0.5270 - val_output_1_loss: 0.5267\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0408 - output_1_loss: 0.0407 - val_loss: 0.0775 - val_output_1_loss: 0.0773\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0855 - output_1_loss: 0.0854 - val_loss: 0.5007 - val_output_1_loss: 0.5004\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0391 - output_1_loss: 0.0390 - val_loss: 0.0763 - val_output_1_loss: 0.0761\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0802 - output_1_loss: 0.0801 - val_loss: 0.4744 - val_output_1_loss: 0.4741\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0354 - output_1_loss: 0.0353 - val_loss: 0.0753 - val_output_1_loss: 0.0751\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0701 - output_1_loss: 0.0700 - val_loss: 0.4514 - val_output_1_loss: 0.4511\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0696 - output_1_loss: 0.0695Epoch 75/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0696 - output_1_loss: 0.0695 - val_loss: 0.4293 - val_output_1_loss: 0.4290\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0329 - output_1_loss: 0.0328 - val_loss: 0.0742 - val_output_1_loss: 0.0740\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0727 - output_1_loss: 0.0726Epoch 76/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0727 - output_1_loss: 0.0726 - val_loss: 0.4092 - val_output_1_loss: 0.4090\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0309 - output_1_loss: 0.0308 - val_loss: 0.0733 - val_output_1_loss: 0.0731\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0674 - output_1_loss: 0.0672 - val_loss: 0.3883 - val_output_1_loss: 0.3880\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0293 - output_1_loss: 0.0292 - val_loss: 0.0723 - val_output_1_loss: 0.0721\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0623 - output_1_loss: 0.0622 - val_loss: 0.3726 - val_output_1_loss: 0.3724\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0285 - output_1_loss: 0.0285 - val_loss: 0.0717 - val_output_1_loss: 0.0715\n",
      "Epoch 17/100\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0353 - output_1_loss: 0.0352 - val_loss: 0.0710 - val_output_1_loss: 0.0708\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0583 - output_1_loss: 0.0581 - val_loss: 0.3583 - val_output_1_loss: 0.3581\n",
      "Epoch 80/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0425 - output_1_loss: 0.0424 - val_loss: 0.0704 - val_output_1_loss: 0.0703\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0545 - output_1_loss: 0.0543 - val_loss: 0.3473 - val_output_1_loss: 0.3470\n",
      "Epoch 19/100\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0638 - output_1_loss: 0.0637 - val_loss: 0.3345 - val_output_1_loss: 0.3343\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0429 - output_1_loss: 0.0428 - val_loss: 0.0700 - val_output_1_loss: 0.0698\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0415 - output_1_loss: 0.0414Epoch 20/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0415 - output_1_loss: 0.0414 - val_loss: 0.0696 - val_output_1_loss: 0.0694\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0813 - output_1_loss: 0.0812 - val_loss: 0.3216 - val_output_1_loss: 0.3213\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0562 - output_1_loss: 0.0561Epoch 83/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0562 - output_1_loss: 0.0561 - val_loss: 0.3085 - val_output_1_loss: 0.3083\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0394 - output_1_loss: 0.0393 - val_loss: 0.0692 - val_output_1_loss: 0.0690\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0420 - output_1_loss: 0.0418Epoch 84/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0420 - output_1_loss: 0.0418 - val_loss: 0.2961 - val_output_1_loss: 0.2959\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0404 - output_1_loss: 0.0403 - val_loss: 0.0689 - val_output_1_loss: 0.0687\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1271 - output_1_loss: 0.1270 - val_loss: 0.0689 - val_output_1_loss: 0.0687\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0371 - output_1_loss: 0.0369 - val_loss: 0.2850 - val_output_1_loss: 0.2847\n",
      "Epoch 24/100\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0409 - output_1_loss: 0.0408 - val_loss: 0.0689 - val_output_1_loss: 0.0688\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0352 - output_1_loss: 0.0351 - val_loss: 0.2749 - val_output_1_loss: 0.2746\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0450 - output_1_loss: 0.0449 - val_loss: 0.0692 - val_output_1_loss: 0.0691\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0386 - output_1_loss: 0.0385 - val_loss: 0.2659 - val_output_1_loss: 0.2656\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0486 - output_1_loss: 0.0485 - val_loss: 0.0692 - val_output_1_loss: 0.0691\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0438 - output_1_loss: 0.0437 - val_loss: 0.0690 - val_output_1_loss: 0.0689\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0398 - output_1_loss: 0.0397 - val_loss: 0.2578 - val_output_1_loss: 0.2575\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0628 - output_1_loss: 0.0627 - val_loss: 0.2511 - val_output_1_loss: 0.2508\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.0440 - output_1_loss: 0.0439 - val_loss: 0.2452 - val_output_1_loss: 0.2449\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0409 - output_1_loss: 0.0408 - val_loss: 0.2391 - val_output_1_loss: 0.2388\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0324 - output_1_loss: 0.0323 - val_loss: 0.2335 - val_output_1_loss: 0.2333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0327 - output_1_loss: 0.0326 - val_loss: 0.2289 - val_output_1_loss: 0.2287\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:24:31,799]\u001b[0m Trial 62 finished with value: 0.038461538461538464 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 1.8, 'sparsity_coefficient': 7.403889492851949e-05, 'bn_momentum': 0.9578392693419874}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0376 - output_1_loss: 0.0375 - val_loss: 0.2255 - val_output_1_loss: 0.2252\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0318 - output_1_loss: 0.0317Epoch 1/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0318 - output_1_loss: 0.0317 - val_loss: 0.2222 - val_output_1_loss: 0.2219\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.0332 - output_1_loss: 0.0331 - val_loss: 0.2188 - val_output_1_loss: 0.2186\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0287 - output_1_loss: 0.0286 - val_loss: 0.2165 - val_output_1_loss: 0.2163\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0326 - output_1_loss: 0.0325 - val_loss: 0.2179 - val_output_1_loss: 0.2177\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0203 - output_1_loss: 0.0202 - val_loss: 0.2147 - val_output_1_loss: 0.2144\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0236 - output_1_loss: 0.0235 - val_loss: 0.2109 - val_output_1_loss: 0.2106\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0219 - output_1_loss: 0.0218 - val_loss: 0.2072 - val_output_1_loss: 0.2070\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0215 - output_1_loss: 0.0214 - val_loss: 0.2041 - val_output_1_loss: 0.2039\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0206 - output_1_loss: 0.0205 - val_loss: 0.2019 - val_output_1_loss: 0.2017\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0199 - output_1_loss: 0.0198 - val_loss: 0.2005 - val_output_1_loss: 0.2002\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0190 - output_1_loss: 0.0189 - val_loss: 0.1998 - val_output_1_loss: 0.1995\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0184 - output_1_loss: 0.0183 - val_loss: 0.1997 - val_output_1_loss: 0.1994\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0172 - output_1_loss: 0.0171 - val_loss: 0.2001 - val_output_1_loss: 0.1999\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0168 - output_1_loss: 0.0167 - val_loss: 0.2008 - val_output_1_loss: 0.2005\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0166 - output_1_loss: 0.0165 - val_loss: 0.2015 - val_output_1_loss: 0.2012\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0165 - output_1_loss: 0.0164 - val_loss: 0.2022 - val_output_1_loss: 0.2019\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0160 - output_1_loss: 0.0159 - val_loss: 0.2026 - val_output_1_loss: 0.2023\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:24:39,178]\u001b[0m Trial 63 finished with value: 0.05263157894736842 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 1.4, 'sparsity_coefficient': 7.032023891400261e-05, 'bn_momentum': 0.9580465293279258}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.7830 - output_1_loss: 0.7830 - val_loss: 0.6824 - val_output_1_loss: 0.6824\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.6351 - output_1_loss: 0.6351 - val_loss: 0.6707 - val_output_1_loss: 0.6706\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.5731 - output_1_loss: 0.5731 - val_loss: 0.6589 - val_output_1_loss: 0.6588\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3402 - output_1_loss: 0.3402 - val_loss: 0.6425 - val_output_1_loss: 0.6424\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1273 - output_1_loss: 0.1273 - val_loss: 0.6182 - val_output_1_loss: 0.6181\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2207 - output_1_loss: 0.2207 - val_loss: 0.5963 - val_output_1_loss: 0.5962\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0878 - output_1_loss: 0.0878 - val_loss: 0.5719 - val_output_1_loss: 0.5718\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0836 - output_1_loss: 0.0836 - val_loss: 0.5425 - val_output_1_loss: 0.5425\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0860 - output_1_loss: 0.0860 - val_loss: 0.5108 - val_output_1_loss: 0.5107\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0797 - output_1_loss: 0.0797 - val_loss: 0.4812 - val_output_1_loss: 0.4812\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0720 - output_1_loss: 0.0719 - val_loss: 0.4533 - val_output_1_loss: 0.4532\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0723 - output_1_loss: 0.0723 - val_loss: 0.4276 - val_output_1_loss: 0.4276\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0694 - output_1_loss: 0.0693 - val_loss: 0.4022 - val_output_1_loss: 0.4021\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0691 - output_1_loss: 0.0691 - val_loss: 0.3772 - val_output_1_loss: 0.3771\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0655 - output_1_loss: 0.0655 - val_loss: 0.3521 - val_output_1_loss: 0.3521\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0630 - output_1_loss: 0.0630 - val_loss: 0.3293 - val_output_1_loss: 0.3293\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0631 - output_1_loss: 0.0631 - val_loss: 0.3094 - val_output_1_loss: 0.3093\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0707 - output_1_loss: 0.0707 - val_loss: 0.2943 - val_output_1_loss: 0.2943\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7555 - output_1_loss: 0.7553Epoch 19/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.0670 - output_1_loss: 0.0670 - val_loss: 0.2794 - val_output_1_loss: 0.2794\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0658 - output_1_loss: 0.0658 - val_loss: 0.2669 - val_output_1_loss: 0.2669\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0620 - output_1_loss: 0.0620 - val_loss: 0.2552 - val_output_1_loss: 0.2551\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0625 - output_1_loss: 0.0624 - val_loss: 0.2434 - val_output_1_loss: 0.2433\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0569 - output_1_loss: 0.0569 - val_loss: 0.2332 - val_output_1_loss: 0.2332\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0576 - output_1_loss: 0.0576 - val_loss: 0.2238 - val_output_1_loss: 0.2238\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0565 - output_1_loss: 0.0565 - val_loss: 0.2153 - val_output_1_loss: 0.2152\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.7555 - output_1_loss: 0.7553 - val_loss: 0.6827 - val_output_1_loss: 0.6819\n",
      "Epoch 2/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0556 - output_1_loss: 0.0556 - val_loss: 0.2070 - val_output_1_loss: 0.2070\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.6922 - output_1_loss: 0.6920 - val_loss: 0.6707 - val_output_1_loss: 0.6700\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0495 - output_1_loss: 0.0495 - val_loss: 0.1993 - val_output_1_loss: 0.1993\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5883 - output_1_loss: 0.5881Epoch 28/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0484 - output_1_loss: 0.0483 - val_loss: 0.1921 - val_output_1_loss: 0.1921\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5883 - output_1_loss: 0.5881 - val_loss: 0.6593 - val_output_1_loss: 0.6586\n",
      "Epoch 4/100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5389 - output_1_loss: 0.5387 - val_loss: 0.6477 - val_output_1_loss: 0.6471\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0445 - output_1_loss: 0.0445 - val_loss: 0.1859 - val_output_1_loss: 0.1858\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4423 - output_1_loss: 0.4421 - val_loss: 0.6351 - val_output_1_loss: 0.6345\n",
      "Epoch 30/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0405 - output_1_loss: 0.0405 - val_loss: 0.1799 - val_output_1_loss: 0.1798\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.3310 - output_1_loss: 0.3309 - val_loss: 0.6206 - val_output_1_loss: 0.6200\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0554 - output_1_loss: 0.0554 - val_loss: 0.1746 - val_output_1_loss: 0.1746\n",
      "Epoch 32/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0442 - output_1_loss: 0.0441 - val_loss: 0.1699 - val_output_1_loss: 0.1698\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.4372 - output_1_loss: 0.4371 - val_loss: 0.6054 - val_output_1_loss: 0.6049\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0451 - output_1_loss: 0.0450 - val_loss: 0.1659 - val_output_1_loss: 0.1658\n",
      "Epoch 8/100\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0442 - output_1_loss: 0.0441 - val_loss: 0.1622 - val_output_1_loss: 0.1621\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.3890 - output_1_loss: 0.3889 - val_loss: 0.5901 - val_output_1_loss: 0.5896\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0353 - output_1_loss: 0.0353 - val_loss: 0.1592 - val_output_1_loss: 0.1592\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.2876 - output_1_loss: 0.2875 - val_loss: 0.5767 - val_output_1_loss: 0.5763\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0434 - output_1_loss: 0.0434 - val_loss: 0.1567 - val_output_1_loss: 0.1567\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.2620 - output_1_loss: 0.2618 - val_loss: 0.5633 - val_output_1_loss: 0.5628\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0394 - output_1_loss: 0.0394 - val_loss: 0.1544 - val_output_1_loss: 0.1544\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0414 - output_1_loss: 0.0414Epoch 11/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0414 - output_1_loss: 0.0414 - val_loss: 0.1522 - val_output_1_loss: 0.1521\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.3013 - output_1_loss: 0.3012 - val_loss: 0.5508 - val_output_1_loss: 0.5503\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.0362 - output_1_loss: 0.0361 - val_loss: 0.1500 - val_output_1_loss: 0.1500\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 0.3074 - output_1_loss: 0.3073 - val_loss: 0.5365 - val_output_1_loss: 0.5361\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0351 - output_1_loss: 0.0351 - val_loss: 0.1482 - val_output_1_loss: 0.1482\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0324 - output_1_loss: 0.0324 - val_loss: 0.1468 - val_output_1_loss: 0.1467\n",
      "Epoch 13/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0302 - output_1_loss: 0.0301 - val_loss: 0.1454 - val_output_1_loss: 0.1454\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.3168 - output_1_loss: 0.3167 - val_loss: 0.5223 - val_output_1_loss: 0.5218\n",
      "Epoch 43/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0290 - output_1_loss: 0.0290 - val_loss: 0.1438 - val_output_1_loss: 0.1438\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.2115 - output_1_loss: 0.2114 - val_loss: 0.5046 - val_output_1_loss: 0.5042\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.2557 - output_1_loss: 0.2555 - val_loss: 0.4886 - val_output_1_loss: 0.4881\n",
      "Epoch 16/100\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0261 - output_1_loss: 0.0261 - val_loss: 0.1422 - val_output_1_loss: 0.1422\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.3135 - output_1_loss: 0.3133 - val_loss: 0.4772 - val_output_1_loss: 0.4768\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0237 - output_1_loss: 0.0237Epoch 17/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0237 - output_1_loss: 0.0237 - val_loss: 0.1406 - val_output_1_loss: 0.1406\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.1900 - output_1_loss: 0.1898 - val_loss: 0.4519 - val_output_1_loss: 0.4515\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0215 - output_1_loss: 0.0215 - val_loss: 0.1391 - val_output_1_loss: 0.1391\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0191 - output_1_loss: 0.0190Epoch 18/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0191 - output_1_loss: 0.0190 - val_loss: 0.1377 - val_output_1_loss: 0.1377\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2672 - output_1_loss: 0.2670 - val_loss: 0.4377 - val_output_1_loss: 0.4373\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0180 - output_1_loss: 0.0180 - val_loss: 0.1363 - val_output_1_loss: 0.1362\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0205 - output_1_loss: 0.0204 - val_loss: 0.1348 - val_output_1_loss: 0.1348\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0177 - output_1_loss: 0.0177Epoch 19/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.2024 - output_1_loss: 0.2022 - val_loss: 0.4218 - val_output_1_loss: 0.4213\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.0177 - output_1_loss: 0.0177 - val_loss: 0.1336 - val_output_1_loss: 0.1335\n",
      "Epoch 51/100\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0237 - output_1_loss: 0.0237 - val_loss: 0.1320 - val_output_1_loss: 0.1320\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.1407 - output_1_loss: 0.1405 - val_loss: 0.4082 - val_output_1_loss: 0.4077\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0196 - output_1_loss: 0.0196 - val_loss: 0.1305 - val_output_1_loss: 0.1304\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0889 - output_1_loss: 0.0887 - val_loss: 0.3786 - val_output_1_loss: 0.3782\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1037 - output_1_loss: 0.1035 - val_loss: 0.3610 - val_output_1_loss: 0.3606\n",
      "Epoch 23/100\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0217 - output_1_loss: 0.0217 - val_loss: 0.1288 - val_output_1_loss: 0.1288\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0755 - output_1_loss: 0.0754 - val_loss: 0.3388 - val_output_1_loss: 0.3384\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0275 - output_1_loss: 0.0275 - val_loss: 0.1272 - val_output_1_loss: 0.1271\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0141 - output_1_loss: 0.0141Epoch 24/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.0141 - output_1_loss: 0.0141 - val_loss: 0.1256 - val_output_1_loss: 0.1255\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1841 - output_1_loss: 0.1839 - val_loss: 0.3253 - val_output_1_loss: 0.3249\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0169 - output_1_loss: 0.0169 - val_loss: 0.1239 - val_output_1_loss: 0.1239\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.1134 - output_1_loss: 0.1132 - val_loss: 0.3092 - val_output_1_loss: 0.3087\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0134 - output_1_loss: 0.0134 - val_loss: 0.1222 - val_output_1_loss: 0.1221\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0155 - output_1_loss: 0.0155 - val_loss: 0.1212 - val_output_1_loss: 0.1211\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.1156 - output_1_loss: 0.1154 - val_loss: 0.2967 - val_output_1_loss: 0.2963\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0120 - output_1_loss: 0.0119 - val_loss: 0.1202 - val_output_1_loss: 0.1201\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1234 - output_1_loss: 0.1233Epoch 60/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1234 - output_1_loss: 0.1233 - val_loss: 0.2736 - val_output_1_loss: 0.2732\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0423 - output_1_loss: 0.0423 - val_loss: 0.1183 - val_output_1_loss: 0.1183\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0136 - output_1_loss: 0.0136 - val_loss: 0.1164 - val_output_1_loss: 0.1164\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0181 - output_1_loss: 0.0180Epoch 28/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0181 - output_1_loss: 0.0180 - val_loss: 0.1157 - val_output_1_loss: 0.1156\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.1304 - output_1_loss: 0.1302 - val_loss: 0.2530 - val_output_1_loss: 0.2526\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0171 - output_1_loss: 0.0171 - val_loss: 0.1153 - val_output_1_loss: 0.1153\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0158 - output_1_loss: 0.0158 - val_loss: 0.1154 - val_output_1_loss: 0.1153\n",
      "Epoch 65/100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0268 - output_1_loss: 0.0268 - val_loss: 0.1157 - val_output_1_loss: 0.1156\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0255 - output_1_loss: 0.0254 - val_loss: 0.1160 - val_output_1_loss: 0.1159\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.1793 - output_1_loss: 0.1791 - val_loss: 0.2352 - val_output_1_loss: 0.2348\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0265 - output_1_loss: 0.0264 - val_loss: 0.1160 - val_output_1_loss: 0.1159\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0177 - output_1_loss: 0.0177Epoch 30/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0177 - output_1_loss: 0.0177 - val_loss: 0.1148 - val_output_1_loss: 0.1148\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.0927 - output_1_loss: 0.0925 - val_loss: 0.2232 - val_output_1_loss: 0.2229\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0172 - output_1_loss: 0.0172 - val_loss: 0.1135 - val_output_1_loss: 0.1135\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0341 - output_1_loss: 0.0340 - val_loss: 0.1117 - val_output_1_loss: 0.1117\n",
      "Epoch 31/100\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0315 - output_1_loss: 0.0315 - val_loss: 0.1101 - val_output_1_loss: 0.1101\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.1445 - output_1_loss: 0.1444 - val_loss: 0.2112 - val_output_1_loss: 0.2108\n",
      "Epoch 32/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0208 - output_1_loss: 0.0208 - val_loss: 0.1086 - val_output_1_loss: 0.1085\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0719 - output_1_loss: 0.0718 - val_loss: 0.2019 - val_output_1_loss: 0.2015\n",
      "Epoch 73/100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0253 - output_1_loss: 0.0253 - val_loss: 0.1069 - val_output_1_loss: 0.1069\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.1655 - output_1_loss: 0.1654 - val_loss: 0.1896 - val_output_1_loss: 0.1892\n",
      "Epoch 74/100\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0253 - output_1_loss: 0.0252 - val_loss: 0.1060 - val_output_1_loss: 0.1059\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.2860 - output_1_loss: 0.2859 - val_loss: 0.1812 - val_output_1_loss: 0.1808\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0243 - output_1_loss: 0.0242Epoch 35/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0243 - output_1_loss: 0.0242 - val_loss: 0.1051 - val_output_1_loss: 0.1051\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.1083 - output_1_loss: 0.1082 - val_loss: 0.1730 - val_output_1_loss: 0.1726\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0303 - output_1_loss: 0.0303 - val_loss: 0.1037 - val_output_1_loss: 0.1037\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0286 - output_1_loss: 0.0286Epoch 36/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0286 - output_1_loss: 0.0286 - val_loss: 0.1026 - val_output_1_loss: 0.1025\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0290 - output_1_loss: 0.0290 - val_loss: 0.1017 - val_output_1_loss: 0.1017\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.1838 - output_1_loss: 0.1837 - val_loss: 0.1684 - val_output_1_loss: 0.1681\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.1972 - output_1_loss: 0.1971 - val_loss: 0.1671 - val_output_1_loss: 0.1668\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.0271 - output_1_loss: 0.0271 - val_loss: 0.1013 - val_output_1_loss: 0.1012\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.0265 - output_1_loss: 0.0264 - val_loss: 0.1004 - val_output_1_loss: 0.1004\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.1262 - output_1_loss: 0.1261 - val_loss: 0.1634 - val_output_1_loss: 0.1631\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0307 - output_1_loss: 0.0306 - val_loss: 0.1004 - val_output_1_loss: 0.1004\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0295 - output_1_loss: 0.0294Epoch 39/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0295 - output_1_loss: 0.0294 - val_loss: 0.0996 - val_output_1_loss: 0.0996\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0860 - output_1_loss: 0.0859Epoch 83/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0269 - output_1_loss: 0.0269 - val_loss: 0.0989 - val_output_1_loss: 0.0988\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.0860 - output_1_loss: 0.0859 - val_loss: 0.1590 - val_output_1_loss: 0.1587\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0247 - output_1_loss: 0.0247Epoch 40/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.0247 - output_1_loss: 0.0247 - val_loss: 0.0978 - val_output_1_loss: 0.0977\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.0784 - output_1_loss: 0.0783 - val_loss: 0.1532 - val_output_1_loss: 0.1529\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.0223 - output_1_loss: 0.0223 - val_loss: 0.0966 - val_output_1_loss: 0.0965\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0806 - output_1_loss: 0.0805Epoch 86/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0806 - output_1_loss: 0.0805 - val_loss: 0.1469 - val_output_1_loss: 0.1466\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0208 - output_1_loss: 0.0208 - val_loss: 0.0956 - val_output_1_loss: 0.0956\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0177 - output_1_loss: 0.0177 - val_loss: 0.0947 - val_output_1_loss: 0.0947\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1005 - output_1_loss: 0.1004Epoch 88/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.1005 - output_1_loss: 0.1004 - val_loss: 0.1466 - val_output_1_loss: 0.1463\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0164 - output_1_loss: 0.0164 - val_loss: 0.0939 - val_output_1_loss: 0.0938\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0153 - output_1_loss: 0.0153 - val_loss: 0.0930 - val_output_1_loss: 0.0930\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1644 - output_1_loss: 0.1642Epoch 90/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.1644 - output_1_loss: 0.1642 - val_loss: 0.1389 - val_output_1_loss: 0.1386\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0146 - output_1_loss: 0.0145 - val_loss: 0.0921 - val_output_1_loss: 0.0921\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1779 - output_1_loss: 0.1777Epoch 91/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0209 - output_1_loss: 0.0209 - val_loss: 0.0915 - val_output_1_loss: 0.0914\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1779 - output_1_loss: 0.1777 - val_loss: 0.1328 - val_output_1_loss: 0.1325\n",
      "Epoch 92/100\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.0189 - output_1_loss: 0.0188 - val_loss: 0.0910 - val_output_1_loss: 0.0909\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.0828 - output_1_loss: 0.0826 - val_loss: 0.1298 - val_output_1_loss: 0.1295\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0199 - output_1_loss: 0.0198 - val_loss: 0.0904 - val_output_1_loss: 0.0903\n",
      "Epoch 46/100\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0505 - output_1_loss: 0.0505 - val_loss: 0.0900 - val_output_1_loss: 0.0900\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0847 - output_1_loss: 0.0846 - val_loss: 0.1272 - val_output_1_loss: 0.1269\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1889 - output_1_loss: 0.1887 - val_loss: 0.1265 - val_output_1_loss: 0.1261\n",
      "Epoch 95/100\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0720 - output_1_loss: 0.0720 - val_loss: 0.0891 - val_output_1_loss: 0.0891\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.1326 - output_1_loss: 0.1325 - val_loss: 0.1233 - val_output_1_loss: 0.1230\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1464 - output_1_loss: 0.1463 - val_loss: 0.1196 - val_output_1_loss: 0.1192\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0209 - output_1_loss: 0.0209Epoch 50/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0209 - output_1_loss: 0.0209 - val_loss: 0.0893 - val_output_1_loss: 0.0893\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1610 - output_1_loss: 0.1609 - val_loss: 0.1197 - val_output_1_loss: 0.1193\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0216 - output_1_loss: 0.0216 - val_loss: 0.0894 - val_output_1_loss: 0.0894\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0223 - output_1_loss: 0.0223 - val_loss: 0.0893 - val_output_1_loss: 0.0893\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.1183 - output_1_loss: 0.1181 - val_loss: 0.1156 - val_output_1_loss: 0.1152\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0296 - output_1_loss: 0.0296 - val_loss: 0.0891 - val_output_1_loss: 0.0890\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0394 - output_1_loss: 0.0393Epoch 52/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.0394 - output_1_loss: 0.0393 - val_loss: 0.0887 - val_output_1_loss: 0.0887\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.0851 - output_1_loss: 0.0849 - val_loss: 0.1122 - val_output_1_loss: 0.1118\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0974 - output_1_loss: 0.0973 - val_loss: 0.1084 - val_output_1_loss: 0.1081\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:25:26,712]\u001b[0m Trial 64 finished with value: 0.012195121951219513 and parameters: {'feature_dim': 512, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.4, 'sparsity_coefficient': 1.100790310205412e-05, 'bn_momentum': 0.9665499836535817}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 569ms/step - loss: 0.1133 - output_1_loss: 0.1132 - val_loss: 0.1040 - val_output_1_loss: 0.1036\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1000 - output_1_loss: 0.0998Epoch 1/100\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.1000 - output_1_loss: 0.0998 - val_loss: 0.1000 - val_output_1_loss: 0.0997\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.0935 - output_1_loss: 0.0934 - val_loss: 0.0985 - val_output_1_loss: 0.0981\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0962 - output_1_loss: 0.0961 - val_loss: 0.0985 - val_output_1_loss: 0.0982\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.0768 - output_1_loss: 0.0767 - val_loss: 0.0964 - val_output_1_loss: 0.0960\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.0734 - output_1_loss: 0.0733 - val_loss: 0.0946 - val_output_1_loss: 0.0943\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.1027 - output_1_loss: 0.1025 - val_loss: 0.0908 - val_output_1_loss: 0.0905\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1431 - output_1_loss: 0.1430 - val_loss: 0.0922 - val_output_1_loss: 0.0919\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.0964 - output_1_loss: 0.0963 - val_loss: 0.0908 - val_output_1_loss: 0.0904\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.1300 - output_1_loss: 0.1299 - val_loss: 0.0859 - val_output_1_loss: 0.0855\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.1026 - output_1_loss: 0.1025 - val_loss: 0.0835 - val_output_1_loss: 0.0832\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1215 - output_1_loss: 0.1214 - val_loss: 0.0823 - val_output_1_loss: 0.0820\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.1564 - output_1_loss: 0.1563 - val_loss: 0.0819 - val_output_1_loss: 0.0816\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0950 - output_1_loss: 0.0949 - val_loss: 0.0804 - val_output_1_loss: 0.0801\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.0832 - output_1_loss: 0.0831 - val_loss: 0.0788 - val_output_1_loss: 0.0785\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.1067 - output_1_loss: 0.1066 - val_loss: 0.0782 - val_output_1_loss: 0.0779\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1303 - output_1_loss: 0.1302 - val_loss: 0.0786 - val_output_1_loss: 0.0782\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0723 - output_1_loss: 0.0722 - val_loss: 0.0796 - val_output_1_loss: 0.0792\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.0974 - output_1_loss: 0.0973 - val_loss: 0.0777 - val_output_1_loss: 0.0774\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.0781 - output_1_loss: 0.0780 - val_loss: 0.0762 - val_output_1_loss: 0.0759\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1690 - output_1_loss: 0.1689 - val_loss: 0.0762 - val_output_1_loss: 0.0759\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1091 - output_1_loss: 0.1089 - val_loss: 0.0751 - val_output_1_loss: 0.0747\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.0995 - output_1_loss: 0.0993 - val_loss: 0.0725 - val_output_1_loss: 0.0722\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0948 - output_1_loss: 0.0946 - val_loss: 0.0718 - val_output_1_loss: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1029 - output_1_loss: 0.1027 - val_loss: 0.0720 - val_output_1_loss: 0.0717\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0984 - output_1_loss: 0.0982 - val_loss: 0.0741 - val_output_1_loss: 0.0737\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0981 - output_1_loss: 0.0979 - val_loss: 0.0749 - val_output_1_loss: 0.0745\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0880 - output_1_loss: 0.0878 - val_loss: 0.0741 - val_output_1_loss: 0.0738\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.2334 - output_1_loss: 0.2332 - val_loss: 0.0743 - val_output_1_loss: 0.0740\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:25:41,293]\u001b[0m Trial 65 finished with value: 0.09090909090909091 and parameters: {'feature_dim': 512, 'n_step': 4, 'n_shared': 2, 'relaxation_factor': 2.5, 'sparsity_coefficient': 0.00016125887206059134, 'bn_momentum': 0.9691459965799855}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.7257 - output_1_loss: 0.7254 - val_loss: 0.6885 - val_output_1_loss: 0.6875\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.7117 - output_1_loss: 0.7115 - val_loss: 0.6834 - val_output_1_loss: 0.6825\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.7519 - output_1_loss: 0.7517 - val_loss: 0.6792 - val_output_1_loss: 0.6783\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.6865 - output_1_loss: 0.6862 - val_loss: 0.6742 - val_output_1_loss: 0.6734\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.6314 - output_1_loss: 0.6312 - val_loss: 0.6692 - val_output_1_loss: 0.6684\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.6435 - output_1_loss: 0.6433 - val_loss: 0.6641 - val_output_1_loss: 0.6633\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.6516 - output_1_loss: 0.6513 - val_loss: 0.6579 - val_output_1_loss: 0.6572\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.6538 - output_1_loss: 0.6535 - val_loss: 0.6539 - val_output_1_loss: 0.6532\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.6181 - output_1_loss: 0.6179 - val_loss: 0.6494 - val_output_1_loss: 0.6487\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.5930 - output_1_loss: 0.5927 - val_loss: 0.6433 - val_output_1_loss: 0.6426\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.5745 - output_1_loss: 0.5742 - val_loss: 0.6363 - val_output_1_loss: 0.6356\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.6309 - output_1_loss: 0.6307 - val_loss: 0.6304 - val_output_1_loss: 0.6297\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5237 - output_1_loss: 0.5234 - val_loss: 0.6242 - val_output_1_loss: 0.6236\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4764 - output_1_loss: 0.4761 - val_loss: 0.6195 - val_output_1_loss: 0.6189\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5419 - output_1_loss: 0.5416 - val_loss: 0.6141 - val_output_1_loss: 0.6135\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5587 - output_1_loss: 0.5585 - val_loss: 0.6085 - val_output_1_loss: 0.6079\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5200 - output_1_loss: 0.5198 - val_loss: 0.6040 - val_output_1_loss: 0.6034\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4838 - output_1_loss: 0.4835 - val_loss: 0.5981 - val_output_1_loss: 0.5976\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4889 - output_1_loss: 0.4886 - val_loss: 0.5937 - val_output_1_loss: 0.5931\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4597 - output_1_loss: 0.4594 - val_loss: 0.5894 - val_output_1_loss: 0.5888\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4388 - output_1_loss: 0.4385 - val_loss: 0.5847 - val_output_1_loss: 0.5842\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4273 - output_1_loss: 0.4270 - val_loss: 0.5801 - val_output_1_loss: 0.5796\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.4254 - output_1_loss: 0.4252 - val_loss: 0.5742 - val_output_1_loss: 0.5737\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4276 - output_1_loss: 0.4273 - val_loss: 0.5690 - val_output_1_loss: 0.5685\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3806 - output_1_loss: 0.3803 - val_loss: 0.5608 - val_output_1_loss: 0.5603\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3958 - output_1_loss: 0.3955 - val_loss: 0.5557 - val_output_1_loss: 0.5551\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3929 - output_1_loss: 0.3926 - val_loss: 0.5513 - val_output_1_loss: 0.5508\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.3912 - output_1_loss: 0.3909 - val_loss: 0.5442 - val_output_1_loss: 0.5437\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4736 - output_1_loss: 0.4733 - val_loss: 0.5382 - val_output_1_loss: 0.5377\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.4170 - output_1_loss: 0.4167 - val_loss: 0.5312 - val_output_1_loss: 0.5307\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3120 - output_1_loss: 0.3117 - val_loss: 0.5234 - val_output_1_loss: 0.5229\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.3869 - output_1_loss: 0.3867 - val_loss: 0.5185 - val_output_1_loss: 0.5180\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3385 - output_1_loss: 0.3382 - val_loss: 0.5138 - val_output_1_loss: 0.5133\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.3290 - output_1_loss: 0.3288 - val_loss: 0.5077 - val_output_1_loss: 0.5073\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.3209 - output_1_loss: 0.3206 - val_loss: 0.5002 - val_output_1_loss: 0.4998\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.3368 - output_1_loss: 0.3365 - val_loss: 0.4939 - val_output_1_loss: 0.4934\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2922 - output_1_loss: 0.2920 - val_loss: 0.4867 - val_output_1_loss: 0.4863\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3131 - output_1_loss: 0.3128 - val_loss: 0.4782 - val_output_1_loss: 0.4777\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3129 - output_1_loss: 0.3127 - val_loss: 0.4708 - val_output_1_loss: 0.4703\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.3960 - output_1_loss: 0.3958 - val_loss: 0.4634 - val_output_1_loss: 0.4629\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3486 - output_1_loss: 0.3483 - val_loss: 0.4571 - val_output_1_loss: 0.4566\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.1896 - output_1_loss: 1.1160 - val_loss: 0.9642 - val_output_1_loss: 0.6907\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3183 - output_1_loss: 0.3180Epoch 2/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.3183 - output_1_loss: 0.3180 - val_loss: 0.4506 - val_output_1_loss: 0.4502\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 1.0661 - output_1_loss: 0.9944 - val_loss: 0.9472 - val_output_1_loss: 0.6886\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3160 - output_1_loss: 0.3157 - val_loss: 0.4435 - val_output_1_loss: 0.4430\n",
      "Epoch 44/100\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2917 - output_1_loss: 0.2914 - val_loss: 0.4358 - val_output_1_loss: 0.4353\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 1.1040 - output_1_loss: 1.0332 - val_loss: 0.9303 - val_output_1_loss: 0.6863\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3060 - output_1_loss: 0.3058 - val_loss: 0.4297 - val_output_1_loss: 0.4292\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 1.0254 - output_1_loss: 0.9508 - val_loss: 0.9180 - val_output_1_loss: 0.6839\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3640 - output_1_loss: 0.3638 - val_loss: 0.4233 - val_output_1_loss: 0.4229\n",
      "Epoch 5/100\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.0467 - output_1_loss: 0.9765 - val_loss: 0.9075 - val_output_1_loss: 0.6814\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3018 - output_1_loss: 0.3016 - val_loss: 0.4152 - val_output_1_loss: 0.4147\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3064 - output_1_loss: 0.3062Epoch 6/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.3064 - output_1_loss: 0.3062 - val_loss: 0.4103 - val_output_1_loss: 0.4098\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.9933 - output_1_loss: 0.9232 - val_loss: 0.8996 - val_output_1_loss: 0.6788\n",
      "Epoch 7/100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.0733 - output_1_loss: 1.0072 - val_loss: 0.8926 - val_output_1_loss: 0.6761\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2603 - output_1_loss: 0.2601 - val_loss: 0.4030 - val_output_1_loss: 0.4025\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9405 - output_1_loss: 0.8729Epoch 50/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.9405 - output_1_loss: 0.8729 - val_loss: 0.8835 - val_output_1_loss: 0.6739\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2759 - output_1_loss: 0.2756Epoch 9/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2759 - output_1_loss: 0.2756 - val_loss: 0.3974 - val_output_1_loss: 0.3970\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.0070 - output_1_loss: 0.9379 - val_loss: 0.8738 - val_output_1_loss: 0.6715\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.2396 - output_1_loss: 0.2394 - val_loss: 0.3898 - val_output_1_loss: 0.3894\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.8694 - output_1_loss: 0.8000 - val_loss: 0.8713 - val_output_1_loss: 0.6692\n",
      "Epoch 11/100\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2048 - output_1_loss: 0.2046 - val_loss: 0.3794 - val_output_1_loss: 0.3790\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.9509 - output_1_loss: 0.8846 - val_loss: 0.8642 - val_output_1_loss: 0.6667\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2476 - output_1_loss: 0.2473Epoch 12/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2476 - output_1_loss: 0.2473 - val_loss: 0.3726 - val_output_1_loss: 0.3722\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.9142 - output_1_loss: 0.8462 - val_loss: 0.8555 - val_output_1_loss: 0.6645\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.2584 - output_1_loss: 0.2582 - val_loss: 0.3636 - val_output_1_loss: 0.3632\n",
      "Epoch 13/100\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2757 - output_1_loss: 0.2755 - val_loss: 0.3595 - val_output_1_loss: 0.3591\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.8349 - output_1_loss: 0.7661 - val_loss: 0.8469 - val_output_1_loss: 0.6617\n",
      "Epoch 56/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.2407 - output_1_loss: 0.2404 - val_loss: 0.3531 - val_output_1_loss: 0.3526\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.9129 - output_1_loss: 0.8462 - val_loss: 0.8358 - val_output_1_loss: 0.6589\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2551 - output_1_loss: 0.2548Epoch 15/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2551 - output_1_loss: 0.2548 - val_loss: 0.3502 - val_output_1_loss: 0.3498\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.8198 - output_1_loss: 0.7540 - val_loss: 0.8298 - val_output_1_loss: 0.6559\n",
      "Epoch 16/100\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2774 - output_1_loss: 0.2771 - val_loss: 0.3447 - val_output_1_loss: 0.3443\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.7938 - output_1_loss: 0.7287 - val_loss: 0.8241 - val_output_1_loss: 0.6537\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3789 - output_1_loss: 0.3787Epoch 17/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3789 - output_1_loss: 0.3787 - val_loss: 0.3408 - val_output_1_loss: 0.3404\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.8077 - output_1_loss: 0.7414 - val_loss: 0.8190 - val_output_1_loss: 0.6514\n",
      "Epoch 18/100\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7642 - output_1_loss: 0.6994 - val_loss: 0.8099 - val_output_1_loss: 0.6483\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2376 - output_1_loss: 0.2373 - val_loss: 0.3332 - val_output_1_loss: 0.3328\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2067 - output_1_loss: 0.2065Epoch 19/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2067 - output_1_loss: 0.2065 - val_loss: 0.3245 - val_output_1_loss: 0.3241\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.7423 - output_1_loss: 0.6820 - val_loss: 0.8038 - val_output_1_loss: 0.6461\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2021 - output_1_loss: 0.2018 - val_loss: 0.3159 - val_output_1_loss: 0.3155\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.7800 - output_1_loss: 0.7168 - val_loss: 0.8014 - val_output_1_loss: 0.6440\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1518 - output_1_loss: 0.1516 - val_loss: 0.3065 - val_output_1_loss: 0.3061\n",
      "Epoch 64/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1426 - output_1_loss: 0.1424 - val_loss: 0.2994 - val_output_1_loss: 0.2990\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7601 - output_1_loss: 0.6958 - val_loss: 0.7986 - val_output_1_loss: 0.6416\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1451 - output_1_loss: 0.1449 - val_loss: 0.2938 - val_output_1_loss: 0.2934\n",
      "Epoch 22/100\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1120 - output_1_loss: 0.1118 - val_loss: 0.2836 - val_output_1_loss: 0.2832\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7265 - output_1_loss: 0.6591 - val_loss: 0.7915 - val_output_1_loss: 0.6388\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1111 - output_1_loss: 0.1108Epoch 23/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1111 - output_1_loss: 0.1108 - val_loss: 0.2692 - val_output_1_loss: 0.2688\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.6889 - output_1_loss: 0.6290 - val_loss: 0.7838 - val_output_1_loss: 0.6374\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0933 - output_1_loss: 0.0931 - val_loss: 0.2578 - val_output_1_loss: 0.2574\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6935 - output_1_loss: 0.6331Epoch 69/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6935 - output_1_loss: 0.6331 - val_loss: 0.7784 - val_output_1_loss: 0.6326\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0874 - output_1_loss: 0.0872 - val_loss: 0.2446 - val_output_1_loss: 0.2442\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7113 - output_1_loss: 0.6523Epoch 70/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.7113 - output_1_loss: 0.6523 - val_loss: 0.7728 - val_output_1_loss: 0.6279\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1195 - output_1_loss: 0.1193 - val_loss: 0.2390 - val_output_1_loss: 0.2386\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6981 - output_1_loss: 0.6358Epoch 71/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6981 - output_1_loss: 0.6358 - val_loss: 0.7664 - val_output_1_loss: 0.6245\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1190 - output_1_loss: 0.1188 - val_loss: 0.2313 - val_output_1_loss: 0.2309\n",
      "Epoch 72/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1629 - output_1_loss: 0.1627 - val_loss: 0.2309 - val_output_1_loss: 0.2305\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.6693 - output_1_loss: 0.6042 - val_loss: 0.7618 - val_output_1_loss: 0.6210\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1934 - output_1_loss: 0.1932 - val_loss: 0.2261 - val_output_1_loss: 0.2257\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6570 - output_1_loss: 0.6025 - val_loss: 0.7587 - val_output_1_loss: 0.6164\n",
      "Epoch 29/100\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6471 - output_1_loss: 0.5891 - val_loss: 0.7529 - val_output_1_loss: 0.6128\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1187 - output_1_loss: 0.1185 - val_loss: 0.2207 - val_output_1_loss: 0.2203\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1351 - output_1_loss: 0.1349Epoch 30/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1351 - output_1_loss: 0.1349 - val_loss: 0.2145 - val_output_1_loss: 0.2141\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6459 - output_1_loss: 0.5881 - val_loss: 0.7406 - val_output_1_loss: 0.6080\n",
      "Epoch 31/100\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6368 - output_1_loss: 0.5785 - val_loss: 0.7344 - val_output_1_loss: 0.6051\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2110 - output_1_loss: 0.2108 - val_loss: 0.2147 - val_output_1_loss: 0.2144\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1019 - output_1_loss: 0.1017 - val_loss: 0.2148 - val_output_1_loss: 0.2144\n",
      "Epoch 78/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1025 - output_1_loss: 0.1023 - val_loss: 0.2120 - val_output_1_loss: 0.2116\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.6184 - output_1_loss: 0.5618 - val_loss: 0.7284 - val_output_1_loss: 0.6011\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0859 - output_1_loss: 0.0857Epoch 33/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0859 - output_1_loss: 0.0857 - val_loss: 0.2048 - val_output_1_loss: 0.2044\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5905 - output_1_loss: 0.5359 - val_loss: 0.7238 - val_output_1_loss: 0.5972\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1379 - output_1_loss: 0.1377 - val_loss: 0.1989 - val_output_1_loss: 0.1986\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6197 - output_1_loss: 0.5616 - val_loss: 0.7145 - val_output_1_loss: 0.5913\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1323 - output_1_loss: 0.1321 - val_loss: 0.1970 - val_output_1_loss: 0.1967\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6227 - output_1_loss: 0.5636Epoch 82/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6227 - output_1_loss: 0.5636 - val_loss: 0.7083 - val_output_1_loss: 0.5874\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1285 - output_1_loss: 0.1283 - val_loss: 0.1956 - val_output_1_loss: 0.1953\n",
      "Epoch 83/100\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1884 - output_1_loss: 0.1882 - val_loss: 0.1910 - val_output_1_loss: 0.1907\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.6137 - output_1_loss: 0.5554 - val_loss: 0.7032 - val_output_1_loss: 0.5836\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.1150 - output_1_loss: 0.1148 - val_loss: 0.1859 - val_output_1_loss: 0.1856\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.6048 - output_1_loss: 0.5461 - val_loss: 0.6964 - val_output_1_loss: 0.5791\n",
      "Epoch 38/100\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0952 - output_1_loss: 0.0951 - val_loss: 0.1804 - val_output_1_loss: 0.1801\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5810 - output_1_loss: 0.5233 - val_loss: 0.6906 - val_output_1_loss: 0.5745\n",
      "Epoch 39/100\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5816 - output_1_loss: 0.5222 - val_loss: 0.6865 - val_output_1_loss: 0.5716\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0894 - output_1_loss: 0.0892 - val_loss: 0.1745 - val_output_1_loss: 0.1742\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0894 - output_1_loss: 0.0893 - val_loss: 0.1698 - val_output_1_loss: 0.1695\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.5681 - output_1_loss: 0.5136 - val_loss: 0.6830 - val_output_1_loss: 0.5692\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5902 - output_1_loss: 0.5356Epoch 88/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5902 - output_1_loss: 0.5356 - val_loss: 0.6816 - val_output_1_loss: 0.5681\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1012 - output_1_loss: 0.1010 - val_loss: 0.1654 - val_output_1_loss: 0.1650\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5663 - output_1_loss: 0.5105 - val_loss: 0.6778 - val_output_1_loss: 0.5642\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1141 - output_1_loss: 0.1139 - val_loss: 0.1602 - val_output_1_loss: 0.1599\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5324 - output_1_loss: 0.4785 - val_loss: 0.6701 - val_output_1_loss: 0.5567\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1186 - output_1_loss: 0.1184 - val_loss: 0.1572 - val_output_1_loss: 0.1569\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5471 - output_1_loss: 0.4923 - val_loss: 0.6595 - val_output_1_loss: 0.5464\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1127 - output_1_loss: 0.1125 - val_loss: 0.1543 - val_output_1_loss: 0.1539\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5714 - output_1_loss: 0.5182Epoch 92/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5714 - output_1_loss: 0.5182 - val_loss: 0.6504 - val_output_1_loss: 0.5390\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1242 - output_1_loss: 0.1239 - val_loss: 0.1468 - val_output_1_loss: 0.1465\n",
      "Epoch 93/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1318 - output_1_loss: 0.1316 - val_loss: 0.1413 - val_output_1_loss: 0.1409\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5123 - output_1_loss: 0.4583 - val_loss: 0.6442 - val_output_1_loss: 0.5339\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1422 - output_1_loss: 0.1420 - val_loss: 0.1377 - val_output_1_loss: 0.1374\n",
      "Epoch 95/100\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1294 - output_1_loss: 0.1291 - val_loss: 0.1316 - val_output_1_loss: 0.1313\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.5470 - output_1_loss: 0.4950 - val_loss: 0.6360 - val_output_1_loss: 0.5288\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1049 - output_1_loss: 0.1047Epoch 48/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1049 - output_1_loss: 0.1047 - val_loss: 0.1301 - val_output_1_loss: 0.1298\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5051 - output_1_loss: 0.4515 - val_loss: 0.6289 - val_output_1_loss: 0.5233\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1018 - output_1_loss: 0.1015 - val_loss: 0.1267 - val_output_1_loss: 0.1264\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5086 - output_1_loss: 0.4556 - val_loss: 0.6256 - val_output_1_loss: 0.5207\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0914 - output_1_loss: 0.0912 - val_loss: 0.1235 - val_output_1_loss: 0.1232\n",
      "Epoch 99/100\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1027 - output_1_loss: 0.1025 - val_loss: 0.1180 - val_output_1_loss: 0.1177\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5343 - output_1_loss: 0.4815 - val_loss: 0.6189 - val_output_1_loss: 0.5154\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0937 - output_1_loss: 0.0935 - val_loss: 0.1152 - val_output_1_loss: 0.1149\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.4891 - output_1_loss: 0.4360 - val_loss: 0.6101 - val_output_1_loss: 0.5111\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.4840 - output_1_loss: 0.4297 - val_loss: 0.6029 - val_output_1_loss: 0.5052\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5024 - output_1_loss: 0.4470 - val_loss: 0.6014 - val_output_1_loss: 0.5033\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4846 - output_1_loss: 0.4299 - val_loss: 0.5936 - val_output_1_loss: 0.4970\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4902 - output_1_loss: 0.4356 - val_loss: 0.5869 - val_output_1_loss: 0.4925\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:26:17,650]\u001b[0m Trial 66 finished with value: 0.014285714285714285 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 2, 'relaxation_factor': 2.5, 'sparsity_coefficient': 0.00018721601477028046, 'bn_momentum': 0.9612591773685311}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4755 - output_1_loss: 0.4176 - val_loss: 0.5877 - val_output_1_loss: 0.4907\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4668 - output_1_loss: 0.4083 - val_loss: 0.5870 - val_output_1_loss: 0.4886\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4717 - output_1_loss: 0.4126Epoch 1/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.4717 - output_1_loss: 0.4126 - val_loss: 0.5833 - val_output_1_loss: 0.4833\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4896 - output_1_loss: 0.4325 - val_loss: 0.5831 - val_output_1_loss: 0.4817\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.4868 - output_1_loss: 0.4282 - val_loss: 0.5855 - val_output_1_loss: 0.4826\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4501 - output_1_loss: 0.3921 - val_loss: 0.5832 - val_output_1_loss: 0.4785\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4489 - output_1_loss: 0.3893 - val_loss: 0.5793 - val_output_1_loss: 0.4732\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.4490 - output_1_loss: 0.3883 - val_loss: 0.5710 - val_output_1_loss: 0.4639\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.4452 - output_1_loss: 0.3855 - val_loss: 0.5640 - val_output_1_loss: 0.4555\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.5001 - output_1_loss: 0.4374 - val_loss: 0.5609 - val_output_1_loss: 0.4502\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.4410 - output_1_loss: 0.3763 - val_loss: 0.5570 - val_output_1_loss: 0.4451\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.4614 - output_1_loss: 0.3968 - val_loss: 0.5563 - val_output_1_loss: 0.4415\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.4189 - output_1_loss: 0.3557 - val_loss: 0.5489 - val_output_1_loss: 0.4353\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.4604 - output_1_loss: 0.3952 - val_loss: 0.5424 - val_output_1_loss: 0.4300\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.4247 - output_1_loss: 0.3620 - val_loss: 0.5346 - val_output_1_loss: 0.4225\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.4169 - output_1_loss: 0.3585 - val_loss: 0.5263 - val_output_1_loss: 0.4126\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4167 - output_1_loss: 0.3562 - val_loss: 0.5298 - val_output_1_loss: 0.4138\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.3942 - output_1_loss: 0.3364 - val_loss: 0.5244 - val_output_1_loss: 0.4087\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.3423 - output_1_loss: 0.2846 - val_loss: 0.5158 - val_output_1_loss: 0.4015\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3643 - output_1_loss: 0.3027 - val_loss: 0.5053 - val_output_1_loss: 0.3952\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4222 - output_1_loss: 0.3620 - val_loss: 0.4997 - val_output_1_loss: 0.3913\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3884 - output_1_loss: 0.3273 - val_loss: 0.4952 - val_output_1_loss: 0.3866\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4037 - output_1_loss: 0.3440 - val_loss: 0.4895 - val_output_1_loss: 0.3825\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.3659 - output_1_loss: 0.3077 - val_loss: 0.4794 - val_output_1_loss: 0.3743\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3476 - output_1_loss: 0.2866 - val_loss: 0.4800 - val_output_1_loss: 0.3749\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.4087 - output_1_loss: 0.3475 - val_loss: 0.4757 - val_output_1_loss: 0.3710\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.4066 - output_1_loss: 0.3453 - val_loss: 0.4793 - val_output_1_loss: 0.3727\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3841 - output_1_loss: 0.3270 - val_loss: 0.4779 - val_output_1_loss: 0.3686\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.3567 - output_1_loss: 0.2995 - val_loss: 0.4759 - val_output_1_loss: 0.3652\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.3944 - output_1_loss: 0.3381 - val_loss: 0.4622 - val_output_1_loss: 0.3525\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.3158 - output_1_loss: 0.2603 - val_loss: 0.4480 - val_output_1_loss: 0.3416\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.3045 - output_1_loss: 0.2511 - val_loss: 0.4391 - val_output_1_loss: 0.3345\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.3322 - output_1_loss: 0.2762 - val_loss: 0.4345 - val_output_1_loss: 0.3317\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.2925 - output_1_loss: 0.2349 - val_loss: 0.4264 - val_output_1_loss: 0.3238\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.2801 - output_1_loss: 0.2228 - val_loss: 0.4164 - val_output_1_loss: 0.3152\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.2940 - output_1_loss: 0.2394 - val_loss: 0.4056 - val_output_1_loss: 0.3068\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.3014 - output_1_loss: 0.2491 - val_loss: 0.4039 - val_output_1_loss: 0.3056\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.2572 - output_1_loss: 0.2107 - val_loss: 0.4025 - val_output_1_loss: 0.3056\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2313 - output_1_loss: 0.1840 - val_loss: 0.4018 - val_output_1_loss: 0.3077\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2091 - output_1_loss: 0.1613 - val_loss: 0.3946 - val_output_1_loss: 0.3048\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1995 - output_1_loss: 0.1499 - val_loss: 0.3870 - val_output_1_loss: 0.2991\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1913 - output_1_loss: 0.1417 - val_loss: 0.3756 - val_output_1_loss: 0.2896\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2071 - output_1_loss: 0.1581 - val_loss: 0.3679 - val_output_1_loss: 0.2831\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.2040 - output_1_loss: 0.1528 - val_loss: 0.3616 - val_output_1_loss: 0.2783\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1869 - output_1_loss: 0.1370 - val_loss: 0.3530 - val_output_1_loss: 0.2729\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:26:36,681]\u001b[0m Trial 67 finished with value: 0.017241379310344827 and parameters: {'feature_dim': 64, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 2.1, 'sparsity_coefficient': 0.053015159455992944, 'bn_momentum': 0.9617525283232676}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.9274 - output_1_loss: 0.9273Epoch 1/100\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.9274 - output_1_loss: 0.9273 - val_loss: 0.6918 - val_output_1_loss: 0.6916\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.8927 - output_1_loss: 0.8927 - val_loss: 0.6897 - val_output_1_loss: 0.6895\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.9389 - output_1_loss: 0.9389 - val_loss: 0.6878 - val_output_1_loss: 0.6876\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.9345 - output_1_loss: 0.9344 - val_loss: 0.6863 - val_output_1_loss: 0.6861\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.8526 - output_1_loss: 0.8526 - val_loss: 0.6847 - val_output_1_loss: 0.6845\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.7639 - output_1_loss: 0.7638 - val_loss: 0.6824 - val_output_1_loss: 0.6822\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.8360 - output_1_loss: 0.8360 - val_loss: 0.6808 - val_output_1_loss: 0.6806\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.8277 - output_1_loss: 0.8276 - val_loss: 0.6791 - val_output_1_loss: 0.6790\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.8311 - output_1_loss: 0.8310 - val_loss: 0.6771 - val_output_1_loss: 0.6770\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.8927 - output_1_loss: 0.8927 - val_loss: 0.6753 - val_output_1_loss: 0.6751\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.8205 - output_1_loss: 0.8204 - val_loss: 0.6730 - val_output_1_loss: 0.6729\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.7871 - output_1_loss: 0.7870 - val_loss: 0.6710 - val_output_1_loss: 0.6709\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.7745 - output_1_loss: 0.7744 - val_loss: 0.6693 - val_output_1_loss: 0.6692\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.7901 - output_1_loss: 0.7900 - val_loss: 0.6678 - val_output_1_loss: 0.6677\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.8217 - output_1_loss: 0.8216 - val_loss: 0.6663 - val_output_1_loss: 0.6662\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.7915 - output_1_loss: 0.7915 - val_loss: 0.6641 - val_output_1_loss: 0.6640\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.7758 - output_1_loss: 0.7758 - val_loss: 0.6623 - val_output_1_loss: 0.6622\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7427 - output_1_loss: 0.7426 - val_loss: 0.6605 - val_output_1_loss: 0.6603\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.7382 - output_1_loss: 0.7381 - val_loss: 0.6582 - val_output_1_loss: 0.6581\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.7428 - output_1_loss: 0.7428 - val_loss: 0.6556 - val_output_1_loss: 0.6554\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.7256 - output_1_loss: 0.7255 - val_loss: 0.6529 - val_output_1_loss: 0.6528\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.7268 - output_1_loss: 0.7268 - val_loss: 0.6513 - val_output_1_loss: 0.6512\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.6924 - output_1_loss: 0.6923 - val_loss: 0.6489 - val_output_1_loss: 0.6487\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.6924 - output_1_loss: 0.6924 - val_loss: 0.6466 - val_output_1_loss: 0.6464\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.6926 - output_1_loss: 0.6925 - val_loss: 0.6439 - val_output_1_loss: 0.6438\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.6694 - output_1_loss: 0.6693 - val_loss: 0.6421 - val_output_1_loss: 0.6420\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.7141 - output_1_loss: 0.7140 - val_loss: 0.6395 - val_output_1_loss: 0.6394\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.6627 - output_1_loss: 0.6626 - val_loss: 0.6371 - val_output_1_loss: 0.6370\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.6870 - output_1_loss: 0.6869 - val_loss: 0.6345 - val_output_1_loss: 0.6344\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.6752 - output_1_loss: 0.6751 - val_loss: 0.6318 - val_output_1_loss: 0.6316\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.6559 - output_1_loss: 0.6558 - val_loss: 0.6297 - val_output_1_loss: 0.6295\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.6401 - output_1_loss: 0.6401 - val_loss: 0.6271 - val_output_1_loss: 0.6270\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.6301 - output_1_loss: 0.6300 - val_loss: 0.6245 - val_output_1_loss: 0.6244\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.6112 - output_1_loss: 0.6112 - val_loss: 0.6224 - val_output_1_loss: 0.6223\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.5893 - output_1_loss: 0.5892 - val_loss: 0.6198 - val_output_1_loss: 0.6197\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5940 - output_1_loss: 0.5940 - val_loss: 0.6168 - val_output_1_loss: 0.6167\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6620 - output_1_loss: 0.6619 - val_loss: 0.6129 - val_output_1_loss: 0.6128\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6042 - output_1_loss: 0.6041 - val_loss: 0.6102 - val_output_1_loss: 0.6101\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.6251 - output_1_loss: 0.6251 - val_loss: 0.6078 - val_output_1_loss: 0.6077\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.6139 - output_1_loss: 0.6138 - val_loss: 0.6050 - val_output_1_loss: 0.6049\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5872 - output_1_loss: 0.5871 - val_loss: 0.6020 - val_output_1_loss: 0.6020\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5575 - output_1_loss: 0.5575 - val_loss: 0.5990 - val_output_1_loss: 0.5990\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5679 - output_1_loss: 0.5678 - val_loss: 0.5960 - val_output_1_loss: 0.5959\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.5731 - output_1_loss: 0.5731 - val_loss: 0.5940 - val_output_1_loss: 0.5940\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5831 - output_1_loss: 0.5830 - val_loss: 0.5923 - val_output_1_loss: 0.5922\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.5501 - output_1_loss: 0.5500 - val_loss: 0.5905 - val_output_1_loss: 0.5904\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.5556 - output_1_loss: 0.5556 - val_loss: 0.5874 - val_output_1_loss: 0.5873\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5481 - output_1_loss: 0.5480 - val_loss: 0.5838 - val_output_1_loss: 0.5837\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5721 - output_1_loss: 0.5721 - val_loss: 0.5836 - val_output_1_loss: 0.5836\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5581 - output_1_loss: 0.5581 - val_loss: 0.5815 - val_output_1_loss: 0.5814\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5653 - output_1_loss: 0.5652 - val_loss: 0.5779 - val_output_1_loss: 0.5778\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5308 - output_1_loss: 0.5308 - val_loss: 0.5740 - val_output_1_loss: 0.5739\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5282 - output_1_loss: 0.5281 - val_loss: 0.5710 - val_output_1_loss: 0.5709\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5282 - output_1_loss: 0.5282 - val_loss: 0.5682 - val_output_1_loss: 0.5681\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4954 - output_1_loss: 0.4954 - val_loss: 0.5645 - val_output_1_loss: 0.5644\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.5373 - output_1_loss: 0.5372 - val_loss: 0.5622 - val_output_1_loss: 0.5621\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5056 - output_1_loss: 0.5056 - val_loss: 0.5573 - val_output_1_loss: 0.5572\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5494 - output_1_loss: 0.5493 - val_loss: 0.5531 - val_output_1_loss: 0.5530\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4928 - output_1_loss: 0.4927 - val_loss: 0.5523 - val_output_1_loss: 0.5522\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4751 - output_1_loss: 0.4751 - val_loss: 0.5487 - val_output_1_loss: 0.5486\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.4864 - output_1_loss: 0.4863 - val_loss: 0.5447 - val_output_1_loss: 0.5446\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4609 - output_1_loss: 0.4608 - val_loss: 0.5398 - val_output_1_loss: 0.5397\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4711 - output_1_loss: 0.4711 - val_loss: 0.5372 - val_output_1_loss: 0.5371\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4559 - output_1_loss: 0.4558 - val_loss: 0.5322 - val_output_1_loss: 0.5321\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4902 - output_1_loss: 0.4901 - val_loss: 0.5287 - val_output_1_loss: 0.5286\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4593 - output_1_loss: 0.4592 - val_loss: 0.5252 - val_output_1_loss: 0.5251\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.4173 - output_1_loss: 0.4173 - val_loss: 0.5219 - val_output_1_loss: 0.5218\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.4858 - output_1_loss: 0.4857 - val_loss: 0.5180 - val_output_1_loss: 0.5179\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.4759 - output_1_loss: 0.4759 - val_loss: 0.5144 - val_output_1_loss: 0.5143\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5292 - output_1_loss: 0.5292 - val_loss: 0.5102 - val_output_1_loss: 0.5102\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.4728 - output_1_loss: 0.4727 - val_loss: 0.5066 - val_output_1_loss: 0.5066\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4201 - output_1_loss: 0.4201 - val_loss: 0.5023 - val_output_1_loss: 0.5022\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4268 - output_1_loss: 0.4267 - val_loss: 0.4981 - val_output_1_loss: 0.4981\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4484 - output_1_loss: 0.4484 - val_loss: 0.4931 - val_output_1_loss: 0.4931\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4027 - output_1_loss: 0.4026 - val_loss: 0.4887 - val_output_1_loss: 0.4886\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4332 - output_1_loss: 0.4331 - val_loss: 0.4851 - val_output_1_loss: 0.4850\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.4325 - output_1_loss: 0.4324 - val_loss: 0.4818 - val_output_1_loss: 0.4817\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4372 - output_1_loss: 0.4372 - val_loss: 0.4787 - val_output_1_loss: 0.4787\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.7044 - output_1_loss: 0.7043 - val_loss: 0.6925 - val_output_1_loss: 0.6923\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4283 - output_1_loss: 0.4283 - val_loss: 0.4763 - val_output_1_loss: 0.4762\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3651 - output_1_loss: 0.3651 - val_loss: 0.4681 - val_output_1_loss: 0.4681\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.4362 - output_1_loss: 0.4362 - val_loss: 0.4659 - val_output_1_loss: 0.4658\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4111 - output_1_loss: 0.4111 - val_loss: 0.4629 - val_output_1_loss: 0.4628\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4060 - output_1_loss: 0.4059 - val_loss: 0.4599 - val_output_1_loss: 0.4598\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.4305 - output_1_loss: 0.4305 - val_loss: 0.4537 - val_output_1_loss: 0.4537\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4026 - output_1_loss: 0.4026 - val_loss: 0.4526 - val_output_1_loss: 0.4525\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4052 - output_1_loss: 0.4052 - val_loss: 0.4469 - val_output_1_loss: 0.4468\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4011 - output_1_loss: 0.4010 - val_loss: 0.4420 - val_output_1_loss: 0.4419\n",
      "Epoch 88/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3868 - output_1_loss: 0.3867 - val_loss: 0.4374 - val_output_1_loss: 0.4374\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6954 - output_1_loss: 0.6954 - val_loss: 0.6903 - val_output_1_loss: 0.6902\n",
      "Epoch 3/100\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.3854 - output_1_loss: 0.3854 - val_loss: 0.4331 - val_output_1_loss: 0.4330\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.6930 - output_1_loss: 0.6930 - val_loss: 0.6877 - val_output_1_loss: 0.6875\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.3697 - output_1_loss: 0.3697 - val_loss: 0.4312 - val_output_1_loss: 0.4312\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3892 - output_1_loss: 0.3892 - val_loss: 0.4290 - val_output_1_loss: 0.4289\n",
      "Epoch 92/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3597 - output_1_loss: 0.3596 - val_loss: 0.4179 - val_output_1_loss: 0.4178\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6547 - output_1_loss: 0.6546Epoch 93/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.6547 - output_1_loss: 0.6546 - val_loss: 0.6848 - val_output_1_loss: 0.6847\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3237 - output_1_loss: 0.3236 - val_loss: 0.4047 - val_output_1_loss: 0.4047\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3140 - output_1_loss: 0.3140 - val_loss: 0.3905 - val_output_1_loss: 0.3904\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.3416 - output_1_loss: 0.3415 - val_loss: 0.3702 - val_output_1_loss: 0.3702\n",
      "Epoch 5/100\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3538 - output_1_loss: 0.3538 - val_loss: 0.3611 - val_output_1_loss: 0.3610\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.6479 - output_1_loss: 0.6479 - val_loss: 0.6825 - val_output_1_loss: 0.6823\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3333 - output_1_loss: 0.3333 - val_loss: 0.3479 - val_output_1_loss: 0.3478\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6847 - output_1_loss: 0.6846 - val_loss: 0.6787 - val_output_1_loss: 0.6786\n",
      "Epoch 7/100\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3424 - output_1_loss: 0.3423 - val_loss: 0.3422 - val_output_1_loss: 0.3421\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.6614 - output_1_loss: 0.6614 - val_loss: 0.6753 - val_output_1_loss: 0.6752\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.3182 - output_1_loss: 0.3182 - val_loss: 0.3336 - val_output_1_loss: 0.3336\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.6399 - output_1_loss: 0.6399 - val_loss: 0.6701 - val_output_1_loss: 0.6699\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3495 - output_1_loss: 0.3494 - val_loss: 0.3340 - val_output_1_loss: 0.3340\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.6606 - output_1_loss: 0.6605 - val_loss: 0.6691 - val_output_1_loss: 0.6690\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.6435 - output_1_loss: 0.6434 - val_loss: 0.6655 - val_output_1_loss: 0.6654\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6219 - output_1_loss: 0.6219 - val_loss: 0.6623 - val_output_1_loss: 0.6622\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6228 - output_1_loss: 0.6228 - val_loss: 0.6580 - val_output_1_loss: 0.6579\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:27:13,967]\u001b[0m Trial 68 finished with value: 0.07692307692307693 and parameters: {'feature_dim': 32, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 2.2, 'sparsity_coefficient': 3.990899806921439e-05, 'bn_momentum': 0.9640359972194441}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 503ms/step - loss: 0.6105 - output_1_loss: 0.6104 - val_loss: 0.6545 - val_output_1_loss: 0.6544\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5941 - output_1_loss: 0.5941Epoch 1/100\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.5941 - output_1_loss: 0.5941 - val_loss: 0.6493 - val_output_1_loss: 0.6491\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.5969 - output_1_loss: 0.5968 - val_loss: 0.6460 - val_output_1_loss: 0.6459\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.5819 - output_1_loss: 0.5818 - val_loss: 0.6430 - val_output_1_loss: 0.6428\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6013 - output_1_loss: 0.6012 - val_loss: 0.6395 - val_output_1_loss: 0.6394\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5904 - output_1_loss: 0.5904 - val_loss: 0.6354 - val_output_1_loss: 0.6353\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.5970 - output_1_loss: 0.5969 - val_loss: 0.6326 - val_output_1_loss: 0.6325\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.6119 - output_1_loss: 0.6118 - val_loss: 0.6291 - val_output_1_loss: 0.6289\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.6285 - output_1_loss: 0.6284 - val_loss: 0.6267 - val_output_1_loss: 0.6266\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.5353 - output_1_loss: 0.5353 - val_loss: 0.6226 - val_output_1_loss: 0.6225\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.5780 - output_1_loss: 0.5779 - val_loss: 0.6187 - val_output_1_loss: 0.6185\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.5939 - output_1_loss: 0.5938 - val_loss: 0.6158 - val_output_1_loss: 0.6157\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.5304 - output_1_loss: 0.5304 - val_loss: 0.6149 - val_output_1_loss: 0.6148\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.5198 - output_1_loss: 0.5197 - val_loss: 0.6114 - val_output_1_loss: 0.6113\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.5401 - output_1_loss: 0.5400 - val_loss: 0.6064 - val_output_1_loss: 0.6063\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.5198 - output_1_loss: 0.5198 - val_loss: 0.6017 - val_output_1_loss: 0.6016\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.5194 - output_1_loss: 0.5194 - val_loss: 0.5988 - val_output_1_loss: 0.5987\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.5378 - output_1_loss: 0.5378 - val_loss: 0.5986 - val_output_1_loss: 0.5985\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.5200 - output_1_loss: 0.5199 - val_loss: 0.5948 - val_output_1_loss: 0.5947\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.4891 - output_1_loss: 0.4891 - val_loss: 0.5876 - val_output_1_loss: 0.5875\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.5219 - output_1_loss: 0.5218 - val_loss: 0.5837 - val_output_1_loss: 0.5836\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.4790 - output_1_loss: 0.4789 - val_loss: 0.5753 - val_output_1_loss: 0.5752\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5060 - output_1_loss: 0.5060 - val_loss: 0.5718 - val_output_1_loss: 0.5718\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.4679 - output_1_loss: 0.4678 - val_loss: 0.5651 - val_output_1_loss: 0.5650\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.4796 - output_1_loss: 0.4796 - val_loss: 0.5596 - val_output_1_loss: 0.5596\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4919 - output_1_loss: 0.4918 - val_loss: 0.5598 - val_output_1_loss: 0.5597\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.5125 - output_1_loss: 0.5124 - val_loss: 0.5562 - val_output_1_loss: 0.5561\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.4914 - output_1_loss: 0.4913 - val_loss: 0.5528 - val_output_1_loss: 0.5527\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.4733 - output_1_loss: 0.4732 - val_loss: 0.5440 - val_output_1_loss: 0.5439\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.4784 - output_1_loss: 0.4784 - val_loss: 0.5393 - val_output_1_loss: 0.5392\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.4303 - output_1_loss: 0.4302 - val_loss: 0.5215 - val_output_1_loss: 0.5215\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 0.4255 - output_1_loss: 0.4254 - val_loss: 0.5088 - val_output_1_loss: 0.5087\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.4463 - output_1_loss: 0.4463 - val_loss: 0.5020 - val_output_1_loss: 0.5019\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.4424 - output_1_loss: 0.4423 - val_loss: 0.4987 - val_output_1_loss: 0.4986\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.4212 - output_1_loss: 0.4212 - val_loss: 0.4954 - val_output_1_loss: 0.4953\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4202 - output_1_loss: 0.4201 - val_loss: 0.4808 - val_output_1_loss: 0.4808\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3831 - output_1_loss: 0.3830 - val_loss: 0.4757 - val_output_1_loss: 0.4756\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3952 - output_1_loss: 0.3952 - val_loss: 0.4682 - val_output_1_loss: 0.4681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3903 - output_1_loss: 0.3903 - val_loss: 0.4574 - val_output_1_loss: 0.4573\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3836 - output_1_loss: 0.3835 - val_loss: 0.4400 - val_output_1_loss: 0.4400\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.4112 - output_1_loss: 0.4111 - val_loss: 0.4460 - val_output_1_loss: 0.4459\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4263 - output_1_loss: 0.4263 - val_loss: 0.4422 - val_output_1_loss: 0.4422\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3729 - output_1_loss: 0.3729 - val_loss: 0.4320 - val_output_1_loss: 0.4319\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.3702 - output_1_loss: 0.3701 - val_loss: 0.4139 - val_output_1_loss: 0.4138\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3668 - output_1_loss: 0.3668 - val_loss: 0.4053 - val_output_1_loss: 0.4052\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3432 - output_1_loss: 0.3432 - val_loss: 0.4075 - val_output_1_loss: 0.4074\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3368 - output_1_loss: 0.3367 - val_loss: 0.3909 - val_output_1_loss: 0.3909\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3172 - output_1_loss: 0.3172 - val_loss: 0.3900 - val_output_1_loss: 0.3899\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.3639 - output_1_loss: 0.3639 - val_loss: 0.3666 - val_output_1_loss: 0.3666\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3705 - output_1_loss: 0.3704 - val_loss: 0.3817 - val_output_1_loss: 0.3817\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3162 - output_1_loss: 0.3161 - val_loss: 0.3503 - val_output_1_loss: 0.3502\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3124 - output_1_loss: 0.3124 - val_loss: 0.3383 - val_output_1_loss: 0.3382\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2661 - output_1_loss: 0.2660 - val_loss: 0.3404 - val_output_1_loss: 0.3404\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7982 - output_1_loss: 0.7982Epoch 66/100\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2908 - output_1_loss: 0.2908 - val_loss: 0.3090 - val_output_1_loss: 0.3089\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3280 - output_1_loss: 0.3280 - val_loss: 0.3154 - val_output_1_loss: 0.3154\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2827 - output_1_loss: 0.2827 - val_loss: 0.3349 - val_output_1_loss: 0.3349\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3244 - output_1_loss: 0.3243 - val_loss: 0.3192 - val_output_1_loss: 0.3191\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3371 - output_1_loss: 0.3371 - val_loss: 0.3105 - val_output_1_loss: 0.3105\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.3397 - output_1_loss: 0.3397 - val_loss: 0.3049 - val_output_1_loss: 0.3049\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.3294 - output_1_loss: 0.3294 - val_loss: 0.2990 - val_output_1_loss: 0.2990\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3003 - output_1_loss: 0.3003 - val_loss: 0.3075 - val_output_1_loss: 0.3075\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3085 - output_1_loss: 0.3085 - val_loss: 0.3004 - val_output_1_loss: 0.3003\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.2667 - output_1_loss: 0.2666 - val_loss: 0.2870 - val_output_1_loss: 0.2869\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2594 - output_1_loss: 0.2593 - val_loss: 0.2552 - val_output_1_loss: 0.2551\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2957 - output_1_loss: 0.2956 - val_loss: 0.2618 - val_output_1_loss: 0.2617\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.7982 - output_1_loss: 0.7982 - val_loss: 0.6846 - val_output_1_loss: 0.6846\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2848 - output_1_loss: 0.2847 - val_loss: 0.2392 - val_output_1_loss: 0.2392\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2591 - output_1_loss: 0.2590 - val_loss: 0.2468 - val_output_1_loss: 0.2468\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2390 - output_1_loss: 0.2390 - val_loss: 0.2457 - val_output_1_loss: 0.2457\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3317 - output_1_loss: 0.3317 - val_loss: 0.2397 - val_output_1_loss: 0.2397\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2240 - output_1_loss: 0.2240 - val_loss: 0.2383 - val_output_1_loss: 0.2382\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2567 - output_1_loss: 0.2566 - val_loss: 0.2190 - val_output_1_loss: 0.2189\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2516 - output_1_loss: 0.2515 - val_loss: 0.1976 - val_output_1_loss: 0.1976\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2612 - output_1_loss: 0.2611 - val_loss: 0.1941 - val_output_1_loss: 0.1940\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2597 - output_1_loss: 0.2596 - val_loss: 0.2180 - val_output_1_loss: 0.2179\n",
      "Epoch 2/100\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2361 - output_1_loss: 0.2360 - val_loss: 0.2162 - val_output_1_loss: 0.2161\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.6913 - output_1_loss: 0.6913 - val_loss: 0.6753 - val_output_1_loss: 0.6753\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2365 - output_1_loss: 0.2365 - val_loss: 0.2057 - val_output_1_loss: 0.2056\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3081 - output_1_loss: 0.3080 - val_loss: 0.2142 - val_output_1_loss: 0.2141\n",
      "Epoch 90/100\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.2027 - output_1_loss: 0.2027 - val_loss: 0.1998 - val_output_1_loss: 0.1997\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.6432 - output_1_loss: 0.6432 - val_loss: 0.6657 - val_output_1_loss: 0.6657\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.6617 - output_1_loss: 0.6617 - val_loss: 0.6575 - val_output_1_loss: 0.6575\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.5353 - output_1_loss: 0.5353 - val_loss: 0.6462 - val_output_1_loss: 0.6462\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.4652 - output_1_loss: 0.4652 - val_loss: 0.6310 - val_output_1_loss: 0.6310\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.3746 - output_1_loss: 0.3746 - val_loss: 0.6176 - val_output_1_loss: 0.6176\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:27:45,921]\u001b[0m Trial 69 finished with value: 0.1111111111111111 and parameters: {'feature_dim': 32, 'n_step': 7, 'n_shared': 3, 'relaxation_factor': 1.2, 'sparsity_coefficient': 2.8448046722926952e-05, 'bn_momentum': 0.9039025042431633}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.4603 - output_1_loss: 0.4603 - val_loss: 0.6053 - val_output_1_loss: 0.6053\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.3933 - output_1_loss: 0.3933 - val_loss: 0.5882 - val_output_1_loss: 0.5882\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3315 - output_1_loss: 0.3315Epoch 1/100\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.3315 - output_1_loss: 0.3315 - val_loss: 0.5674 - val_output_1_loss: 0.5674\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.3583 - output_1_loss: 0.3583 - val_loss: 0.5527 - val_output_1_loss: 0.5527\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2647 - output_1_loss: 0.2647 - val_loss: 0.5364 - val_output_1_loss: 0.5364\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.3569 - output_1_loss: 0.3569 - val_loss: 0.5197 - val_output_1_loss: 0.5197\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.2627 - output_1_loss: 0.2627 - val_loss: 0.4945 - val_output_1_loss: 0.4945\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.2078 - output_1_loss: 0.2078 - val_loss: 0.4699 - val_output_1_loss: 0.4699\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.2614 - output_1_loss: 0.2614 - val_loss: 0.4553 - val_output_1_loss: 0.4553\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.3715 - output_1_loss: 0.3715 - val_loss: 0.4432 - val_output_1_loss: 0.4432\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2055 - output_1_loss: 0.2055 - val_loss: 0.4182 - val_output_1_loss: 0.4182\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2767 - output_1_loss: 0.2767 - val_loss: 0.4094 - val_output_1_loss: 0.4094\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.1524 - output_1_loss: 0.1524 - val_loss: 0.3811 - val_output_1_loss: 0.3811\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.1912 - output_1_loss: 0.1912 - val_loss: 0.3606 - val_output_1_loss: 0.3606\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.1533 - output_1_loss: 0.1533 - val_loss: 0.3383 - val_output_1_loss: 0.3383\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.1919 - output_1_loss: 0.1919 - val_loss: 0.3268 - val_output_1_loss: 0.3268\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.1652 - output_1_loss: 0.1652 - val_loss: 0.3076 - val_output_1_loss: 0.3076\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.1985 - output_1_loss: 0.1985 - val_loss: 0.2935 - val_output_1_loss: 0.2935\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1594 - output_1_loss: 0.1594 - val_loss: 0.2861 - val_output_1_loss: 0.2861\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.1395 - output_1_loss: 0.1395 - val_loss: 0.2717 - val_output_1_loss: 0.2717\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.1819 - output_1_loss: 0.1819 - val_loss: 0.2508 - val_output_1_loss: 0.2508\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.1882 - output_1_loss: 0.1882 - val_loss: 0.2298 - val_output_1_loss: 0.2298\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.1502 - output_1_loss: 0.1502 - val_loss: 0.2162 - val_output_1_loss: 0.2162\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.0859 - output_1_loss: 0.0859 - val_loss: 0.1875 - val_output_1_loss: 0.1875\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.0946 - output_1_loss: 0.0946 - val_loss: 0.1518 - val_output_1_loss: 0.1518\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.1119 - output_1_loss: 0.1119 - val_loss: 0.1488 - val_output_1_loss: 0.1488\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.1023 - output_1_loss: 0.1023 - val_loss: 0.1334 - val_output_1_loss: 0.1334\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.0943 - output_1_loss: 0.0943 - val_loss: 0.1275 - val_output_1_loss: 0.1275\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.0979 - output_1_loss: 0.0979 - val_loss: 0.1180 - val_output_1_loss: 0.1180\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.0911 - output_1_loss: 0.0911 - val_loss: 0.1083 - val_output_1_loss: 0.1083\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.1173 - output_1_loss: 0.1173 - val_loss: 0.0949 - val_output_1_loss: 0.0949\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.1293 - output_1_loss: 0.1293 - val_loss: 0.0852 - val_output_1_loss: 0.0852\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.0889 - output_1_loss: 0.0889 - val_loss: 0.0898 - val_output_1_loss: 0.0898\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1058 - output_1_loss: 0.1058 - val_loss: 0.0923 - val_output_1_loss: 0.0923\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.0877 - output_1_loss: 0.0877 - val_loss: 0.0831 - val_output_1_loss: 0.0831\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1191 - output_1_loss: 0.1191 - val_loss: 0.0848 - val_output_1_loss: 0.0848\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0832 - output_1_loss: 0.0832 - val_loss: 0.0937 - val_output_1_loss: 0.0937\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0795 - output_1_loss: 0.0795 - val_loss: 0.0864 - val_output_1_loss: 0.0864\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1250 - output_1_loss: 0.1250 - val_loss: 0.0945 - val_output_1_loss: 0.0945\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0956 - output_1_loss: 0.0956 - val_loss: 0.0703 - val_output_1_loss: 0.0703\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0800 - output_1_loss: 0.0800 - val_loss: 0.0700 - val_output_1_loss: 0.0700\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2014 - output_1_loss: 0.2014 - val_loss: 0.0739 - val_output_1_loss: 0.0739\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0837 - output_1_loss: 0.0837 - val_loss: 0.0743 - val_output_1_loss: 0.0743\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0785 - output_1_loss: 0.0785 - val_loss: 0.0774 - val_output_1_loss: 0.0774\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1110 - output_1_loss: 0.1110 - val_loss: 0.0776 - val_output_1_loss: 0.0776\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0867 - output_1_loss: 0.0867 - val_loss: 0.0706 - val_output_1_loss: 0.0706\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:28:09,025]\u001b[0m Trial 70 finished with value: 0.058823529411764705 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 1, 'relaxation_factor': 1.2, 'sparsity_coefficient': 1.2007412978766646e-08, 'bn_momentum': 0.9005075239349811}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.7233 - output_1_loss: 0.7233 - val_loss: 0.6852 - val_output_1_loss: 0.6852\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.6893 - output_1_loss: 0.6893 - val_loss: 0.6771 - val_output_1_loss: 0.6771\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.5966 - output_1_loss: 0.5966 - val_loss: 0.6696 - val_output_1_loss: 0.6696\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.5204 - output_1_loss: 0.5204 - val_loss: 0.6578 - val_output_1_loss: 0.6578\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.5485 - output_1_loss: 0.5485 - val_loss: 0.6481 - val_output_1_loss: 0.6481\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.4711 - output_1_loss: 0.4711 - val_loss: 0.6403 - val_output_1_loss: 0.6403\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.4582 - output_1_loss: 0.4582 - val_loss: 0.6309 - val_output_1_loss: 0.6309\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.5828 - output_1_loss: 0.5828 - val_loss: 0.6189 - val_output_1_loss: 0.6189\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.3779 - output_1_loss: 0.3779 - val_loss: 0.6109 - val_output_1_loss: 0.6109\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.4631 - output_1_loss: 0.4631 - val_loss: 0.6001 - val_output_1_loss: 0.6001\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.3590 - output_1_loss: 0.3590 - val_loss: 0.5882 - val_output_1_loss: 0.5882\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3509 - output_1_loss: 0.3509 - val_loss: 0.5741 - val_output_1_loss: 0.5741\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.3450 - output_1_loss: 0.3450 - val_loss: 0.5594 - val_output_1_loss: 0.5594\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.4353 - output_1_loss: 0.4353 - val_loss: 0.5483 - val_output_1_loss: 0.5483\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.3143 - output_1_loss: 0.3143 - val_loss: 0.5357 - val_output_1_loss: 0.5357\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.2684 - output_1_loss: 0.2684 - val_loss: 0.5128 - val_output_1_loss: 0.5128\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.2643 - output_1_loss: 0.2643 - val_loss: 0.4959 - val_output_1_loss: 0.4959\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.2849 - output_1_loss: 0.2849 - val_loss: 0.4838 - val_output_1_loss: 0.4838\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2071 - output_1_loss: 0.2071 - val_loss: 0.4689 - val_output_1_loss: 0.4689\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2330 - output_1_loss: 0.2330 - val_loss: 0.4570 - val_output_1_loss: 0.4570\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2802 - output_1_loss: 0.2802 - val_loss: 0.4446 - val_output_1_loss: 0.4446\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.2611 - output_1_loss: 0.2611 - val_loss: 0.4272 - val_output_1_loss: 0.4272\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2898 - output_1_loss: 0.2898 - val_loss: 0.4151 - val_output_1_loss: 0.4151\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2114 - output_1_loss: 0.2114 - val_loss: 0.3857 - val_output_1_loss: 0.3857\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.1977 - output_1_loss: 0.1977 - val_loss: 0.3621 - val_output_1_loss: 0.3621\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.1876 - output_1_loss: 0.1876 - val_loss: 0.3490 - val_output_1_loss: 0.3490\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.1503 - output_1_loss: 0.1503 - val_loss: 0.3261 - val_output_1_loss: 0.3261\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.2155 - output_1_loss: 0.2155 - val_loss: 0.3126 - val_output_1_loss: 0.3126\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1468 - output_1_loss: 0.1468 - val_loss: 0.2905 - val_output_1_loss: 0.2905\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.1402 - output_1_loss: 0.1402 - val_loss: 0.2687 - val_output_1_loss: 0.2687\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.2684 - output_1_loss: 0.2684 - val_loss: 0.2703 - val_output_1_loss: 0.2703\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1540 - output_1_loss: 0.1540 - val_loss: 0.2545 - val_output_1_loss: 0.2545\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.2404 - output_1_loss: 0.2404 - val_loss: 0.2217 - val_output_1_loss: 0.2217\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2094 - output_1_loss: 0.2094 - val_loss: 0.2192 - val_output_1_loss: 0.2192\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.1144 - output_1_loss: 0.1144 - val_loss: 0.2115 - val_output_1_loss: 0.2115\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1233 - output_1_loss: 0.1233 - val_loss: 0.2063 - val_output_1_loss: 0.2063\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.1087 - output_1_loss: 0.1087 - val_loss: 0.1896 - val_output_1_loss: 0.1896\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1323 - output_1_loss: 0.1323 - val_loss: 0.1844 - val_output_1_loss: 0.1844\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1800 - output_1_loss: 0.1800 - val_loss: 0.1770 - val_output_1_loss: 0.1770\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1656 - output_1_loss: 0.1656 - val_loss: 0.1749 - val_output_1_loss: 0.1749\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1974 - output_1_loss: 0.1974 - val_loss: 0.1753 - val_output_1_loss: 0.1753\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0917 - output_1_loss: 0.0917 - val_loss: 0.1690 - val_output_1_loss: 0.1690\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1176 - output_1_loss: 0.1176 - val_loss: 0.1581 - val_output_1_loss: 0.1581\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1461 - output_1_loss: 0.1461 - val_loss: 0.1528 - val_output_1_loss: 0.1528\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1361 - output_1_loss: 0.1361 - val_loss: 0.1524 - val_output_1_loss: 0.1524\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1181 - output_1_loss: 0.1181 - val_loss: 0.1463 - val_output_1_loss: 0.1463\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1154 - output_1_loss: 0.1154 - val_loss: 0.1381 - val_output_1_loss: 0.1381\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1692 - output_1_loss: 0.1692 - val_loss: 0.1414 - val_output_1_loss: 0.1414\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1026 - output_1_loss: 0.1026 - val_loss: 0.1358 - val_output_1_loss: 0.1358\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1242 - output_1_loss: 0.1242 - val_loss: 0.1263 - val_output_1_loss: 0.1263\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1582 - output_1_loss: 0.1582 - val_loss: 0.1183 - val_output_1_loss: 0.1183\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.1392 - output_1_loss: 0.1392 - val_loss: 0.1150 - val_output_1_loss: 0.1150\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1556 - output_1_loss: 0.1556 - val_loss: 0.1174 - val_output_1_loss: 0.1174\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.0929 - output_1_loss: 0.0929 - val_loss: 0.1084 - val_output_1_loss: 0.1084\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.1259 - output_1_loss: 0.1259 - val_loss: 0.1039 - val_output_1_loss: 0.1039\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1642 - output_1_loss: 0.1642 - val_loss: 0.0955 - val_output_1_loss: 0.0955\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.1086 - output_1_loss: 0.1086 - val_loss: 0.0924 - val_output_1_loss: 0.0924\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1235 - output_1_loss: 0.1235 - val_loss: 0.0874 - val_output_1_loss: 0.0874\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0997 - output_1_loss: 0.0997 - val_loss: 0.0845 - val_output_1_loss: 0.0845\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.1080 - output_1_loss: 0.1080 - val_loss: 0.0805 - val_output_1_loss: 0.0805\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 31s 31s/step - loss: 0.9122 - output_1_loss: 0.8957 - val_loss: 0.7509 - val_output_1_loss: 0.6859\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1304 - output_1_loss: 0.1304 - val_loss: 0.0790 - val_output_1_loss: 0.0790\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0810 - output_1_loss: 0.0810 - val_loss: 0.0769 - val_output_1_loss: 0.0769\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1217 - output_1_loss: 0.1217 - val_loss: 0.0746 - val_output_1_loss: 0.0746\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0868 - output_1_loss: 0.0868Epoch 2/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0868 - output_1_loss: 0.0868 - val_loss: 0.0710 - val_output_1_loss: 0.0710\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.8071 - output_1_loss: 0.7906 - val_loss: 0.7394 - val_output_1_loss: 0.6782\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.1101 - output_1_loss: 0.1101 - val_loss: 0.0675 - val_output_1_loss: 0.0675\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1992 - output_1_loss: 0.1992 - val_loss: 0.0706 - val_output_1_loss: 0.0706\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.7334 - output_1_loss: 0.7171 - val_loss: 0.7278 - val_output_1_loss: 0.6708\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1610 - output_1_loss: 0.1610Epoch 4/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1610 - output_1_loss: 0.1610 - val_loss: 0.0699 - val_output_1_loss: 0.0699\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0929 - output_1_loss: 0.0929 - val_loss: 0.0698 - val_output_1_loss: 0.0698\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.7783 - output_1_loss: 0.7615 - val_loss: 0.7175 - val_output_1_loss: 0.6629\n",
      "Epoch 5/100\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0807 - output_1_loss: 0.0807 - val_loss: 0.0676 - val_output_1_loss: 0.0676\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.6424 - output_1_loss: 0.6262 - val_loss: 0.7084 - val_output_1_loss: 0.6556\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1157 - output_1_loss: 0.1157 - val_loss: 0.0670 - val_output_1_loss: 0.0670\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.6306 - output_1_loss: 0.6143 - val_loss: 0.6987 - val_output_1_loss: 0.6480\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0885 - output_1_loss: 0.0885 - val_loss: 0.0657 - val_output_1_loss: 0.0657\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1302 - output_1_loss: 0.1302Epoch 7/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1302 - output_1_loss: 0.1302 - val_loss: 0.0655 - val_output_1_loss: 0.0655\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.5446 - output_1_loss: 0.5285 - val_loss: 0.6897 - val_output_1_loss: 0.6407\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0883 - output_1_loss: 0.0883 - val_loss: 0.0648 - val_output_1_loss: 0.0648\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.5387 - output_1_loss: 0.5233 - val_loss: 0.6815 - val_output_1_loss: 0.6336\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5536 - output_1_loss: 0.5374Epoch 74/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5536 - output_1_loss: 0.5374 - val_loss: 0.6726 - val_output_1_loss: 0.6256\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0952 - output_1_loss: 0.0952 - val_loss: 0.0650 - val_output_1_loss: 0.0650\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0964 - output_1_loss: 0.0964 - val_loss: 0.0654 - val_output_1_loss: 0.0654\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1029 - output_1_loss: 0.1029 - val_loss: 0.0693 - val_output_1_loss: 0.0693\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.5115 - output_1_loss: 0.4959 - val_loss: 0.6629 - val_output_1_loss: 0.6176\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0911 - output_1_loss: 0.0911 - val_loss: 0.0716 - val_output_1_loss: 0.0716\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0979 - output_1_loss: 0.0979 - val_loss: 0.0662 - val_output_1_loss: 0.0662\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.4581 - output_1_loss: 0.4433 - val_loss: 0.6539 - val_output_1_loss: 0.6087\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.4813 - output_1_loss: 0.4658 - val_loss: 0.6442 - val_output_1_loss: 0.5995\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.4308 - output_1_loss: 0.4166 - val_loss: 0.6348 - val_output_1_loss: 0.5911\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4911 - output_1_loss: 0.4761 - val_loss: 0.6271 - val_output_1_loss: 0.5839\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3887 - output_1_loss: 0.3744 - val_loss: 0.6172 - val_output_1_loss: 0.5751\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3407 - output_1_loss: 0.3252 - val_loss: 0.6090 - val_output_1_loss: 0.5671\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3179 - output_1_loss: 0.3039 - val_loss: 0.6002 - val_output_1_loss: 0.5589\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:28:49,689]\u001b[0m Trial 71 finished with value: 0.05555555555555555 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 1, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 2.5042579804129487e-08, 'bn_momentum': 0.9478165971374257}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3183 - output_1_loss: 0.3039 - val_loss: 0.5902 - val_output_1_loss: 0.5493\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2894 - output_1_loss: 0.2754Epoch 1/100\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2894 - output_1_loss: 0.2754 - val_loss: 0.5777 - val_output_1_loss: 0.5377\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3906 - output_1_loss: 0.3779 - val_loss: 0.5682 - val_output_1_loss: 0.5291\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.2782 - output_1_loss: 0.2658 - val_loss: 0.5572 - val_output_1_loss: 0.5190\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2764 - output_1_loss: 0.2632 - val_loss: 0.5467 - val_output_1_loss: 0.5097\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.2044 - output_1_loss: 0.1912 - val_loss: 0.5351 - val_output_1_loss: 0.4986\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.2686 - output_1_loss: 0.2546 - val_loss: 0.5257 - val_output_1_loss: 0.4894\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.1943 - output_1_loss: 0.1808 - val_loss: 0.5139 - val_output_1_loss: 0.4779\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.1653 - output_1_loss: 0.1528 - val_loss: 0.4997 - val_output_1_loss: 0.4652\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.2441 - output_1_loss: 0.2304 - val_loss: 0.4893 - val_output_1_loss: 0.4555\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.1865 - output_1_loss: 0.1734 - val_loss: 0.4774 - val_output_1_loss: 0.4447\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.1532 - output_1_loss: 0.1405 - val_loss: 0.4664 - val_output_1_loss: 0.4335\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.1540 - output_1_loss: 0.1408 - val_loss: 0.4541 - val_output_1_loss: 0.4212\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.2251 - output_1_loss: 0.2108 - val_loss: 0.4441 - val_output_1_loss: 0.4118\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.1624 - output_1_loss: 0.1500 - val_loss: 0.4335 - val_output_1_loss: 0.4009\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.1431 - output_1_loss: 0.1297 - val_loss: 0.4215 - val_output_1_loss: 0.3899\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.1167 - output_1_loss: 0.1040 - val_loss: 0.4090 - val_output_1_loss: 0.3769\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.1579 - output_1_loss: 0.1458 - val_loss: 0.3950 - val_output_1_loss: 0.3630\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.1186 - output_1_loss: 0.1066 - val_loss: 0.3849 - val_output_1_loss: 0.3534\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.1453 - output_1_loss: 0.1332 - val_loss: 0.3704 - val_output_1_loss: 0.3393\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.1136 - output_1_loss: 0.1006 - val_loss: 0.3605 - val_output_1_loss: 0.3295\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.1313 - output_1_loss: 0.1183 - val_loss: 0.3463 - val_output_1_loss: 0.3152\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 0.1239 - output_1_loss: 0.1121 - val_loss: 0.3327 - val_output_1_loss: 0.3017\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1731 - output_1_loss: 0.1619 - val_loss: 0.3212 - val_output_1_loss: 0.2903\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1696 - output_1_loss: 0.1583 - val_loss: 0.3158 - val_output_1_loss: 0.2854\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1108 - output_1_loss: 0.0983 - val_loss: 0.2988 - val_output_1_loss: 0.2687\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1401 - output_1_loss: 0.1256 - val_loss: 0.2915 - val_output_1_loss: 0.2611\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0995 - output_1_loss: 0.0881 - val_loss: 0.2811 - val_output_1_loss: 0.2515\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.1113 - output_1_loss: 0.1013 - val_loss: 0.2757 - val_output_1_loss: 0.2466\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.1103 - output_1_loss: 0.0994 - val_loss: 0.2598 - val_output_1_loss: 0.2308\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.1412 - output_1_loss: 0.1292 - val_loss: 0.2544 - val_output_1_loss: 0.2254\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1317 - output_1_loss: 0.1200 - val_loss: 0.2436 - val_output_1_loss: 0.2145\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2767 - output_1_loss: 0.2655 - val_loss: 0.2412 - val_output_1_loss: 0.2121\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1491 - output_1_loss: 0.1385 - val_loss: 0.2330 - val_output_1_loss: 0.2045\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1041 - output_1_loss: 0.0938 - val_loss: 0.2270 - val_output_1_loss: 0.1991\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1799 - output_1_loss: 0.1685 - val_loss: 0.2238 - val_output_1_loss: 0.1962\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6840 - output_1_loss: 0.6836Epoch 54/100\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.1522 - output_1_loss: 0.1410 - val_loss: 0.2149 - val_output_1_loss: 0.1873\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.1210 - output_1_loss: 0.1103 - val_loss: 0.2120 - val_output_1_loss: 0.1838\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0985 - output_1_loss: 0.0872 - val_loss: 0.2073 - val_output_1_loss: 0.1792\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1581 - output_1_loss: 0.1457 - val_loss: 0.2004 - val_output_1_loss: 0.1726\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 19s 19s/step - loss: 0.6840 - output_1_loss: 0.6836 - val_loss: 0.6908 - val_output_1_loss: 0.6891\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.1377 - output_1_loss: 0.1256 - val_loss: 0.1869 - val_output_1_loss: 0.1598\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1679 - output_1_loss: 0.1566Epoch 2/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1679 - output_1_loss: 0.1566 - val_loss: 0.1848 - val_output_1_loss: 0.1579\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6686 - output_1_loss: 0.6681 - val_loss: 0.6864 - val_output_1_loss: 0.6847\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6525 - output_1_loss: 0.6521 - val_loss: 0.6825 - val_output_1_loss: 0.6809\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.1257 - output_1_loss: 0.1138 - val_loss: 0.1781 - val_output_1_loss: 0.1514\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6529 - output_1_loss: 0.6524Epoch 61/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.6529 - output_1_loss: 0.6524 - val_loss: 0.6775 - val_output_1_loss: 0.6761\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6448 - output_1_loss: 0.6443 - val_loss: 0.6748 - val_output_1_loss: 0.6734\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.1831 - output_1_loss: 0.1711 - val_loss: 0.1719 - val_output_1_loss: 0.1450\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6293 - output_1_loss: 0.6289 - val_loss: 0.6707 - val_output_1_loss: 0.6693\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1062 - output_1_loss: 0.0939Epoch 7/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.1062 - output_1_loss: 0.0939 - val_loss: 0.1664 - val_output_1_loss: 0.1396\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6450 - output_1_loss: 0.6445 - val_loss: 0.6664 - val_output_1_loss: 0.6650\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1264 - output_1_loss: 0.1148 - val_loss: 0.1605 - val_output_1_loss: 0.1335\n",
      "Epoch 8/100\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5748 - output_1_loss: 0.5743 - val_loss: 0.6619 - val_output_1_loss: 0.6606\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.1294 - output_1_loss: 0.1192 - val_loss: 0.1522 - val_output_1_loss: 0.1255\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5720 - output_1_loss: 0.5716 - val_loss: 0.6601 - val_output_1_loss: 0.6589\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1043 - output_1_loss: 0.0936Epoch 10/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1043 - output_1_loss: 0.0936 - val_loss: 0.1483 - val_output_1_loss: 0.1216\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.5269 - output_1_loss: 0.5264 - val_loss: 0.6548 - val_output_1_loss: 0.6536\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.5550 - output_1_loss: 0.5546 - val_loss: 0.6503 - val_output_1_loss: 0.6491\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.1464 - output_1_loss: 0.1353 - val_loss: 0.1470 - val_output_1_loss: 0.1208\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.5552 - output_1_loss: 0.5547 - val_loss: 0.6464 - val_output_1_loss: 0.6452\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5802 - output_1_loss: 0.5797 - val_loss: 0.6410 - val_output_1_loss: 0.6398\n",
      "Epoch 14/100\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5639 - output_1_loss: 0.5634 - val_loss: 0.6367 - val_output_1_loss: 0.6356\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1642 - output_1_loss: 0.1533Epoch 15/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1642 - output_1_loss: 0.1533 - val_loss: 0.1448 - val_output_1_loss: 0.1191\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.4933 - output_1_loss: 0.4929 - val_loss: 0.6335 - val_output_1_loss: 0.6324\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1941 - output_1_loss: 0.1830 - val_loss: 0.1458 - val_output_1_loss: 0.1205\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.5268 - output_1_loss: 0.5264 - val_loss: 0.6300 - val_output_1_loss: 0.6289\n",
      "Epoch 17/100\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4913 - output_1_loss: 0.4908 - val_loss: 0.6257 - val_output_1_loss: 0.6246\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0991 - output_1_loss: 0.0892 - val_loss: 0.1437 - val_output_1_loss: 0.1183\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.5115 - output_1_loss: 0.5111 - val_loss: 0.6196 - val_output_1_loss: 0.6185\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.5320 - output_1_loss: 0.5316 - val_loss: 0.6148 - val_output_1_loss: 0.6138\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4698 - output_1_loss: 0.4693Epoch 70/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.4698 - output_1_loss: 0.4693 - val_loss: 0.6096 - val_output_1_loss: 0.6086\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4349 - output_1_loss: 0.4345 - val_loss: 0.6020 - val_output_1_loss: 0.6010\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1057 - output_1_loss: 0.0950 - val_loss: 0.1419 - val_output_1_loss: 0.1164\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1261 - output_1_loss: 0.1158Epoch 22/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1261 - output_1_loss: 0.1158 - val_loss: 0.1365 - val_output_1_loss: 0.1114\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4266 - output_1_loss: 0.4261 - val_loss: 0.5958 - val_output_1_loss: 0.5949\n",
      "Epoch 23/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4317 - output_1_loss: 0.4312 - val_loss: 0.5890 - val_output_1_loss: 0.5881\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4495 - output_1_loss: 0.4490 - val_loss: 0.5824 - val_output_1_loss: 0.5815\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.1072 - output_1_loss: 0.0939 - val_loss: 0.1341 - val_output_1_loss: 0.1088\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4366 - output_1_loss: 0.4362 - val_loss: 0.5772 - val_output_1_loss: 0.5763\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1020 - output_1_loss: 0.0886Epoch 26/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.3215 - output_1_loss: 0.3211 - val_loss: 0.5654 - val_output_1_loss: 0.5646\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1020 - output_1_loss: 0.0886 - val_loss: 0.1314 - val_output_1_loss: 0.1063\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3693 - output_1_loss: 0.3689 - val_loss: 0.5563 - val_output_1_loss: 0.5555\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3407 - output_1_loss: 0.3403 - val_loss: 0.5481 - val_output_1_loss: 0.5473\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1172 - output_1_loss: 0.1040 - val_loss: 0.1296 - val_output_1_loss: 0.1052\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2365 - output_1_loss: 0.2360 - val_loss: 0.5330 - val_output_1_loss: 0.5322\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3089 - output_1_loss: 0.3084 - val_loss: 0.5200 - val_output_1_loss: 0.5193\n",
      "Epoch 75/100\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3348 - output_1_loss: 0.3344 - val_loss: 0.5114 - val_output_1_loss: 0.5107\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.1151 - output_1_loss: 0.1028 - val_loss: 0.1276 - val_output_1_loss: 0.1036\n",
      "Epoch 76/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3616 - output_1_loss: 0.3612 - val_loss: 0.5071 - val_output_1_loss: 0.5063\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.1563 - output_1_loss: 0.1445 - val_loss: 0.1261 - val_output_1_loss: 0.1020\n",
      "Epoch 77/100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.2836 - output_1_loss: 0.2833 - val_loss: 0.4976 - val_output_1_loss: 0.4969\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.1300 - output_1_loss: 0.1166 - val_loss: 0.1238 - val_output_1_loss: 0.0999\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3603 - output_1_loss: 0.3599 - val_loss: 0.4870 - val_output_1_loss: 0.4863\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3314 - output_1_loss: 0.3310 - val_loss: 0.4736 - val_output_1_loss: 0.4729\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1981 - output_1_loss: 0.1850 - val_loss: 0.1209 - val_output_1_loss: 0.0968\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2663 - output_1_loss: 0.2660Epoch 79/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2663 - output_1_loss: 0.2660 - val_loss: 0.4604 - val_output_1_loss: 0.4597\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1069 - output_1_loss: 0.0948Epoch 37/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1956 - output_1_loss: 0.1952 - val_loss: 0.4408 - val_output_1_loss: 0.4402\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.1069 - output_1_loss: 0.0948 - val_loss: 0.1197 - val_output_1_loss: 0.0961\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1877 - output_1_loss: 0.1873 - val_loss: 0.4237 - val_output_1_loss: 0.4231\n",
      "Epoch 39/100\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1612 - output_1_loss: 0.1608 - val_loss: 0.4064 - val_output_1_loss: 0.4058\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1135 - output_1_loss: 0.1009 - val_loss: 0.1197 - val_output_1_loss: 0.0955\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1437 - output_1_loss: 0.1433 - val_loss: 0.3874 - val_output_1_loss: 0.3869\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1656 - output_1_loss: 0.1652 - val_loss: 0.3702 - val_output_1_loss: 0.3696\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1676 - output_1_loss: 0.1673Epoch 81/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1676 - output_1_loss: 0.1673 - val_loss: 0.3513 - val_output_1_loss: 0.3507\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1550 - output_1_loss: 0.1546 - val_loss: 0.3343 - val_output_1_loss: 0.3337\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1168 - output_1_loss: 0.1056 - val_loss: 0.1172 - val_output_1_loss: 0.0930\n",
      "Epoch 82/100\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1862 - output_1_loss: 0.1741 - val_loss: 0.1179 - val_output_1_loss: 0.0934\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2153 - output_1_loss: 0.2149 - val_loss: 0.3261 - val_output_1_loss: 0.3255\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1882 - output_1_loss: 0.1771Epoch 45/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1548 - output_1_loss: 0.1545 - val_loss: 0.3092 - val_output_1_loss: 0.3086\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1882 - output_1_loss: 0.1771 - val_loss: 0.1166 - val_output_1_loss: 0.0918\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1103 - output_1_loss: 0.1099 - val_loss: 0.2891 - val_output_1_loss: 0.2885\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1445 - output_1_loss: 0.1442 - val_loss: 0.2729 - val_output_1_loss: 0.2723\n",
      "Epoch 48/100\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1857 - output_1_loss: 0.1854 - val_loss: 0.2661 - val_output_1_loss: 0.2655\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.1249 - output_1_loss: 0.1130 - val_loss: 0.1156 - val_output_1_loss: 0.0905\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1096 - output_1_loss: 0.1092 - val_loss: 0.2507 - val_output_1_loss: 0.2502\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1040 - output_1_loss: 0.1037 - val_loss: 0.2355 - val_output_1_loss: 0.2350\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1564 - output_1_loss: 0.1561Epoch 85/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1564 - output_1_loss: 0.1561 - val_loss: 0.2260 - val_output_1_loss: 0.2255\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1032 - output_1_loss: 0.0899Epoch 52/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1032 - output_1_loss: 0.0899 - val_loss: 0.1140 - val_output_1_loss: 0.0887\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1103 - output_1_loss: 0.1100Epoch 86/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1103 - output_1_loss: 0.1100 - val_loss: 0.2093 - val_output_1_loss: 0.2088\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1044 - output_1_loss: 0.0912Epoch 53/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.1044 - output_1_loss: 0.0912 - val_loss: 0.1130 - val_output_1_loss: 0.0880\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0971 - output_1_loss: 0.0968 - val_loss: 0.1949 - val_output_1_loss: 0.1944\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1321 - output_1_loss: 0.1185Epoch 54/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1321 - output_1_loss: 0.1185 - val_loss: 0.1108 - val_output_1_loss: 0.0860\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0934 - output_1_loss: 0.0931 - val_loss: 0.1837 - val_output_1_loss: 0.1832\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1222 - output_1_loss: 0.1090Epoch 55/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1222 - output_1_loss: 0.1090 - val_loss: 0.1113 - val_output_1_loss: 0.0869\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0949 - output_1_loss: 0.0947 - val_loss: 0.1684 - val_output_1_loss: 0.1679\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.1088 - output_1_loss: 0.0958 - val_loss: 0.1092 - val_output_1_loss: 0.0852\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0861 - output_1_loss: 0.0858 - val_loss: 0.1559 - val_output_1_loss: 0.1554\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0850 - output_1_loss: 0.0848 - val_loss: 0.1456 - val_output_1_loss: 0.1451\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0826 - output_1_loss: 0.0823Epoch 90/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0826 - output_1_loss: 0.0823 - val_loss: 0.1365 - val_output_1_loss: 0.1360\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0977 - output_1_loss: 0.0974 - val_loss: 0.1318 - val_output_1_loss: 0.1313\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.1128 - output_1_loss: 0.0992 - val_loss: 0.1075 - val_output_1_loss: 0.0837\n",
      "Epoch 91/100\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.2362 - output_1_loss: 0.2359 - val_loss: 0.1286 - val_output_1_loss: 0.1281\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.1069 - output_1_loss: 0.0930 - val_loss: 0.1064 - val_output_1_loss: 0.0826\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0972 - output_1_loss: 0.0969Epoch 92/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0972 - output_1_loss: 0.0969 - val_loss: 0.1211 - val_output_1_loss: 0.1206\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1067 - output_1_loss: 0.0939Epoch 62/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0940 - output_1_loss: 0.0937 - val_loss: 0.1165 - val_output_1_loss: 0.1160\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.1067 - output_1_loss: 0.0939 - val_loss: 0.1049 - val_output_1_loss: 0.0810\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0886 - output_1_loss: 0.0882 - val_loss: 0.1102 - val_output_1_loss: 0.1097\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0824 - output_1_loss: 0.0821Epoch 93/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0824 - output_1_loss: 0.0821 - val_loss: 0.1054 - val_output_1_loss: 0.1050\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0808 - output_1_loss: 0.0805 - val_loss: 0.1015 - val_output_1_loss: 0.1011\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1385 - output_1_loss: 0.1253 - val_loss: 0.1020 - val_output_1_loss: 0.0779\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0922 - output_1_loss: 0.0787Epoch 66/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0903 - output_1_loss: 0.0900 - val_loss: 0.0998 - val_output_1_loss: 0.0994\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0922 - output_1_loss: 0.0787 - val_loss: 0.1011 - val_output_1_loss: 0.0771\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0784 - output_1_loss: 0.0781 - val_loss: 0.0942 - val_output_1_loss: 0.0938\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1183 - output_1_loss: 0.1038Epoch 68/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0771 - output_1_loss: 0.0768 - val_loss: 0.0892 - val_output_1_loss: 0.0888\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.1183 - output_1_loss: 0.1038 - val_loss: 0.0995 - val_output_1_loss: 0.0751\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1002 - output_1_loss: 0.0867Epoch 69/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1002 - output_1_loss: 0.0867 - val_loss: 0.0978 - val_output_1_loss: 0.0737\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0789 - output_1_loss: 0.0786 - val_loss: 0.0870 - val_output_1_loss: 0.0866\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.1226 - output_1_loss: 0.1085 - val_loss: 0.1006 - val_output_1_loss: 0.0760\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0788 - output_1_loss: 0.0785 - val_loss: 0.0850 - val_output_1_loss: 0.0846\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0869 - output_1_loss: 0.0754Epoch 71/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0869 - output_1_loss: 0.0754 - val_loss: 0.1018 - val_output_1_loss: 0.0772\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0821 - output_1_loss: 0.0818 - val_loss: 0.0830 - val_output_1_loss: 0.0826\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1143 - output_1_loss: 0.1018Epoch 72/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1143 - output_1_loss: 0.1018 - val_loss: 0.0995 - val_output_1_loss: 0.0749\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0758 - output_1_loss: 0.0755 - val_loss: 0.0801 - val_output_1_loss: 0.0797\n",
      "Epoch 73/100\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0920 - output_1_loss: 0.0793 - val_loss: 0.0989 - val_output_1_loss: 0.0746\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0744 - output_1_loss: 0.0741 - val_loss: 0.0782 - val_output_1_loss: 0.0778\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0739 - output_1_loss: 0.0736 - val_loss: 0.0766 - val_output_1_loss: 0.0762\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0739 - output_1_loss: 0.0737 - val_loss: 0.0754 - val_output_1_loss: 0.0750\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0734 - output_1_loss: 0.0731 - val_loss: 0.0738 - val_output_1_loss: 0.0734\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0730 - output_1_loss: 0.0727 - val_loss: 0.0715 - val_output_1_loss: 0.0711\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0775 - output_1_loss: 0.0773 - val_loss: 0.0695 - val_output_1_loss: 0.0691\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:29:27,985]\u001b[0m Trial 72 finished with value: 0.02857142857142857 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 1, 'relaxation_factor': 1.6, 'sparsity_coefficient': 0.013331208941542973, 'bn_momentum': 0.9768020626410179}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.0779 - output_1_loss: 0.0776 - val_loss: 0.0684 - val_output_1_loss: 0.0681\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0829 - output_1_loss: 0.0826 - val_loss: 0.0674 - val_output_1_loss: 0.0670\n",
      "Epoch 81/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0782 - output_1_loss: 0.0779 - val_loss: 0.0682 - val_output_1_loss: 0.0679\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0783 - output_1_loss: 0.0780 - val_loss: 0.0684 - val_output_1_loss: 0.0680\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0820 - output_1_loss: 0.0817 - val_loss: 0.0675 - val_output_1_loss: 0.0671\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0777 - output_1_loss: 0.0774 - val_loss: 0.0662 - val_output_1_loss: 0.0658\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.0787 - output_1_loss: 0.0784 - val_loss: 0.0653 - val_output_1_loss: 0.0650\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0794 - output_1_loss: 0.0791 - val_loss: 0.0666 - val_output_1_loss: 0.0663\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0838 - output_1_loss: 0.0835 - val_loss: 0.0661 - val_output_1_loss: 0.0658\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0819 - output_1_loss: 0.0816 - val_loss: 0.0654 - val_output_1_loss: 0.0651\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0809 - output_1_loss: 0.0806 - val_loss: 0.0643 - val_output_1_loss: 0.0639\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0793 - output_1_loss: 0.0790 - val_loss: 0.0635 - val_output_1_loss: 0.0632\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0754 - output_1_loss: 0.0750 - val_loss: 0.0629 - val_output_1_loss: 0.0625\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0844 - output_1_loss: 0.0841 - val_loss: 0.0627 - val_output_1_loss: 0.0624\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0937 - output_1_loss: 0.0934 - val_loss: 0.0621 - val_output_1_loss: 0.0617\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0828 - output_1_loss: 0.0825 - val_loss: 0.0625 - val_output_1_loss: 0.0621\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0915 - output_1_loss: 0.0911 - val_loss: 0.0644 - val_output_1_loss: 0.0640\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0864 - output_1_loss: 0.0861 - val_loss: 0.0650 - val_output_1_loss: 0.0647\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0822 - output_1_loss: 0.0819 - val_loss: 0.0671 - val_output_1_loss: 0.0668\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1311 - output_1_loss: 0.1307 - val_loss: 0.0684 - val_output_1_loss: 0.0681\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:29:35,977]\u001b[0m Trial 73 finished with value: 0.037037037037037035 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.00031065694835707904, 'bn_momentum': 0.9344206694860404}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.6016 - output_1_loss: 0.6011 - val_loss: 0.6901 - val_output_1_loss: 0.6884\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.6005 - output_1_loss: 0.6000 - val_loss: 0.6852 - val_output_1_loss: 0.6836\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.5347 - output_1_loss: 0.5342 - val_loss: 0.6798 - val_output_1_loss: 0.6783\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.5489 - output_1_loss: 0.5484 - val_loss: 0.6734 - val_output_1_loss: 0.6720\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.5893 - output_1_loss: 0.5888 - val_loss: 0.6676 - val_output_1_loss: 0.6662\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5972 - output_1_loss: 0.5967 - val_loss: 0.6625 - val_output_1_loss: 0.6612\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.5571 - output_1_loss: 0.5565 - val_loss: 0.6572 - val_output_1_loss: 0.6559\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5381 - output_1_loss: 0.5376 - val_loss: 0.6519 - val_output_1_loss: 0.6506\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.5615 - output_1_loss: 0.5610 - val_loss: 0.6470 - val_output_1_loss: 0.6458\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.5144 - output_1_loss: 0.5139 - val_loss: 0.6415 - val_output_1_loss: 0.6402\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.5557 - output_1_loss: 0.5551 - val_loss: 0.6359 - val_output_1_loss: 0.6346\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.4760 - output_1_loss: 0.4755 - val_loss: 0.6297 - val_output_1_loss: 0.6285\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.4925 - output_1_loss: 0.4920 - val_loss: 0.6248 - val_output_1_loss: 0.6237\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5390 - output_1_loss: 0.5385 - val_loss: 0.6191 - val_output_1_loss: 0.6179\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4485 - output_1_loss: 0.4480 - val_loss: 0.6116 - val_output_1_loss: 0.6105\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4681 - output_1_loss: 0.4677 - val_loss: 0.6062 - val_output_1_loss: 0.6051\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4229 - output_1_loss: 0.4224 - val_loss: 0.5987 - val_output_1_loss: 0.5976\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5215 - output_1_loss: 0.5211 - val_loss: 0.5943 - val_output_1_loss: 0.5933\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4500 - output_1_loss: 0.4496 - val_loss: 0.5899 - val_output_1_loss: 0.5889\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4838 - output_1_loss: 0.4833 - val_loss: 0.5849 - val_output_1_loss: 0.5839\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4900 - output_1_loss: 0.4896 - val_loss: 0.5803 - val_output_1_loss: 0.5793\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.4197 - output_1_loss: 0.4192 - val_loss: 0.5754 - val_output_1_loss: 0.5745\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4463 - output_1_loss: 0.4458 - val_loss: 0.5714 - val_output_1_loss: 0.5705\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.4103 - output_1_loss: 0.4099 - val_loss: 0.5648 - val_output_1_loss: 0.5639\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4650 - output_1_loss: 0.4646 - val_loss: 0.5602 - val_output_1_loss: 0.5593\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.4644 - output_1_loss: 0.4640 - val_loss: 0.5554 - val_output_1_loss: 0.5545\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.3621 - output_1_loss: 0.3617 - val_loss: 0.5502 - val_output_1_loss: 0.5493\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.3018 - output_1_loss: 0.3014 - val_loss: 0.5415 - val_output_1_loss: 0.5407\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4625 - output_1_loss: 0.4621 - val_loss: 0.5360 - val_output_1_loss: 0.5351\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3256 - output_1_loss: 0.3252 - val_loss: 0.5257 - val_output_1_loss: 0.5249\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2676 - output_1_loss: 0.2673 - val_loss: 0.5164 - val_output_1_loss: 0.5156\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2457 - output_1_loss: 0.2453 - val_loss: 0.5059 - val_output_1_loss: 0.5051\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2273 - output_1_loss: 0.2269 - val_loss: 0.4984 - val_output_1_loss: 0.4976\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2065 - output_1_loss: 0.2061 - val_loss: 0.4873 - val_output_1_loss: 0.4866\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2128 - output_1_loss: 0.2125 - val_loss: 0.4764 - val_output_1_loss: 0.4756\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1374 - output_1_loss: 0.1370 - val_loss: 0.4646 - val_output_1_loss: 0.4639\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1480 - output_1_loss: 0.1477 - val_loss: 0.4521 - val_output_1_loss: 0.4514\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1533 - output_1_loss: 0.1529 - val_loss: 0.4428 - val_output_1_loss: 0.4422\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.1228 - output_1_loss: 0.1225 - val_loss: 0.4323 - val_output_1_loss: 0.4317\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1071 - output_1_loss: 0.1068 - val_loss: 0.4163 - val_output_1_loss: 0.4157\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1652 - output_1_loss: 0.1648 - val_loss: 0.4086 - val_output_1_loss: 0.4079\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1599 - output_1_loss: 0.1596 - val_loss: 0.3982 - val_output_1_loss: 0.3975\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1334 - output_1_loss: 0.1331 - val_loss: 0.3875 - val_output_1_loss: 0.3869\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2224 - output_1_loss: 0.2220 - val_loss: 0.3755 - val_output_1_loss: 0.3748\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2131 - output_1_loss: 0.2128 - val_loss: 0.3682 - val_output_1_loss: 0.3675\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1449 - output_1_loss: 0.1445 - val_loss: 0.3625 - val_output_1_loss: 0.3618\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1566 - output_1_loss: 0.1562 - val_loss: 0.3552 - val_output_1_loss: 0.3546\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1536 - output_1_loss: 0.1532 - val_loss: 0.3459 - val_output_1_loss: 0.3453\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1845 - output_1_loss: 0.1841 - val_loss: 0.3355 - val_output_1_loss: 0.3349\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2240 - output_1_loss: 0.2237 - val_loss: 0.3218 - val_output_1_loss: 0.3211\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1957 - output_1_loss: 0.1953 - val_loss: 0.3111 - val_output_1_loss: 0.3105\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9874 - output_1_loss: 0.9573Epoch 52/100\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1317 - output_1_loss: 0.1313 - val_loss: 0.2939 - val_output_1_loss: 0.2933\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.1265 - output_1_loss: 0.1261 - val_loss: 0.2781 - val_output_1_loss: 0.2775\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.1268 - output_1_loss: 0.1265 - val_loss: 0.2621 - val_output_1_loss: 0.2615\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1183 - output_1_loss: 0.1180 - val_loss: 0.2532 - val_output_1_loss: 0.2526\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1021 - output_1_loss: 0.1017 - val_loss: 0.2558 - val_output_1_loss: 0.2552\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0854 - output_1_loss: 0.0851 - val_loss: 0.2544 - val_output_1_loss: 0.2539\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0931 - output_1_loss: 0.0928 - val_loss: 0.2416 - val_output_1_loss: 0.2410\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1118 - output_1_loss: 0.1115 - val_loss: 0.2130 - val_output_1_loss: 0.2125\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1178 - output_1_loss: 0.1175 - val_loss: 0.1899 - val_output_1_loss: 0.1894\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0939 - output_1_loss: 0.0936 - val_loss: 0.1755 - val_output_1_loss: 0.1750\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0908 - output_1_loss: 0.0905 - val_loss: 0.1614 - val_output_1_loss: 0.1610\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1652 - output_1_loss: 0.1649 - val_loss: 0.1589 - val_output_1_loss: 0.1584\n",
      "1/1 [==============================] - 36s 36s/step - loss: 0.9874 - output_1_loss: 0.9573 - val_loss: 0.8177 - val_output_1_loss: 0.6866\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1477 - output_1_loss: 0.1473 - val_loss: 0.1552 - val_output_1_loss: 0.1547\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0955 - output_1_loss: 0.0952 - val_loss: 0.1455 - val_output_1_loss: 0.1450\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1700 - output_1_loss: 0.1697 - val_loss: 0.1371 - val_output_1_loss: 0.1366\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1004 - output_1_loss: 0.1000 - val_loss: 0.1494 - val_output_1_loss: 0.1489\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3046 - output_1_loss: 0.3042 - val_loss: 0.1706 - val_output_1_loss: 0.1701\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2973 - output_1_loss: 0.2970 - val_loss: 0.1707 - val_output_1_loss: 0.1702\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3010 - output_1_loss: 0.3006 - val_loss: 0.1594 - val_output_1_loss: 0.1589\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.3400 - output_1_loss: 0.3396 - val_loss: 0.1504 - val_output_1_loss: 0.1499\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 0.8210 - output_1_loss: 0.7915 - val_loss: 0.8002 - val_output_1_loss: 0.6783\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7241 - output_1_loss: 0.6935 - val_loss: 0.7840 - val_output_1_loss: 0.6701\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.6908 - output_1_loss: 0.6602 - val_loss: 0.7699 - val_output_1_loss: 0.6624\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:30:16,538]\u001b[0m Trial 74 finished with value: 1.0 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.0003211808675778546, 'bn_momentum': 0.9316851843962773}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6797 - output_1_loss: 0.6494Epoch 1/100\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.6797 - output_1_loss: 0.6494 - val_loss: 0.7554 - val_output_1_loss: 0.6540\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.6362 - output_1_loss: 0.6072 - val_loss: 0.7462 - val_output_1_loss: 0.6464\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 0.5977 - output_1_loss: 0.5684 - val_loss: 0.7325 - val_output_1_loss: 0.6388\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.5484 - output_1_loss: 0.5193 - val_loss: 0.7202 - val_output_1_loss: 0.6308\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.5636 - output_1_loss: 0.5337 - val_loss: 0.7081 - val_output_1_loss: 0.6238\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.4817 - output_1_loss: 0.4535 - val_loss: 0.6986 - val_output_1_loss: 0.6153\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4422 - output_1_loss: 0.4147 - val_loss: 0.6820 - val_output_1_loss: 0.6048\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.3938 - output_1_loss: 0.3680 - val_loss: 0.6706 - val_output_1_loss: 0.5961\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.4421 - output_1_loss: 0.4178 - val_loss: 0.6588 - val_output_1_loss: 0.5865\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.3712 - output_1_loss: 0.3464 - val_loss: 0.6474 - val_output_1_loss: 0.5746\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.3082 - output_1_loss: 0.2856 - val_loss: 0.6327 - val_output_1_loss: 0.5634\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.3967 - output_1_loss: 0.3749 - val_loss: 0.6233 - val_output_1_loss: 0.5549\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 0.2895 - output_1_loss: 0.2693 - val_loss: 0.6127 - val_output_1_loss: 0.5448\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 0.2244 - output_1_loss: 0.2055 - val_loss: 0.5966 - val_output_1_loss: 0.5317\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.2334 - output_1_loss: 0.2125 - val_loss: 0.5812 - val_output_1_loss: 0.5174\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.2284 - output_1_loss: 0.2059 - val_loss: 0.5707 - val_output_1_loss: 0.5071\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.2674 - output_1_loss: 0.2459 - val_loss: 0.5592 - val_output_1_loss: 0.4963\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.2428 - output_1_loss: 0.2201 - val_loss: 0.5428 - val_output_1_loss: 0.4781\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.2759 - output_1_loss: 0.2533 - val_loss: 0.5306 - val_output_1_loss: 0.4654\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.1663 - output_1_loss: 0.1417 - val_loss: 0.5150 - val_output_1_loss: 0.4500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.2506 - output_1_loss: 0.2256 - val_loss: 0.5000 - val_output_1_loss: 0.4359\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.2700 - output_1_loss: 0.2439 - val_loss: 0.4904 - val_output_1_loss: 0.4265\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.1802 - output_1_loss: 0.1542 - val_loss: 0.4738 - val_output_1_loss: 0.4091\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.2551 - output_1_loss: 0.2299 - val_loss: 0.4660 - val_output_1_loss: 0.4007\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1762 - output_1_loss: 0.1508 - val_loss: 0.4476 - val_output_1_loss: 0.3833\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.2096 - output_1_loss: 0.1827 - val_loss: 0.4369 - val_output_1_loss: 0.3731\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.1485 - output_1_loss: 0.1245 - val_loss: 0.4219 - val_output_1_loss: 0.3591\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2543 - output_1_loss: 0.2311 - val_loss: 0.4279 - val_output_1_loss: 0.3620\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1318 - output_1_loss: 0.1116 - val_loss: 0.4097 - val_output_1_loss: 0.3459\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.1515 - output_1_loss: 0.1284 - val_loss: 0.3891 - val_output_1_loss: 0.3248\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.2140 - output_1_loss: 0.1924 - val_loss: 0.3789 - val_output_1_loss: 0.3122\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.1614 - output_1_loss: 0.1393 - val_loss: 0.3721 - val_output_1_loss: 0.3049\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.2376 - output_1_loss: 0.2184 - val_loss: 0.3612 - val_output_1_loss: 0.2968\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.7412 - output_1_loss: 0.7370 - val_loss: 0.7028 - val_output_1_loss: 0.6885\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1649 - output_1_loss: 0.1430 - val_loss: 0.3488 - val_output_1_loss: 0.2842\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1360 - output_1_loss: 0.1150Epoch 2/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1360 - output_1_loss: 0.1150 - val_loss: 0.3332 - val_output_1_loss: 0.2707\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.7418 - output_1_loss: 0.7376 - val_loss: 0.6981 - val_output_1_loss: 0.6845\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1087 - output_1_loss: 0.0859 - val_loss: 0.3175 - val_output_1_loss: 0.2571\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.7102 - output_1_loss: 0.7061 - val_loss: 0.6946 - val_output_1_loss: 0.6817\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7389 - output_1_loss: 0.7348 - val_loss: 0.6884 - val_output_1_loss: 0.6759\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6803 - output_1_loss: 0.6762Epoch 41/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6803 - output_1_loss: 0.6762 - val_loss: 0.6836 - val_output_1_loss: 0.6716\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1665 - output_1_loss: 0.1445Epoch 6/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.1665 - output_1_loss: 0.1445 - val_loss: 0.2942 - val_output_1_loss: 0.2333\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6909 - output_1_loss: 0.6867 - val_loss: 0.6777 - val_output_1_loss: 0.6661\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1488 - output_1_loss: 0.1261Epoch 7/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.1488 - output_1_loss: 0.1261 - val_loss: 0.2886 - val_output_1_loss: 0.2255\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.6219 - output_1_loss: 0.6178 - val_loss: 0.6736 - val_output_1_loss: 0.6625\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.6901 - output_1_loss: 0.6859 - val_loss: 0.6713 - val_output_1_loss: 0.6603\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.1325 - output_1_loss: 0.1101 - val_loss: 0.2856 - val_output_1_loss: 0.2231\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6448 - output_1_loss: 0.6405 - val_loss: 0.6659 - val_output_1_loss: 0.6551\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6232 - output_1_loss: 0.6189Epoch 44/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6232 - output_1_loss: 0.6189 - val_loss: 0.6602 - val_output_1_loss: 0.6497\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1310 - output_1_loss: 0.1063Epoch 11/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1310 - output_1_loss: 0.1063 - val_loss: 0.2831 - val_output_1_loss: 0.2211\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6145 - output_1_loss: 0.6103Epoch 45/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6145 - output_1_loss: 0.6103 - val_loss: 0.6560 - val_output_1_loss: 0.6459\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1724 - output_1_loss: 0.1498Epoch 12/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.1724 - output_1_loss: 0.1498 - val_loss: 0.2768 - val_output_1_loss: 0.2131\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.5790 - output_1_loss: 0.5749 - val_loss: 0.6516 - val_output_1_loss: 0.6416\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5507 - output_1_loss: 0.5465 - val_loss: 0.6466 - val_output_1_loss: 0.6369\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5045 - output_1_loss: 0.5004 - val_loss: 0.6399 - val_output_1_loss: 0.6305\n",
      "Epoch 15/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.5317 - output_1_loss: 0.5277 - val_loss: 0.6369 - val_output_1_loss: 0.6277\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1232 - output_1_loss: 0.1004 - val_loss: 0.2679 - val_output_1_loss: 0.2036\n",
      "Epoch 16/100\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.5768 - output_1_loss: 0.5728 - val_loss: 0.6316 - val_output_1_loss: 0.6225\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.1276 - output_1_loss: 0.1053 - val_loss: 0.2591 - val_output_1_loss: 0.1953\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5361 - output_1_loss: 0.5320 - val_loss: 0.6265 - val_output_1_loss: 0.6175\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5842 - output_1_loss: 0.5802 - val_loss: 0.6214 - val_output_1_loss: 0.6125\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.1268 - output_1_loss: 0.1055 - val_loss: 0.2531 - val_output_1_loss: 0.1897\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5276 - output_1_loss: 0.5236 - val_loss: 0.6152 - val_output_1_loss: 0.6063\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5575 - output_1_loss: 0.5535 - val_loss: 0.6081 - val_output_1_loss: 0.5994\n",
      "Epoch 21/100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.5157 - output_1_loss: 0.5118 - val_loss: 0.6022 - val_output_1_loss: 0.5934\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1686 - output_1_loss: 0.1471Epoch 22/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.5317 - output_1_loss: 0.5279 - val_loss: 0.5966 - val_output_1_loss: 0.5880\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.1686 - output_1_loss: 0.1471 - val_loss: 0.2469 - val_output_1_loss: 0.1853\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4781 - output_1_loss: 0.4743 - val_loss: 0.5892 - val_output_1_loss: 0.5808\n",
      "Epoch 24/100\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4271 - output_1_loss: 0.4234 - val_loss: 0.5806 - val_output_1_loss: 0.5723\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.1338 - output_1_loss: 0.1138 - val_loss: 0.2314 - val_output_1_loss: 0.1705\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4445 - output_1_loss: 0.4410 - val_loss: 0.5723 - val_output_1_loss: 0.5642\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.4719 - output_1_loss: 0.4682 - val_loss: 0.5677 - val_output_1_loss: 0.5597\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.1668 - output_1_loss: 0.1451 - val_loss: 0.2266 - val_output_1_loss: 0.1661\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4803 - output_1_loss: 0.4765 - val_loss: 0.5628 - val_output_1_loss: 0.5549\n",
      "Epoch 52/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4376 - output_1_loss: 0.4338 - val_loss: 0.5577 - val_output_1_loss: 0.5498\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.1078 - output_1_loss: 0.0869 - val_loss: 0.2188 - val_output_1_loss: 0.1593\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.4078 - output_1_loss: 0.4043 - val_loss: 0.5490 - val_output_1_loss: 0.5413\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3970 - output_1_loss: 0.3935 - val_loss: 0.5437 - val_output_1_loss: 0.5362\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3875 - output_1_loss: 0.3839Epoch 53/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3875 - output_1_loss: 0.3839 - val_loss: 0.5339 - val_output_1_loss: 0.5266\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1202 - output_1_loss: 0.1000Epoch 32/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1202 - output_1_loss: 0.1000 - val_loss: 0.2165 - val_output_1_loss: 0.1563\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4377 - output_1_loss: 0.4339 - val_loss: 0.5233 - val_output_1_loss: 0.5161\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3939 - output_1_loss: 0.3902 - val_loss: 0.5158 - val_output_1_loss: 0.5088\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4098 - output_1_loss: 0.4062 - val_loss: 0.5095 - val_output_1_loss: 0.5027\n",
      "Epoch 54/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1093 - output_1_loss: 0.0882 - val_loss: 0.2202 - val_output_1_loss: 0.1603\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3636 - output_1_loss: 0.3602 - val_loss: 0.4998 - val_output_1_loss: 0.4932\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1226 - output_1_loss: 0.1014Epoch 36/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4195 - output_1_loss: 0.4161 - val_loss: 0.4902 - val_output_1_loss: 0.4837\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.1226 - output_1_loss: 0.1014 - val_loss: 0.2101 - val_output_1_loss: 0.1520\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1594 - output_1_loss: 0.1409Epoch 37/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3943 - output_1_loss: 0.3909 - val_loss: 0.4797 - val_output_1_loss: 0.4734\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1594 - output_1_loss: 0.1409 - val_loss: 0.2026 - val_output_1_loss: 0.1469\n",
      "Epoch 38/100\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.3470 - output_1_loss: 0.3436 - val_loss: 0.4682 - val_output_1_loss: 0.4622\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1175 - output_1_loss: 0.0980Epoch 39/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3445 - output_1_loss: 0.3412 - val_loss: 0.4541 - val_output_1_loss: 0.4483\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.1175 - output_1_loss: 0.0980 - val_loss: 0.1994 - val_output_1_loss: 0.1437\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1766 - output_1_loss: 0.1569Epoch 40/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2737 - output_1_loss: 0.2706 - val_loss: 0.4385 - val_output_1_loss: 0.4329\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.1766 - output_1_loss: 0.1569 - val_loss: 0.1902 - val_output_1_loss: 0.1355\n",
      "Epoch 41/100\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1349 - output_1_loss: 0.1135 - val_loss: 0.1916 - val_output_1_loss: 0.1372\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.2298 - output_1_loss: 0.2266 - val_loss: 0.4210 - val_output_1_loss: 0.4156\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1799 - output_1_loss: 0.1606Epoch 42/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2508 - output_1_loss: 0.2477 - val_loss: 0.4049 - val_output_1_loss: 0.3996\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1799 - output_1_loss: 0.1606 - val_loss: 0.1879 - val_output_1_loss: 0.1339\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1882 - output_1_loss: 0.1852 - val_loss: 0.3877 - val_output_1_loss: 0.3826\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2902 - output_1_loss: 0.2870 - val_loss: 0.3807 - val_output_1_loss: 0.3756\n",
      "Epoch 45/100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3304 - output_1_loss: 0.3270 - val_loss: 0.3675 - val_output_1_loss: 0.3624\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2978 - output_1_loss: 0.2945 - val_loss: 0.3551 - val_output_1_loss: 0.3502\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.2192 - output_1_loss: 0.1984 - val_loss: 0.1829 - val_output_1_loss: 0.1284\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2506 - output_1_loss: 0.2472 - val_loss: 0.3457 - val_output_1_loss: 0.3408\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2795 - output_1_loss: 0.2757Epoch 62/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.2795 - output_1_loss: 0.2757 - val_loss: 0.3400 - val_output_1_loss: 0.3349\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1119 - output_1_loss: 0.0931 - val_loss: 0.1862 - val_output_1_loss: 0.1312\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3199 - output_1_loss: 0.3162 - val_loss: 0.3326 - val_output_1_loss: 0.3275\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3093 - output_1_loss: 0.3056 - val_loss: 0.3266 - val_output_1_loss: 0.3215\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.1957 - output_1_loss: 0.1754 - val_loss: 0.1826 - val_output_1_loss: 0.1280\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3035 - output_1_loss: 0.2997 - val_loss: 0.3138 - val_output_1_loss: 0.3087\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1086 - output_1_loss: 0.0887Epoch 52/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.1086 - output_1_loss: 0.0887 - val_loss: 0.1796 - val_output_1_loss: 0.1251\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3754 - output_1_loss: 0.3716Epoch 65/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3754 - output_1_loss: 0.3716 - val_loss: 0.3116 - val_output_1_loss: 0.3064\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1146 - output_1_loss: 0.0926Epoch 53/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.1146 - output_1_loss: 0.0926 - val_loss: 0.1775 - val_output_1_loss: 0.1245\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.3305 - output_1_loss: 0.3269 - val_loss: 0.3079 - val_output_1_loss: 0.3026\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1263 - output_1_loss: 0.1053Epoch 54/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.1263 - output_1_loss: 0.1053 - val_loss: 0.1758 - val_output_1_loss: 0.1237\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3588 - output_1_loss: 0.3551 - val_loss: 0.3047 - val_output_1_loss: 0.2994\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1170 - output_1_loss: 0.0949 - val_loss: 0.1781 - val_output_1_loss: 0.1259\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.2982 - output_1_loss: 0.2946 - val_loss: 0.2997 - val_output_1_loss: 0.2945\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1470 - output_1_loss: 0.1245Epoch 56/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1470 - output_1_loss: 0.1245 - val_loss: 0.1793 - val_output_1_loss: 0.1258\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2370 - output_1_loss: 0.2334 - val_loss: 0.2926 - val_output_1_loss: 0.2874\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1919 - output_1_loss: 0.1708 - val_loss: 0.1802 - val_output_1_loss: 0.1254\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3007 - output_1_loss: 0.2973 - val_loss: 0.2876 - val_output_1_loss: 0.2824\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1850 - output_1_loss: 0.1659Epoch 58/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1965 - output_1_loss: 0.1930 - val_loss: 0.2792 - val_output_1_loss: 0.2741\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.1850 - output_1_loss: 0.1659 - val_loss: 0.1715 - val_output_1_loss: 0.1156\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.2044 - output_1_loss: 0.2011 - val_loss: 0.2727 - val_output_1_loss: 0.2677\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2019 - output_1_loss: 0.1830 - val_loss: 0.1682 - val_output_1_loss: 0.1133\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1895 - output_1_loss: 0.1861 - val_loss: 0.2663 - val_output_1_loss: 0.2614\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1652 - output_1_loss: 0.1619 - val_loss: 0.2570 - val_output_1_loss: 0.2521\n",
      "Epoch 62/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1301 - output_1_loss: 0.1269 - val_loss: 0.2414 - val_output_1_loss: 0.2365\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1268 - output_1_loss: 0.1091Epoch 63/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.1268 - output_1_loss: 0.1091 - val_loss: 0.1564 - val_output_1_loss: 0.1030\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1209 - output_1_loss: 0.1177 - val_loss: 0.2264 - val_output_1_loss: 0.2216\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.1184 - output_1_loss: 0.1003 - val_loss: 0.1496 - val_output_1_loss: 0.0971\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1109 - output_1_loss: 0.1077 - val_loss: 0.2143 - val_output_1_loss: 0.2096\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1050 - output_1_loss: 0.1018 - val_loss: 0.1984 - val_output_1_loss: 0.1937\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2215 - output_1_loss: 0.2180Epoch 74/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2215 - output_1_loss: 0.2180 - val_loss: 0.1939 - val_output_1_loss: 0.1892\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2176 - output_1_loss: 0.1995Epoch 67/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.2176 - output_1_loss: 0.1995 - val_loss: 0.1445 - val_output_1_loss: 0.0930\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2245 - output_1_loss: 0.2210Epoch 75/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2245 - output_1_loss: 0.2210 - val_loss: 0.1874 - val_output_1_loss: 0.1828\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.1120 - output_1_loss: 0.0921 - val_loss: 0.1464 - val_output_1_loss: 0.0946\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2611 - output_1_loss: 0.2575 - val_loss: 0.1841 - val_output_1_loss: 0.1796\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1040 - output_1_loss: 0.0868Epoch 69/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1762 - output_1_loss: 0.1727 - val_loss: 0.1872 - val_output_1_loss: 0.1828\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.1040 - output_1_loss: 0.0868 - val_loss: 0.1425 - val_output_1_loss: 0.0883\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1852 - output_1_loss: 0.1817Epoch 77/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1852 - output_1_loss: 0.1817 - val_loss: 0.1777 - val_output_1_loss: 0.1733\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1393 - output_1_loss: 0.1199 - val_loss: 0.1433 - val_output_1_loss: 0.0892\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1963 - output_1_loss: 0.1929Epoch 78/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1963 - output_1_loss: 0.1929 - val_loss: 0.1820 - val_output_1_loss: 0.1777\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1222 - output_1_loss: 0.1026 - val_loss: 0.1444 - val_output_1_loss: 0.0912\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1774 - output_1_loss: 0.1738 - val_loss: 0.1645 - val_output_1_loss: 0.1604\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1305 - output_1_loss: 0.1126 - val_loss: 0.1433 - val_output_1_loss: 0.0912\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1461 - output_1_loss: 0.1427 - val_loss: 0.1513 - val_output_1_loss: 0.1471\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2755 - output_1_loss: 0.2723 - val_loss: 0.1522 - val_output_1_loss: 0.1480\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1889 - output_1_loss: 0.1856 - val_loss: 0.1564 - val_output_1_loss: 0.1522\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.1172 - output_1_loss: 0.0996 - val_loss: 0.1416 - val_output_1_loss: 0.0887\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1822 - output_1_loss: 0.1788 - val_loss: 0.1484 - val_output_1_loss: 0.1444\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1481 - output_1_loss: 0.1281Epoch 77/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1481 - output_1_loss: 0.1281 - val_loss: 0.1401 - val_output_1_loss: 0.0877\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2159 - output_1_loss: 0.2124Epoch 82/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2159 - output_1_loss: 0.2124 - val_loss: 0.1249 - val_output_1_loss: 0.1209\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.3032 - output_1_loss: 0.2998 - val_loss: 0.1353 - val_output_1_loss: 0.1314\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1477 - output_1_loss: 0.1445 - val_loss: 0.1289 - val_output_1_loss: 0.1250\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.1112 - output_1_loss: 0.0910 - val_loss: 0.1387 - val_output_1_loss: 0.0859\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1663 - output_1_loss: 0.1633 - val_loss: 0.1256 - val_output_1_loss: 0.1218\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1366 - output_1_loss: 0.1336 - val_loss: 0.1293 - val_output_1_loss: 0.1254\n",
      "Epoch 83/100\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1112 - output_1_loss: 0.0885 - val_loss: 0.1398 - val_output_1_loss: 0.0864\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.1849 - output_1_loss: 0.1816 - val_loss: 0.1424 - val_output_1_loss: 0.1386\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.1200 - output_1_loss: 0.0978 - val_loss: 0.1324 - val_output_1_loss: 0.0802\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:30:55,588]\u001b[0m Trial 76 finished with value: 0.021739130434782608 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.1, 'sparsity_coefficient': 0.0025300136818125736, 'bn_momentum': 0.9295290447418003}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 610ms/step - loss: 0.1128 - output_1_loss: 0.0910 - val_loss: 0.1265 - val_output_1_loss: 0.0758\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1495 - output_1_loss: 0.1281Epoch 1/100\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.1495 - output_1_loss: 0.1281 - val_loss: 0.1196 - val_output_1_loss: 0.0709\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 0.1466 - output_1_loss: 0.1239 - val_loss: 0.1184 - val_output_1_loss: 0.0718\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1425 - output_1_loss: 0.1208 - val_loss: 0.1218 - val_output_1_loss: 0.0750\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1383 - output_1_loss: 0.1158 - val_loss: 0.1231 - val_output_1_loss: 0.0760\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1268 - output_1_loss: 0.1051 - val_loss: 0.1246 - val_output_1_loss: 0.0768\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1689 - output_1_loss: 0.1478 - val_loss: 0.1225 - val_output_1_loss: 0.0742\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.1678 - output_1_loss: 0.1460 - val_loss: 0.1332 - val_output_1_loss: 0.0837\n",
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:31:04,568]\u001b[0m Trial 75 finished with value: 0.16666666666666666 and parameters: {'feature_dim': 256, 'n_step': 8, 'n_shared': 1, 'relaxation_factor': 1.8, 'sparsity_coefficient': 0.03189518864495295, 'bn_momentum': 0.9735054038214133}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.6982 - output_1_loss: 0.6975 - val_loss: 0.6910 - val_output_1_loss: 0.6880\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.7140 - output_1_loss: 0.7132 - val_loss: 0.6870 - val_output_1_loss: 0.6842\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.6155 - output_1_loss: 0.6147 - val_loss: 0.6799 - val_output_1_loss: 0.6773\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6787 - output_1_loss: 0.6779 - val_loss: 0.6738 - val_output_1_loss: 0.6714\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.6381 - output_1_loss: 0.6373 - val_loss: 0.6689 - val_output_1_loss: 0.6665\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6666 - output_1_loss: 0.6658 - val_loss: 0.6666 - val_output_1_loss: 0.6643\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.6085 - output_1_loss: 0.6076 - val_loss: 0.6616 - val_output_1_loss: 0.6594\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5709 - output_1_loss: 0.5700 - val_loss: 0.6569 - val_output_1_loss: 0.6547\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5595 - output_1_loss: 0.5587 - val_loss: 0.6507 - val_output_1_loss: 0.6486\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5321 - output_1_loss: 0.5312 - val_loss: 0.6458 - val_output_1_loss: 0.6438\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5518 - output_1_loss: 0.5510 - val_loss: 0.6401 - val_output_1_loss: 0.6382\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4938 - output_1_loss: 0.4931 - val_loss: 0.6346 - val_output_1_loss: 0.6328\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.5295 - output_1_loss: 0.5287 - val_loss: 0.6290 - val_output_1_loss: 0.6271\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.4577 - output_1_loss: 0.4570 - val_loss: 0.6247 - val_output_1_loss: 0.6229\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5129 - output_1_loss: 0.5122 - val_loss: 0.6167 - val_output_1_loss: 0.6150\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5312 - output_1_loss: 0.5305 - val_loss: 0.6089 - val_output_1_loss: 0.6072\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.5027 - output_1_loss: 0.5019 - val_loss: 0.6042 - val_output_1_loss: 0.6025\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4949 - output_1_loss: 0.4941 - val_loss: 0.5980 - val_output_1_loss: 0.5964\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4570 - output_1_loss: 0.4564 - val_loss: 0.5941 - val_output_1_loss: 0.5924\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7929 - output_1_loss: 0.7923Epoch 20/100\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.4557 - output_1_loss: 0.4550 - val_loss: 0.5840 - val_output_1_loss: 0.5823\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.3939 - output_1_loss: 0.3932 - val_loss: 0.5772 - val_output_1_loss: 0.5756\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4403 - output_1_loss: 0.4396 - val_loss: 0.5678 - val_output_1_loss: 0.5663\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4561 - output_1_loss: 0.4554 - val_loss: 0.5652 - val_output_1_loss: 0.5637\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4994 - output_1_loss: 0.4987 - val_loss: 0.5599 - val_output_1_loss: 0.5584\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4027 - output_1_loss: 0.4021 - val_loss: 0.5562 - val_output_1_loss: 0.5548\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.7929 - output_1_loss: 0.7923 - val_loss: 0.6930 - val_output_1_loss: 0.6905\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4422 - output_1_loss: 0.4415 - val_loss: 0.5481 - val_output_1_loss: 0.5467\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.8479 - output_1_loss: 0.8473 - val_loss: 0.6902 - val_output_1_loss: 0.6879\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.4403 - output_1_loss: 0.4396 - val_loss: 0.5441 - val_output_1_loss: 0.5427\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7818 - output_1_loss: 0.7812 - val_loss: 0.6851 - val_output_1_loss: 0.6830\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3950 - output_1_loss: 0.3943Epoch 4/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3950 - output_1_loss: 0.3943 - val_loss: 0.5381 - val_output_1_loss: 0.5367\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.8203 - output_1_loss: 0.8197 - val_loss: 0.6826 - val_output_1_loss: 0.6806\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4326 - output_1_loss: 0.4320Epoch 5/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4326 - output_1_loss: 0.4320 - val_loss: 0.5298 - val_output_1_loss: 0.5285\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7273 - output_1_loss: 0.7267Epoch 30/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.7273 - output_1_loss: 0.7267 - val_loss: 0.6792 - val_output_1_loss: 0.6773\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.3980 - output_1_loss: 0.3974 - val_loss: 0.5290 - val_output_1_loss: 0.5276\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7686 - output_1_loss: 0.7680 - val_loss: 0.6752 - val_output_1_loss: 0.6734\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3649 - output_1_loss: 0.3643Epoch 7/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3649 - output_1_loss: 0.3643 - val_loss: 0.5206 - val_output_1_loss: 0.5192\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7389 - output_1_loss: 0.7383 - val_loss: 0.6721 - val_output_1_loss: 0.6704\n",
      "Epoch 8/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.7126 - output_1_loss: 0.7120 - val_loss: 0.6687 - val_output_1_loss: 0.6670\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3409 - output_1_loss: 0.3403 - val_loss: 0.5095 - val_output_1_loss: 0.5081\n",
      "Epoch 9/100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.7074 - output_1_loss: 0.7068 - val_loss: 0.6647 - val_output_1_loss: 0.6630\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3019 - output_1_loss: 0.3013 - val_loss: 0.5000 - val_output_1_loss: 0.4986\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7054 - output_1_loss: 0.7048Epoch 34/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.7054 - output_1_loss: 0.7048 - val_loss: 0.6601 - val_output_1_loss: 0.6585\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3157 - output_1_loss: 0.3151 - val_loss: 0.4834 - val_output_1_loss: 0.4821\n",
      "Epoch 35/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3742 - output_1_loss: 0.3736 - val_loss: 0.4823 - val_output_1_loss: 0.4810\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6972 - output_1_loss: 0.6966 - val_loss: 0.6573 - val_output_1_loss: 0.6557\n",
      "Epoch 12/100\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6766 - output_1_loss: 0.6760 - val_loss: 0.6539 - val_output_1_loss: 0.6523\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3140 - output_1_loss: 0.3134 - val_loss: 0.4783 - val_output_1_loss: 0.4770\n",
      "Epoch 13/100\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6510 - output_1_loss: 0.6504 - val_loss: 0.6517 - val_output_1_loss: 0.6502\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2962 - output_1_loss: 0.2956 - val_loss: 0.4703 - val_output_1_loss: 0.4691\n",
      "Epoch 38/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6121 - output_1_loss: 0.6115 - val_loss: 0.6461 - val_output_1_loss: 0.6446\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3795 - output_1_loss: 0.3788 - val_loss: 0.4627 - val_output_1_loss: 0.4615\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3305 - output_1_loss: 0.3299Epoch 15/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.3305 - output_1_loss: 0.3299 - val_loss: 0.4580 - val_output_1_loss: 0.4568\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.6550 - output_1_loss: 0.6544 - val_loss: 0.6427 - val_output_1_loss: 0.6412\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.4074 - output_1_loss: 0.4067 - val_loss: 0.4507 - val_output_1_loss: 0.4495\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6259 - output_1_loss: 0.6254 - val_loss: 0.6371 - val_output_1_loss: 0.6356\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.3505 - output_1_loss: 0.3498 - val_loss: 0.4358 - val_output_1_loss: 0.4346\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.6220 - output_1_loss: 0.6214 - val_loss: 0.6332 - val_output_1_loss: 0.6318\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2846 - output_1_loss: 0.2839 - val_loss: 0.4142 - val_output_1_loss: 0.4130\n",
      "Epoch 43/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2914 - output_1_loss: 0.2908 - val_loss: 0.4085 - val_output_1_loss: 0.4073\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.5782 - output_1_loss: 0.5776 - val_loss: 0.6309 - val_output_1_loss: 0.6295\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.2605 - output_1_loss: 0.2599 - val_loss: 0.4070 - val_output_1_loss: 0.4058\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5863 - output_1_loss: 0.5857 - val_loss: 0.6285 - val_output_1_loss: 0.6271\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2363 - output_1_loss: 0.2357 - val_loss: 0.3912 - val_output_1_loss: 0.3900\n",
      "Epoch 20/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.2818 - output_1_loss: 0.2812 - val_loss: 0.3726 - val_output_1_loss: 0.3715\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6189 - output_1_loss: 0.6184 - val_loss: 0.6246 - val_output_1_loss: 0.6233\n",
      "Epoch 47/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.3507 - output_1_loss: 0.3502 - val_loss: 0.3661 - val_output_1_loss: 0.3649\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.6102 - output_1_loss: 0.6097 - val_loss: 0.6183 - val_output_1_loss: 0.6170\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.3156 - output_1_loss: 0.3151 - val_loss: 0.3569 - val_output_1_loss: 0.3558\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.6324 - output_1_loss: 0.6319 - val_loss: 0.6157 - val_output_1_loss: 0.6144\n",
      "Epoch 23/100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2887 - output_1_loss: 0.2882 - val_loss: 0.3611 - val_output_1_loss: 0.3600\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.5881 - output_1_loss: 0.5875 - val_loss: 0.6096 - val_output_1_loss: 0.6084\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2475 - output_1_loss: 0.2469Epoch 24/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2475 - output_1_loss: 0.2469 - val_loss: 0.3361 - val_output_1_loss: 0.3350\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5906 - output_1_loss: 0.5900 - val_loss: 0.6045 - val_output_1_loss: 0.6033\n",
      "Epoch 25/100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5393 - output_1_loss: 0.5387 - val_loss: 0.5995 - val_output_1_loss: 0.5983\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.2818 - output_1_loss: 0.2813 - val_loss: 0.3068 - val_output_1_loss: 0.3058\n",
      "Epoch 26/100\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6176 - output_1_loss: 0.6171 - val_loss: 0.5911 - val_output_1_loss: 0.5899\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2787 - output_1_loss: 0.2782 - val_loss: 0.2969 - val_output_1_loss: 0.2959\n",
      "Epoch 53/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2505 - output_1_loss: 0.2499 - val_loss: 0.2868 - val_output_1_loss: 0.2859\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.5051 - output_1_loss: 0.5045 - val_loss: 0.5877 - val_output_1_loss: 0.5865\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2794 - output_1_loss: 0.2789 - val_loss: 0.2870 - val_output_1_loss: 0.2860\n",
      "Epoch 55/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3395 - output_1_loss: 0.3390 - val_loss: 0.2831 - val_output_1_loss: 0.2822\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.5128 - output_1_loss: 0.5123 - val_loss: 0.5837 - val_output_1_loss: 0.5825\n",
      "Epoch 56/100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2821 - output_1_loss: 0.2816 - val_loss: 0.2861 - val_output_1_loss: 0.2852\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5467 - output_1_loss: 0.5461Epoch 57/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.5467 - output_1_loss: 0.5461 - val_loss: 0.5832 - val_output_1_loss: 0.5820\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2366 - output_1_loss: 0.2361 - val_loss: 0.2671 - val_output_1_loss: 0.2661\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4944 - output_1_loss: 0.4938 - val_loss: 0.5804 - val_output_1_loss: 0.5792\n",
      "Epoch 31/100\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5267 - output_1_loss: 0.5261 - val_loss: 0.5824 - val_output_1_loss: 0.5813\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2935 - output_1_loss: 0.2930 - val_loss: 0.2739 - val_output_1_loss: 0.2730\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.2674 - output_1_loss: 0.2669 - val_loss: 0.2773 - val_output_1_loss: 0.2764\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.5166 - output_1_loss: 0.5160 - val_loss: 0.5786 - val_output_1_loss: 0.5774\n",
      "Epoch 33/100\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.5045 - output_1_loss: 0.5039 - val_loss: 0.5732 - val_output_1_loss: 0.5720\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2097 - output_1_loss: 0.2091 - val_loss: 0.2336 - val_output_1_loss: 0.2328\n",
      "Epoch 34/100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4954 - output_1_loss: 0.4948 - val_loss: 0.5649 - val_output_1_loss: 0.5637\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.2589 - output_1_loss: 0.2583 - val_loss: 0.2428 - val_output_1_loss: 0.2420\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2418 - output_1_loss: 0.2413 - val_loss: 0.2431 - val_output_1_loss: 0.2423\n",
      "Epoch 63/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2239 - output_1_loss: 0.2234 - val_loss: 0.2289 - val_output_1_loss: 0.2282\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.5852 - output_1_loss: 0.5847 - val_loss: 0.5557 - val_output_1_loss: 0.5544\n",
      "Epoch 64/100\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.2582 - output_1_loss: 0.2577 - val_loss: 0.2387 - val_output_1_loss: 0.2380\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.5134 - output_1_loss: 0.5128 - val_loss: 0.5473 - val_output_1_loss: 0.5462\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2301 - output_1_loss: 0.2295 - val_loss: 0.2294 - val_output_1_loss: 0.2287\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4133 - output_1_loss: 0.4128 - val_loss: 0.5441 - val_output_1_loss: 0.5429\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1905 - output_1_loss: 0.1900 - val_loss: 0.2248 - val_output_1_loss: 0.2241\n",
      "Epoch 67/100\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2469 - output_1_loss: 0.2463 - val_loss: 0.2076 - val_output_1_loss: 0.2069\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5113 - output_1_loss: 0.5108 - val_loss: 0.5430 - val_output_1_loss: 0.5419\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2084 - output_1_loss: 0.2077Epoch 39/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.2084 - output_1_loss: 0.2077 - val_loss: 0.1991 - val_output_1_loss: 0.1984\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4838 - output_1_loss: 0.4833 - val_loss: 0.5336 - val_output_1_loss: 0.5325\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1799 - output_1_loss: 0.1793Epoch 40/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1799 - output_1_loss: 0.1793 - val_loss: 0.1863 - val_output_1_loss: 0.1856\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5278 - output_1_loss: 0.5274 - val_loss: 0.5295 - val_output_1_loss: 0.5284\n",
      "Epoch 41/100\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4186 - output_1_loss: 0.4181 - val_loss: 0.5195 - val_output_1_loss: 0.5185\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2037 - output_1_loss: 0.2030 - val_loss: 0.1829 - val_output_1_loss: 0.1822\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4549 - output_1_loss: 0.4544Epoch 71/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4549 - output_1_loss: 0.4544 - val_loss: 0.5058 - val_output_1_loss: 0.5048\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2140 - output_1_loss: 0.2133 - val_loss: 0.1923 - val_output_1_loss: 0.1916\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.3894 - output_1_loss: 0.3889 - val_loss: 0.4934 - val_output_1_loss: 0.4924\n",
      "Epoch 44/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3968 - output_1_loss: 0.3963 - val_loss: 0.4893 - val_output_1_loss: 0.4884\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1888 - output_1_loss: 0.1881 - val_loss: 0.1783 - val_output_1_loss: 0.1776\n",
      "Epoch 73/100\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1755 - output_1_loss: 0.1748 - val_loss: 0.1891 - val_output_1_loss: 0.1884\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1887 - output_1_loss: 0.1881 - val_loss: 0.1860 - val_output_1_loss: 0.1853\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4497 - output_1_loss: 0.4492 - val_loss: 0.4868 - val_output_1_loss: 0.4859\n",
      "Epoch 75/100\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2176 - output_1_loss: 0.2170 - val_loss: 0.1883 - val_output_1_loss: 0.1876\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.4323 - output_1_loss: 0.4318 - val_loss: 0.4765 - val_output_1_loss: 0.4757\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2732 - output_1_loss: 0.2725 - val_loss: 0.1545 - val_output_1_loss: 0.1538\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4669 - output_1_loss: 0.4664Epoch 77/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4669 - output_1_loss: 0.4664 - val_loss: 0.4696 - val_output_1_loss: 0.4687\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2227 - output_1_loss: 0.2220Epoch 48/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2227 - output_1_loss: 0.2220 - val_loss: 0.1648 - val_output_1_loss: 0.1640\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4109 - output_1_loss: 0.4104 - val_loss: 0.4589 - val_output_1_loss: 0.4581\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1826 - output_1_loss: 0.1819 - val_loss: 0.1437 - val_output_1_loss: 0.1430\n",
      "Epoch 79/100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1628 - output_1_loss: 0.1621 - val_loss: 0.1463 - val_output_1_loss: 0.1456\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4048 - output_1_loss: 0.4043 - val_loss: 0.4516 - val_output_1_loss: 0.4507\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1769 - output_1_loss: 0.1762 - val_loss: 0.1450 - val_output_1_loss: 0.1443\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3866 - output_1_loss: 0.3861 - val_loss: 0.4372 - val_output_1_loss: 0.4364\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2138 - output_1_loss: 0.2131 - val_loss: 0.1388 - val_output_1_loss: 0.1380\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3367 - output_1_loss: 0.3362 - val_loss: 0.4402 - val_output_1_loss: 0.4394\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1554 - output_1_loss: 0.1547Epoch 52/100\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.1554 - output_1_loss: 0.1547 - val_loss: 0.1300 - val_output_1_loss: 0.1292\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.3771 - output_1_loss: 0.3766 - val_loss: 0.4293 - val_output_1_loss: 0.4286\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.2039 - output_1_loss: 0.2032 - val_loss: 0.1259 - val_output_1_loss: 0.1252\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3837 - output_1_loss: 0.3832 - val_loss: 0.4461 - val_output_1_loss: 0.4453\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1572 - output_1_loss: 0.1565 - val_loss: 0.1400 - val_output_1_loss: 0.1393\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3638 - output_1_loss: 0.3633Epoch 85/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3638 - output_1_loss: 0.3633 - val_loss: 0.4375 - val_output_1_loss: 0.4368\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1718 - output_1_loss: 0.1712 - val_loss: 0.1392 - val_output_1_loss: 0.1385\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4002 - output_1_loss: 0.3997 - val_loss: 0.4297 - val_output_1_loss: 0.4290\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1671 - output_1_loss: 0.1664 - val_loss: 0.1364 - val_output_1_loss: 0.1357\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1324 - output_1_loss: 0.1317 - val_loss: 0.1363 - val_output_1_loss: 0.1356\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.3675 - output_1_loss: 0.3671 - val_loss: 0.4273 - val_output_1_loss: 0.4265\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.4536 - output_1_loss: 0.4532 - val_loss: 0.4234 - val_output_1_loss: 0.4227\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.2338 - output_1_loss: 0.2332 - val_loss: 0.1458 - val_output_1_loss: 0.1451\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4183 - output_1_loss: 0.4179 - val_loss: 0.4151 - val_output_1_loss: 0.4144\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.4106 - output_1_loss: 0.4101 - val_loss: 0.4095 - val_output_1_loss: 0.4089\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3522 - output_1_loss: 0.3517 - val_loss: 0.4007 - val_output_1_loss: 0.4000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4265 - output_1_loss: 0.4260 - val_loss: 0.3898 - val_output_1_loss: 0.3891\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.4132 - output_1_loss: 0.4128 - val_loss: 0.3855 - val_output_1_loss: 0.3849\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.3131 - output_1_loss: 0.3126 - val_loss: 0.3729 - val_output_1_loss: 0.3722\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.3217 - output_1_loss: 0.3212 - val_loss: 0.3612 - val_output_1_loss: 0.3605\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3280 - output_1_loss: 0.3275 - val_loss: 0.3524 - val_output_1_loss: 0.3518\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3020 - output_1_loss: 0.3016 - val_loss: 0.3478 - val_output_1_loss: 0.3472\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:31:50,792]\u001b[0m Trial 77 finished with value: 0.05 and parameters: {'feature_dim': 64, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 2.2, 'sparsity_coefficient': 0.0005918221898844971, 'bn_momentum': 0.9203023586002974}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 385ms/step - loss: 0.3315 - output_1_loss: 0.3310 - val_loss: 0.3345 - val_output_1_loss: 0.3338\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3585 - output_1_loss: 0.3580 - val_loss: 0.3446 - val_output_1_loss: 0.3439\n",
      "Epoch 69/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2832 - output_1_loss: 0.2827 - val_loss: 0.3358 - val_output_1_loss: 0.3351\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.3209 - output_1_loss: 0.3204 - val_loss: 0.3304 - val_output_1_loss: 0.3297\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.2814 - output_1_loss: 0.2809 - val_loss: 0.3103 - val_output_1_loss: 0.3096\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.2676 - output_1_loss: 0.2671 - val_loss: 0.2931 - val_output_1_loss: 0.2924\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3130 - output_1_loss: 0.3125 - val_loss: 0.2838 - val_output_1_loss: 0.2831\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.2930 - output_1_loss: 0.2925 - val_loss: 0.2743 - val_output_1_loss: 0.2736\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.2458 - output_1_loss: 0.2453 - val_loss: 0.2469 - val_output_1_loss: 0.2463\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.3026 - output_1_loss: 0.3021 - val_loss: 0.2361 - val_output_1_loss: 0.2354\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2492 - output_1_loss: 0.2487 - val_loss: 0.2524 - val_output_1_loss: 0.2517\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.3841 - output_1_loss: 0.3836 - val_loss: 0.2542 - val_output_1_loss: 0.2535\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.2643 - output_1_loss: 0.2639 - val_loss: 0.2488 - val_output_1_loss: 0.2482\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2888 - output_1_loss: 0.2884 - val_loss: 0.2482 - val_output_1_loss: 0.2476\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2808 - output_1_loss: 0.2804 - val_loss: 0.2512 - val_output_1_loss: 0.2506\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:31:58,288]\u001b[0m Trial 78 finished with value: 0.012195121951219513 and parameters: {'feature_dim': 64, 'n_step': 5, 'n_shared': 4, 'relaxation_factor': 2.2, 'sparsity_coefficient': 0.00047802737605358954, 'bn_momentum': 0.9180139313799557}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.6980 - output_1_loss: 0.6975 - val_loss: 0.6859 - val_output_1_loss: 0.6844\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6606 - output_1_loss: 0.6601 - val_loss: 0.6769 - val_output_1_loss: 0.6755\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.6497 - output_1_loss: 0.6493 - val_loss: 0.6685 - val_output_1_loss: 0.6673\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.5428 - output_1_loss: 0.5424 - val_loss: 0.6594 - val_output_1_loss: 0.6582\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.5465 - output_1_loss: 0.5460 - val_loss: 0.6524 - val_output_1_loss: 0.6513\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.3812 - output_1_loss: 0.3808 - val_loss: 0.6403 - val_output_1_loss: 0.6392\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.3163 - output_1_loss: 0.3160 - val_loss: 0.6292 - val_output_1_loss: 0.6281\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1876 - output_1_loss: 0.1873 - val_loss: 0.6142 - val_output_1_loss: 0.6132\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1630 - output_1_loss: 0.1626 - val_loss: 0.6006 - val_output_1_loss: 0.5996\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1316 - output_1_loss: 0.1313 - val_loss: 0.5856 - val_output_1_loss: 0.5846\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0956 - output_1_loss: 0.0952 - val_loss: 0.5698 - val_output_1_loss: 0.5689\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0863 - output_1_loss: 0.0860 - val_loss: 0.5531 - val_output_1_loss: 0.5522\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0802 - output_1_loss: 0.0799 - val_loss: 0.5349 - val_output_1_loss: 0.5340\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0920 - output_1_loss: 0.0917 - val_loss: 0.5188 - val_output_1_loss: 0.5179\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0839 - output_1_loss: 0.0836 - val_loss: 0.5026 - val_output_1_loss: 0.5018\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0977 - output_1_loss: 0.0974 - val_loss: 0.4906 - val_output_1_loss: 0.4898\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.0937 - output_1_loss: 0.0934 - val_loss: 0.4804 - val_output_1_loss: 0.4797\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0908 - output_1_loss: 0.0905 - val_loss: 0.4649 - val_output_1_loss: 0.4642\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0858 - output_1_loss: 0.0855 - val_loss: 0.4481 - val_output_1_loss: 0.4474\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0926 - output_1_loss: 0.0923 - val_loss: 0.4363 - val_output_1_loss: 0.4356\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1628 - output_1_loss: 0.1625 - val_loss: 0.4231 - val_output_1_loss: 0.4224\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0837 - output_1_loss: 0.0834 - val_loss: 0.4056 - val_output_1_loss: 0.4050\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.7339 - output_1_loss: 0.6958 - val_loss: 0.8059 - val_output_1_loss: 0.6844\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0898 - output_1_loss: 0.0895 - val_loss: 0.3893 - val_output_1_loss: 0.3888\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6403 - output_1_loss: 0.6006 - val_loss: 0.7877 - val_output_1_loss: 0.6752\n",
      "Epoch 3/100\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0888 - output_1_loss: 0.0885 - val_loss: 0.3737 - val_output_1_loss: 0.3732\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6290 - output_1_loss: 0.5888 - val_loss: 0.7717 - val_output_1_loss: 0.6659\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5554 - output_1_loss: 0.5200Epoch 25/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.5554 - output_1_loss: 0.5200 - val_loss: 0.7532 - val_output_1_loss: 0.6569\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0837 - output_1_loss: 0.0834 - val_loss: 0.3674 - val_output_1_loss: 0.3669\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0683 - output_1_loss: 0.0681Epoch 5/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0683 - output_1_loss: 0.0681 - val_loss: 0.3562 - val_output_1_loss: 0.3557\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4908 - output_1_loss: 0.4518 - val_loss: 0.7351 - val_output_1_loss: 0.6457\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0665 - output_1_loss: 0.0662 - val_loss: 0.3453 - val_output_1_loss: 0.3448\n",
      "Epoch 28/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0962 - output_1_loss: 0.0959 - val_loss: 0.3318 - val_output_1_loss: 0.3313\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2797 - output_1_loss: 0.2436 - val_loss: 0.7150 - val_output_1_loss: 0.6288\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2221 - output_1_loss: 0.1875Epoch 29/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2221 - output_1_loss: 0.1875 - val_loss: 0.6897 - val_output_1_loss: 0.6074\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0670 - output_1_loss: 0.0667 - val_loss: 0.3225 - val_output_1_loss: 0.3221\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.1770 - output_1_loss: 0.1450 - val_loss: 0.6586 - val_output_1_loss: 0.5811\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1306 - output_1_loss: 0.1003Epoch 30/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1306 - output_1_loss: 0.1003 - val_loss: 0.6248 - val_output_1_loss: 0.5515\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0734 - output_1_loss: 0.0732 - val_loss: 0.3133 - val_output_1_loss: 0.3129\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1183 - output_1_loss: 0.0882Epoch 31/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1183 - output_1_loss: 0.0882 - val_loss: 0.5868 - val_output_1_loss: 0.5165\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0750 - output_1_loss: 0.0747 - val_loss: 0.3049 - val_output_1_loss: 0.3045\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1166 - output_1_loss: 0.0878 - val_loss: 0.5529 - val_output_1_loss: 0.4849\n",
      "Epoch 12/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0773 - output_1_loss: 0.0770 - val_loss: 0.2973 - val_output_1_loss: 0.2968\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1136 - output_1_loss: 0.0848 - val_loss: 0.5176 - val_output_1_loss: 0.4521\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1085 - output_1_loss: 0.0810 - val_loss: 0.4797 - val_output_1_loss: 0.4164\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0782 - output_1_loss: 0.0779 - val_loss: 0.2902 - val_output_1_loss: 0.2898\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0742 - output_1_loss: 0.0739Epoch 14/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0742 - output_1_loss: 0.0739 - val_loss: 0.2838 - val_output_1_loss: 0.2833\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1022 - output_1_loss: 0.0755 - val_loss: 0.4462 - val_output_1_loss: 0.3840\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0981 - output_1_loss: 0.0712Epoch 35/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0981 - output_1_loss: 0.0712 - val_loss: 0.4165 - val_output_1_loss: 0.3550\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0724 - output_1_loss: 0.0721 - val_loss: 0.2781 - val_output_1_loss: 0.2777\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0697 - output_1_loss: 0.0694Epoch 16/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0697 - output_1_loss: 0.0694 - val_loss: 0.2731 - val_output_1_loss: 0.2727\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0932 - output_1_loss: 0.0671 - val_loss: 0.3895 - val_output_1_loss: 0.3286\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0894 - output_1_loss: 0.0634Epoch 37/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0894 - output_1_loss: 0.0634 - val_loss: 0.3638 - val_output_1_loss: 0.3035\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0627 - output_1_loss: 0.0624Epoch 18/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0627 - output_1_loss: 0.0624 - val_loss: 0.2679 - val_output_1_loss: 0.2674\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0906 - output_1_loss: 0.0654 - val_loss: 0.3416 - val_output_1_loss: 0.2820\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0692 - output_1_loss: 0.0689Epoch 19/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0692 - output_1_loss: 0.0689 - val_loss: 0.2624 - val_output_1_loss: 0.2620\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0889 - output_1_loss: 0.0642Epoch 39/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0889 - output_1_loss: 0.0642 - val_loss: 0.3223 - val_output_1_loss: 0.2635\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0671 - output_1_loss: 0.0669 - val_loss: 0.2572 - val_output_1_loss: 0.2568\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0601 - output_1_loss: 0.0599Epoch 20/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0601 - output_1_loss: 0.0599 - val_loss: 0.2517 - val_output_1_loss: 0.2513\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0860 - output_1_loss: 0.0622 - val_loss: 0.3042 - val_output_1_loss: 0.2459\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0619 - output_1_loss: 0.0616 - val_loss: 0.2466 - val_output_1_loss: 0.2462\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0836 - output_1_loss: 0.0605 - val_loss: 0.2878 - val_output_1_loss: 0.2300\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0626 - output_1_loss: 0.0623Epoch 22/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0626 - output_1_loss: 0.0623 - val_loss: 0.2421 - val_output_1_loss: 0.2417\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0829 - output_1_loss: 0.0604Epoch 43/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0829 - output_1_loss: 0.0604 - val_loss: 0.2723 - val_output_1_loss: 0.2152\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0635 - output_1_loss: 0.0633 - val_loss: 0.2379 - val_output_1_loss: 0.2375\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0823 - output_1_loss: 0.0602Epoch 44/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0823 - output_1_loss: 0.0602 - val_loss: 0.2598 - val_output_1_loss: 0.2034\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0669 - output_1_loss: 0.0666 - val_loss: 0.2340 - val_output_1_loss: 0.2336\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0810 - output_1_loss: 0.0592Epoch 45/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0810 - output_1_loss: 0.0592 - val_loss: 0.2488 - val_output_1_loss: 0.1931\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0620 - output_1_loss: 0.0617 - val_loss: 0.2305 - val_output_1_loss: 0.2301\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0622 - output_1_loss: 0.0620Epoch 25/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0622 - output_1_loss: 0.0620 - val_loss: 0.2273 - val_output_1_loss: 0.2269\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0793 - output_1_loss: 0.0579 - val_loss: 0.2381 - val_output_1_loss: 0.1833\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0599 - output_1_loss: 0.0596 - val_loss: 0.2249 - val_output_1_loss: 0.2245\n",
      "Epoch 48/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0569 - output_1_loss: 0.0566 - val_loss: 0.2231 - val_output_1_loss: 0.2227\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0766 - output_1_loss: 0.0557 - val_loss: 0.2304 - val_output_1_loss: 0.1764\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0583 - output_1_loss: 0.0580 - val_loss: 0.2208 - val_output_1_loss: 0.2204\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0747 - output_1_loss: 0.0542 - val_loss: 0.2238 - val_output_1_loss: 0.1706\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0730 - output_1_loss: 0.0530Epoch 50/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0730 - output_1_loss: 0.0530 - val_loss: 0.2181 - val_output_1_loss: 0.1656\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0572 - output_1_loss: 0.0570 - val_loss: 0.2180 - val_output_1_loss: 0.2176\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0719 - output_1_loss: 0.0524Epoch 51/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0719 - output_1_loss: 0.0524 - val_loss: 0.2134 - val_output_1_loss: 0.1616\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0585 - output_1_loss: 0.0582 - val_loss: 0.2148 - val_output_1_loss: 0.2144\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0708 - output_1_loss: 0.0519 - val_loss: 0.2093 - val_output_1_loss: 0.1581\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0579 - output_1_loss: 0.0576 - val_loss: 0.2113 - val_output_1_loss: 0.2109\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0690 - output_1_loss: 0.0505 - val_loss: 0.2055 - val_output_1_loss: 0.1550\n",
      "Epoch 32/100\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0677 - output_1_loss: 0.0495 - val_loss: 0.2021 - val_output_1_loss: 0.1523\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0571 - output_1_loss: 0.0569 - val_loss: 0.2078 - val_output_1_loss: 0.2075\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0570 - output_1_loss: 0.0568 - val_loss: 0.2045 - val_output_1_loss: 0.2041\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0660 - output_1_loss: 0.0484 - val_loss: 0.1989 - val_output_1_loss: 0.1497\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0646 - output_1_loss: 0.0474Epoch 55/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0646 - output_1_loss: 0.0474 - val_loss: 0.1958 - val_output_1_loss: 0.1472\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0569 - output_1_loss: 0.0567 - val_loss: 0.2012 - val_output_1_loss: 0.2009\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0632 - output_1_loss: 0.0465 - val_loss: 0.1927 - val_output_1_loss: 0.1448\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0614 - output_1_loss: 0.0449Epoch 56/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0614 - output_1_loss: 0.0449 - val_loss: 0.1897 - val_output_1_loss: 0.1424\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0571 - output_1_loss: 0.0568 - val_loss: 0.1981 - val_output_1_loss: 0.1977\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0572 - output_1_loss: 0.0569Epoch 37/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0572 - output_1_loss: 0.0569 - val_loss: 0.1951 - val_output_1_loss: 0.1947\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0626 - output_1_loss: 0.0458 - val_loss: 0.1868 - val_output_1_loss: 0.1400\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0599 - output_1_loss: 0.0596 - val_loss: 0.1919 - val_output_1_loss: 0.1915\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0616 - output_1_loss: 0.0449 - val_loss: 0.1840 - val_output_1_loss: 0.1377\n",
      "Epoch 39/100\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0596 - output_1_loss: 0.0593 - val_loss: 0.1887 - val_output_1_loss: 0.1883\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0609 - output_1_loss: 0.0443 - val_loss: 0.1814 - val_output_1_loss: 0.1356\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0591 - output_1_loss: 0.0588 - val_loss: 0.1856 - val_output_1_loss: 0.1853\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0599 - output_1_loss: 0.0435 - val_loss: 0.1788 - val_output_1_loss: 0.1334\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0588 - output_1_loss: 0.0585 - val_loss: 0.1826 - val_output_1_loss: 0.1823\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0594 - output_1_loss: 0.0432 - val_loss: 0.1761 - val_output_1_loss: 0.1313\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0582 - output_1_loss: 0.0579Epoch 42/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0582 - output_1_loss: 0.0579 - val_loss: 0.1795 - val_output_1_loss: 0.1791\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0585 - output_1_loss: 0.0426 - val_loss: 0.1734 - val_output_1_loss: 0.1292\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0574 - output_1_loss: 0.0419Epoch 63/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0574 - output_1_loss: 0.0419 - val_loss: 0.1707 - val_output_1_loss: 0.1271\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0583 - output_1_loss: 0.0581 - val_loss: 0.1761 - val_output_1_loss: 0.1758\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0625 - output_1_loss: 0.0622 - val_loss: 0.1726 - val_output_1_loss: 0.1722\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0569 - output_1_loss: 0.0417 - val_loss: 0.1684 - val_output_1_loss: 0.1255\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0559 - output_1_loss: 0.0409Epoch 65/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0559 - output_1_loss: 0.0409 - val_loss: 0.1660 - val_output_1_loss: 0.1239\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0653 - output_1_loss: 0.0651 - val_loss: 0.1687 - val_output_1_loss: 0.1684\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0663 - output_1_loss: 0.0516 - val_loss: 0.1611 - val_output_1_loss: 0.1196\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0644 - output_1_loss: 0.0642 - val_loss: 0.1647 - val_output_1_loss: 0.1644\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0572 - output_1_loss: 0.0423 - val_loss: 0.1571 - val_output_1_loss: 0.1163\n",
      "Epoch 48/100\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0748 - output_1_loss: 0.0601 - val_loss: 0.1548 - val_output_1_loss: 0.1145\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0633 - output_1_loss: 0.0631 - val_loss: 0.1610 - val_output_1_loss: 0.1607\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0625 - output_1_loss: 0.0623Epoch 49/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0625 - output_1_loss: 0.0623 - val_loss: 0.1575 - val_output_1_loss: 0.1571\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0751 - output_1_loss: 0.0602 - val_loss: 0.1535 - val_output_1_loss: 0.1137\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0611 - output_1_loss: 0.0608 - val_loss: 0.1543 - val_output_1_loss: 0.1539\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0630 - output_1_loss: 0.0475Epoch 70/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0630 - output_1_loss: 0.0475 - val_loss: 0.1523 - val_output_1_loss: 0.1131\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0612 - output_1_loss: 0.0610 - val_loss: 0.1513 - val_output_1_loss: 0.1510\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0623 - output_1_loss: 0.0468 - val_loss: 0.1509 - val_output_1_loss: 0.1125\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0610 - output_1_loss: 0.0608 - val_loss: 0.1491 - val_output_1_loss: 0.1487\n",
      "Epoch 72/100\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0567 - output_1_loss: 0.0565 - val_loss: 0.1469 - val_output_1_loss: 0.1466\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0597 - output_1_loss: 0.0442 - val_loss: 0.1502 - val_output_1_loss: 0.1125\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0565 - output_1_loss: 0.0563 - val_loss: 0.1449 - val_output_1_loss: 0.1446\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0707 - output_1_loss: 0.0551 - val_loss: 0.1496 - val_output_1_loss: 0.1127\n",
      "Epoch 74/100\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0562 - output_1_loss: 0.0560 - val_loss: 0.1429 - val_output_1_loss: 0.1425\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0706 - output_1_loss: 0.0553 - val_loss: 0.1492 - val_output_1_loss: 0.1132\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0559 - output_1_loss: 0.0557 - val_loss: 0.1409 - val_output_1_loss: 0.1405\n",
      "Epoch 55/100\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0682 - output_1_loss: 0.0534 - val_loss: 0.1493 - val_output_1_loss: 0.1140\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0605 - output_1_loss: 0.0602 - val_loss: 0.1388 - val_output_1_loss: 0.1385\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0656 - output_1_loss: 0.0511 - val_loss: 0.1500 - val_output_1_loss: 0.1152\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0622 - output_1_loss: 0.0482Epoch 77/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0622 - output_1_loss: 0.0482 - val_loss: 0.1506 - val_output_1_loss: 0.1163\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0532 - output_1_loss: 0.0396 - val_loss: 0.1514 - val_output_1_loss: 0.1178\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0597 - output_1_loss: 0.0594 - val_loss: 0.1365 - val_output_1_loss: 0.1361\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0524 - output_1_loss: 0.0390 - val_loss: 0.1524 - val_output_1_loss: 0.1193\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0589 - output_1_loss: 0.0586 - val_loss: 0.1335 - val_output_1_loss: 0.1332\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0576 - output_1_loss: 0.0573 - val_loss: 0.1300 - val_output_1_loss: 0.1296\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0654 - output_1_loss: 0.0651 - val_loss: 0.1274 - val_output_1_loss: 0.1270\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0702 - output_1_loss: 0.0699 - val_loss: 0.1275 - val_output_1_loss: 0.1272\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0631 - output_1_loss: 0.0628 - val_loss: 0.1287 - val_output_1_loss: 0.1283\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0628 - output_1_loss: 0.0625 - val_loss: 0.1305 - val_output_1_loss: 0.1301\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0633 - output_1_loss: 0.0630 - val_loss: 0.1315 - val_output_1_loss: 0.1311\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0593 - output_1_loss: 0.0590 - val_loss: 0.1328 - val_output_1_loss: 0.1325\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:32:31,459]\u001b[0m Trial 80 finished with value: 0.08333333333333333 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 0.020218016716579284, 'bn_momentum': 0.9501106395191422}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:32:33,521]\u001b[0m Trial 79 finished with value: 0.058823529411764705 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 2.6, 'sparsity_coefficient': 0.00025610963993493823, 'bn_momentum': 0.9509738104157784}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.7442 - output_1_loss: 0.7440 - val_loss: 0.6900 - val_output_1_loss: 0.6892\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.7414 - output_1_loss: 0.7391 - val_loss: 0.6894 - val_output_1_loss: 0.6826\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.6607 - output_1_loss: 0.6586 - val_loss: 0.6804 - val_output_1_loss: 0.6742\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.6029 - output_1_loss: 0.6007 - val_loss: 0.6681 - val_output_1_loss: 0.6622\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6219 - output_1_loss: 0.6198 - val_loss: 0.6599 - val_output_1_loss: 0.6543\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.5671 - output_1_loss: 0.5651 - val_loss: 0.6482 - val_output_1_loss: 0.6430\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.4519 - output_1_loss: 0.4499 - val_loss: 0.6324 - val_output_1_loss: 0.6274\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.3866 - output_1_loss: 0.3847 - val_loss: 0.6194 - val_output_1_loss: 0.6146\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3974 - output_1_loss: 0.3955 - val_loss: 0.6059 - val_output_1_loss: 0.6012\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3216 - output_1_loss: 0.3196 - val_loss: 0.5926 - val_output_1_loss: 0.5880\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.3014 - output_1_loss: 0.2997 - val_loss: 0.5799 - val_output_1_loss: 0.5755\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1422 - output_1_loss: 0.1407 - val_loss: 0.5642 - val_output_1_loss: 0.5599\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1617 - output_1_loss: 0.1600 - val_loss: 0.5472 - val_output_1_loss: 0.5430\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3436 - output_1_loss: 0.3416 - val_loss: 0.5339 - val_output_1_loss: 0.5298\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.3007 - output_1_loss: 0.2987 - val_loss: 0.5254 - val_output_1_loss: 0.5212\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3891 - output_1_loss: 0.3873 - val_loss: 0.5105 - val_output_1_loss: 0.5064\n",
      "Epoch 16/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1635 - output_1_loss: 0.1618 - val_loss: 0.4875 - val_output_1_loss: 0.4835\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6891 - output_1_loss: 0.6889 - val_loss: 0.6862 - val_output_1_loss: 0.6855\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.2376 - output_1_loss: 0.2359 - val_loss: 0.4731 - val_output_1_loss: 0.4692\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.7278 - output_1_loss: 0.7275 - val_loss: 0.6811 - val_output_1_loss: 0.6804\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2101 - output_1_loss: 0.2086Epoch 4/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2101 - output_1_loss: 0.2086 - val_loss: 0.4520 - val_output_1_loss: 0.4481\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.7210 - output_1_loss: 0.7208 - val_loss: 0.6768 - val_output_1_loss: 0.6761\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.1649 - output_1_loss: 0.1634 - val_loss: 0.4159 - val_output_1_loss: 0.4122\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6724 - output_1_loss: 0.6722Epoch 20/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6724 - output_1_loss: 0.6722 - val_loss: 0.6733 - val_output_1_loss: 0.6726\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1002 - output_1_loss: 0.0987 - val_loss: 0.3837 - val_output_1_loss: 0.3801\n",
      "Epoch 21/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6622 - output_1_loss: 0.6620 - val_loss: 0.6685 - val_output_1_loss: 0.6679\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0948 - output_1_loss: 0.0933 - val_loss: 0.3501 - val_output_1_loss: 0.3465\n",
      "Epoch 22/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1150 - output_1_loss: 0.1135 - val_loss: 0.3227 - val_output_1_loss: 0.3192\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6437 - output_1_loss: 0.6434 - val_loss: 0.6632 - val_output_1_loss: 0.6626\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1269 - output_1_loss: 0.1253Epoch 8/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.1269 - output_1_loss: 0.1253 - val_loss: 0.2999 - val_output_1_loss: 0.2963\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.6167 - output_1_loss: 0.6165 - val_loss: 0.6592 - val_output_1_loss: 0.6586\n",
      "Epoch 9/100\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6134 - output_1_loss: 0.6132 - val_loss: 0.6543 - val_output_1_loss: 0.6538\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.1169 - output_1_loss: 0.1151 - val_loss: 0.2803 - val_output_1_loss: 0.2769\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6049 - output_1_loss: 0.6047 - val_loss: 0.6505 - val_output_1_loss: 0.6500\n",
      "Epoch 11/100\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.5630 - output_1_loss: 0.5628 - val_loss: 0.6458 - val_output_1_loss: 0.6453\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0839 - output_1_loss: 0.0822 - val_loss: 0.2543 - val_output_1_loss: 0.2509\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5714 - output_1_loss: 0.5712Epoch 26/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5714 - output_1_loss: 0.5712 - val_loss: 0.6410 - val_output_1_loss: 0.6405\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0873 - output_1_loss: 0.0857 - val_loss: 0.2356 - val_output_1_loss: 0.2322\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5398 - output_1_loss: 0.5396Epoch 27/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.5398 - output_1_loss: 0.5396 - val_loss: 0.6381 - val_output_1_loss: 0.6376\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1255 - output_1_loss: 0.1239 - val_loss: 0.2120 - val_output_1_loss: 0.2087\n",
      "Epoch 28/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.5767 - output_1_loss: 0.5765 - val_loss: 0.6346 - val_output_1_loss: 0.6341\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0749 - output_1_loss: 0.0733 - val_loss: 0.1928 - val_output_1_loss: 0.1896\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4889 - output_1_loss: 0.4887 - val_loss: 0.6299 - val_output_1_loss: 0.6294\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1001 - output_1_loss: 0.0986 - val_loss: 0.1742 - val_output_1_loss: 0.1710\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.5712 - output_1_loss: 0.5710 - val_loss: 0.6258 - val_output_1_loss: 0.6253\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1040 - output_1_loss: 0.1024 - val_loss: 0.1722 - val_output_1_loss: 0.1691\n",
      "Epoch 31/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0819 - output_1_loss: 0.0804 - val_loss: 0.1534 - val_output_1_loss: 0.1504\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.5407 - output_1_loss: 0.5406 - val_loss: 0.6205 - val_output_1_loss: 0.6200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1398 - output_1_loss: 0.1383Epoch 18/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1398 - output_1_loss: 0.1383 - val_loss: 0.1415 - val_output_1_loss: 0.1385\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.5750 - output_1_loss: 0.5748 - val_loss: 0.6159 - val_output_1_loss: 0.6154\n",
      "Epoch 19/100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5192 - output_1_loss: 0.5190 - val_loss: 0.6114 - val_output_1_loss: 0.6110\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1056 - output_1_loss: 0.1041 - val_loss: 0.1316 - val_output_1_loss: 0.1286\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5300 - output_1_loss: 0.5298 - val_loss: 0.6069 - val_output_1_loss: 0.6065\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0956 - output_1_loss: 0.0941 - val_loss: 0.1296 - val_output_1_loss: 0.1266\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5618 - output_1_loss: 0.5616 - val_loss: 0.6026 - val_output_1_loss: 0.6022\n",
      "Epoch 22/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4917 - output_1_loss: 0.4916 - val_loss: 0.5995 - val_output_1_loss: 0.5991\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1001 - output_1_loss: 0.0986 - val_loss: 0.1193 - val_output_1_loss: 0.1163\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4899 - output_1_loss: 0.4897Epoch 36/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4899 - output_1_loss: 0.4897 - val_loss: 0.5920 - val_output_1_loss: 0.5916\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0811 - output_1_loss: 0.0796Epoch 24/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0811 - output_1_loss: 0.0796 - val_loss: 0.1089 - val_output_1_loss: 0.1060\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4515 - output_1_loss: 0.4513 - val_loss: 0.5866 - val_output_1_loss: 0.5861\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0939 - output_1_loss: 0.0925Epoch 25/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0939 - output_1_loss: 0.0925 - val_loss: 0.1065 - val_output_1_loss: 0.1037\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4306 - output_1_loss: 0.4304Epoch 38/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0837 - output_1_loss: 0.0824 - val_loss: 0.1066 - val_output_1_loss: 0.1038\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4306 - output_1_loss: 0.4304 - val_loss: 0.5780 - val_output_1_loss: 0.5776\n",
      "Epoch 39/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1340 - output_1_loss: 0.1326 - val_loss: 0.1081 - val_output_1_loss: 0.1054\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.4633 - output_1_loss: 0.4632 - val_loss: 0.5712 - val_output_1_loss: 0.5708\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0845 - output_1_loss: 0.0832 - val_loss: 0.1036 - val_output_1_loss: 0.1009\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.4858 - output_1_loss: 0.4856 - val_loss: 0.5662 - val_output_1_loss: 0.5659\n",
      "Epoch 28/100\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4305 - output_1_loss: 0.4303 - val_loss: 0.5589 - val_output_1_loss: 0.5586\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1095 - output_1_loss: 0.1081 - val_loss: 0.0935 - val_output_1_loss: 0.0908\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4049 - output_1_loss: 0.4047Epoch 42/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4049 - output_1_loss: 0.4047 - val_loss: 0.5537 - val_output_1_loss: 0.5534\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0881 - output_1_loss: 0.0868 - val_loss: 0.0844 - val_output_1_loss: 0.0817\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.4736 - output_1_loss: 0.4734 - val_loss: 0.5493 - val_output_1_loss: 0.5489\n",
      "Epoch 31/100\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4245 - output_1_loss: 0.4243 - val_loss: 0.5437 - val_output_1_loss: 0.5434\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0643 - output_1_loss: 0.0629 - val_loss: 0.0815 - val_output_1_loss: 0.0788\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0628 - output_1_loss: 0.0613Epoch 32/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0628 - output_1_loss: 0.0613 - val_loss: 0.0881 - val_output_1_loss: 0.0855\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0688 - output_1_loss: 0.0673 - val_loss: 0.0924 - val_output_1_loss: 0.0898\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.4245 - output_1_loss: 0.4243 - val_loss: 0.5383 - val_output_1_loss: 0.5379\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0687 - output_1_loss: 0.0672 - val_loss: 0.0926 - val_output_1_loss: 0.0901\n",
      "Epoch 47/100\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0662 - output_1_loss: 0.0647 - val_loss: 0.0897 - val_output_1_loss: 0.0871\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4072 - output_1_loss: 0.4071 - val_loss: 0.5288 - val_output_1_loss: 0.5285\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0710 - output_1_loss: 0.0694 - val_loss: 0.0868 - val_output_1_loss: 0.0843\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.3718 - output_1_loss: 0.3716 - val_loss: 0.5200 - val_output_1_loss: 0.5197\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.3657 - output_1_loss: 0.3655 - val_loss: 0.5105 - val_output_1_loss: 0.5102\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.3642 - output_1_loss: 0.3640 - val_loss: 0.5015 - val_output_1_loss: 0.5012\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3594 - output_1_loss: 0.3593 - val_loss: 0.4934 - val_output_1_loss: 0.4931\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.3154 - output_1_loss: 0.3152 - val_loss: 0.4834 - val_output_1_loss: 0.4831\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.3156 - output_1_loss: 0.3154 - val_loss: 0.4748 - val_output_1_loss: 0.4745\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2684 - output_1_loss: 0.2682 - val_loss: 0.4648 - val_output_1_loss: 0.4645\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3710 - output_1_loss: 0.3709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:33:12,099]\u001b[0m Trial 81 finished with value: 0.3333333333333333 and parameters: {'feature_dim': 256, 'n_step': 4, 'n_shared': 2, 'relaxation_factor': 1.7000000000000002, 'sparsity_coefficient': 0.0011992246343041813, 'bn_momentum': 0.9107518944145984}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.3710 - output_1_loss: 0.3709 - val_loss: 0.4550 - val_output_1_loss: 0.4547\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.3722 - output_1_loss: 0.3721 - val_loss: 0.4434 - val_output_1_loss: 0.4431\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3093 - output_1_loss: 0.3091Epoch 1/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.3093 - output_1_loss: 0.3091 - val_loss: 0.4338 - val_output_1_loss: 0.4335\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.2529 - output_1_loss: 0.2527 - val_loss: 0.4228 - val_output_1_loss: 0.4225\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.2764 - output_1_loss: 0.2762 - val_loss: 0.4149 - val_output_1_loss: 0.4146\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.2806 - output_1_loss: 0.2804 - val_loss: 0.4106 - val_output_1_loss: 0.4103\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.2783 - output_1_loss: 0.2781 - val_loss: 0.4043 - val_output_1_loss: 0.4040\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.3378 - output_1_loss: 0.3377 - val_loss: 0.3983 - val_output_1_loss: 0.3981\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.3584 - output_1_loss: 0.3582 - val_loss: 0.3900 - val_output_1_loss: 0.3897\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.2276 - output_1_loss: 0.2274 - val_loss: 0.3780 - val_output_1_loss: 0.3777\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.2743 - output_1_loss: 0.2741 - val_loss: 0.3722 - val_output_1_loss: 0.3719\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.3118 - output_1_loss: 0.3116 - val_loss: 0.3664 - val_output_1_loss: 0.3662\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2840 - output_1_loss: 0.2839 - val_loss: 0.3587 - val_output_1_loss: 0.3584\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.2494 - output_1_loss: 0.2492 - val_loss: 0.3525 - val_output_1_loss: 0.3522\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2201 - output_1_loss: 0.2199 - val_loss: 0.3481 - val_output_1_loss: 0.3478\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1836 - output_1_loss: 0.1834 - val_loss: 0.3402 - val_output_1_loss: 0.3399\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.1602 - output_1_loss: 0.1600 - val_loss: 0.3216 - val_output_1_loss: 0.3213\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1871 - output_1_loss: 0.1870 - val_loss: 0.3130 - val_output_1_loss: 0.3127\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.1308 - output_1_loss: 0.1306 - val_loss: 0.2997 - val_output_1_loss: 0.2994\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1194 - output_1_loss: 0.1193 - val_loss: 0.2908 - val_output_1_loss: 0.2906\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1273 - output_1_loss: 0.1271 - val_loss: 0.2825 - val_output_1_loss: 0.2822\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1806 - output_1_loss: 0.1804 - val_loss: 0.2718 - val_output_1_loss: 0.2715\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1423 - output_1_loss: 0.1422 - val_loss: 0.2676 - val_output_1_loss: 0.2673\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1843 - output_1_loss: 0.1842 - val_loss: 0.2668 - val_output_1_loss: 0.2665\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1511 - output_1_loss: 0.1509 - val_loss: 0.2571 - val_output_1_loss: 0.2569\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.1105 - output_1_loss: 0.1103 - val_loss: 0.2434 - val_output_1_loss: 0.2431\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.1245 - output_1_loss: 0.1243 - val_loss: 0.2218 - val_output_1_loss: 0.2215\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1095 - output_1_loss: 0.1094 - val_loss: 0.2042 - val_output_1_loss: 0.2040\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0968 - output_1_loss: 0.0966 - val_loss: 0.1886 - val_output_1_loss: 0.1883\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0845 - output_1_loss: 0.0844 - val_loss: 0.1724 - val_output_1_loss: 0.1721\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0933 - output_1_loss: 0.0932 - val_loss: 0.1592 - val_output_1_loss: 0.1590\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0909 - output_1_loss: 0.0907 - val_loss: 0.1472 - val_output_1_loss: 0.1469\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0936 - output_1_loss: 0.0934 - val_loss: 0.1397 - val_output_1_loss: 0.1395\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0810 - output_1_loss: 0.0809 - val_loss: 0.1295 - val_output_1_loss: 0.1293\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0821 - output_1_loss: 0.0819 - val_loss: 0.1200 - val_output_1_loss: 0.1198\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0831 - output_1_loss: 0.0830 - val_loss: 0.1107 - val_output_1_loss: 0.1105\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0787 - output_1_loss: 0.0786 - val_loss: 0.1015 - val_output_1_loss: 0.1013\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0891 - output_1_loss: 0.0889 - val_loss: 0.0986 - val_output_1_loss: 0.0984\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1172 - output_1_loss: 0.1170 - val_loss: 0.0969 - val_output_1_loss: 0.0967\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1268 - output_1_loss: 0.1266 - val_loss: 0.0926 - val_output_1_loss: 0.0924\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1087 - output_1_loss: 0.1085 - val_loss: 0.0877 - val_output_1_loss: 0.0875\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0819 - output_1_loss: 0.0817 - val_loss: 0.0837 - val_output_1_loss: 0.0835\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0813 - output_1_loss: 0.0811 - val_loss: 0.0802 - val_output_1_loss: 0.0800\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0785 - output_1_loss: 0.0783 - val_loss: 0.0787 - val_output_1_loss: 0.0786\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1086 - output_1_loss: 0.1085 - val_loss: 0.0762 - val_output_1_loss: 0.0761\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1203 - output_1_loss: 0.1201 - val_loss: 0.0750 - val_output_1_loss: 0.0748\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0950 - output_1_loss: 0.0948 - val_loss: 0.0751 - val_output_1_loss: 0.0749\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1042 - output_1_loss: 0.1040 - val_loss: 0.0783 - val_output_1_loss: 0.0781\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1012 - output_1_loss: 0.1010 - val_loss: 0.0803 - val_output_1_loss: 0.0801\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1043 - output_1_loss: 0.1041 - val_loss: 0.0834 - val_output_1_loss: 0.0832\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0928 - output_1_loss: 0.0926 - val_loss: 0.0823 - val_output_1_loss: 0.0821\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:33:30,708]\u001b[0m Trial 82 finished with value: 0.5 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.00013843956896171202, 'bn_momentum': 0.9419033012760172}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 18s 18s/step - loss: 0.7142 - output_1_loss: 0.7140 - val_loss: 0.6896 - val_output_1_loss: 0.6891\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6812 - output_1_loss: 0.6810 - val_loss: 0.6860 - val_output_1_loss: 0.6855\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6444 - output_1_loss: 0.6443Epoch 1/100\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.6444 - output_1_loss: 0.6443 - val_loss: 0.6814 - val_output_1_loss: 0.6809\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.6641 - output_1_loss: 0.6640 - val_loss: 0.6775 - val_output_1_loss: 0.6770\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.6799 - output_1_loss: 0.6798 - val_loss: 0.6729 - val_output_1_loss: 0.6725\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.6215 - output_1_loss: 0.6213 - val_loss: 0.6681 - val_output_1_loss: 0.6677\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.6320 - output_1_loss: 0.6318 - val_loss: 0.6649 - val_output_1_loss: 0.6645\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.6261 - output_1_loss: 0.6259 - val_loss: 0.6610 - val_output_1_loss: 0.6606\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5978 - output_1_loss: 0.5976 - val_loss: 0.6577 - val_output_1_loss: 0.6573\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.5569 - output_1_loss: 0.5567 - val_loss: 0.6539 - val_output_1_loss: 0.6535\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.6009 - output_1_loss: 0.6008 - val_loss: 0.6498 - val_output_1_loss: 0.6494\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.5350 - output_1_loss: 0.5348 - val_loss: 0.6449 - val_output_1_loss: 0.6445\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.5301 - output_1_loss: 0.5299 - val_loss: 0.6397 - val_output_1_loss: 0.6393\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.5408 - output_1_loss: 0.5407 - val_loss: 0.6344 - val_output_1_loss: 0.6340\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5366 - output_1_loss: 0.5364 - val_loss: 0.6302 - val_output_1_loss: 0.6299\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5530 - output_1_loss: 0.5528 - val_loss: 0.6259 - val_output_1_loss: 0.6255\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5253 - output_1_loss: 0.5251 - val_loss: 0.6210 - val_output_1_loss: 0.6206\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.5193 - output_1_loss: 0.5192 - val_loss: 0.6156 - val_output_1_loss: 0.6153\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4907 - output_1_loss: 0.4905 - val_loss: 0.6105 - val_output_1_loss: 0.6102\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.4845 - output_1_loss: 0.4844 - val_loss: 0.6060 - val_output_1_loss: 0.6057\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.4881 - output_1_loss: 0.4879 - val_loss: 0.6001 - val_output_1_loss: 0.5998\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.4687 - output_1_loss: 0.4685 - val_loss: 0.5934 - val_output_1_loss: 0.5931\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.4704 - output_1_loss: 0.4702 - val_loss: 0.5876 - val_output_1_loss: 0.5873\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4678 - output_1_loss: 0.4676 - val_loss: 0.5819 - val_output_1_loss: 0.5816\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.4167 - output_1_loss: 0.4165 - val_loss: 0.5756 - val_output_1_loss: 0.5753\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.4368 - output_1_loss: 0.4367 - val_loss: 0.5712 - val_output_1_loss: 0.5708\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.3882 - output_1_loss: 0.3880 - val_loss: 0.5631 - val_output_1_loss: 0.5627\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.4054 - output_1_loss: 0.4053 - val_loss: 0.5537 - val_output_1_loss: 0.5534\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3514 - output_1_loss: 0.3512 - val_loss: 0.5461 - val_output_1_loss: 0.5459\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3321 - output_1_loss: 0.3319 - val_loss: 0.5388 - val_output_1_loss: 0.5385\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3346 - output_1_loss: 0.3345 - val_loss: 0.5317 - val_output_1_loss: 0.5314\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2439 - output_1_loss: 0.2437 - val_loss: 0.5219 - val_output_1_loss: 0.5216\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2635 - output_1_loss: 0.2633 - val_loss: 0.5115 - val_output_1_loss: 0.5113\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2290 - output_1_loss: 0.2289 - val_loss: 0.4974 - val_output_1_loss: 0.4971\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2457 - output_1_loss: 0.2456 - val_loss: 0.4856 - val_output_1_loss: 0.4853\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2492 - output_1_loss: 0.2490 - val_loss: 0.4739 - val_output_1_loss: 0.4736\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2791 - output_1_loss: 0.2790 - val_loss: 0.4604 - val_output_1_loss: 0.4601\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2004 - output_1_loss: 0.2003 - val_loss: 0.4477 - val_output_1_loss: 0.4475\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2220 - output_1_loss: 0.2218 - val_loss: 0.4353 - val_output_1_loss: 0.4350\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2125 - output_1_loss: 0.2123 - val_loss: 0.4227 - val_output_1_loss: 0.4224\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1627 - output_1_loss: 0.1625 - val_loss: 0.4120 - val_output_1_loss: 0.4117\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.1583 - output_1_loss: 0.1582 - val_loss: 0.3993 - val_output_1_loss: 0.3991\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.2015 - output_1_loss: 0.2014 - val_loss: 0.3913 - val_output_1_loss: 0.3911\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1626 - output_1_loss: 0.1625 - val_loss: 0.3843 - val_output_1_loss: 0.3840\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1509 - output_1_loss: 0.1508 - val_loss: 0.3762 - val_output_1_loss: 0.3760\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1538 - output_1_loss: 0.1537 - val_loss: 0.3687 - val_output_1_loss: 0.3685\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1177 - output_1_loss: 0.1176 - val_loss: 0.3615 - val_output_1_loss: 0.3612\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1252 - output_1_loss: 0.1250 - val_loss: 0.3559 - val_output_1_loss: 0.3557\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1309 - output_1_loss: 0.1308 - val_loss: 0.3479 - val_output_1_loss: 0.3476\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1016 - output_1_loss: 0.1014 - val_loss: 0.3379 - val_output_1_loss: 0.3377\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0947 - output_1_loss: 0.0946 - val_loss: 0.3267 - val_output_1_loss: 0.3265\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0974 - output_1_loss: 0.0973 - val_loss: 0.3153 - val_output_1_loss: 0.3151\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0939 - output_1_loss: 0.0938 - val_loss: 0.3048 - val_output_1_loss: 0.3046\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 1.0600 - output_1_loss: 1.0598 - val_loss: 0.6904 - val_output_1_loss: 0.6897\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1115 - output_1_loss: 0.1113 - val_loss: 0.2934 - val_output_1_loss: 0.2932\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0914 - output_1_loss: 0.0913 - val_loss: 0.2816 - val_output_1_loss: 0.2813\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0826 - output_1_loss: 0.0825 - val_loss: 0.2687 - val_output_1_loss: 0.2685\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1127 - output_1_loss: 0.1125 - val_loss: 0.2577 - val_output_1_loss: 0.2575\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0984 - output_1_loss: 0.0983 - val_loss: 0.2473 - val_output_1_loss: 0.2471\n",
      "Epoch 59/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0901 - output_1_loss: 0.0900 - val_loss: 0.2395 - val_output_1_loss: 0.2392\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.8531 - output_1_loss: 0.8529 - val_loss: 0.6869 - val_output_1_loss: 0.6863\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9084 - output_1_loss: 0.9082Epoch 60/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.9084 - output_1_loss: 0.9082 - val_loss: 0.6841 - val_output_1_loss: 0.6835\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0896 - output_1_loss: 0.0894Epoch 4/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0896 - output_1_loss: 0.0894 - val_loss: 0.2326 - val_output_1_loss: 0.2324\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.9431 - output_1_loss: 0.9429 - val_loss: 0.6810 - val_output_1_loss: 0.6804\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1044 - output_1_loss: 0.1043 - val_loss: 0.2286 - val_output_1_loss: 0.2284\n",
      "Epoch 62/100\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1036 - output_1_loss: 0.1035 - val_loss: 0.2194 - val_output_1_loss: 0.2192\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.9017 - output_1_loss: 0.9015 - val_loss: 0.6776 - val_output_1_loss: 0.6771\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1316 - output_1_loss: 0.1314 - val_loss: 0.2135 - val_output_1_loss: 0.2133\n",
      "Epoch 6/100\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0934 - output_1_loss: 0.0932 - val_loss: 0.2102 - val_output_1_loss: 0.2100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.8898 - output_1_loss: 0.8896 - val_loss: 0.6736 - val_output_1_loss: 0.6731\n",
      "Epoch 65/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.7781 - output_1_loss: 0.7779 - val_loss: 0.6696 - val_output_1_loss: 0.6691\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1024 - output_1_loss: 0.1023 - val_loss: 0.2069 - val_output_1_loss: 0.2067\n",
      "Epoch 66/100\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0958 - output_1_loss: 0.0956 - val_loss: 0.2007 - val_output_1_loss: 0.2005\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.8694 - output_1_loss: 0.8692 - val_loss: 0.6654 - val_output_1_loss: 0.6650\n",
      "Epoch 9/100\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7970 - output_1_loss: 0.7969 - val_loss: 0.6608 - val_output_1_loss: 0.6603\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1287 - output_1_loss: 0.1285 - val_loss: 0.1917 - val_output_1_loss: 0.1915\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.8125 - output_1_loss: 0.8124 - val_loss: 0.6565 - val_output_1_loss: 0.6560\n",
      "Epoch 11/100\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7761 - output_1_loss: 0.7760 - val_loss: 0.6530 - val_output_1_loss: 0.6526\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0930 - output_1_loss: 0.0929 - val_loss: 0.1868 - val_output_1_loss: 0.1866\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1012 - output_1_loss: 0.1011 - val_loss: 0.1872 - val_output_1_loss: 0.1870\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.7786 - output_1_loss: 0.7785 - val_loss: 0.6499 - val_output_1_loss: 0.6495\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1167 - output_1_loss: 0.1166Epoch 13/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1167 - output_1_loss: 0.1166 - val_loss: 0.1714 - val_output_1_loss: 0.1713\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7533 - output_1_loss: 0.7531 - val_loss: 0.6461 - val_output_1_loss: 0.6457\n",
      "Epoch 14/100\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7257 - output_1_loss: 0.7256 - val_loss: 0.6411 - val_output_1_loss: 0.6407\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0890 - output_1_loss: 0.0888Epoch 15/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.0890 - output_1_loss: 0.0888 - val_loss: 0.1514 - val_output_1_loss: 0.1513\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.7017 - output_1_loss: 0.7016 - val_loss: 0.6380 - val_output_1_loss: 0.6376\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1332 - output_1_loss: 0.1331 - val_loss: 0.1516 - val_output_1_loss: 0.1515\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0815 - output_1_loss: 0.0814Epoch 16/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0815 - output_1_loss: 0.0814 - val_loss: 0.1462 - val_output_1_loss: 0.1461\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6790 - output_1_loss: 0.6789 - val_loss: 0.6336 - val_output_1_loss: 0.6332\n",
      "Epoch 17/100\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6240 - output_1_loss: 0.6238 - val_loss: 0.6290 - val_output_1_loss: 0.6286\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0826 - output_1_loss: 0.0825 - val_loss: 0.1403 - val_output_1_loss: 0.1401\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1748 - output_1_loss: 0.1747Epoch 18/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1748 - output_1_loss: 0.1747 - val_loss: 0.1340 - val_output_1_loss: 0.1339\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6502 - output_1_loss: 0.6501 - val_loss: 0.6254 - val_output_1_loss: 0.6251\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1049 - output_1_loss: 0.1047 - val_loss: 0.1309 - val_output_1_loss: 0.1307\n",
      "Epoch 77/100\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0850 - output_1_loss: 0.0849 - val_loss: 0.1279 - val_output_1_loss: 0.1277\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6380 - output_1_loss: 0.6379 - val_loss: 0.6214 - val_output_1_loss: 0.6210\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6294 - output_1_loss: 0.6293Epoch 78/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6294 - output_1_loss: 0.6293 - val_loss: 0.6186 - val_output_1_loss: 0.6182\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0927 - output_1_loss: 0.0926 - val_loss: 0.1266 - val_output_1_loss: 0.1264\n",
      "Epoch 79/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1433 - output_1_loss: 0.1432 - val_loss: 0.1231 - val_output_1_loss: 0.1229\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6080 - output_1_loss: 0.6079 - val_loss: 0.6158 - val_output_1_loss: 0.6154\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6033 - output_1_loss: 0.6032Epoch 80/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6033 - output_1_loss: 0.6032 - val_loss: 0.6112 - val_output_1_loss: 0.6108\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1135 - output_1_loss: 0.1134 - val_loss: 0.1165 - val_output_1_loss: 0.1163\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6201 - output_1_loss: 0.6200 - val_loss: 0.6076 - val_output_1_loss: 0.6072\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0774 - output_1_loss: 0.0773 - val_loss: 0.1102 - val_output_1_loss: 0.1101\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1039 - output_1_loss: 0.1038Epoch 24/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1039 - output_1_loss: 0.1038 - val_loss: 0.1101 - val_output_1_loss: 0.1099\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.6122 - output_1_loss: 0.6120 - val_loss: 0.6025 - val_output_1_loss: 0.6021\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0970 - output_1_loss: 0.0969 - val_loss: 0.1103 - val_output_1_loss: 0.1101\n",
      "Epoch 84/100\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0872 - output_1_loss: 0.0870 - val_loss: 0.1069 - val_output_1_loss: 0.1068\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.6077 - output_1_loss: 0.6076 - val_loss: 0.5979 - val_output_1_loss: 0.5975\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0911 - output_1_loss: 0.0910 - val_loss: 0.1003 - val_output_1_loss: 0.1002\n",
      "Epoch 86/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1185 - output_1_loss: 0.1184 - val_loss: 0.0982 - val_output_1_loss: 0.0981\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5897 - output_1_loss: 0.5896 - val_loss: 0.5939 - val_output_1_loss: 0.5935\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0850 - output_1_loss: 0.0849 - val_loss: 0.0971 - val_output_1_loss: 0.0970\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.5675 - output_1_loss: 0.5673 - val_loss: 0.5901 - val_output_1_loss: 0.5897\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0993 - output_1_loss: 0.0992Epoch 28/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0993 - output_1_loss: 0.0992 - val_loss: 0.0916 - val_output_1_loss: 0.0915\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5812 - output_1_loss: 0.5810 - val_loss: 0.5858 - val_output_1_loss: 0.5855\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0858 - output_1_loss: 0.0857 - val_loss: 0.0907 - val_output_1_loss: 0.0905\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5463 - output_1_loss: 0.5462Epoch 90/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.5463 - output_1_loss: 0.5462 - val_loss: 0.5818 - val_output_1_loss: 0.5814\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1018 - output_1_loss: 0.1016 - val_loss: 0.0905 - val_output_1_loss: 0.0903\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.5370 - output_1_loss: 0.5369 - val_loss: 0.5767 - val_output_1_loss: 0.5763\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0986 - output_1_loss: 0.0985 - val_loss: 0.0865 - val_output_1_loss: 0.0864\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5042 - output_1_loss: 0.5040 - val_loss: 0.5718 - val_output_1_loss: 0.5715\n",
      "Epoch 32/100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0994 - output_1_loss: 0.0993 - val_loss: 0.0876 - val_output_1_loss: 0.0875\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4903 - output_1_loss: 0.4902Epoch 93/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.4903 - output_1_loss: 0.4902 - val_loss: 0.5673 - val_output_1_loss: 0.5670\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0889 - output_1_loss: 0.0887 - val_loss: 0.0863 - val_output_1_loss: 0.0861\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.4980 - output_1_loss: 0.4978 - val_loss: 0.5634 - val_output_1_loss: 0.5630\n",
      "Epoch 34/100\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0772 - output_1_loss: 0.0771 - val_loss: 0.0826 - val_output_1_loss: 0.0824\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4716 - output_1_loss: 0.4714 - val_loss: 0.5585 - val_output_1_loss: 0.5582\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0762 - output_1_loss: 0.0761 - val_loss: 0.0841 - val_output_1_loss: 0.0840\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4905 - output_1_loss: 0.4904 - val_loss: 0.5542 - val_output_1_loss: 0.5539\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0732 - output_1_loss: 0.0731 - val_loss: 0.0801 - val_output_1_loss: 0.0799\n",
      "Epoch 97/100\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4604 - output_1_loss: 0.4602 - val_loss: 0.5493 - val_output_1_loss: 0.5490\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0793 - output_1_loss: 0.0791 - val_loss: 0.0779 - val_output_1_loss: 0.0777\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.3924 - output_1_loss: 0.3922 - val_loss: 0.5440 - val_output_1_loss: 0.5437\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0700 - output_1_loss: 0.0699 - val_loss: 0.0768 - val_output_1_loss: 0.0766\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3907 - output_1_loss: 0.3906 - val_loss: 0.5383 - val_output_1_loss: 0.5380\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0680 - output_1_loss: 0.0679 - val_loss: 0.0740 - val_output_1_loss: 0.0738\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3476 - output_1_loss: 0.3474 - val_loss: 0.5319 - val_output_1_loss: 0.5316\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.0672 - output_1_loss: 0.0671 - val_loss: 0.0729 - val_output_1_loss: 0.0727\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.3744 - output_1_loss: 0.3743 - val_loss: 0.5264 - val_output_1_loss: 0.5261\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.3238 - output_1_loss: 0.3236 - val_loss: 0.5201 - val_output_1_loss: 0.5198\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3504 - output_1_loss: 0.3503 - val_loss: 0.5137 - val_output_1_loss: 0.5134\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.3770 - output_1_loss: 0.3769 - val_loss: 0.5078 - val_output_1_loss: 0.5075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3564 - output_1_loss: 0.3563 - val_loss: 0.5016 - val_output_1_loss: 0.5013\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2941 - output_1_loss: 0.2940 - val_loss: 0.4941 - val_output_1_loss: 0.4939\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.2490 - output_1_loss: 0.2489 - val_loss: 0.4856 - val_output_1_loss: 0.4853\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:34:00,938]\u001b[0m Trial 83 finished with value: 0.16666666666666666 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.00010190830341990044, 'bn_momentum': 0.9430989369751598}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2755 - output_1_loss: 0.2753 - val_loss: 0.4786 - val_output_1_loss: 0.4783\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2434 - output_1_loss: 0.2433Epoch 1/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.2434 - output_1_loss: 0.2433 - val_loss: 0.4701 - val_output_1_loss: 0.4699\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.2304 - output_1_loss: 0.2302 - val_loss: 0.4634 - val_output_1_loss: 0.4631\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.2412 - output_1_loss: 0.2411 - val_loss: 0.4549 - val_output_1_loss: 0.4546\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.2028 - output_1_loss: 0.2026 - val_loss: 0.4423 - val_output_1_loss: 0.4421\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1642 - output_1_loss: 0.1641 - val_loss: 0.4293 - val_output_1_loss: 0.4291\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.1525 - output_1_loss: 0.1524 - val_loss: 0.4186 - val_output_1_loss: 0.4184\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 0.1538 - output_1_loss: 0.1537 - val_loss: 0.4024 - val_output_1_loss: 0.4022\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.1872 - output_1_loss: 0.1871 - val_loss: 0.3936 - val_output_1_loss: 0.3933\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.1798 - output_1_loss: 0.1797 - val_loss: 0.3774 - val_output_1_loss: 0.3772\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.1319 - output_1_loss: 0.1318 - val_loss: 0.3591 - val_output_1_loss: 0.3589\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.2145 - output_1_loss: 0.2144 - val_loss: 0.3456 - val_output_1_loss: 0.3454\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1814 - output_1_loss: 0.1813 - val_loss: 0.3321 - val_output_1_loss: 0.3318\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1603 - output_1_loss: 0.1602 - val_loss: 0.3178 - val_output_1_loss: 0.3175\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1307 - output_1_loss: 0.1306 - val_loss: 0.3045 - val_output_1_loss: 0.3042\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1200 - output_1_loss: 0.1199 - val_loss: 0.2932 - val_output_1_loss: 0.2930\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.1067 - output_1_loss: 0.1066 - val_loss: 0.2824 - val_output_1_loss: 0.2822\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 0.1040 - output_1_loss: 0.1039 - val_loss: 0.2709 - val_output_1_loss: 0.2706\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.1071 - output_1_loss: 0.1070 - val_loss: 0.2593 - val_output_1_loss: 0.2591\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.0984 - output_1_loss: 0.0982 - val_loss: 0.2469 - val_output_1_loss: 0.2467\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 0.0863 - output_1_loss: 0.0861 - val_loss: 0.2344 - val_output_1_loss: 0.2342\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.0817 - output_1_loss: 0.0816 - val_loss: 0.2231 - val_output_1_loss: 0.2229\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0877 - output_1_loss: 0.0876 - val_loss: 0.2125 - val_output_1_loss: 0.2123\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0790 - output_1_loss: 0.0788 - val_loss: 0.2025 - val_output_1_loss: 0.2023\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0760 - output_1_loss: 0.0758 - val_loss: 0.1917 - val_output_1_loss: 0.1915\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0758 - output_1_loss: 0.0757 - val_loss: 0.1813 - val_output_1_loss: 0.1811\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0747 - output_1_loss: 0.0745 - val_loss: 0.1714 - val_output_1_loss: 0.1712\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.0728 - output_1_loss: 0.0726 - val_loss: 0.1625 - val_output_1_loss: 0.1623\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0714 - output_1_loss: 0.0713 - val_loss: 0.1545 - val_output_1_loss: 0.1544\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0703 - output_1_loss: 0.0701 - val_loss: 0.1470 - val_output_1_loss: 0.1468\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0703 - output_1_loss: 0.0701 - val_loss: 0.1402 - val_output_1_loss: 0.1400\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0729 - output_1_loss: 0.0728 - val_loss: 0.1350 - val_output_1_loss: 0.1348\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0703 - output_1_loss: 0.0702 - val_loss: 0.1299 - val_output_1_loss: 0.1297\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0722 - output_1_loss: 0.0721 - val_loss: 0.1255 - val_output_1_loss: 0.1253\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0694 - output_1_loss: 0.0693 - val_loss: 0.1209 - val_output_1_loss: 0.1207\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0700 - output_1_loss: 0.0698 - val_loss: 0.1160 - val_output_1_loss: 0.1158\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0706 - output_1_loss: 0.0705 - val_loss: 0.1117 - val_output_1_loss: 0.1115\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0757 - output_1_loss: 0.0756 - val_loss: 0.1087 - val_output_1_loss: 0.1086\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0780 - output_1_loss: 0.0779 - val_loss: 0.1059 - val_output_1_loss: 0.1057\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0724 - output_1_loss: 0.0723 - val_loss: 0.1027 - val_output_1_loss: 0.1025\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0804 - output_1_loss: 0.0803 - val_loss: 0.0993 - val_output_1_loss: 0.0992\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0779 - output_1_loss: 0.0778 - val_loss: 0.0968 - val_output_1_loss: 0.0966\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0712 - output_1_loss: 0.0711 - val_loss: 0.0956 - val_output_1_loss: 0.0954\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0699 - output_1_loss: 0.0698 - val_loss: 0.0948 - val_output_1_loss: 0.0946\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0689 - output_1_loss: 0.0687 - val_loss: 0.0935 - val_output_1_loss: 0.0934\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0691 - output_1_loss: 0.0690 - val_loss: 0.0863 - val_output_1_loss: 0.0861\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0814 - output_1_loss: 0.0813 - val_loss: 0.0844 - val_output_1_loss: 0.0843\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0785 - output_1_loss: 0.0783 - val_loss: 0.0825 - val_output_1_loss: 0.0823\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0884 - output_1_loss: 0.0883 - val_loss: 0.0818 - val_output_1_loss: 0.0816\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0799 - output_1_loss: 0.0798 - val_loss: 0.0809 - val_output_1_loss: 0.0807\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0724 - output_1_loss: 0.0723 - val_loss: 0.0799 - val_output_1_loss: 0.0797\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8242 - output_1_loss: 0.8242Epoch 98/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0732 - output_1_loss: 0.0731 - val_loss: 0.0790 - val_output_1_loss: 0.0788\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.0721 - output_1_loss: 0.0720 - val_loss: 0.0780 - val_output_1_loss: 0.0778\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0715 - output_1_loss: 0.0714 - val_loss: 0.0770 - val_output_1_loss: 0.0768\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.8242 - output_1_loss: 0.8242 - val_loss: 0.6903 - val_output_1_loss: 0.6901\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:34:22,671]\u001b[0m Trial 84 finished with value: 0.3333333333333333 and parameters: {'feature_dim': 64, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.00011489169541261755, 'bn_momentum': 0.9564990143965427}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.8511 - output_1_loss: 0.8510 - val_loss: 0.6870 - val_output_1_loss: 0.6868\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.7848 - output_1_loss: 0.7847 - val_loss: 0.6848 - val_output_1_loss: 0.6847\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.7821 - output_1_loss: 0.7820 - val_loss: 0.6811 - val_output_1_loss: 0.6809\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.7891 - output_1_loss: 0.7890 - val_loss: 0.6780 - val_output_1_loss: 0.6778\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.7525 - output_1_loss: 0.7524 - val_loss: 0.6747 - val_output_1_loss: 0.6745\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.7035 - output_1_loss: 0.7034 - val_loss: 0.6698 - val_output_1_loss: 0.6697\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.6929 - output_1_loss: 0.6929 - val_loss: 0.6659 - val_output_1_loss: 0.6657\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.7065 - output_1_loss: 0.7065 - val_loss: 0.6623 - val_output_1_loss: 0.6621\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.7179 - output_1_loss: 0.7178 - val_loss: 0.6583 - val_output_1_loss: 0.6582\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.6348 - output_1_loss: 0.6347 - val_loss: 0.6539 - val_output_1_loss: 0.6538\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.6437 - output_1_loss: 0.6436 - val_loss: 0.6484 - val_output_1_loss: 0.6483\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.6733 - output_1_loss: 0.6732 - val_loss: 0.6454 - val_output_1_loss: 0.6453\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6639 - output_1_loss: 0.6638 - val_loss: 0.6422 - val_output_1_loss: 0.6421\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.6760 - output_1_loss: 0.6760 - val_loss: 0.6369 - val_output_1_loss: 0.6367\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.6220 - output_1_loss: 0.6219 - val_loss: 0.6321 - val_output_1_loss: 0.6320\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.6438 - output_1_loss: 0.6438 - val_loss: 0.6291 - val_output_1_loss: 0.6289\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.6167 - output_1_loss: 0.6167 - val_loss: 0.6257 - val_output_1_loss: 0.6256\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.5814 - output_1_loss: 0.5814 - val_loss: 0.6214 - val_output_1_loss: 0.6213\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5421 - output_1_loss: 0.5421 - val_loss: 0.6171 - val_output_1_loss: 0.6170\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5974 - output_1_loss: 0.5973 - val_loss: 0.6147 - val_output_1_loss: 0.6146\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.5741 - output_1_loss: 0.5740 - val_loss: 0.6114 - val_output_1_loss: 0.6113\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5572 - output_1_loss: 0.5572 - val_loss: 0.6032 - val_output_1_loss: 0.6031\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5768 - output_1_loss: 0.5767 - val_loss: 0.5961 - val_output_1_loss: 0.5960\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.5775 - output_1_loss: 0.5775 - val_loss: 0.5917 - val_output_1_loss: 0.5916\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5142 - output_1_loss: 0.5142 - val_loss: 0.5872 - val_output_1_loss: 0.5871\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5045 - output_1_loss: 0.5045 - val_loss: 0.5787 - val_output_1_loss: 0.5786\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5573 - output_1_loss: 0.5572 - val_loss: 0.5744 - val_output_1_loss: 0.5743\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5306 - output_1_loss: 0.5306 - val_loss: 0.5717 - val_output_1_loss: 0.5716\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5024 - output_1_loss: 0.5023 - val_loss: 0.5681 - val_output_1_loss: 0.5680\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.5228 - output_1_loss: 0.5228 - val_loss: 0.5635 - val_output_1_loss: 0.5634\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4434 - output_1_loss: 0.4433 - val_loss: 0.5555 - val_output_1_loss: 0.5554\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.5291 - output_1_loss: 0.5291 - val_loss: 0.5522 - val_output_1_loss: 0.5521\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5106 - output_1_loss: 0.5106 - val_loss: 0.5484 - val_output_1_loss: 0.5483\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.4985 - output_1_loss: 0.4984 - val_loss: 0.5445 - val_output_1_loss: 0.5444\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.4684 - output_1_loss: 0.4683 - val_loss: 0.5409 - val_output_1_loss: 0.5408\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.4482 - output_1_loss: 0.4481 - val_loss: 0.5341 - val_output_1_loss: 0.5340\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4356 - output_1_loss: 0.4356 - val_loss: 0.5282 - val_output_1_loss: 0.5281\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3650 - output_1_loss: 0.3649 - val_loss: 0.5210 - val_output_1_loss: 0.5209\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.5253 - output_1_loss: 0.5253 - val_loss: 0.5145 - val_output_1_loss: 0.5144\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4341 - output_1_loss: 0.4340 - val_loss: 0.5083 - val_output_1_loss: 0.5082\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4478 - output_1_loss: 0.4478 - val_loss: 0.5046 - val_output_1_loss: 0.5045\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3827 - output_1_loss: 0.3827 - val_loss: 0.4975 - val_output_1_loss: 0.4974\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4627 - output_1_loss: 0.4626 - val_loss: 0.4904 - val_output_1_loss: 0.4903\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3236 - output_1_loss: 0.3236 - val_loss: 0.4773 - val_output_1_loss: 0.4772\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.4324 - output_1_loss: 0.4323 - val_loss: 0.4726 - val_output_1_loss: 0.4725\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3874 - output_1_loss: 0.3873 - val_loss: 0.4664 - val_output_1_loss: 0.4663\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.4358 - output_1_loss: 0.4358 - val_loss: 0.4638 - val_output_1_loss: 0.4637\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3914 - output_1_loss: 0.3913 - val_loss: 0.4578 - val_output_1_loss: 0.4577\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 371ms/step - loss: 0.4477 - output_1_loss: 0.4477 - val_loss: 0.4563 - val_output_1_loss: 0.4562\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3906 - output_1_loss: 0.3905 - val_loss: 0.4540 - val_output_1_loss: 0.4539\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.4373 - output_1_loss: 0.4373 - val_loss: 0.4455 - val_output_1_loss: 0.4454\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3606 - output_1_loss: 0.3605 - val_loss: 0.4400 - val_output_1_loss: 0.4399\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4417 - output_1_loss: 0.4416 - val_loss: 0.4354 - val_output_1_loss: 0.4353\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3359 - output_1_loss: 0.3359 - val_loss: 0.4295 - val_output_1_loss: 0.4294\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3546 - output_1_loss: 0.3546 - val_loss: 0.4302 - val_output_1_loss: 0.4301\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3907 - output_1_loss: 0.3907 - val_loss: 0.4294 - val_output_1_loss: 0.4293\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.8716 - output_1_loss: 0.8716 - val_loss: 0.6907 - val_output_1_loss: 0.6906\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.3354 - output_1_loss: 0.3354 - val_loss: 0.4260 - val_output_1_loss: 0.4259\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3809 - output_1_loss: 0.3809 - val_loss: 0.4207 - val_output_1_loss: 0.4206\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.3703 - output_1_loss: 0.3703 - val_loss: 0.4138 - val_output_1_loss: 0.4137\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3459 - output_1_loss: 0.3459 - val_loss: 0.4094 - val_output_1_loss: 0.4093\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4152 - output_1_loss: 0.4152 - val_loss: 0.4020 - val_output_1_loss: 0.4020\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4485 - output_1_loss: 0.4484 - val_loss: 0.3921 - val_output_1_loss: 0.3920\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3264 - output_1_loss: 0.3263 - val_loss: 0.3866 - val_output_1_loss: 0.3866\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3218 - output_1_loss: 0.3218 - val_loss: 0.3779 - val_output_1_loss: 0.3778\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3138 - output_1_loss: 0.3138 - val_loss: 0.3823 - val_output_1_loss: 0.3823\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2897 - output_1_loss: 0.2897 - val_loss: 0.3745 - val_output_1_loss: 0.3744\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3764 - output_1_loss: 0.3764 - val_loss: 0.3711 - val_output_1_loss: 0.3710\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2812 - output_1_loss: 0.2812 - val_loss: 0.3686 - val_output_1_loss: 0.3686\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2949 - output_1_loss: 0.2949 - val_loss: 0.3650 - val_output_1_loss: 0.3649\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3123 - output_1_loss: 0.3122 - val_loss: 0.3603 - val_output_1_loss: 0.3603\n",
      "Epoch 72/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.2643 - output_1_loss: 0.2642 - val_loss: 0.3501 - val_output_1_loss: 0.3500\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.8230 - output_1_loss: 0.8230 - val_loss: 0.6871 - val_output_1_loss: 0.6871\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2256 - output_1_loss: 0.2255 - val_loss: 0.3366 - val_output_1_loss: 0.3365\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8052 - output_1_loss: 0.8052 - val_loss: 0.6828 - val_output_1_loss: 0.6828\n",
      "Epoch 4/100\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.7481 - output_1_loss: 0.7481 - val_loss: 0.6780 - val_output_1_loss: 0.6780\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3139 - output_1_loss: 0.3139 - val_loss: 0.3268 - val_output_1_loss: 0.3268\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7995 - output_1_loss: 0.7995 - val_loss: 0.6756 - val_output_1_loss: 0.6755\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.2944 - output_1_loss: 0.2944 - val_loss: 0.3222 - val_output_1_loss: 0.3222\n",
      "Epoch 76/100\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3265 - output_1_loss: 0.3265 - val_loss: 0.3188 - val_output_1_loss: 0.3188\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7557 - output_1_loss: 0.7557 - val_loss: 0.6709 - val_output_1_loss: 0.6709\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2761 - output_1_loss: 0.2761Epoch 7/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.2761 - output_1_loss: 0.2761 - val_loss: 0.3184 - val_output_1_loss: 0.3184\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7194 - output_1_loss: 0.7194Epoch 78/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.7194 - output_1_loss: 0.7194 - val_loss: 0.6672 - val_output_1_loss: 0.6672\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2949 - output_1_loss: 0.2948 - val_loss: 0.3141 - val_output_1_loss: 0.3140\n",
      "Epoch 79/100\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2622 - output_1_loss: 0.2622 - val_loss: 0.3069 - val_output_1_loss: 0.3069\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7183 - output_1_loss: 0.7183 - val_loss: 0.6636 - val_output_1_loss: 0.6636\n",
      "Epoch 80/100\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3062 - output_1_loss: 0.3061 - val_loss: 0.2957 - val_output_1_loss: 0.2956\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7171 - output_1_loss: 0.7170 - val_loss: 0.6601 - val_output_1_loss: 0.6601\n",
      "Epoch 10/100\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6910 - output_1_loss: 0.6909 - val_loss: 0.6572 - val_output_1_loss: 0.6571\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.2390 - output_1_loss: 0.2390 - val_loss: 0.2845 - val_output_1_loss: 0.2844\n",
      "Epoch 82/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2834 - output_1_loss: 0.2834 - val_loss: 0.2772 - val_output_1_loss: 0.2772\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7228 - output_1_loss: 0.7228 - val_loss: 0.6537 - val_output_1_loss: 0.6537\n",
      "Epoch 83/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1986 - output_1_loss: 0.1985 - val_loss: 0.2659 - val_output_1_loss: 0.2659\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6476 - output_1_loss: 0.6476 - val_loss: 0.6493 - val_output_1_loss: 0.6493\n",
      "Epoch 13/100\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6444 - output_1_loss: 0.6444 - val_loss: 0.6450 - val_output_1_loss: 0.6449\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.2624 - output_1_loss: 0.2624 - val_loss: 0.2546 - val_output_1_loss: 0.2546\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6200 - output_1_loss: 0.6200 - val_loss: 0.6421 - val_output_1_loss: 0.6421\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3208 - output_1_loss: 0.3207 - val_loss: 0.2555 - val_output_1_loss: 0.2554\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6318 - output_1_loss: 0.6318 - val_loss: 0.6379 - val_output_1_loss: 0.6379\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.2404 - output_1_loss: 0.2404 - val_loss: 0.2415 - val_output_1_loss: 0.2415\n",
      "Epoch 16/100\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.6302 - output_1_loss: 0.6302 - val_loss: 0.6334 - val_output_1_loss: 0.6334\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2433 - output_1_loss: 0.2433 - val_loss: 0.2369 - val_output_1_loss: 0.2368\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5952 - output_1_loss: 0.5952Epoch 88/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5952 - output_1_loss: 0.5952 - val_loss: 0.6300 - val_output_1_loss: 0.6300\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2443 - output_1_loss: 0.2442 - val_loss: 0.2373 - val_output_1_loss: 0.2373\n",
      "Epoch 89/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2586 - output_1_loss: 0.2586 - val_loss: 0.2423 - val_output_1_loss: 0.2422\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5828 - output_1_loss: 0.5828 - val_loss: 0.6267 - val_output_1_loss: 0.6267\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1958 - output_1_loss: 0.1957 - val_loss: 0.2431 - val_output_1_loss: 0.2431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.2570 - output_1_loss: 0.2570 - val_loss: 0.2426 - val_output_1_loss: 0.2425\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.6335 - output_1_loss: 0.6335 - val_loss: 0.6231 - val_output_1_loss: 0.6231\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.2387 - output_1_loss: 0.2387 - val_loss: 0.2350 - val_output_1_loss: 0.2349\n",
      "Epoch 93/100\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.2481 - output_1_loss: 0.2480 - val_loss: 0.2314 - val_output_1_loss: 0.2314\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5763 - output_1_loss: 0.5763 - val_loss: 0.6183 - val_output_1_loss: 0.6183\n",
      "Epoch 94/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1998 - output_1_loss: 0.1998 - val_loss: 0.2282 - val_output_1_loss: 0.2282\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.5553 - output_1_loss: 0.5553 - val_loss: 0.6118 - val_output_1_loss: 0.6118\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5592 - output_1_loss: 0.5592 - val_loss: 0.6073 - val_output_1_loss: 0.6073\n",
      "Epoch 23/100\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.5694 - output_1_loss: 0.5694 - val_loss: 0.6029 - val_output_1_loss: 0.6029\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.1998 - output_1_loss: 0.1998 - val_loss: 0.2254 - val_output_1_loss: 0.2253\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.5453 - output_1_loss: 0.5453 - val_loss: 0.5959 - val_output_1_loss: 0.5959\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5108 - output_1_loss: 0.5108Epoch 96/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5108 - output_1_loss: 0.5108 - val_loss: 0.5858 - val_output_1_loss: 0.5857\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2016 - output_1_loss: 0.2016Epoch 26/100\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2016 - output_1_loss: 0.2016 - val_loss: 0.2270 - val_output_1_loss: 0.2270\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.5342 - output_1_loss: 0.5342 - val_loss: 0.5779 - val_output_1_loss: 0.5779\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.2212 - output_1_loss: 0.2212 - val_loss: 0.2189 - val_output_1_loss: 0.2189\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.2150 - output_1_loss: 0.2149 - val_loss: 0.2151 - val_output_1_loss: 0.2151\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.5054 - output_1_loss: 0.5054 - val_loss: 0.5726 - val_output_1_loss: 0.5726\n",
      "Epoch 28/100\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2243 - output_1_loss: 0.2243 - val_loss: 0.2168 - val_output_1_loss: 0.2167\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.5480 - output_1_loss: 0.5480 - val_loss: 0.5694 - val_output_1_loss: 0.5693\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2392 - output_1_loss: 0.2392 - val_loss: 0.2036 - val_output_1_loss: 0.2035\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5059 - output_1_loss: 0.5059 - val_loss: 0.5640 - val_output_1_loss: 0.5640\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 0.5372 - output_1_loss: 0.5372 - val_loss: 0.5634 - val_output_1_loss: 0.5634\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.4597 - output_1_loss: 0.4597 - val_loss: 0.5614 - val_output_1_loss: 0.5614\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4686 - output_1_loss: 0.4686 - val_loss: 0.5548 - val_output_1_loss: 0.5548\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.5040 - output_1_loss: 0.5040 - val_loss: 0.5504 - val_output_1_loss: 0.5504\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4594 - output_1_loss: 0.4594 - val_loss: 0.5450 - val_output_1_loss: 0.5450\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4710 - output_1_loss: 0.4710 - val_loss: 0.5391 - val_output_1_loss: 0.5390\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.4064 - output_1_loss: 0.4064 - val_loss: 0.5335 - val_output_1_loss: 0.5335\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:34:57,556]\u001b[0m Trial 85 finished with value: 0.0136986301369863 and parameters: {'feature_dim': 64, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 4.220150728384892e-05, 'bn_momentum': 0.952379923343806}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4711 - output_1_loss: 0.4711 - val_loss: 0.5284 - val_output_1_loss: 0.5284\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4560 - output_1_loss: 0.4559Epoch 1/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.4560 - output_1_loss: 0.4559 - val_loss: 0.5233 - val_output_1_loss: 0.5232\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.4578 - output_1_loss: 0.4578 - val_loss: 0.5178 - val_output_1_loss: 0.5178\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.4580 - output_1_loss: 0.4580 - val_loss: 0.5165 - val_output_1_loss: 0.5165\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.4684 - output_1_loss: 0.4684 - val_loss: 0.5111 - val_output_1_loss: 0.5111\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.3948 - output_1_loss: 0.3948 - val_loss: 0.5050 - val_output_1_loss: 0.5049\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.4190 - output_1_loss: 0.4190 - val_loss: 0.5009 - val_output_1_loss: 0.5008\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.3807 - output_1_loss: 0.3807 - val_loss: 0.4922 - val_output_1_loss: 0.4922\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 0.4454 - output_1_loss: 0.4454 - val_loss: 0.4862 - val_output_1_loss: 0.4862\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.3966 - output_1_loss: 0.3966 - val_loss: 0.4789 - val_output_1_loss: 0.4789\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.3519 - output_1_loss: 0.3519 - val_loss: 0.4732 - val_output_1_loss: 0.4732\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.3427 - output_1_loss: 0.3427 - val_loss: 0.4656 - val_output_1_loss: 0.4656\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.3969 - output_1_loss: 0.3969 - val_loss: 0.4600 - val_output_1_loss: 0.4600\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4143 - output_1_loss: 0.4143 - val_loss: 0.4543 - val_output_1_loss: 0.4542\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.3354 - output_1_loss: 0.3354 - val_loss: 0.4452 - val_output_1_loss: 0.4452\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.3588 - output_1_loss: 0.3588 - val_loss: 0.4364 - val_output_1_loss: 0.4364\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3508 - output_1_loss: 0.3508 - val_loss: 0.4208 - val_output_1_loss: 0.4208\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.3613 - output_1_loss: 0.3613 - val_loss: 0.4218 - val_output_1_loss: 0.4218\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3756 - output_1_loss: 0.3756 - val_loss: 0.4106 - val_output_1_loss: 0.4106\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3590 - output_1_loss: 0.3590 - val_loss: 0.4143 - val_output_1_loss: 0.4143\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3522 - output_1_loss: 0.3522 - val_loss: 0.4089 - val_output_1_loss: 0.4088\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3486 - output_1_loss: 0.3486 - val_loss: 0.4028 - val_output_1_loss: 0.4028\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.3050 - output_1_loss: 0.3050 - val_loss: 0.3852 - val_output_1_loss: 0.3852\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3264 - output_1_loss: 0.3264 - val_loss: 0.3811 - val_output_1_loss: 0.3810\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.2900 - output_1_loss: 0.2900 - val_loss: 0.3724 - val_output_1_loss: 0.3724\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.2854 - output_1_loss: 0.2854 - val_loss: 0.3593 - val_output_1_loss: 0.3593\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.2615 - output_1_loss: 0.2615 - val_loss: 0.3537 - val_output_1_loss: 0.3537\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.3926 - output_1_loss: 0.3926 - val_loss: 0.3465 - val_output_1_loss: 0.3465\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.2787 - output_1_loss: 0.2787 - val_loss: 0.3354 - val_output_1_loss: 0.3354\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.2868 - output_1_loss: 0.2868 - val_loss: 0.3267 - val_output_1_loss: 0.3267\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.3211 - output_1_loss: 0.3211 - val_loss: 0.3257 - val_output_1_loss: 0.3257\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.2959 - output_1_loss: 0.2959 - val_loss: 0.3141 - val_output_1_loss: 0.3141\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.3126 - output_1_loss: 0.3126 - val_loss: 0.3079 - val_output_1_loss: 0.3078\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.2422 - output_1_loss: 0.2421 - val_loss: 0.2975 - val_output_1_loss: 0.2975\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.2768 - output_1_loss: 0.2768 - val_loss: 0.2847 - val_output_1_loss: 0.2847\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.3083 - output_1_loss: 0.3083 - val_loss: 0.2902 - val_output_1_loss: 0.2902\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2904 - output_1_loss: 0.2904 - val_loss: 0.2982 - val_output_1_loss: 0.2982\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2731 - output_1_loss: 0.2731 - val_loss: 0.3023 - val_output_1_loss: 0.3023\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2865 - output_1_loss: 0.2865 - val_loss: 0.2878 - val_output_1_loss: 0.2878\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.2974 - output_1_loss: 0.2974 - val_loss: 0.2737 - val_output_1_loss: 0.2737\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 0.3005 - output_1_loss: 0.3005 - val_loss: 0.2724 - val_output_1_loss: 0.2724\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2406 - output_1_loss: 0.2406 - val_loss: 0.2631 - val_output_1_loss: 0.2631\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2018 - output_1_loss: 0.2018 - val_loss: 0.2644 - val_output_1_loss: 0.2644\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2807 - output_1_loss: 0.2807 - val_loss: 0.2631 - val_output_1_loss: 0.2631\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.1839 - output_1_loss: 0.1839 - val_loss: 0.2688 - val_output_1_loss: 0.2688\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2302 - output_1_loss: 0.2301 - val_loss: 0.2593 - val_output_1_loss: 0.2593\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.2452 - output_1_loss: 0.2452 - val_loss: 0.2542 - val_output_1_loss: 0.2542\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2438 - output_1_loss: 0.2438 - val_loss: 0.2512 - val_output_1_loss: 0.2512\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2697 - output_1_loss: 0.2697 - val_loss: 0.2407 - val_output_1_loss: 0.2407\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1984 - output_1_loss: 0.1984 - val_loss: 0.2373 - val_output_1_loss: 0.2373\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.2341 - output_1_loss: 0.2341 - val_loss: 0.2331 - val_output_1_loss: 0.2331\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2236 - output_1_loss: 0.2235 - val_loss: 0.2322 - val_output_1_loss: 0.2322\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1864 - output_1_loss: 0.1864 - val_loss: 0.2181 - val_output_1_loss: 0.2181\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1714 - output_1_loss: 0.1714 - val_loss: 0.2039 - val_output_1_loss: 0.2039\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1370 - output_1_loss: 0.1370 - val_loss: 0.2042 - val_output_1_loss: 0.2042\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1749 - output_1_loss: 0.1749 - val_loss: 0.2008 - val_output_1_loss: 0.2008\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.2299 - output_1_loss: 0.2299 - val_loss: 0.1908 - val_output_1_loss: 0.1908\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2229 - output_1_loss: 0.2229 - val_loss: 0.1782 - val_output_1_loss: 0.1782\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1988 - output_1_loss: 0.1988 - val_loss: 0.1648 - val_output_1_loss: 0.1647\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1573 - output_1_loss: 0.1573 - val_loss: 0.1728 - val_output_1_loss: 0.1728\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1750 - output_1_loss: 0.1750 - val_loss: 0.1742 - val_output_1_loss: 0.1742\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1772 - output_1_loss: 0.1772 - val_loss: 0.1711 - val_output_1_loss: 0.1711\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1726 - output_1_loss: 0.1726 - val_loss: 0.1737 - val_output_1_loss: 0.1737\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2562 - output_1_loss: 0.2562 - val_loss: 0.1702 - val_output_1_loss: 0.1702\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:35:22,068]\u001b[0m Trial 86 finished with value: 0.3333333333333333 and parameters: {'feature_dim': 64, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 2.2, 'sparsity_coefficient': 5.741548306423301e-06, 'bn_momentum': 0.9423075485263551}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.7160 - output_1_loss: 0.6277 - val_loss: 1.0404 - val_output_1_loss: 0.6879\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.7203 - output_1_loss: 0.6288 - val_loss: 1.0136 - val_output_1_loss: 0.6839\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.7275 - output_1_loss: 0.6369 - val_loss: 0.9924 - val_output_1_loss: 0.6804\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.6715 - output_1_loss: 0.5807 - val_loss: 0.9764 - val_output_1_loss: 0.6752\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.6811 - output_1_loss: 0.5901 - val_loss: 0.9619 - val_output_1_loss: 0.6717\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.7409 - output_1_loss: 0.6498 - val_loss: 0.9479 - val_output_1_loss: 0.6673\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.6137 - output_1_loss: 0.5214 - val_loss: 0.9350 - val_output_1_loss: 0.6618\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.5904 - output_1_loss: 0.5014 - val_loss: 0.9246 - val_output_1_loss: 0.6567\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.6422 - output_1_loss: 0.5486 - val_loss: 0.9143 - val_output_1_loss: 0.6533\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.6497 - output_1_loss: 0.5615 - val_loss: 0.9043 - val_output_1_loss: 0.6494\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.6034 - output_1_loss: 0.5166 - val_loss: 0.8919 - val_output_1_loss: 0.6442\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.5837 - output_1_loss: 0.4949 - val_loss: 0.8796 - val_output_1_loss: 0.6375\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.5099 - output_1_loss: 0.4265 - val_loss: 0.8649 - val_output_1_loss: 0.6282\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.5706 - output_1_loss: 0.4892 - val_loss: 0.8492 - val_output_1_loss: 0.6201\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 0.5803 - output_1_loss: 0.5004 - val_loss: 0.8378 - val_output_1_loss: 0.6147\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.5345 - output_1_loss: 0.4541 - val_loss: 0.8241 - val_output_1_loss: 0.6096\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5440 - output_1_loss: 0.4646 - val_loss: 0.8124 - val_output_1_loss: 0.6041\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.5286 - output_1_loss: 0.4505 - val_loss: 0.8034 - val_output_1_loss: 0.6006\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.5663 - output_1_loss: 0.4817 - val_loss: 0.7911 - val_output_1_loss: 0.5931\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.5590 - output_1_loss: 0.4755 - val_loss: 0.7735 - val_output_1_loss: 0.5842\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.5292 - output_1_loss: 0.4502 - val_loss: 0.7623 - val_output_1_loss: 0.5793\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.5101 - output_1_loss: 0.4318 - val_loss: 0.7584 - val_output_1_loss: 0.5750\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 0.4808 - output_1_loss: 0.4023 - val_loss: 0.7515 - val_output_1_loss: 0.5701\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.3829 - output_1_loss: 0.3040 - val_loss: 0.7381 - val_output_1_loss: 0.5633\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.5499 - output_1_loss: 0.4724 - val_loss: 0.7348 - val_output_1_loss: 0.5587\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.5000 - output_1_loss: 0.4194 - val_loss: 0.7150 - val_output_1_loss: 0.5416\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.4712 - output_1_loss: 0.3884 - val_loss: 0.7131 - val_output_1_loss: 0.5374\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.5356 - output_1_loss: 0.4507 - val_loss: 0.7019 - val_output_1_loss: 0.5293\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.4732 - output_1_loss: 0.3925 - val_loss: 0.6912 - val_output_1_loss: 0.5224\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4808 - output_1_loss: 0.4002 - val_loss: 0.6865 - val_output_1_loss: 0.5151\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4634 - output_1_loss: 0.3841 - val_loss: 0.6879 - val_output_1_loss: 0.5132\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.5000 - output_1_loss: 0.4187 - val_loss: 0.6693 - val_output_1_loss: 0.5004\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.4677 - output_1_loss: 0.3889 - val_loss: 0.6652 - val_output_1_loss: 0.4974\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4492 - output_1_loss: 0.3694 - val_loss: 0.6659 - val_output_1_loss: 0.4950\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.3861 - output_1_loss: 0.3102 - val_loss: 0.6580 - val_output_1_loss: 0.4873\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.3555 - output_1_loss: 0.2808 - val_loss: 0.6450 - val_output_1_loss: 0.4755\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.4596 - output_1_loss: 0.3840 - val_loss: 0.6391 - val_output_1_loss: 0.4703\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4624 - output_1_loss: 0.3864 - val_loss: 0.6301 - val_output_1_loss: 0.4613\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.4070 - output_1_loss: 0.3312 - val_loss: 0.6257 - val_output_1_loss: 0.4567\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4554 - output_1_loss: 0.3804 - val_loss: 0.6245 - val_output_1_loss: 0.4560\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3179 - output_1_loss: 0.2463 - val_loss: 0.6090 - val_output_1_loss: 0.4448\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3836 - output_1_loss: 0.3118 - val_loss: 0.6042 - val_output_1_loss: 0.4423\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.3387 - output_1_loss: 0.2682 - val_loss: 0.5935 - val_output_1_loss: 0.4323\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3440 - output_1_loss: 0.2727 - val_loss: 0.5835 - val_output_1_loss: 0.4235\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4470 - output_1_loss: 0.3775 - val_loss: 0.5735 - val_output_1_loss: 0.4175\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4132 - output_1_loss: 0.3404 - val_loss: 0.5613 - val_output_1_loss: 0.4060\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3460 - output_1_loss: 0.2714 - val_loss: 0.5566 - val_output_1_loss: 0.4007\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3923 - output_1_loss: 0.3088 - val_loss: 0.5490 - val_output_1_loss: 0.3934\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4437 - output_1_loss: 0.3640 - val_loss: 0.5342 - val_output_1_loss: 0.3816\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.4048 - output_1_loss: 0.3242 - val_loss: 0.5207 - val_output_1_loss: 0.3720\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3330 - output_1_loss: 0.2489 - val_loss: 0.5150 - val_output_1_loss: 0.3643\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2706 - output_1_loss: 0.1861 - val_loss: 0.5037 - val_output_1_loss: 0.3524\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3463 - output_1_loss: 0.2649 - val_loss: 0.5055 - val_output_1_loss: 0.3551\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3824 - output_1_loss: 0.2977 - val_loss: 0.5030 - val_output_1_loss: 0.3536\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.2923 - output_1_loss: 0.2100 - val_loss: 0.4952 - val_output_1_loss: 0.3468\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2911 - output_1_loss: 0.2092 - val_loss: 0.4825 - val_output_1_loss: 0.3332\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.2947 - output_1_loss: 0.2175 - val_loss: 0.4646 - val_output_1_loss: 0.3178\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.3100 - output_1_loss: 0.2319 - val_loss: 0.4525 - val_output_1_loss: 0.3056\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.2954 - output_1_loss: 0.2159 - val_loss: 0.4440 - val_output_1_loss: 0.2981\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3722 - output_1_loss: 0.2892 - val_loss: 0.4271 - val_output_1_loss: 0.2839\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3192 - output_1_loss: 0.2379 - val_loss: 0.4295 - val_output_1_loss: 0.2888\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.8183 - output_1_loss: 0.7471 - val_loss: 0.9654 - val_output_1_loss: 0.6846\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2872 - output_1_loss: 0.2065 - val_loss: 0.4214 - val_output_1_loss: 0.2803\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.2833 - output_1_loss: 0.2028 - val_loss: 0.4255 - val_output_1_loss: 0.2839\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 0.7613 - output_1_loss: 0.6877 - val_loss: 0.9381 - val_output_1_loss: 0.6757\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.2446 - output_1_loss: 0.1683 - val_loss: 0.4372 - val_output_1_loss: 0.2955\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2849 - output_1_loss: 0.2061 - val_loss: 0.4021 - val_output_1_loss: 0.2645\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7114 - output_1_loss: 0.6405Epoch 66/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7114 - output_1_loss: 0.6405 - val_loss: 0.9105 - val_output_1_loss: 0.6672\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2949 - output_1_loss: 0.2144Epoch 4/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.2949 - output_1_loss: 0.2144 - val_loss: 0.3852 - val_output_1_loss: 0.2541\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.6715 - output_1_loss: 0.5981 - val_loss: 0.8891 - val_output_1_loss: 0.6576\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.2678 - output_1_loss: 0.1865 - val_loss: 0.3855 - val_output_1_loss: 0.2547\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.6455 - output_1_loss: 0.5763 - val_loss: 0.8663 - val_output_1_loss: 0.6474\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2712 - output_1_loss: 0.1919 - val_loss: 0.3739 - val_output_1_loss: 0.2430\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.6536 - output_1_loss: 0.5844 - val_loss: 0.8511 - val_output_1_loss: 0.6390\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.3145 - output_1_loss: 0.2373 - val_loss: 0.3692 - val_output_1_loss: 0.2392\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.5080 - output_1_loss: 0.4356 - val_loss: 0.8319 - val_output_1_loss: 0.6281\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2515 - output_1_loss: 0.1732Epoch 8/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.2515 - output_1_loss: 0.1732 - val_loss: 0.3647 - val_output_1_loss: 0.2367\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.5532 - output_1_loss: 0.4838 - val_loss: 0.8116 - val_output_1_loss: 0.6170\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2841 - output_1_loss: 0.2071Epoch 9/100\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.2841 - output_1_loss: 0.2071 - val_loss: 0.3613 - val_output_1_loss: 0.2374\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5752 - output_1_loss: 0.5052Epoch 72/100\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5752 - output_1_loss: 0.5052 - val_loss: 0.7984 - val_output_1_loss: 0.6066\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.3088 - output_1_loss: 0.2311 - val_loss: 0.3591 - val_output_1_loss: 0.2383\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4950 - output_1_loss: 0.4274 - val_loss: 0.7848 - val_output_1_loss: 0.5947\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.3779 - output_1_loss: 0.2974 - val_loss: 0.3521 - val_output_1_loss: 0.2359\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.3811 - output_1_loss: 0.3194 - val_loss: 0.7698 - val_output_1_loss: 0.5822\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2903 - output_1_loss: 0.2079 - val_loss: 0.3342 - val_output_1_loss: 0.2182\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.4453 - output_1_loss: 0.3860 - val_loss: 0.7510 - val_output_1_loss: 0.5698\n",
      "Epoch 75/100\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3465 - output_1_loss: 0.2684 - val_loss: 0.3270 - val_output_1_loss: 0.2124\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.4169 - output_1_loss: 0.3541 - val_loss: 0.7339 - val_output_1_loss: 0.5580\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.2855 - output_1_loss: 0.2066 - val_loss: 0.3175 - val_output_1_loss: 0.2037\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.4273 - output_1_loss: 0.3595 - val_loss: 0.7216 - val_output_1_loss: 0.5439\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2067 - output_1_loss: 0.1276Epoch 15/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.2067 - output_1_loss: 0.1276 - val_loss: 0.3124 - val_output_1_loss: 0.2003\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4507 - output_1_loss: 0.3909 - val_loss: 0.7070 - val_output_1_loss: 0.5309\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3039 - output_1_loss: 0.2254Epoch 16/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3039 - output_1_loss: 0.2254 - val_loss: 0.3038 - val_output_1_loss: 0.1941\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3483 - output_1_loss: 0.2886 - val_loss: 0.6897 - val_output_1_loss: 0.5143\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2917 - output_1_loss: 0.2159 - val_loss: 0.3014 - val_output_1_loss: 0.1912\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4067 - output_1_loss: 0.3403Epoch 80/100\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.4067 - output_1_loss: 0.3403 - val_loss: 0.6761 - val_output_1_loss: 0.5018\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2610 - output_1_loss: 0.1853 - val_loss: 0.3036 - val_output_1_loss: 0.1926\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3475 - output_1_loss: 0.2793 - val_loss: 0.6618 - val_output_1_loss: 0.4902\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2113 - output_1_loss: 0.1368 - val_loss: 0.2965 - val_output_1_loss: 0.1834\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.2142 - output_1_loss: 0.1608 - val_loss: 0.6342 - val_output_1_loss: 0.4663\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.2252 - output_1_loss: 0.1497 - val_loss: 0.2755 - val_output_1_loss: 0.1654\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.2461 - output_1_loss: 0.1715 - val_loss: 0.2811 - val_output_1_loss: 0.1705\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.4692 - output_1_loss: 0.4094 - val_loss: 0.6135 - val_output_1_loss: 0.4517\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2413 - output_1_loss: 0.1674 - val_loss: 0.2917 - val_output_1_loss: 0.1799\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2463 - output_1_loss: 0.1722 - val_loss: 0.2905 - val_output_1_loss: 0.1792\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.3294 - output_1_loss: 0.2717 - val_loss: 0.5928 - val_output_1_loss: 0.4338\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2719 - output_1_loss: 0.1950 - val_loss: 0.2900 - val_output_1_loss: 0.1774\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1937 - output_1_loss: 0.1192 - val_loss: 0.2846 - val_output_1_loss: 0.1750\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.2627 - output_1_loss: 0.2045 - val_loss: 0.5719 - val_output_1_loss: 0.4190\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2543 - output_1_loss: 0.1947 - val_loss: 0.5499 - val_output_1_loss: 0.4028\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.2031 - output_1_loss: 0.1511 - val_loss: 0.5303 - val_output_1_loss: 0.3869\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1562 - output_1_loss: 0.1039 - val_loss: 0.4990 - val_output_1_loss: 0.3583\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2640 - output_1_loss: 0.2094 - val_loss: 0.4882 - val_output_1_loss: 0.3493\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.2113 - output_1_loss: 0.1558 - val_loss: 0.4677 - val_output_1_loss: 0.3280\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:35:59,267]\u001b[0m Trial 87 finished with value: 0.02702702702702703 and parameters: {'feature_dim': 64, 'n_step': 6, 'n_shared': 3, 'relaxation_factor': 1.9, 'sparsity_coefficient': 0.07115302919014888, 'bn_momentum': 0.9428266116100652}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.2418 - output_1_loss: 0.1926 - val_loss: 0.4551 - val_output_1_loss: 0.3175\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3635 - output_1_loss: 0.3173Epoch 1/100\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.3635 - output_1_loss: 0.3173 - val_loss: 0.4478 - val_output_1_loss: 0.3114\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.2229 - output_1_loss: 0.1665 - val_loss: 0.4327 - val_output_1_loss: 0.2974\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.2417 - output_1_loss: 0.1923 - val_loss: 0.4141 - val_output_1_loss: 0.2800\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.2059 - output_1_loss: 0.1566 - val_loss: 0.4094 - val_output_1_loss: 0.2731\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.1479 - output_1_loss: 0.0921 - val_loss: 0.3886 - val_output_1_loss: 0.2546\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.2161 - output_1_loss: 0.1596 - val_loss: 0.3825 - val_output_1_loss: 0.2473\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.2789 - output_1_loss: 0.2251 - val_loss: 0.3771 - val_output_1_loss: 0.2417\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1789 - output_1_loss: 0.1277 - val_loss: 0.3665 - val_output_1_loss: 0.2309\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1984 - output_1_loss: 0.1494 - val_loss: 0.3602 - val_output_1_loss: 0.2246\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.1856 - output_1_loss: 0.1394 - val_loss: 0.3493 - val_output_1_loss: 0.2176\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.1760 - output_1_loss: 0.1352 - val_loss: 0.3360 - val_output_1_loss: 0.2084\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.1629 - output_1_loss: 0.1223 - val_loss: 0.3207 - val_output_1_loss: 0.1956\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2031 - output_1_loss: 0.1640 - val_loss: 0.3124 - val_output_1_loss: 0.1893\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 0.5076 - output_1_loss: 0.4652 - val_loss: 0.3070 - val_output_1_loss: 0.1863\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1822 - output_1_loss: 0.1405 - val_loss: 0.2915 - val_output_1_loss: 0.1742\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1833 - output_1_loss: 0.1396 - val_loss: 0.2911 - val_output_1_loss: 0.1726\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.1775 - output_1_loss: 0.1382 - val_loss: 0.2865 - val_output_1_loss: 0.1673\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.2071 - output_1_loss: 0.1638 - val_loss: 0.2762 - val_output_1_loss: 0.1596\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3035 - output_1_loss: 0.2601 - val_loss: 0.2692 - val_output_1_loss: 0.1559\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1467 - output_1_loss: 0.0962 - val_loss: 0.2557 - val_output_1_loss: 0.1463\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1707 - output_1_loss: 0.1185 - val_loss: 0.2443 - val_output_1_loss: 0.1372\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.1753 - output_1_loss: 0.1198 - val_loss: 0.2362 - val_output_1_loss: 0.1304\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 355ms/step - loss: 0.2381 - output_1_loss: 0.1813 - val_loss: 0.2293 - val_output_1_loss: 0.1240\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.8792 - output_1_loss: 0.8785 - val_loss: 0.6867 - val_output_1_loss: 0.6851\n",
      "Epoch 52/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.7551 - output_1_loss: 0.7544 - val_loss: 0.6782 - val_output_1_loss: 0.6767\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.1378 - output_1_loss: 0.0866 - val_loss: 0.2234 - val_output_1_loss: 0.1185\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5630 - output_1_loss: 0.5624 - val_loss: 0.6697 - val_output_1_loss: 0.6684\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4090 - output_1_loss: 0.4084 - val_loss: 0.6577 - val_output_1_loss: 0.6564\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2303 - output_1_loss: 0.2298 - val_loss: 0.6400 - val_output_1_loss: 0.6388\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1557 - output_1_loss: 0.1552Epoch 53/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1557 - output_1_loss: 0.1552 - val_loss: 0.6199 - val_output_1_loss: 0.6187\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1197 - output_1_loss: 0.1192 - val_loss: 0.5954 - val_output_1_loss: 0.5943\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1864 - output_1_loss: 0.1489 - val_loss: 0.2121 - val_output_1_loss: 0.1099\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1178 - output_1_loss: 0.1174 - val_loss: 0.5727 - val_output_1_loss: 0.5716\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1953 - output_1_loss: 0.1482 - val_loss: 0.2022 - val_output_1_loss: 0.1034\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1078 - output_1_loss: 0.1074Epoch 55/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1078 - output_1_loss: 0.1074 - val_loss: 0.5480 - val_output_1_loss: 0.5469\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1798 - output_1_loss: 0.1364 - val_loss: 0.2047 - val_output_1_loss: 0.1060\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0875 - output_1_loss: 0.0872 - val_loss: 0.5219 - val_output_1_loss: 0.5209\n",
      "Epoch 56/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0877 - output_1_loss: 0.0873 - val_loss: 0.4951 - val_output_1_loss: 0.4941\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.1988 - output_1_loss: 0.1471 - val_loss: 0.2001 - val_output_1_loss: 0.1002\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0743 - output_1_loss: 0.0740 - val_loss: 0.4679 - val_output_1_loss: 0.4669\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1339 - output_1_loss: 0.0856 - val_loss: 0.2030 - val_output_1_loss: 0.1002\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0647 - output_1_loss: 0.0644 - val_loss: 0.4405 - val_output_1_loss: 0.4395\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.1518 - output_1_loss: 0.1018 - val_loss: 0.2028 - val_output_1_loss: 0.1016\n",
      "Epoch 59/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0633 - output_1_loss: 0.0630 - val_loss: 0.4126 - val_output_1_loss: 0.4117\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1489 - output_1_loss: 0.1040 - val_loss: 0.1993 - val_output_1_loss: 0.0972\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0612 - output_1_loss: 0.0608Epoch 60/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0612 - output_1_loss: 0.0608 - val_loss: 0.3860 - val_output_1_loss: 0.3851\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2004 - output_1_loss: 0.1538Epoch 16/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0582 - output_1_loss: 0.0579 - val_loss: 0.3592 - val_output_1_loss: 0.3583\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.2004 - output_1_loss: 0.1538 - val_loss: 0.1978 - val_output_1_loss: 0.0933\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0561 - output_1_loss: 0.0558 - val_loss: 0.3349 - val_output_1_loss: 0.3341\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2826 - output_1_loss: 0.2399Epoch 18/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0551 - output_1_loss: 0.0548 - val_loss: 0.3126 - val_output_1_loss: 0.3117\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.2826 - output_1_loss: 0.2399 - val_loss: 0.1945 - val_output_1_loss: 0.0906\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0542 - output_1_loss: 0.0539 - val_loss: 0.2923 - val_output_1_loss: 0.2915\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.1568 - output_1_loss: 0.1102 - val_loss: 0.1925 - val_output_1_loss: 0.0913\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0529 - output_1_loss: 0.0525Epoch 63/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0529 - output_1_loss: 0.0525 - val_loss: 0.2745 - val_output_1_loss: 0.2736\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1970 - output_1_loss: 0.1569 - val_loss: 0.1928 - val_output_1_loss: 0.0955\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0514 - output_1_loss: 0.0511Epoch 64/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0514 - output_1_loss: 0.0511 - val_loss: 0.2587 - val_output_1_loss: 0.2578\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1540 - output_1_loss: 0.1124 - val_loss: 0.1896 - val_output_1_loss: 0.0905\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0499 - output_1_loss: 0.0496Epoch 65/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0499 - output_1_loss: 0.0496 - val_loss: 0.2447 - val_output_1_loss: 0.2439\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1204 - output_1_loss: 0.0795 - val_loss: 0.1934 - val_output_1_loss: 0.0932\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0488 - output_1_loss: 0.0485 - val_loss: 0.2325 - val_output_1_loss: 0.2317\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0489 - output_1_loss: 0.0485 - val_loss: 0.2216 - val_output_1_loss: 0.2208\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.1746 - output_1_loss: 0.1255 - val_loss: 0.1850 - val_output_1_loss: 0.0879\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0483 - output_1_loss: 0.0480 - val_loss: 0.2120 - val_output_1_loss: 0.2112\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0480 - output_1_loss: 0.0477 - val_loss: 0.2035 - val_output_1_loss: 0.2027\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0473 - output_1_loss: 0.0470 - val_loss: 0.1959 - val_output_1_loss: 0.1952\n",
      "Epoch 28/100\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0466 - output_1_loss: 0.0463 - val_loss: 0.1893 - val_output_1_loss: 0.1886\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0459 - output_1_loss: 0.0456 - val_loss: 0.1835 - val_output_1_loss: 0.1827\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.2359 - output_1_loss: 0.1845 - val_loss: 0.1826 - val_output_1_loss: 0.0842\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2123 - output_1_loss: 0.1631 - val_loss: 0.1838 - val_output_1_loss: 0.0840\n",
      "Epoch 30/100\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0453 - output_1_loss: 0.0450 - val_loss: 0.1783 - val_output_1_loss: 0.1776\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1776 - output_1_loss: 0.1208 - val_loss: 0.1894 - val_output_1_loss: 0.0875\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0447 - output_1_loss: 0.0444Epoch 70/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0447 - output_1_loss: 0.0444 - val_loss: 0.1738 - val_output_1_loss: 0.1731\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1523 - output_1_loss: 0.0984 - val_loss: 0.1842 - val_output_1_loss: 0.0823\n",
      "Epoch 71/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1472 - output_1_loss: 0.0946 - val_loss: 0.1830 - val_output_1_loss: 0.0821\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0443 - output_1_loss: 0.0440 - val_loss: 0.1699 - val_output_1_loss: 0.1692\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0439 - output_1_loss: 0.0436 - val_loss: 0.1664 - val_output_1_loss: 0.1657\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.1610 - output_1_loss: 0.1110 - val_loss: 0.1772 - val_output_1_loss: 0.0826\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0434 - output_1_loss: 0.0431 - val_loss: 0.1632 - val_output_1_loss: 0.1625\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0428 - output_1_loss: 0.0425 - val_loss: 0.1602 - val_output_1_loss: 0.1595\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0421 - output_1_loss: 0.0418 - val_loss: 0.1573 - val_output_1_loss: 0.1567\n",
      "Epoch 73/100\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0415 - output_1_loss: 0.0412 - val_loss: 0.1547 - val_output_1_loss: 0.1540\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1670 - output_1_loss: 0.1192 - val_loss: 0.1748 - val_output_1_loss: 0.0831\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0409 - output_1_loss: 0.0406 - val_loss: 0.1522 - val_output_1_loss: 0.1515\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0404 - output_1_loss: 0.0401 - val_loss: 0.1498 - val_output_1_loss: 0.1492\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0399 - output_1_loss: 0.0396 - val_loss: 0.1478 - val_output_1_loss: 0.1472\n",
      "Epoch 41/100\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0392 - output_1_loss: 0.0389 - val_loss: 0.1461 - val_output_1_loss: 0.1454\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2308 - output_1_loss: 0.1907 - val_loss: 0.1764 - val_output_1_loss: 0.0813\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0386 - output_1_loss: 0.0383Epoch 75/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0386 - output_1_loss: 0.0383 - val_loss: 0.1447 - val_output_1_loss: 0.1440\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1201 - output_1_loss: 0.0704 - val_loss: 0.1756 - val_output_1_loss: 0.0789\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2775 - output_1_loss: 0.2317Epoch 43/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2775 - output_1_loss: 0.2317 - val_loss: 0.1771 - val_output_1_loss: 0.0783\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0381 - output_1_loss: 0.0378 - val_loss: 0.1434 - val_output_1_loss: 0.1427\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0376 - output_1_loss: 0.0374 - val_loss: 0.1421 - val_output_1_loss: 0.1415\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.1615 - output_1_loss: 0.1139 - val_loss: 0.1729 - val_output_1_loss: 0.0765\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0372 - output_1_loss: 0.0369 - val_loss: 0.1411 - val_output_1_loss: 0.1405\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0366 - output_1_loss: 0.0363 - val_loss: 0.1401 - val_output_1_loss: 0.1395\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0360 - output_1_loss: 0.0357Epoch 78/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0360 - output_1_loss: 0.0357 - val_loss: 0.1391 - val_output_1_loss: 0.1385\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1456 - output_1_loss: 0.0987 - val_loss: 0.1622 - val_output_1_loss: 0.0716\n",
      "Epoch 79/100\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2362 - output_1_loss: 0.1896 - val_loss: 0.1698 - val_output_1_loss: 0.0753\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0355 - output_1_loss: 0.0352 - val_loss: 0.1381 - val_output_1_loss: 0.1375\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1276 - output_1_loss: 0.0874 - val_loss: 0.1710 - val_output_1_loss: 0.0758\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0351 - output_1_loss: 0.0348 - val_loss: 0.1372 - val_output_1_loss: 0.1366\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1521 - output_1_loss: 0.1087 - val_loss: 0.2081 - val_output_1_loss: 0.1171\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0346 - output_1_loss: 0.0344 - val_loss: 0.1365 - val_output_1_loss: 0.1359\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1497 - output_1_loss: 0.1013 - val_loss: 0.1823 - val_output_1_loss: 0.0935\n",
      "Epoch 83/100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0343 - output_1_loss: 0.0340 - val_loss: 0.1358 - val_output_1_loss: 0.1352\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.1249 - output_1_loss: 0.0729 - val_loss: 0.1612 - val_output_1_loss: 0.0715\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0339 - output_1_loss: 0.0336 - val_loss: 0.1352 - val_output_1_loss: 0.1346\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0334 - output_1_loss: 0.0332 - val_loss: 0.1347 - val_output_1_loss: 0.1341\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.2262 - output_1_loss: 0.1728 - val_loss: 0.1609 - val_output_1_loss: 0.0703\n",
      "Epoch 85/100\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1996 - output_1_loss: 0.1449 - val_loss: 0.1675 - val_output_1_loss: 0.0748\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0328 - output_1_loss: 0.0326 - val_loss: 0.1342 - val_output_1_loss: 0.1336\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2672 - output_1_loss: 0.2163 - val_loss: 0.1655 - val_output_1_loss: 0.0725\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0328 - output_1_loss: 0.0325 - val_loss: 0.1339 - val_output_1_loss: 0.1333\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1527 - output_1_loss: 0.0967 - val_loss: 0.1688 - val_output_1_loss: 0.0747\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0322 - output_1_loss: 0.0319 - val_loss: 0.1337 - val_output_1_loss: 0.1331\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1645 - output_1_loss: 0.1130Epoch 57/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1645 - output_1_loss: 0.1130 - val_loss: 0.1666 - val_output_1_loss: 0.0729\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0318 - output_1_loss: 0.0316 - val_loss: 0.1336 - val_output_1_loss: 0.1331\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0357 - output_1_loss: 0.0354Epoch 89/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0357 - output_1_loss: 0.0354 - val_loss: 0.1341 - val_output_1_loss: 0.1336\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1534 - output_1_loss: 0.0951Epoch 59/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0316 - output_1_loss: 0.0313 - val_loss: 0.1346 - val_output_1_loss: 0.1340\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1534 - output_1_loss: 0.0951 - val_loss: 0.1648 - val_output_1_loss: 0.0738\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0312 - output_1_loss: 0.0309 - val_loss: 0.1345 - val_output_1_loss: 0.1339\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0332 - output_1_loss: 0.0329 - val_loss: 0.1349 - val_output_1_loss: 0.1344\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0304 - output_1_loss: 0.0301 - val_loss: 0.1345 - val_output_1_loss: 0.1340\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:36:24,088]\u001b[0m Trial 89 finished with value: 0.06666666666666667 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 2.0, 'sparsity_coefficient': 0.00021095244801502773, 'bn_momentum': 0.9474551746631757}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:36:25,435]\u001b[0m Trial 88 finished with value: 0.025 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 2, 'relaxation_factor': 1.9, 'sparsity_coefficient': 0.061166299535881416, 'bn_momentum': 0.9457743060906304}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.8098 - output_1_loss: 0.8098 - val_loss: 0.6910 - val_output_1_loss: 0.6909\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.7110 - output_1_loss: 0.7110 - val_loss: 0.6892 - val_output_1_loss: 0.6891\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.7890 - output_1_loss: 0.7890 - val_loss: 0.6901 - val_output_1_loss: 0.6900\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7393 - output_1_loss: 0.7393 - val_loss: 0.6861 - val_output_1_loss: 0.6860\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8207 - output_1_loss: 0.8206 - val_loss: 0.6871 - val_output_1_loss: 0.6870\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7055 - output_1_loss: 0.7054Epoch 3/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7055 - output_1_loss: 0.7054 - val_loss: 0.6843 - val_output_1_loss: 0.6842\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.7423 - output_1_loss: 0.7423 - val_loss: 0.6843 - val_output_1_loss: 0.6842\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.7082 - output_1_loss: 0.7081 - val_loss: 0.6817 - val_output_1_loss: 0.6816\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7051 - output_1_loss: 0.7051Epoch 4/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.7051 - output_1_loss: 0.7051 - val_loss: 0.6791 - val_output_1_loss: 0.6790\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7348 - output_1_loss: 0.7348Epoch 7/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7106 - output_1_loss: 0.7106 - val_loss: 0.6770 - val_output_1_loss: 0.6769\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.7348 - output_1_loss: 0.7348 - val_loss: 0.6800 - val_output_1_loss: 0.6799\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.6464 - output_1_loss: 0.6464 - val_loss: 0.6738 - val_output_1_loss: 0.6737\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7058 - output_1_loss: 0.7057 - val_loss: 0.6764 - val_output_1_loss: 0.6763\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6597 - output_1_loss: 0.6597 - val_loss: 0.6711 - val_output_1_loss: 0.6710\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.6789 - output_1_loss: 0.6788 - val_loss: 0.6730 - val_output_1_loss: 0.6729\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6113 - output_1_loss: 0.6113 - val_loss: 0.6671 - val_output_1_loss: 0.6670\n",
      "Epoch 11/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.6230 - output_1_loss: 0.6229 - val_loss: 0.6642 - val_output_1_loss: 0.6641\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6306 - output_1_loss: 0.6306 - val_loss: 0.6693 - val_output_1_loss: 0.6692\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.7244 - output_1_loss: 0.7243 - val_loss: 0.6657 - val_output_1_loss: 0.6656\n",
      "Epoch 12/100\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.6157 - output_1_loss: 0.6156 - val_loss: 0.6608 - val_output_1_loss: 0.6607\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6345 - output_1_loss: 0.6344 - val_loss: 0.6634 - val_output_1_loss: 0.6633\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5769 - output_1_loss: 0.5768 - val_loss: 0.6587 - val_output_1_loss: 0.6586\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6075 - output_1_loss: 0.6074 - val_loss: 0.6603 - val_output_1_loss: 0.6602\n",
      "Epoch 14/100\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.5834 - output_1_loss: 0.5833 - val_loss: 0.6557 - val_output_1_loss: 0.6556\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.6849 - output_1_loss: 0.6849 - val_loss: 0.6563 - val_output_1_loss: 0.6562\n",
      "Epoch 15/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5559 - output_1_loss: 0.5558 - val_loss: 0.6514 - val_output_1_loss: 0.6513\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6509 - output_1_loss: 0.6508 - val_loss: 0.6518 - val_output_1_loss: 0.6517\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5994 - output_1_loss: 0.5993 - val_loss: 0.6479 - val_output_1_loss: 0.6478\n",
      "Epoch 16/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5261 - output_1_loss: 0.5261 - val_loss: 0.6471 - val_output_1_loss: 0.6470\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.5680 - output_1_loss: 0.5679 - val_loss: 0.6436 - val_output_1_loss: 0.6435\n",
      "Epoch 17/100\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5110 - output_1_loss: 0.5109 - val_loss: 0.6433 - val_output_1_loss: 0.6432\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.5332 - output_1_loss: 0.5332 - val_loss: 0.6390 - val_output_1_loss: 0.6389\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5225 - output_1_loss: 0.5225 - val_loss: 0.6348 - val_output_1_loss: 0.6347\n",
      "Epoch 18/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5172 - output_1_loss: 0.5171 - val_loss: 0.6393 - val_output_1_loss: 0.6392\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4633 - output_1_loss: 0.4632 - val_loss: 0.6292 - val_output_1_loss: 0.6291\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4931 - output_1_loss: 0.4930 - val_loss: 0.6349 - val_output_1_loss: 0.6348\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4496 - output_1_loss: 0.4495 - val_loss: 0.6215 - val_output_1_loss: 0.6214\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4952 - output_1_loss: 0.4952 - val_loss: 0.6304 - val_output_1_loss: 0.6303\n",
      "Epoch 21/100\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4215 - output_1_loss: 0.4214 - val_loss: 0.6246 - val_output_1_loss: 0.6245\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.4365 - output_1_loss: 0.4365 - val_loss: 0.6137 - val_output_1_loss: 0.6136\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3805 - output_1_loss: 0.3804 - val_loss: 0.6052 - val_output_1_loss: 0.6051\n",
      "Epoch 22/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.4156 - output_1_loss: 0.4156 - val_loss: 0.6190 - val_output_1_loss: 0.6190\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.3536 - output_1_loss: 0.3536 - val_loss: 0.5973 - val_output_1_loss: 0.5972\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3743 - output_1_loss: 0.3743 - val_loss: 0.6122 - val_output_1_loss: 0.6121\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3249 - output_1_loss: 0.3248 - val_loss: 0.5883 - val_output_1_loss: 0.5883\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.4506 - output_1_loss: 0.4506 - val_loss: 0.6073 - val_output_1_loss: 0.6073\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3370 - output_1_loss: 0.3369Epoch 23/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3370 - output_1_loss: 0.3369 - val_loss: 0.5996 - val_output_1_loss: 0.5995\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2925 - output_1_loss: 0.2924 - val_loss: 0.5799 - val_output_1_loss: 0.5798\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3059 - output_1_loss: 0.3058 - val_loss: 0.5912 - val_output_1_loss: 0.5911\n",
      "Epoch 27/100\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2788 - output_1_loss: 0.2788 - val_loss: 0.5816 - val_output_1_loss: 0.5815\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2666 - output_1_loss: 0.2665 - val_loss: 0.5710 - val_output_1_loss: 0.5709\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2363 - output_1_loss: 0.2362 - val_loss: 0.5609 - val_output_1_loss: 0.5608\n",
      "Epoch 28/100\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2456 - output_1_loss: 0.2455 - val_loss: 0.5718 - val_output_1_loss: 0.5717\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2188 - output_1_loss: 0.2188 - val_loss: 0.5493 - val_output_1_loss: 0.5492\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2279 - output_1_loss: 0.2278 - val_loss: 0.5612 - val_output_1_loss: 0.5611\n",
      "Epoch 30/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2079 - output_1_loss: 0.2078 - val_loss: 0.5503 - val_output_1_loss: 0.5502\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2105 - output_1_loss: 0.2104 - val_loss: 0.5377 - val_output_1_loss: 0.5377\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1914 - output_1_loss: 0.1914 - val_loss: 0.5377 - val_output_1_loss: 0.5376\n",
      "Epoch 32/100\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1766 - output_1_loss: 0.1766 - val_loss: 0.5252 - val_output_1_loss: 0.5251\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1969 - output_1_loss: 0.1968 - val_loss: 0.5259 - val_output_1_loss: 0.5258\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1642 - output_1_loss: 0.1641 - val_loss: 0.5120 - val_output_1_loss: 0.5119\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1872 - output_1_loss: 0.1872 - val_loss: 0.5143 - val_output_1_loss: 0.5143\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1496 - output_1_loss: 0.1496 - val_loss: 0.4974 - val_output_1_loss: 0.4973\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1760 - output_1_loss: 0.1760 - val_loss: 0.5016 - val_output_1_loss: 0.5015\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1354 - output_1_loss: 0.1353Epoch 31/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1354 - output_1_loss: 0.1353 - val_loss: 0.4816 - val_output_1_loss: 0.4816\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1573 - output_1_loss: 0.1572Epoch 36/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1573 - output_1_loss: 0.1572 - val_loss: 0.4882 - val_output_1_loss: 0.4881\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1257 - output_1_loss: 0.1256 - val_loss: 0.4653 - val_output_1_loss: 0.4653\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1482 - output_1_loss: 0.1481 - val_loss: 0.4743 - val_output_1_loss: 0.4742\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1365 - output_1_loss: 0.1364Epoch 37/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1365 - output_1_loss: 0.1364 - val_loss: 0.4598 - val_output_1_loss: 0.4597\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1148 - output_1_loss: 0.1147 - val_loss: 0.4480 - val_output_1_loss: 0.4479\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1071 - output_1_loss: 0.1071Epoch 34/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1071 - output_1_loss: 0.1071 - val_loss: 0.4304 - val_output_1_loss: 0.4303\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1268 - output_1_loss: 0.1268 - val_loss: 0.4448 - val_output_1_loss: 0.4447\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0998 - output_1_loss: 0.0997 - val_loss: 0.4127 - val_output_1_loss: 0.4126\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1198 - output_1_loss: 0.1197 - val_loss: 0.4293 - val_output_1_loss: 0.4292\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0942 - output_1_loss: 0.0942 - val_loss: 0.3951 - val_output_1_loss: 0.3950\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0892 - output_1_loss: 0.0891Epoch 36/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0892 - output_1_loss: 0.0891 - val_loss: 0.3777 - val_output_1_loss: 0.3776\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0839 - output_1_loss: 0.0839 - val_loss: 0.3604 - val_output_1_loss: 0.3603\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1115 - output_1_loss: 0.1114 - val_loss: 0.4138 - val_output_1_loss: 0.4137\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0791 - output_1_loss: 0.0791Epoch 37/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0791 - output_1_loss: 0.0791 - val_loss: 0.3436 - val_output_1_loss: 0.3435\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1045 - output_1_loss: 0.1044 - val_loss: 0.3986 - val_output_1_loss: 0.3986\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0782 - output_1_loss: 0.0781 - val_loss: 0.3272 - val_output_1_loss: 0.3271\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0760 - output_1_loss: 0.0760Epoch 38/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0760 - output_1_loss: 0.0760 - val_loss: 0.3113 - val_output_1_loss: 0.3113\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0985 - output_1_loss: 0.0985 - val_loss: 0.3836 - val_output_1_loss: 0.3835\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0952 - output_1_loss: 0.0951Epoch 46/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0952 - output_1_loss: 0.0951 - val_loss: 0.3696 - val_output_1_loss: 0.3696\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0729 - output_1_loss: 0.0729 - val_loss: 0.2962 - val_output_1_loss: 0.2962\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0889 - output_1_loss: 0.0889 - val_loss: 0.3545 - val_output_1_loss: 0.3545\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0839 - output_1_loss: 0.0839 - val_loss: 0.3401 - val_output_1_loss: 0.3401\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0697 - output_1_loss: 0.0696 - val_loss: 0.2820 - val_output_1_loss: 0.2820\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0806 - output_1_loss: 0.0805 - val_loss: 0.3264 - val_output_1_loss: 0.3264\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0658 - output_1_loss: 0.0658 - val_loss: 0.2690 - val_output_1_loss: 0.2690\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0776 - output_1_loss: 0.0775 - val_loss: 0.3136 - val_output_1_loss: 0.3135\n",
      "Epoch 44/100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0742 - output_1_loss: 0.0741 - val_loss: 0.3015 - val_output_1_loss: 0.3014\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0648 - output_1_loss: 0.0648 - val_loss: 0.2566 - val_output_1_loss: 0.2565\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0787 - output_1_loss: 0.0786 - val_loss: 0.2914 - val_output_1_loss: 0.2914\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0635 - output_1_loss: 0.0634 - val_loss: 0.2448 - val_output_1_loss: 0.2448\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0759 - output_1_loss: 0.0758 - val_loss: 0.2816 - val_output_1_loss: 0.2815\n",
      "Epoch 47/100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0743 - output_1_loss: 0.0743 - val_loss: 0.2723 - val_output_1_loss: 0.2723\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0612 - output_1_loss: 0.0611 - val_loss: 0.2338 - val_output_1_loss: 0.2338\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0713 - output_1_loss: 0.0713Epoch 52/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0713 - output_1_loss: 0.0713 - val_loss: 0.2635 - val_output_1_loss: 0.2635\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0595 - output_1_loss: 0.0595Epoch 49/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0595 - output_1_loss: 0.0595 - val_loss: 0.2237 - val_output_1_loss: 0.2236\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0690 - output_1_loss: 0.0690 - val_loss: 0.2552 - val_output_1_loss: 0.2552\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0583 - output_1_loss: 0.0583 - val_loss: 0.2144 - val_output_1_loss: 0.2143\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0569 - output_1_loss: 0.0569Epoch 50/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0569 - output_1_loss: 0.0569 - val_loss: 0.2059 - val_output_1_loss: 0.2058\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0682 - output_1_loss: 0.0681 - val_loss: 0.2472 - val_output_1_loss: 0.2471\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0554 - output_1_loss: 0.0554Epoch 51/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0554 - output_1_loss: 0.0554 - val_loss: 0.1978 - val_output_1_loss: 0.1978\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0662 - output_1_loss: 0.0661 - val_loss: 0.2391 - val_output_1_loss: 0.2390\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0635 - output_1_loss: 0.0635Epoch 56/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0635 - output_1_loss: 0.0635 - val_loss: 0.2314 - val_output_1_loss: 0.2314\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0547 - output_1_loss: 0.0546 - val_loss: 0.1902 - val_output_1_loss: 0.1902\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0608 - output_1_loss: 0.0607 - val_loss: 0.2240 - val_output_1_loss: 0.2239\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0578 - output_1_loss: 0.0578Epoch 57/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0578 - output_1_loss: 0.0578 - val_loss: 0.2169 - val_output_1_loss: 0.2169\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0543 - output_1_loss: 0.0542 - val_loss: 0.1833 - val_output_1_loss: 0.1833\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0561 - output_1_loss: 0.0560 - val_loss: 0.2103 - val_output_1_loss: 0.2103\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0545 - output_1_loss: 0.0545Epoch 58/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0545 - output_1_loss: 0.0545 - val_loss: 0.2043 - val_output_1_loss: 0.2043\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0536 - output_1_loss: 0.0536 - val_loss: 0.1769 - val_output_1_loss: 0.1768\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0531 - output_1_loss: 0.0530 - val_loss: 0.1983 - val_output_1_loss: 0.1982\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0525 - output_1_loss: 0.0525 - val_loss: 0.1701 - val_output_1_loss: 0.1701\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0509 - output_1_loss: 0.0509 - val_loss: 0.1644 - val_output_1_loss: 0.1644\n",
      "Epoch 61/100\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0523 - output_1_loss: 0.0523 - val_loss: 0.1928 - val_output_1_loss: 0.1927\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0500 - output_1_loss: 0.0500 - val_loss: 0.1596 - val_output_1_loss: 0.1595\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0492 - output_1_loss: 0.0491 - val_loss: 0.1547 - val_output_1_loss: 0.1546\n",
      "Epoch 59/100\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0510 - output_1_loss: 0.0510 - val_loss: 0.1877 - val_output_1_loss: 0.1877\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0478 - output_1_loss: 0.0477 - val_loss: 0.1503 - val_output_1_loss: 0.1503\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0514 - output_1_loss: 0.0513 - val_loss: 0.1832 - val_output_1_loss: 0.1832\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0471 - output_1_loss: 0.0471 - val_loss: 0.1465 - val_output_1_loss: 0.1464\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0493 - output_1_loss: 0.0493Epoch 65/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.0493 - output_1_loss: 0.0493 - val_loss: 0.1786 - val_output_1_loss: 0.1786\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0461 - output_1_loss: 0.0461 - val_loss: 0.1428 - val_output_1_loss: 0.1428\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0451 - output_1_loss: 0.0451Epoch 62/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0451 - output_1_loss: 0.0451 - val_loss: 0.1393 - val_output_1_loss: 0.1392\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0481 - output_1_loss: 0.0480 - val_loss: 0.1734 - val_output_1_loss: 0.1733\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0443 - output_1_loss: 0.0442 - val_loss: 0.1362 - val_output_1_loss: 0.1361\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0436 - output_1_loss: 0.0436Epoch 63/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0436 - output_1_loss: 0.0436 - val_loss: 0.1333 - val_output_1_loss: 0.1332\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0472 - output_1_loss: 0.0472Epoch 69/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0472 - output_1_loss: 0.0472 - val_loss: 0.1680 - val_output_1_loss: 0.1680\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0427 - output_1_loss: 0.0427 - val_loss: 0.1305 - val_output_1_loss: 0.1305\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0418 - output_1_loss: 0.0418Epoch 64/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0418 - output_1_loss: 0.0418 - val_loss: 0.1280 - val_output_1_loss: 0.1279\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0461 - output_1_loss: 0.0461 - val_loss: 0.1627 - val_output_1_loss: 0.1626\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0411 - output_1_loss: 0.0411 - val_loss: 0.1254 - val_output_1_loss: 0.1253\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0450 - output_1_loss: 0.0450 - val_loss: 0.1577 - val_output_1_loss: 0.1576\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0404 - output_1_loss: 0.0404 - val_loss: 0.1227 - val_output_1_loss: 0.1227\n",
      "Epoch 73/100\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0395 - output_1_loss: 0.0395 - val_loss: 0.1206 - val_output_1_loss: 0.1206\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0444 - output_1_loss: 0.0444 - val_loss: 0.1517 - val_output_1_loss: 0.1516\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0429 - output_1_loss: 0.0428 - val_loss: 0.1464 - val_output_1_loss: 0.1463\n",
      "Epoch 74/100\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0389 - output_1_loss: 0.0388 - val_loss: 0.1184 - val_output_1_loss: 0.1183\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0421 - output_1_loss: 0.0420 - val_loss: 0.1435 - val_output_1_loss: 0.1435\n",
      "Epoch 75/100\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0380 - output_1_loss: 0.0379 - val_loss: 0.1163 - val_output_1_loss: 0.1162\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0411 - output_1_loss: 0.0411 - val_loss: 0.1411 - val_output_1_loss: 0.1411\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0407 - output_1_loss: 0.0406 - val_loss: 0.1389 - val_output_1_loss: 0.1389\n",
      "Epoch 71/100\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0372 - output_1_loss: 0.0372 - val_loss: 0.1150 - val_output_1_loss: 0.1150\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0395 - output_1_loss: 0.0395 - val_loss: 0.1364 - val_output_1_loss: 0.1364\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0363 - output_1_loss: 0.0363 - val_loss: 0.1130 - val_output_1_loss: 0.1129\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0386 - output_1_loss: 0.0386 - val_loss: 0.1335 - val_output_1_loss: 0.1334\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0376 - output_1_loss: 0.0375Epoch 78/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0376 - output_1_loss: 0.0375 - val_loss: 0.1309 - val_output_1_loss: 0.1309\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0358 - output_1_loss: 0.0357 - val_loss: 0.1097 - val_output_1_loss: 0.1096\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0352 - output_1_loss: 0.0351Epoch 74/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0352 - output_1_loss: 0.0351 - val_loss: 0.1086 - val_output_1_loss: 0.1086\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0367 - output_1_loss: 0.0366 - val_loss: 0.1290 - val_output_1_loss: 0.1289\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0343 - output_1_loss: 0.0343 - val_loss: 0.1073 - val_output_1_loss: 0.1073\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0358 - output_1_loss: 0.0358 - val_loss: 0.1270 - val_output_1_loss: 0.1270\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0335 - output_1_loss: 0.0335Epoch 76/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0335 - output_1_loss: 0.0335 - val_loss: 0.1053 - val_output_1_loss: 0.1052\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0351 - output_1_loss: 0.0351 - val_loss: 0.1247 - val_output_1_loss: 0.1247\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0328 - output_1_loss: 0.0328 - val_loss: 0.1032 - val_output_1_loss: 0.1032\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0342 - output_1_loss: 0.0342 - val_loss: 0.1219 - val_output_1_loss: 0.1218\n",
      "Epoch 78/100\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0336 - output_1_loss: 0.0336 - val_loss: 0.1181 - val_output_1_loss: 0.1181\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0323 - output_1_loss: 0.0322 - val_loss: 0.1010 - val_output_1_loss: 0.1010\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0326 - output_1_loss: 0.0326 - val_loss: 0.1137 - val_output_1_loss: 0.1136\n",
      "Epoch 80/100\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0316 - output_1_loss: 0.0316 - val_loss: 0.1101 - val_output_1_loss: 0.1101\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0317 - output_1_loss: 0.0317 - val_loss: 0.0994 - val_output_1_loss: 0.0993\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0312 - output_1_loss: 0.0312 - val_loss: 0.0974 - val_output_1_loss: 0.0973\n",
      "Epoch 86/100\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0306 - output_1_loss: 0.0306 - val_loss: 0.0954 - val_output_1_loss: 0.0954\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0307 - output_1_loss: 0.0307 - val_loss: 0.1074 - val_output_1_loss: 0.1074\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0297 - output_1_loss: 0.0296 - val_loss: 0.0943 - val_output_1_loss: 0.0942\n",
      "Epoch 88/100\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0295 - output_1_loss: 0.0294 - val_loss: 0.0939 - val_output_1_loss: 0.0938\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0300 - output_1_loss: 0.0299 - val_loss: 0.1050 - val_output_1_loss: 0.1049\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0284 - output_1_loss: 0.0284 - val_loss: 0.0937 - val_output_1_loss: 0.0937\n",
      "Epoch 90/100\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0280 - output_1_loss: 0.0280 - val_loss: 0.0923 - val_output_1_loss: 0.0922\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0292 - output_1_loss: 0.0291 - val_loss: 0.1015 - val_output_1_loss: 0.1015\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0284 - output_1_loss: 0.0284Epoch 91/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0284 - output_1_loss: 0.0284 - val_loss: 0.0983 - val_output_1_loss: 0.0983\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0275 - output_1_loss: 0.0275 - val_loss: 0.0907 - val_output_1_loss: 0.0907\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0275 - output_1_loss: 0.0275 - val_loss: 0.0946 - val_output_1_loss: 0.0946\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0267 - output_1_loss: 0.0266 - val_loss: 0.0887 - val_output_1_loss: 0.0887\n",
      "Epoch 93/100\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0259 - output_1_loss: 0.0259 - val_loss: 0.0872 - val_output_1_loss: 0.0872\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0269 - output_1_loss: 0.0269 - val_loss: 0.0876 - val_output_1_loss: 0.0876\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0253 - output_1_loss: 0.0253 - val_loss: 0.0863 - val_output_1_loss: 0.0863\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0264 - output_1_loss: 0.0263 - val_loss: 0.0702 - val_output_1_loss: 0.0702\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0246 - output_1_loss: 0.0245 - val_loss: 0.0852 - val_output_1_loss: 0.0851\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0258 - output_1_loss: 0.0257 - val_loss: 0.0623 - val_output_1_loss: 0.0623\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0242 - output_1_loss: 0.0242 - val_loss: 0.0825 - val_output_1_loss: 0.0825\n",
      "Epoch 89/100\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0252 - output_1_loss: 0.0251 - val_loss: 0.0586 - val_output_1_loss: 0.0585\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0236 - output_1_loss: 0.0236 - val_loss: 0.0806 - val_output_1_loss: 0.0805\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0245 - output_1_loss: 0.0245 - val_loss: 0.0551 - val_output_1_loss: 0.0550\n",
      "Epoch 98/100\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0234 - output_1_loss: 0.0233 - val_loss: 0.0796 - val_output_1_loss: 0.0795\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0241 - output_1_loss: 0.0241 - val_loss: 0.0532 - val_output_1_loss: 0.0532\n",
      "Epoch 99/100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0229 - output_1_loss: 0.0229 - val_loss: 0.0787 - val_output_1_loss: 0.0787\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0236 - output_1_loss: 0.0236 - val_loss: 0.0527 - val_output_1_loss: 0.0527\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0226 - output_1_loss: 0.0225 - val_loss: 0.0780 - val_output_1_loss: 0.0780\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0228 - output_1_loss: 0.0227 - val_loss: 0.0605 - val_output_1_loss: 0.0605\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0225 - output_1_loss: 0.0224 - val_loss: 0.0671 - val_output_1_loss: 0.0671\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0216 - output_1_loss: 0.0216 - val_loss: 0.0677 - val_output_1_loss: 0.0677\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0212 - output_1_loss: 0.0211 - val_loss: 0.0673 - val_output_1_loss: 0.0673\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0207 - output_1_loss: 0.0207 - val_loss: 0.0670 - val_output_1_loss: 0.0669\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:37:10,017]\u001b[0m Trial 90 finished with value: 0.07142857142857142 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1.6451359160381268e-05, 'bn_momentum': 0.9391933750769664}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:37:10,392]\u001b[0m Trial 91 finished with value: 1.0 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1.7216138697333867e-05, 'bn_momentum': 0.9286379494836702}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.6590 - output_1_loss: 0.6365 - val_loss: 0.7534 - val_output_1_loss: 0.6889\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.7200 - output_1_loss: 0.7200 - val_loss: 0.6896 - val_output_1_loss: 0.6895\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.7292 - output_1_loss: 0.7291 - val_loss: 0.6843 - val_output_1_loss: 0.6843\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7387 - output_1_loss: 0.7387 - val_loss: 0.6810 - val_output_1_loss: 0.6810\n",
      "Epoch 4/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6289 - output_1_loss: 0.6046 - val_loss: 0.7482 - val_output_1_loss: 0.6860\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.7407 - output_1_loss: 0.7407 - val_loss: 0.6787 - val_output_1_loss: 0.6787\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6523 - output_1_loss: 0.6522 - val_loss: 0.6762 - val_output_1_loss: 0.6761\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6229 - output_1_loss: 0.5996 - val_loss: 0.7432 - val_output_1_loss: 0.6828\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6249 - output_1_loss: 0.6249Epoch 4/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6249 - output_1_loss: 0.6249 - val_loss: 0.6721 - val_output_1_loss: 0.6721\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6503 - output_1_loss: 0.6269 - val_loss: 0.7378 - val_output_1_loss: 0.6791\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.5654 - output_1_loss: 0.5654 - val_loss: 0.6685 - val_output_1_loss: 0.6685\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5950 - output_1_loss: 0.5950 - val_loss: 0.6651 - val_output_1_loss: 0.6651\n",
      "Epoch 5/100\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.5982 - output_1_loss: 0.5742 - val_loss: 0.7329 - val_output_1_loss: 0.6759\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.6013 - output_1_loss: 0.6013 - val_loss: 0.6626 - val_output_1_loss: 0.6625\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4426 - output_1_loss: 0.4426Epoch 6/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4426 - output_1_loss: 0.4426 - val_loss: 0.6578 - val_output_1_loss: 0.6577\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5728 - output_1_loss: 0.5482 - val_loss: 0.7270 - val_output_1_loss: 0.6716\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4316 - output_1_loss: 0.4316 - val_loss: 0.6527 - val_output_1_loss: 0.6526\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5741 - output_1_loss: 0.5495 - val_loss: 0.7222 - val_output_1_loss: 0.6680\n",
      "Epoch 12/100\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3815 - output_1_loss: 0.3815 - val_loss: 0.6462 - val_output_1_loss: 0.6461\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5170 - output_1_loss: 0.4926 - val_loss: 0.7167 - val_output_1_loss: 0.6637\n",
      "Epoch 13/100\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3719 - output_1_loss: 0.3719 - val_loss: 0.6417 - val_output_1_loss: 0.6416\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.5379 - output_1_loss: 0.5139 - val_loss: 0.7113 - val_output_1_loss: 0.6596\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3167 - output_1_loss: 0.3166 - val_loss: 0.6362 - val_output_1_loss: 0.6361\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4755 - output_1_loss: 0.4517 - val_loss: 0.7053 - val_output_1_loss: 0.6547\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3423 - output_1_loss: 0.3423 - val_loss: 0.6315 - val_output_1_loss: 0.6315\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4743 - output_1_loss: 0.4508 - val_loss: 0.6960 - val_output_1_loss: 0.6464\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5257 - output_1_loss: 0.5019Epoch 16/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5257 - output_1_loss: 0.5019 - val_loss: 0.6894 - val_output_1_loss: 0.6409\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2998 - output_1_loss: 0.2998 - val_loss: 0.6239 - val_output_1_loss: 0.6239\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.4728 - output_1_loss: 0.4492 - val_loss: 0.6814 - val_output_1_loss: 0.6339\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4101 - output_1_loss: 0.3863Epoch 17/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4101 - output_1_loss: 0.3863 - val_loss: 0.6728 - val_output_1_loss: 0.6261\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2382 - output_1_loss: 0.2381 - val_loss: 0.6129 - val_output_1_loss: 0.6128\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3873 - output_1_loss: 0.3637 - val_loss: 0.6622 - val_output_1_loss: 0.6164\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2900 - output_1_loss: 0.2900 - val_loss: 0.6056 - val_output_1_loss: 0.6056\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.3285 - output_1_loss: 0.3050 - val_loss: 0.6493 - val_output_1_loss: 0.6043\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2878 - output_1_loss: 0.2645Epoch 19/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2878 - output_1_loss: 0.2645 - val_loss: 0.6360 - val_output_1_loss: 0.5920\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2512 - output_1_loss: 0.2512 - val_loss: 0.5945 - val_output_1_loss: 0.5945\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.2480 - output_1_loss: 0.2248 - val_loss: 0.6217 - val_output_1_loss: 0.5786\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3223 - output_1_loss: 0.2992Epoch 20/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.3223 - output_1_loss: 0.2992 - val_loss: 0.6145 - val_output_1_loss: 0.5721\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1973 - output_1_loss: 0.1972 - val_loss: 0.5803 - val_output_1_loss: 0.5802\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2216 - output_1_loss: 0.1991 - val_loss: 0.5994 - val_output_1_loss: 0.5576\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2165 - output_1_loss: 0.1941Epoch 21/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.2165 - output_1_loss: 0.1941 - val_loss: 0.5821 - val_output_1_loss: 0.5409\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1660 - output_1_loss: 0.1660 - val_loss: 0.5649 - val_output_1_loss: 0.5649\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1891 - output_1_loss: 0.1667 - val_loss: 0.5650 - val_output_1_loss: 0.5244\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1858 - output_1_loss: 0.1635Epoch 22/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1858 - output_1_loss: 0.1635 - val_loss: 0.5467 - val_output_1_loss: 0.5066\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2236 - output_1_loss: 0.2236 - val_loss: 0.5525 - val_output_1_loss: 0.5524\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1976 - output_1_loss: 0.1745 - val_loss: 0.5316 - val_output_1_loss: 0.4919\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1804 - output_1_loss: 0.1804 - val_loss: 0.5384 - val_output_1_loss: 0.5383\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1674 - output_1_loss: 0.1674 - val_loss: 0.5240 - val_output_1_loss: 0.5239\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.2161 - output_1_loss: 0.1929 - val_loss: 0.5167 - val_output_1_loss: 0.4773\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1479 - output_1_loss: 0.1478 - val_loss: 0.5082 - val_output_1_loss: 0.5082\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1290 - output_1_loss: 0.1290Epoch 26/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1290 - output_1_loss: 0.1290 - val_loss: 0.4904 - val_output_1_loss: 0.4903\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1797 - output_1_loss: 0.1572Epoch 27/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1797 - output_1_loss: 0.1572 - val_loss: 0.4982 - val_output_1_loss: 0.4591\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1138 - output_1_loss: 0.1138 - val_loss: 0.4711 - val_output_1_loss: 0.4711\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1426 - output_1_loss: 0.1426Epoch 27/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1426 - output_1_loss: 0.1426 - val_loss: 0.4568 - val_output_1_loss: 0.4568\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1651 - output_1_loss: 0.1431 - val_loss: 0.4764 - val_output_1_loss: 0.4377\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1267 - output_1_loss: 0.1267 - val_loss: 0.4406 - val_output_1_loss: 0.4406\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1376 - output_1_loss: 0.1160 - val_loss: 0.4524 - val_output_1_loss: 0.4141\n",
      "Epoch 30/100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1301 - output_1_loss: 0.1090 - val_loss: 0.4284 - val_output_1_loss: 0.3906\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1084 - output_1_loss: 0.1084 - val_loss: 0.4210 - val_output_1_loss: 0.4210\n",
      "Epoch 31/100\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1023 - output_1_loss: 0.1023 - val_loss: 0.4021 - val_output_1_loss: 0.4021\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1230 - output_1_loss: 0.1020 - val_loss: 0.4049 - val_output_1_loss: 0.3675\n",
      "Epoch 32/100\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1062 - output_1_loss: 0.1062 - val_loss: 0.3871 - val_output_1_loss: 0.3871\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1158 - output_1_loss: 0.0950 - val_loss: 0.3833 - val_output_1_loss: 0.3462\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1105 - output_1_loss: 0.0898Epoch 33/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1105 - output_1_loss: 0.0898 - val_loss: 0.3629 - val_output_1_loss: 0.3262\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0942 - output_1_loss: 0.0942Epoch 33/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0942 - output_1_loss: 0.0942 - val_loss: 0.3676 - val_output_1_loss: 0.3676\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1032 - output_1_loss: 0.0826 - val_loss: 0.3426 - val_output_1_loss: 0.3063\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0997 - output_1_loss: 0.0793Epoch 34/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0997 - output_1_loss: 0.0793 - val_loss: 0.3229 - val_output_1_loss: 0.2871\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0862 - output_1_loss: 0.0862 - val_loss: 0.3473 - val_output_1_loss: 0.3473\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0827 - output_1_loss: 0.0827Epoch 35/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0827 - output_1_loss: 0.0827 - val_loss: 0.3283 - val_output_1_loss: 0.3283\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0966 - output_1_loss: 0.0763 - val_loss: 0.3039 - val_output_1_loss: 0.2687\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0816 - output_1_loss: 0.0816 - val_loss: 0.3098 - val_output_1_loss: 0.3097\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0932 - output_1_loss: 0.0731 - val_loss: 0.2860 - val_output_1_loss: 0.2512\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0781 - output_1_loss: 0.0780 - val_loss: 0.2920 - val_output_1_loss: 0.2920\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0896 - output_1_loss: 0.0697Epoch 38/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0896 - output_1_loss: 0.0697 - val_loss: 0.2691 - val_output_1_loss: 0.2348\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0746 - output_1_loss: 0.0746 - val_loss: 0.2747 - val_output_1_loss: 0.2746\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0718 - output_1_loss: 0.0718 - val_loss: 0.2586 - val_output_1_loss: 0.2585\n",
      "Epoch 38/100\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0876 - output_1_loss: 0.0679 - val_loss: 0.2535 - val_output_1_loss: 0.2197\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0698 - output_1_loss: 0.0697 - val_loss: 0.2437 - val_output_1_loss: 0.2436\n",
      "Epoch 39/100\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0854 - output_1_loss: 0.0659 - val_loss: 0.2387 - val_output_1_loss: 0.2054\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0676 - output_1_loss: 0.0676 - val_loss: 0.2299 - val_output_1_loss: 0.2299\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0832 - output_1_loss: 0.0638 - val_loss: 0.2256 - val_output_1_loss: 0.1927\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0812 - output_1_loss: 0.0620 - val_loss: 0.2141 - val_output_1_loss: 0.1817\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0664 - output_1_loss: 0.0663 - val_loss: 0.2173 - val_output_1_loss: 0.2172\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0652 - output_1_loss: 0.0652 - val_loss: 0.2058 - val_output_1_loss: 0.2058\n",
      "Epoch 42/100\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0793 - output_1_loss: 0.0601 - val_loss: 0.2043 - val_output_1_loss: 0.1723\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0644 - output_1_loss: 0.0644 - val_loss: 0.1955 - val_output_1_loss: 0.1955\n",
      "Epoch 43/100\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0776 - output_1_loss: 0.0584 - val_loss: 0.1953 - val_output_1_loss: 0.1637\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0625 - output_1_loss: 0.0625 - val_loss: 0.1863 - val_output_1_loss: 0.1863\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0606 - output_1_loss: 0.0606 - val_loss: 0.1783 - val_output_1_loss: 0.1782\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0759 - output_1_loss: 0.0569 - val_loss: 0.1871 - val_output_1_loss: 0.1560\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0594 - output_1_loss: 0.0594 - val_loss: 0.1710 - val_output_1_loss: 0.1710\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0745 - output_1_loss: 0.0556 - val_loss: 0.1796 - val_output_1_loss: 0.1489\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0730 - output_1_loss: 0.0543Epoch 48/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0730 - output_1_loss: 0.0543 - val_loss: 0.1728 - val_output_1_loss: 0.1425\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0583 - output_1_loss: 0.0583Epoch 47/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0583 - output_1_loss: 0.0583 - val_loss: 0.1647 - val_output_1_loss: 0.1647\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0715 - output_1_loss: 0.0529 - val_loss: 0.1666 - val_output_1_loss: 0.1367\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0695 - output_1_loss: 0.0509 - val_loss: 0.1608 - val_output_1_loss: 0.1313\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0565 - output_1_loss: 0.0565 - val_loss: 0.1588 - val_output_1_loss: 0.1588\n",
      "Epoch 50/100\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0553 - output_1_loss: 0.0553 - val_loss: 0.1535 - val_output_1_loss: 0.1535\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0712 - output_1_loss: 0.0527 - val_loss: 0.1555 - val_output_1_loss: 0.1263\n",
      "Epoch 51/100\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0536 - output_1_loss: 0.0536 - val_loss: 0.1488 - val_output_1_loss: 0.1488\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0704 - output_1_loss: 0.0519 - val_loss: 0.1505 - val_output_1_loss: 0.1218\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0519 - output_1_loss: 0.0519 - val_loss: 0.1445 - val_output_1_loss: 0.1445\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0688 - output_1_loss: 0.0505 - val_loss: 0.1463 - val_output_1_loss: 0.1180\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0508 - output_1_loss: 0.0507 - val_loss: 0.1407 - val_output_1_loss: 0.1407\n",
      "Epoch 54/100\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0493 - output_1_loss: 0.0493 - val_loss: 0.1374 - val_output_1_loss: 0.1373\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0672 - output_1_loss: 0.0489 - val_loss: 0.1425 - val_output_1_loss: 0.1146\n",
      "Epoch 55/100\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0660 - output_1_loss: 0.0479 - val_loss: 0.1388 - val_output_1_loss: 0.1113\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0475 - output_1_loss: 0.0475 - val_loss: 0.1345 - val_output_1_loss: 0.1345\n",
      "Epoch 56/100\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0459 - output_1_loss: 0.0458 - val_loss: 0.1314 - val_output_1_loss: 0.1314\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0669 - output_1_loss: 0.0489 - val_loss: 0.1351 - val_output_1_loss: 0.1081\n",
      "Epoch 55/100\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0446 - output_1_loss: 0.0446 - val_loss: 0.1284 - val_output_1_loss: 0.1284\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0629 - output_1_loss: 0.0448 - val_loss: 0.1317 - val_output_1_loss: 0.1050\n",
      "Epoch 58/100\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0612 - output_1_loss: 0.0432 - val_loss: 0.1288 - val_output_1_loss: 0.1025\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0433 - output_1_loss: 0.0433 - val_loss: 0.1253 - val_output_1_loss: 0.1252\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0418 - output_1_loss: 0.0418 - val_loss: 0.1222 - val_output_1_loss: 0.1222\n",
      "Epoch 60/100\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0404 - output_1_loss: 0.0404 - val_loss: 0.1192 - val_output_1_loss: 0.1191\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0599 - output_1_loss: 0.0419 - val_loss: 0.1261 - val_output_1_loss: 0.1002\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0568 - output_1_loss: 0.0391 - val_loss: 0.1235 - val_output_1_loss: 0.0979\n",
      "Epoch 61/100\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0393 - output_1_loss: 0.0393 - val_loss: 0.1159 - val_output_1_loss: 0.1159\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0565 - output_1_loss: 0.0389 - val_loss: 0.1217 - val_output_1_loss: 0.0964\n",
      "Epoch 62/100\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0380 - output_1_loss: 0.0380 - val_loss: 0.1127 - val_output_1_loss: 0.1127\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0572 - output_1_loss: 0.0396 - val_loss: 0.1197 - val_output_1_loss: 0.0949\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0560 - output_1_loss: 0.0384 - val_loss: 0.1178 - val_output_1_loss: 0.0933\n",
      "Epoch 63/100\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0368 - output_1_loss: 0.0368 - val_loss: 0.1094 - val_output_1_loss: 0.1094\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0534 - output_1_loss: 0.0359 - val_loss: 0.1163 - val_output_1_loss: 0.0921\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0357 - output_1_loss: 0.0356 - val_loss: 0.1063 - val_output_1_loss: 0.1063\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0537 - output_1_loss: 0.0363 - val_loss: 0.1144 - val_output_1_loss: 0.0905\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0535 - output_1_loss: 0.0363Epoch 65/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0535 - output_1_loss: 0.0363 - val_loss: 0.1128 - val_output_1_loss: 0.0893\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0346 - output_1_loss: 0.0346 - val_loss: 0.1040 - val_output_1_loss: 0.1039\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0511 - output_1_loss: 0.0341 - val_loss: 0.1115 - val_output_1_loss: 0.0883\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0508 - output_1_loss: 0.0338Epoch 66/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0508 - output_1_loss: 0.0338 - val_loss: 0.1106 - val_output_1_loss: 0.0877\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0334 - output_1_loss: 0.0334 - val_loss: 0.1014 - val_output_1_loss: 0.1014\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0323 - output_1_loss: 0.0323Epoch 67/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0323 - output_1_loss: 0.0323 - val_loss: 0.0990 - val_output_1_loss: 0.0989\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0483 - output_1_loss: 0.0315Epoch 68/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0483 - output_1_loss: 0.0315 - val_loss: 0.1101 - val_output_1_loss: 0.0875\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0312 - output_1_loss: 0.0311 - val_loss: 0.0970 - val_output_1_loss: 0.0969\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0305 - output_1_loss: 0.0305Epoch 68/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0305 - output_1_loss: 0.0305 - val_loss: 0.0953 - val_output_1_loss: 0.0953\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0469 - output_1_loss: 0.0303 - val_loss: 0.1093 - val_output_1_loss: 0.0870\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0295 - output_1_loss: 0.0294 - val_loss: 0.0939 - val_output_1_loss: 0.0939\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0292 - output_1_loss: 0.0291Epoch 69/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0292 - output_1_loss: 0.0291 - val_loss: 0.0925 - val_output_1_loss: 0.0925\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0460 - output_1_loss: 0.0296 - val_loss: 0.1083 - val_output_1_loss: 0.0864\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0308 - output_1_loss: 0.0307 - val_loss: 0.0914 - val_output_1_loss: 0.0914\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0453 - output_1_loss: 0.0289 - val_loss: 0.1075 - val_output_1_loss: 0.0858\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0286 - output_1_loss: 0.0285 - val_loss: 0.0902 - val_output_1_loss: 0.0902\n",
      "Epoch 71/100\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0282 - output_1_loss: 0.0281 - val_loss: 0.0888 - val_output_1_loss: 0.0888\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0443 - output_1_loss: 0.0280 - val_loss: 0.1070 - val_output_1_loss: 0.0857\n",
      "Epoch 75/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0433 - output_1_loss: 0.0271 - val_loss: 0.1079 - val_output_1_loss: 0.0868\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.0272 - output_1_loss: 0.0272 - val_loss: 0.0875 - val_output_1_loss: 0.0875\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0428 - output_1_loss: 0.0266 - val_loss: 0.1092 - val_output_1_loss: 0.0884\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0421 - output_1_loss: 0.0260 - val_loss: 0.1099 - val_output_1_loss: 0.0893\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0321 - output_1_loss: 0.0321 - val_loss: 0.0869 - val_output_1_loss: 0.0869\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0413 - output_1_loss: 0.0253 - val_loss: 0.1103 - val_output_1_loss: 0.0900\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0408 - output_1_loss: 0.0248 - val_loss: 0.1074 - val_output_1_loss: 0.0874\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0293 - output_1_loss: 0.0293 - val_loss: 0.0858 - val_output_1_loss: 0.0857\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.0282 - output_1_loss: 0.0282 - val_loss: 0.0841 - val_output_1_loss: 0.0841\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0266 - output_1_loss: 0.0265 - val_loss: 0.0824 - val_output_1_loss: 0.0824\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0254 - output_1_loss: 0.0254 - val_loss: 0.0806 - val_output_1_loss: 0.0806\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0246 - output_1_loss: 0.0246 - val_loss: 0.0791 - val_output_1_loss: 0.0791\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0241 - output_1_loss: 0.0240 - val_loss: 0.0779 - val_output_1_loss: 0.0779\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0238 - output_1_loss: 0.0238 - val_loss: 0.0769 - val_output_1_loss: 0.0769\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:37:51,531]\u001b[0m Trial 93 finished with value: 0.022727272727272728 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 1.5, 'sparsity_coefficient': 0.009413540159379579, 'bn_momentum': 0.9224773810572284}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 430ms/step - loss: 0.0233 - output_1_loss: 0.0233 - val_loss: 0.0761 - val_output_1_loss: 0.0760\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.0230 - output_1_loss: 0.0230 - val_loss: 0.0752 - val_output_1_loss: 0.0752\n",
      "Epoch 1/100\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.0227 - output_1_loss: 0.0227 - val_loss: 0.0748 - val_output_1_loss: 0.0747\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0239 - output_1_loss: 0.0239 - val_loss: 0.0736 - val_output_1_loss: 0.0736\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.0288 - output_1_loss: 0.0288 - val_loss: 0.0733 - val_output_1_loss: 0.0733\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0258 - output_1_loss: 0.0257 - val_loss: 0.0713 - val_output_1_loss: 0.0713\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0245 - output_1_loss: 0.0245 - val_loss: 0.0724 - val_output_1_loss: 0.0724\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0260 - output_1_loss: 0.0259 - val_loss: 0.0721 - val_output_1_loss: 0.0721\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0251 - output_1_loss: 0.0251 - val_loss: 0.0714 - val_output_1_loss: 0.0714\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0255 - output_1_loss: 0.0255 - val_loss: 0.0722 - val_output_1_loss: 0.0722\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0432 - output_1_loss: 0.0432 - val_loss: 0.0743 - val_output_1_loss: 0.0743\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:37:56,372]\u001b[0m Trial 92 finished with value: 0.045454545454545456 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1.1004203686392412e-05, 'bn_momentum': 0.9289041651479666}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.7202 - output_1_loss: 0.7202 - val_loss: 0.6898 - val_output_1_loss: 0.6898\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6639 - output_1_loss: 0.6639 - val_loss: 0.6856 - val_output_1_loss: 0.6856\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.6384 - output_1_loss: 0.6384 - val_loss: 0.6817 - val_output_1_loss: 0.6816\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.5924 - output_1_loss: 0.5924 - val_loss: 0.6773 - val_output_1_loss: 0.6772\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.5468 - output_1_loss: 0.5468 - val_loss: 0.6724 - val_output_1_loss: 0.6723\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.4785 - output_1_loss: 0.4785 - val_loss: 0.6677 - val_output_1_loss: 0.6676\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4333 - output_1_loss: 0.4333 - val_loss: 0.6614 - val_output_1_loss: 0.6614\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3801 - output_1_loss: 0.3801 - val_loss: 0.6529 - val_output_1_loss: 0.6529\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.3481 - output_1_loss: 0.3481 - val_loss: 0.6428 - val_output_1_loss: 0.6428\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2800 - output_1_loss: 0.2800 - val_loss: 0.6293 - val_output_1_loss: 0.6293\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2467 - output_1_loss: 0.2467 - val_loss: 0.6139 - val_output_1_loss: 0.6139\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2199 - output_1_loss: 0.2199 - val_loss: 0.5972 - val_output_1_loss: 0.5972\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2003 - output_1_loss: 0.2003 - val_loss: 0.5798 - val_output_1_loss: 0.5798\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1810 - output_1_loss: 0.1810 - val_loss: 0.5618 - val_output_1_loss: 0.5618\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1642 - output_1_loss: 0.1642 - val_loss: 0.5435 - val_output_1_loss: 0.5434\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1501 - output_1_loss: 0.1501 - val_loss: 0.5253 - val_output_1_loss: 0.5253\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1390 - output_1_loss: 0.1389 - val_loss: 0.5074 - val_output_1_loss: 0.5074\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1286 - output_1_loss: 0.1286 - val_loss: 0.4895 - val_output_1_loss: 0.4895\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1194 - output_1_loss: 0.1194 - val_loss: 0.4720 - val_output_1_loss: 0.4719\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1100 - output_1_loss: 0.1100 - val_loss: 0.4549 - val_output_1_loss: 0.4548\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1043 - output_1_loss: 0.1043 - val_loss: 0.4384 - val_output_1_loss: 0.4384\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0979 - output_1_loss: 0.0979 - val_loss: 0.4227 - val_output_1_loss: 0.4227\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0947 - output_1_loss: 0.0947 - val_loss: 0.4079 - val_output_1_loss: 0.4078\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0884 - output_1_loss: 0.0884 - val_loss: 0.3935 - val_output_1_loss: 0.3935\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0848 - output_1_loss: 0.0848 - val_loss: 0.3799 - val_output_1_loss: 0.3799\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0813 - output_1_loss: 0.0813 - val_loss: 0.3669 - val_output_1_loss: 0.3669\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0778 - output_1_loss: 0.0778 - val_loss: 0.3546 - val_output_1_loss: 0.3546\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.6611 - output_1_loss: 0.6610 - val_loss: 0.6902 - val_output_1_loss: 0.6900\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0745 - output_1_loss: 0.0744 - val_loss: 0.3433 - val_output_1_loss: 0.3433\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6490 - output_1_loss: 0.6489 - val_loss: 0.6876 - val_output_1_loss: 0.6874\n",
      "Epoch 29/100\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0717 - output_1_loss: 0.0717 - val_loss: 0.3327 - val_output_1_loss: 0.3327\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5891 - output_1_loss: 0.5890 - val_loss: 0.6844 - val_output_1_loss: 0.6841\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0691 - output_1_loss: 0.0691 - val_loss: 0.3228 - val_output_1_loss: 0.3228\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6007 - output_1_loss: 0.6006 - val_loss: 0.6813 - val_output_1_loss: 0.6811\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0663 - output_1_loss: 0.0663 - val_loss: 0.3135 - val_output_1_loss: 0.3135\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.5298 - output_1_loss: 0.5297 - val_loss: 0.6778 - val_output_1_loss: 0.6775\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0641 - output_1_loss: 0.0641 - val_loss: 0.3048 - val_output_1_loss: 0.3048\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.4845 - output_1_loss: 0.4844 - val_loss: 0.6738 - val_output_1_loss: 0.6736\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0616 - output_1_loss: 0.0616 - val_loss: 0.2965 - val_output_1_loss: 0.2965\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0599 - output_1_loss: 0.0599 - val_loss: 0.2886 - val_output_1_loss: 0.2886\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.4258 - output_1_loss: 0.4257 - val_loss: 0.6694 - val_output_1_loss: 0.6692\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0581 - output_1_loss: 0.0581 - val_loss: 0.2811 - val_output_1_loss: 0.2811\n",
      "Epoch 36/100\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0562 - output_1_loss: 0.0562 - val_loss: 0.2741 - val_output_1_loss: 0.2741\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.3642 - output_1_loss: 0.3641 - val_loss: 0.6641 - val_output_1_loss: 0.6639\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0546 - output_1_loss: 0.0546 - val_loss: 0.2677 - val_output_1_loss: 0.2676\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3602 - output_1_loss: 0.3601Epoch 38/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3602 - output_1_loss: 0.3601 - val_loss: 0.6579 - val_output_1_loss: 0.6578\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0532 - output_1_loss: 0.0532 - val_loss: 0.2617 - val_output_1_loss: 0.2617\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3121 - output_1_loss: 0.3120Epoch 39/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3121 - output_1_loss: 0.3120 - val_loss: 0.6504 - val_output_1_loss: 0.6502\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0518 - output_1_loss: 0.0518 - val_loss: 0.2563 - val_output_1_loss: 0.2563\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2623 - output_1_loss: 0.2622 - val_loss: 0.6406 - val_output_1_loss: 0.6405\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2359 - output_1_loss: 0.2358Epoch 40/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2359 - output_1_loss: 0.2358 - val_loss: 0.6291 - val_output_1_loss: 0.6290\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0505 - output_1_loss: 0.0505 - val_loss: 0.2513 - val_output_1_loss: 0.2513\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2141 - output_1_loss: 0.2141 - val_loss: 0.6168 - val_output_1_loss: 0.6166\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1876 - output_1_loss: 0.1875 - val_loss: 0.6027 - val_output_1_loss: 0.6025\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0492 - output_1_loss: 0.0491Epoch 15/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0492 - output_1_loss: 0.0491 - val_loss: 0.2467 - val_output_1_loss: 0.2467\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1678 - output_1_loss: 0.1678Epoch 42/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1678 - output_1_loss: 0.1678 - val_loss: 0.5866 - val_output_1_loss: 0.5865\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0479 - output_1_loss: 0.0479Epoch 16/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0479 - output_1_loss: 0.0479 - val_loss: 0.2428 - val_output_1_loss: 0.2428\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1498 - output_1_loss: 0.1498 - val_loss: 0.5699 - val_output_1_loss: 0.5697\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0470 - output_1_loss: 0.0470 - val_loss: 0.2394 - val_output_1_loss: 0.2394\n",
      "Epoch 44/100\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0459 - output_1_loss: 0.0459 - val_loss: 0.2366 - val_output_1_loss: 0.2366\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1358 - output_1_loss: 0.1358 - val_loss: 0.5526 - val_output_1_loss: 0.5524\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1265 - output_1_loss: 0.1264 - val_loss: 0.5353 - val_output_1_loss: 0.5351\n",
      "Epoch 19/100\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1148 - output_1_loss: 0.1147 - val_loss: 0.5162 - val_output_1_loss: 0.5160\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0447 - output_1_loss: 0.0447 - val_loss: 0.2340 - val_output_1_loss: 0.2340\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1076 - output_1_loss: 0.1075Epoch 46/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1076 - output_1_loss: 0.1075 - val_loss: 0.4966 - val_output_1_loss: 0.4965\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0437 - output_1_loss: 0.0437 - val_loss: 0.2317 - val_output_1_loss: 0.2317\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0429 - output_1_loss: 0.0428 - val_loss: 0.2297 - val_output_1_loss: 0.2297\n",
      "Epoch 48/100\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0420 - output_1_loss: 0.0420 - val_loss: 0.2280 - val_output_1_loss: 0.2280\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1001 - output_1_loss: 0.1000 - val_loss: 0.4771 - val_output_1_loss: 0.4769\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0411 - output_1_loss: 0.0411 - val_loss: 0.2264 - val_output_1_loss: 0.2264\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0401 - output_1_loss: 0.0401 - val_loss: 0.2246 - val_output_1_loss: 0.2246\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0939 - output_1_loss: 0.0938Epoch 51/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0939 - output_1_loss: 0.0938 - val_loss: 0.4577 - val_output_1_loss: 0.4576\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0392 - output_1_loss: 0.0392 - val_loss: 0.2228 - val_output_1_loss: 0.2228\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0887 - output_1_loss: 0.0886 - val_loss: 0.4385 - val_output_1_loss: 0.4384\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0383 - output_1_loss: 0.0383 - val_loss: 0.2208 - val_output_1_loss: 0.2208\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0844 - output_1_loss: 0.0843 - val_loss: 0.4194 - val_output_1_loss: 0.4192\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0806 - output_1_loss: 0.0805 - val_loss: 0.4005 - val_output_1_loss: 0.4003\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0373 - output_1_loss: 0.0373Epoch 26/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0373 - output_1_loss: 0.0373 - val_loss: 0.2187 - val_output_1_loss: 0.2187\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0769 - output_1_loss: 0.0769 - val_loss: 0.3821 - val_output_1_loss: 0.3819\n",
      "Epoch 54/100\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0733 - output_1_loss: 0.0732 - val_loss: 0.3644 - val_output_1_loss: 0.3643\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0362 - output_1_loss: 0.0362 - val_loss: 0.2165 - val_output_1_loss: 0.2165\n",
      "Epoch 28/100\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0702 - output_1_loss: 0.0701 - val_loss: 0.3477 - val_output_1_loss: 0.3475\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0354 - output_1_loss: 0.0354 - val_loss: 0.2143 - val_output_1_loss: 0.2142\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0674 - output_1_loss: 0.0674 - val_loss: 0.3319 - val_output_1_loss: 0.3318\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0345 - output_1_loss: 0.0345 - val_loss: 0.2117 - val_output_1_loss: 0.2116\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0337 - output_1_loss: 0.0337 - val_loss: 0.2090 - val_output_1_loss: 0.2090\n",
      "Epoch 58/100\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0649 - output_1_loss: 0.0648 - val_loss: 0.3172 - val_output_1_loss: 0.3171\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0337 - output_1_loss: 0.0337 - val_loss: 0.2054 - val_output_1_loss: 0.2054\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0626 - output_1_loss: 0.0625Epoch 59/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0626 - output_1_loss: 0.0625 - val_loss: 0.3035 - val_output_1_loss: 0.3033\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0328 - output_1_loss: 0.0328 - val_loss: 0.2017 - val_output_1_loss: 0.2016\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0320 - output_1_loss: 0.0320 - val_loss: 0.1981 - val_output_1_loss: 0.1981\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0310 - output_1_loss: 0.0310Epoch 32/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0310 - output_1_loss: 0.0310 - val_loss: 0.1944 - val_output_1_loss: 0.1944\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0603 - output_1_loss: 0.0602Epoch 62/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0603 - output_1_loss: 0.0602 - val_loss: 0.2906 - val_output_1_loss: 0.2905\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0302 - output_1_loss: 0.0302 - val_loss: 0.1906 - val_output_1_loss: 0.1906\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0582 - output_1_loss: 0.0582 - val_loss: 0.2787 - val_output_1_loss: 0.2786\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0564 - output_1_loss: 0.0564 - val_loss: 0.2677 - val_output_1_loss: 0.2676\n",
      "Epoch 63/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0295 - output_1_loss: 0.0295 - val_loss: 0.1867 - val_output_1_loss: 0.1867\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0545 - output_1_loss: 0.0545 - val_loss: 0.2577 - val_output_1_loss: 0.2576\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0287 - output_1_loss: 0.0287 - val_loss: 0.1829 - val_output_1_loss: 0.1828\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0279 - output_1_loss: 0.0279Epoch 36/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0279 - output_1_loss: 0.0279 - val_loss: 0.1788 - val_output_1_loss: 0.1787\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0528 - output_1_loss: 0.0528 - val_loss: 0.2487 - val_output_1_loss: 0.2486\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0272 - output_1_loss: 0.0272Epoch 37/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0272 - output_1_loss: 0.0272 - val_loss: 0.1744 - val_output_1_loss: 0.1744\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0512 - output_1_loss: 0.0511 - val_loss: 0.2406 - val_output_1_loss: 0.2405\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0264 - output_1_loss: 0.0264 - val_loss: 0.1697 - val_output_1_loss: 0.1697\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0495 - output_1_loss: 0.0495 - val_loss: 0.2334 - val_output_1_loss: 0.2333\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0256 - output_1_loss: 0.0256 - val_loss: 0.1650 - val_output_1_loss: 0.1650\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0249 - output_1_loss: 0.0248Epoch 39/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0249 - output_1_loss: 0.0248 - val_loss: 0.1600 - val_output_1_loss: 0.1600\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0480 - output_1_loss: 0.0479 - val_loss: 0.2268 - val_output_1_loss: 0.2267\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0241 - output_1_loss: 0.0241 - val_loss: 0.1550 - val_output_1_loss: 0.1550\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0233 - output_1_loss: 0.0233 - val_loss: 0.1499 - val_output_1_loss: 0.1499\n",
      "Epoch 40/100\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0226 - output_1_loss: 0.0226 - val_loss: 0.1446 - val_output_1_loss: 0.1446\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0466 - output_1_loss: 0.0465 - val_loss: 0.2209 - val_output_1_loss: 0.2208\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0219 - output_1_loss: 0.0219 - val_loss: 0.1393 - val_output_1_loss: 0.1393\n",
      "Epoch 41/100\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0213 - output_1_loss: 0.0213 - val_loss: 0.1343 - val_output_1_loss: 0.1342\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0453 - output_1_loss: 0.0453 - val_loss: 0.2157 - val_output_1_loss: 0.2156\n",
      "Epoch 75/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0208 - output_1_loss: 0.0207 - val_loss: 0.1304 - val_output_1_loss: 0.1304\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0441 - output_1_loss: 0.0440 - val_loss: 0.2110 - val_output_1_loss: 0.2109\n",
      "Epoch 76/100\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0429 - output_1_loss: 0.0428 - val_loss: 0.2070 - val_output_1_loss: 0.2069\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0198 - output_1_loss: 0.0198 - val_loss: 0.1264 - val_output_1_loss: 0.1264\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0417 - output_1_loss: 0.0416 - val_loss: 0.2034 - val_output_1_loss: 0.2033\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0405 - output_1_loss: 0.0405Epoch 77/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0405 - output_1_loss: 0.0405 - val_loss: 0.2003 - val_output_1_loss: 0.2002\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0201 - output_1_loss: 0.0201 - val_loss: 0.1206 - val_output_1_loss: 0.1206\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0207 - output_1_loss: 0.0207 - val_loss: 0.1180 - val_output_1_loss: 0.1179\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0394 - output_1_loss: 0.0393Epoch 79/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0394 - output_1_loss: 0.0393 - val_loss: 0.1976 - val_output_1_loss: 0.1975\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0204 - output_1_loss: 0.0204Epoch 47/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0204 - output_1_loss: 0.0204 - val_loss: 0.1147 - val_output_1_loss: 0.1147\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0382 - output_1_loss: 0.0381Epoch 80/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0382 - output_1_loss: 0.0381 - val_loss: 0.1952 - val_output_1_loss: 0.1951\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0218 - output_1_loss: 0.0218 - val_loss: 0.1099 - val_output_1_loss: 0.1099\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0371 - output_1_loss: 0.0370 - val_loss: 0.1932 - val_output_1_loss: 0.1931\n",
      "Epoch 49/100\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0360 - output_1_loss: 0.0359 - val_loss: 0.1913 - val_output_1_loss: 0.1911\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0214 - output_1_loss: 0.0214 - val_loss: 0.1055 - val_output_1_loss: 0.1055\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0348 - output_1_loss: 0.0347 - val_loss: 0.1894 - val_output_1_loss: 0.1893\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0205 - output_1_loss: 0.0205 - val_loss: 0.1018 - val_output_1_loss: 0.1018\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0337 - output_1_loss: 0.0336 - val_loss: 0.1878 - val_output_1_loss: 0.1877\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0199 - output_1_loss: 0.0199 - val_loss: 0.0984 - val_output_1_loss: 0.0984\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0326 - output_1_loss: 0.0325 - val_loss: 0.1865 - val_output_1_loss: 0.1864\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0184 - output_1_loss: 0.0184 - val_loss: 0.0959 - val_output_1_loss: 0.0959\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0315 - output_1_loss: 0.0315 - val_loss: 0.1854 - val_output_1_loss: 0.1853\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0306 - output_1_loss: 0.0305Epoch 85/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0306 - output_1_loss: 0.0305 - val_loss: 0.1844 - val_output_1_loss: 0.1843\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0177 - output_1_loss: 0.0177 - val_loss: 0.0935 - val_output_1_loss: 0.0935\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0295 - output_1_loss: 0.0294Epoch 86/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0295 - output_1_loss: 0.0294 - val_loss: 0.1837 - val_output_1_loss: 0.1836\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0175 - output_1_loss: 0.0175 - val_loss: 0.0914 - val_output_1_loss: 0.0914\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0170 - output_1_loss: 0.0170 - val_loss: 0.0900 - val_output_1_loss: 0.0900\n",
      "Epoch 56/100\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0285 - output_1_loss: 0.0285 - val_loss: 0.1829 - val_output_1_loss: 0.1828\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0167 - output_1_loss: 0.0167 - val_loss: 0.0888 - val_output_1_loss: 0.0888\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0275 - output_1_loss: 0.0274 - val_loss: 0.1821 - val_output_1_loss: 0.1820\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0266 - output_1_loss: 0.0265 - val_loss: 0.1815 - val_output_1_loss: 0.1814\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0163 - output_1_loss: 0.0163Epoch 59/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0163 - output_1_loss: 0.0163 - val_loss: 0.0880 - val_output_1_loss: 0.0880\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0256 - output_1_loss: 0.0255 - val_loss: 0.1809 - val_output_1_loss: 0.1808\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0160 - output_1_loss: 0.0160 - val_loss: 0.0873 - val_output_1_loss: 0.0873\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0247 - output_1_loss: 0.0246 - val_loss: 0.1799 - val_output_1_loss: 0.1798\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0238 - output_1_loss: 0.0237 - val_loss: 0.1785 - val_output_1_loss: 0.1784\n",
      "Epoch 91/100\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0157 - output_1_loss: 0.0157 - val_loss: 0.0871 - val_output_1_loss: 0.0871\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0223 - output_1_loss: 0.0222 - val_loss: 0.1776 - val_output_1_loss: 0.1775\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0154 - output_1_loss: 0.0154 - val_loss: 0.0876 - val_output_1_loss: 0.0876\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0155 - output_1_loss: 0.0155 - val_loss: 0.0900 - val_output_1_loss: 0.0900\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0150 - output_1_loss: 0.0149Epoch 63/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0150 - output_1_loss: 0.0149 - val_loss: 0.0936 - val_output_1_loss: 0.0936\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0215 - output_1_loss: 0.0215 - val_loss: 0.1767 - val_output_1_loss: 0.1766\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0148 - output_1_loss: 0.0147 - val_loss: 0.0976 - val_output_1_loss: 0.0976\n",
      "Epoch 64/100\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0145 - output_1_loss: 0.0145 - val_loss: 0.1023 - val_output_1_loss: 0.1023\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0203 - output_1_loss: 0.0202 - val_loss: 0.1750 - val_output_1_loss: 0.1749\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.0193 - output_1_loss: 0.0193 - val_loss: 0.1739 - val_output_1_loss: 0.1738\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0185 - output_1_loss: 0.0184 - val_loss: 0.1726 - val_output_1_loss: 0.1725\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0176 - output_1_loss: 0.0175 - val_loss: 0.1711 - val_output_1_loss: 0.1710\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0170 - output_1_loss: 0.0169 - val_loss: 0.1695 - val_output_1_loss: 0.1694\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0160 - output_1_loss: 0.0159 - val_loss: 0.1679 - val_output_1_loss: 0.1678\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0151 - output_1_loss: 0.0151 - val_loss: 0.1666 - val_output_1_loss: 0.1665\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:38:25,060]\u001b[0m Trial 94 finished with value: 0.25 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 0, 'relaxation_factor': 1.6, 'sparsity_coefficient': 3.751516222448968e-06, 'bn_momentum': 0.932393672589251}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0142 - output_1_loss: 0.0142 - val_loss: 0.1648 - val_output_1_loss: 0.1648\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0135 - output_1_loss: 0.0134 - val_loss: 0.1622 - val_output_1_loss: 0.1621\n",
      "Epoch 1/100\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0130 - output_1_loss: 0.0129 - val_loss: 0.1584 - val_output_1_loss: 0.1583\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0124 - output_1_loss: 0.0124 - val_loss: 0.1541 - val_output_1_loss: 0.1540\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0119 - output_1_loss: 0.0118 - val_loss: 0.1490 - val_output_1_loss: 0.1489\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0111 - output_1_loss: 0.0110 - val_loss: 0.1432 - val_output_1_loss: 0.1431\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0105 - output_1_loss: 0.0105 - val_loss: 0.1383 - val_output_1_loss: 0.1382\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0101 - output_1_loss: 0.0100 - val_loss: 0.1346 - val_output_1_loss: 0.1345\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.0095 - output_1_loss: 0.0094 - val_loss: 0.1321 - val_output_1_loss: 0.1320\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0090 - output_1_loss: 0.0089 - val_loss: 0.1298 - val_output_1_loss: 0.1297\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0086 - output_1_loss: 0.0085 - val_loss: 0.1281 - val_output_1_loss: 0.1281\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0083 - output_1_loss: 0.0082 - val_loss: 0.1284 - val_output_1_loss: 0.1283\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0079 - output_1_loss: 0.0078 - val_loss: 0.1296 - val_output_1_loss: 0.1295\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0076 - output_1_loss: 0.0075 - val_loss: 0.1310 - val_output_1_loss: 0.1310\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0073 - output_1_loss: 0.0072 - val_loss: 0.1329 - val_output_1_loss: 0.1329\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0070 - output_1_loss: 0.0070 - val_loss: 0.1362 - val_output_1_loss: 0.1361\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:38:30,866]\u001b[0m Trial 95 finished with value: 0.5 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 0, 'relaxation_factor': 1.6, 'sparsity_coefficient': 2.798183452513248e-05, 'bn_momentum': 0.9318437329503264}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.8127 - output_1_loss: 0.8126 - val_loss: 0.6897 - val_output_1_loss: 0.6894\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.7335 - output_1_loss: 0.7331 - val_loss: 0.6890 - val_output_1_loss: 0.6880\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.7261 - output_1_loss: 0.7256 - val_loss: 0.6838 - val_output_1_loss: 0.6828\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6699 - output_1_loss: 0.6695 - val_loss: 0.6782 - val_output_1_loss: 0.6773\n",
      "Epoch 2/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7718 - output_1_loss: 0.7717 - val_loss: 0.6870 - val_output_1_loss: 0.6867\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5926 - output_1_loss: 0.5922 - val_loss: 0.6726 - val_output_1_loss: 0.6717\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5379 - output_1_loss: 0.5375 - val_loss: 0.6666 - val_output_1_loss: 0.6657\n",
      "Epoch 6/100\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.8201 - output_1_loss: 0.8200 - val_loss: 0.6838 - val_output_1_loss: 0.6835\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4867 - output_1_loss: 0.4863 - val_loss: 0.6602 - val_output_1_loss: 0.6593\n",
      "Epoch 4/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.7470 - output_1_loss: 0.7470 - val_loss: 0.6798 - val_output_1_loss: 0.6796\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4065 - output_1_loss: 0.4061 - val_loss: 0.6538 - val_output_1_loss: 0.6530\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6678 - output_1_loss: 0.6677Epoch 8/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6678 - output_1_loss: 0.6677 - val_loss: 0.6756 - val_output_1_loss: 0.6754\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.2732 - output_1_loss: 0.2728 - val_loss: 0.6456 - val_output_1_loss: 0.6448\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6628 - output_1_loss: 0.6627Epoch 9/100\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.6628 - output_1_loss: 0.6627 - val_loss: 0.6728 - val_output_1_loss: 0.6726\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2315 - output_1_loss: 0.2312Epoch 7/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2315 - output_1_loss: 0.2312 - val_loss: 0.6357 - val_output_1_loss: 0.6349\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6119 - output_1_loss: 0.6119 - val_loss: 0.6700 - val_output_1_loss: 0.6698\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1813 - output_1_loss: 0.1810 - val_loss: 0.6228 - val_output_1_loss: 0.6221\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.5783 - output_1_loss: 0.5782 - val_loss: 0.6672 - val_output_1_loss: 0.6670\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5433 - output_1_loss: 0.5432Epoch 11/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5433 - output_1_loss: 0.5432 - val_loss: 0.6649 - val_output_1_loss: 0.6647\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.4823 - output_1_loss: 0.4822 - val_loss: 0.6600 - val_output_1_loss: 0.6598\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1215 - output_1_loss: 0.1212 - val_loss: 0.6079 - val_output_1_loss: 0.6072\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4275 - output_1_loss: 0.4274 - val_loss: 0.6531 - val_output_1_loss: 0.6530\n",
      "Epoch 12/100\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1057 - output_1_loss: 0.1053 - val_loss: 0.5900 - val_output_1_loss: 0.5893\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.4151 - output_1_loss: 0.4150 - val_loss: 0.6451 - val_output_1_loss: 0.6450\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3527 - output_1_loss: 0.3526 - val_loss: 0.6361 - val_output_1_loss: 0.6360\n",
      "Epoch 14/100\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.3181 - output_1_loss: 0.3180 - val_loss: 0.6257 - val_output_1_loss: 0.6256\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1004 - output_1_loss: 0.1001 - val_loss: 0.5717 - val_output_1_loss: 0.5710\n",
      "Epoch 15/100\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2868 - output_1_loss: 0.2867 - val_loss: 0.6136 - val_output_1_loss: 0.6135\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0869 - output_1_loss: 0.0866 - val_loss: 0.5514 - val_output_1_loss: 0.5508\n",
      "Epoch 16/100\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2638 - output_1_loss: 0.2638 - val_loss: 0.6004 - val_output_1_loss: 0.6003\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0866 - output_1_loss: 0.0863 - val_loss: 0.5327 - val_output_1_loss: 0.5320\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2390 - output_1_loss: 0.2389 - val_loss: 0.5863 - val_output_1_loss: 0.5861\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.2214 - output_1_loss: 0.2213 - val_loss: 0.5715 - val_output_1_loss: 0.5713\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0782 - output_1_loss: 0.0780 - val_loss: 0.5132 - val_output_1_loss: 0.5125\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0705 - output_1_loss: 0.0702 - val_loss: 0.4927 - val_output_1_loss: 0.4920\n",
      "Epoch 19/100\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.2031 - output_1_loss: 0.2030 - val_loss: 0.5557 - val_output_1_loss: 0.5556\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0683 - output_1_loss: 0.0680 - val_loss: 0.4727 - val_output_1_loss: 0.4721\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1884 - output_1_loss: 0.1884Epoch 19/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1884 - output_1_loss: 0.1884 - val_loss: 0.5395 - val_output_1_loss: 0.5393\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0647 - output_1_loss: 0.0645 - val_loss: 0.4529 - val_output_1_loss: 0.4523\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1742 - output_1_loss: 0.1741 - val_loss: 0.5228 - val_output_1_loss: 0.5227\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0621 - output_1_loss: 0.0618 - val_loss: 0.4337 - val_output_1_loss: 0.4331\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1779 - output_1_loss: 0.1778 - val_loss: 0.5076 - val_output_1_loss: 0.5075\n",
      "Epoch 21/100\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.1524 - output_1_loss: 0.1523 - val_loss: 0.4904 - val_output_1_loss: 0.4903\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0590 - output_1_loss: 0.0588 - val_loss: 0.4154 - val_output_1_loss: 0.4148\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1466 - output_1_loss: 0.1465 - val_loss: 0.4731 - val_output_1_loss: 0.4729\n",
      "Epoch 22/100\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.1377 - output_1_loss: 0.1377 - val_loss: 0.4557 - val_output_1_loss: 0.4556\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0550 - output_1_loss: 0.0548 - val_loss: 0.3983 - val_output_1_loss: 0.3977\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.1311 - output_1_loss: 0.1310 - val_loss: 0.4384 - val_output_1_loss: 0.4383\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.0529 - output_1_loss: 0.0526 - val_loss: 0.3816 - val_output_1_loss: 0.3810\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1226 - output_1_loss: 0.1226 - val_loss: 0.4213 - val_output_1_loss: 0.4212\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1144 - output_1_loss: 0.1143 - val_loss: 0.4045 - val_output_1_loss: 0.4044\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0478 - output_1_loss: 0.0475 - val_loss: 0.3656 - val_output_1_loss: 0.3650\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1083 - output_1_loss: 0.1082 - val_loss: 0.3881 - val_output_1_loss: 0.3880\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0457 - output_1_loss: 0.0454 - val_loss: 0.3513 - val_output_1_loss: 0.3507\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1027 - output_1_loss: 0.1026Epoch 26/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1027 - output_1_loss: 0.1026 - val_loss: 0.3720 - val_output_1_loss: 0.3719\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0431 - output_1_loss: 0.0429 - val_loss: 0.3384 - val_output_1_loss: 0.3378\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0978 - output_1_loss: 0.0978 - val_loss: 0.3562 - val_output_1_loss: 0.3561\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0935 - output_1_loss: 0.0934Epoch 27/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0935 - output_1_loss: 0.0934 - val_loss: 0.3410 - val_output_1_loss: 0.3408\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0519 - output_1_loss: 0.0516Epoch 33/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0519 - output_1_loss: 0.0516 - val_loss: 0.3269 - val_output_1_loss: 0.3263\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0893 - output_1_loss: 0.0892 - val_loss: 0.3263 - val_output_1_loss: 0.3261\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0851 - output_1_loss: 0.0851 - val_loss: 0.3122 - val_output_1_loss: 0.3121\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0385 - output_1_loss: 0.0382Epoch 35/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0385 - output_1_loss: 0.0382 - val_loss: 0.3158 - val_output_1_loss: 0.3153\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0816 - output_1_loss: 0.0816 - val_loss: 0.2986 - val_output_1_loss: 0.2985\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0380 - output_1_loss: 0.0377 - val_loss: 0.3051 - val_output_1_loss: 0.3046\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0372 - output_1_loss: 0.0370Epoch 36/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0372 - output_1_loss: 0.0370 - val_loss: 0.2958 - val_output_1_loss: 0.2952\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0787 - output_1_loss: 0.0786 - val_loss: 0.2854 - val_output_1_loss: 0.2853\n",
      "Epoch 31/100\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0756 - output_1_loss: 0.0756 - val_loss: 0.2728 - val_output_1_loss: 0.2727\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0358 - output_1_loss: 0.0356 - val_loss: 0.2876 - val_output_1_loss: 0.2871\n",
      "Epoch 38/100\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0731 - output_1_loss: 0.0731 - val_loss: 0.2608 - val_output_1_loss: 0.2607\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0312 - output_1_loss: 0.0310 - val_loss: 0.2803 - val_output_1_loss: 0.2797\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0709 - output_1_loss: 0.0709 - val_loss: 0.2495 - val_output_1_loss: 0.2494\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0685 - output_1_loss: 0.0684 - val_loss: 0.2390 - val_output_1_loss: 0.2389\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0294 - output_1_loss: 0.0291 - val_loss: 0.2736 - val_output_1_loss: 0.2730\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0666 - output_1_loss: 0.0666 - val_loss: 0.2294 - val_output_1_loss: 0.2293\n",
      "Epoch 34/100\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0279 - output_1_loss: 0.0277 - val_loss: 0.2672 - val_output_1_loss: 0.2666\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0647 - output_1_loss: 0.0646 - val_loss: 0.2206 - val_output_1_loss: 0.2205\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0630 - output_1_loss: 0.0629 - val_loss: 0.2125 - val_output_1_loss: 0.2124\n",
      "Epoch 44/100\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0612 - output_1_loss: 0.0611 - val_loss: 0.2049 - val_output_1_loss: 0.2048\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0255 - output_1_loss: 0.0253 - val_loss: 0.2614 - val_output_1_loss: 0.2608\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0596 - output_1_loss: 0.0596 - val_loss: 0.1978 - val_output_1_loss: 0.1977\n",
      "Epoch 46/100\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0582 - output_1_loss: 0.0581 - val_loss: 0.1913 - val_output_1_loss: 0.1912\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0565 - output_1_loss: 0.0564 - val_loss: 0.1853 - val_output_1_loss: 0.1852\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0234 - output_1_loss: 0.0231 - val_loss: 0.2567 - val_output_1_loss: 0.2562\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0551 - output_1_loss: 0.0551Epoch 37/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0551 - output_1_loss: 0.0551 - val_loss: 0.1796 - val_output_1_loss: 0.1795\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0215 - output_1_loss: 0.0212 - val_loss: 0.2527 - val_output_1_loss: 0.2522\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0550 - output_1_loss: 0.0549 - val_loss: 0.1743 - val_output_1_loss: 0.1742\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0525 - output_1_loss: 0.0524 - val_loss: 0.1690 - val_output_1_loss: 0.1689\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0202 - output_1_loss: 0.0200Epoch 51/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0516 - output_1_loss: 0.0516 - val_loss: 0.1641 - val_output_1_loss: 0.1640\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0202 - output_1_loss: 0.0200 - val_loss: 0.2490 - val_output_1_loss: 0.2484\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0508 - output_1_loss: 0.0508 - val_loss: 0.1597 - val_output_1_loss: 0.1596\n",
      "Epoch 53/100\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0492 - output_1_loss: 0.0491 - val_loss: 0.1558 - val_output_1_loss: 0.1558\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0183 - output_1_loss: 0.0181Epoch 54/100\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0183 - output_1_loss: 0.0181 - val_loss: 0.2456 - val_output_1_loss: 0.2451\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0486 - output_1_loss: 0.0485 - val_loss: 0.1524 - val_output_1_loss: 0.1523\n",
      "Epoch 55/100\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0469 - output_1_loss: 0.0468 - val_loss: 0.1489 - val_output_1_loss: 0.1488\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0173 - output_1_loss: 0.0171 - val_loss: 0.2428 - val_output_1_loss: 0.2423\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0458 - output_1_loss: 0.0457 - val_loss: 0.1447 - val_output_1_loss: 0.1447\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0449 - output_1_loss: 0.0449 - val_loss: 0.1403 - val_output_1_loss: 0.1402\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0146 - output_1_loss: 0.0144Epoch 58/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0146 - output_1_loss: 0.0144 - val_loss: 0.2397 - val_output_1_loss: 0.2392\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0441 - output_1_loss: 0.0440 - val_loss: 0.1359 - val_output_1_loss: 0.1358\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0431 - output_1_loss: 0.0431 - val_loss: 0.1317 - val_output_1_loss: 0.1316\n",
      "Epoch 42/100\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0425 - output_1_loss: 0.0424 - val_loss: 0.1274 - val_output_1_loss: 0.1273\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0139 - output_1_loss: 0.0137 - val_loss: 0.2367 - val_output_1_loss: 0.2362\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0413 - output_1_loss: 0.0412 - val_loss: 0.1230 - val_output_1_loss: 0.1229\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0133 - output_1_loss: 0.0131 - val_loss: 0.2342 - val_output_1_loss: 0.2337\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0410 - output_1_loss: 0.0409 - val_loss: 0.1186 - val_output_1_loss: 0.1185\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0119 - output_1_loss: 0.0116Epoch 63/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0119 - output_1_loss: 0.0116 - val_loss: 0.2316 - val_output_1_loss: 0.2311\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0398 - output_1_loss: 0.0398 - val_loss: 0.1144 - val_output_1_loss: 0.1143\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0394 - output_1_loss: 0.0393 - val_loss: 0.1103 - val_output_1_loss: 0.1102\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - output_1_loss: 0.0099Epoch 65/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0101 - output_1_loss: 0.0099 - val_loss: 0.2292 - val_output_1_loss: 0.2287\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0383 - output_1_loss: 0.0382 - val_loss: 0.1064 - val_output_1_loss: 0.1063\n",
      "Epoch 46/100\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0375 - output_1_loss: 0.0375 - val_loss: 0.1026 - val_output_1_loss: 0.1025\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0089 - output_1_loss: 0.0086 - val_loss: 0.2270 - val_output_1_loss: 0.2265\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0371 - output_1_loss: 0.0370 - val_loss: 0.0991 - val_output_1_loss: 0.0990\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0080 - output_1_loss: 0.0077 - val_loss: 0.2249 - val_output_1_loss: 0.2244\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0361 - output_1_loss: 0.0361Epoch 48/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0361 - output_1_loss: 0.0361 - val_loss: 0.0961 - val_output_1_loss: 0.0960\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0073 - output_1_loss: 0.0070 - val_loss: 0.2227 - val_output_1_loss: 0.2222\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0356 - output_1_loss: 0.0356Epoch 49/100\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0356 - output_1_loss: 0.0356 - val_loss: 0.0931 - val_output_1_loss: 0.0930\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - output_1_loss: 0.0064Epoch 70/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0067 - output_1_loss: 0.0064 - val_loss: 0.2207 - val_output_1_loss: 0.2202\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0349 - output_1_loss: 0.0349 - val_loss: 0.0904 - val_output_1_loss: 0.0903\n",
      "Epoch 50/100\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0342 - output_1_loss: 0.0341 - val_loss: 0.0879 - val_output_1_loss: 0.0878\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0059 - output_1_loss: 0.0056 - val_loss: 0.2184 - val_output_1_loss: 0.2179\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0336 - output_1_loss: 0.0335 - val_loss: 0.0857 - val_output_1_loss: 0.0856\n",
      "Epoch 73/100\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0331 - output_1_loss: 0.0330 - val_loss: 0.0838 - val_output_1_loss: 0.0837\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0055 - output_1_loss: 0.0053 - val_loss: 0.2163 - val_output_1_loss: 0.2159\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0324 - output_1_loss: 0.0324 - val_loss: 0.0820 - val_output_1_loss: 0.0820\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0050 - output_1_loss: 0.0048 - val_loss: 0.2144 - val_output_1_loss: 0.2139\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - output_1_loss: 0.0045Epoch 75/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0047 - output_1_loss: 0.0045 - val_loss: 0.2123 - val_output_1_loss: 0.2118\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0318 - output_1_loss: 0.0317 - val_loss: 0.0805 - val_output_1_loss: 0.0804\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0052 - output_1_loss: 0.0049 - val_loss: 0.2100 - val_output_1_loss: 0.2095\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0313 - output_1_loss: 0.0312Epoch 55/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0313 - output_1_loss: 0.0312 - val_loss: 0.0791 - val_output_1_loss: 0.0791\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0068 - output_1_loss: 0.0065 - val_loss: 0.2083 - val_output_1_loss: 0.2078\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - output_1_loss: 0.0056Epoch 77/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0059 - output_1_loss: 0.0056 - val_loss: 0.2061 - val_output_1_loss: 0.2056\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0309 - output_1_loss: 0.0308 - val_loss: 0.0777 - val_output_1_loss: 0.0777\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0302 - output_1_loss: 0.0302 - val_loss: 0.0765 - val_output_1_loss: 0.0764\n",
      "Epoch 79/100\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0297 - output_1_loss: 0.0297 - val_loss: 0.0755 - val_output_1_loss: 0.0755\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0041 - output_1_loss: 0.0038 - val_loss: 0.2038 - val_output_1_loss: 0.2033\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0294 - output_1_loss: 0.0293 - val_loss: 0.0746 - val_output_1_loss: 0.0746\n",
      "Epoch 81/100\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0288 - output_1_loss: 0.0287 - val_loss: 0.0738 - val_output_1_loss: 0.0737\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0090 - output_1_loss: 0.0088 - val_loss: 0.2014 - val_output_1_loss: 0.2009\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0053 - output_1_loss: 0.0050 - val_loss: 0.1982 - val_output_1_loss: 0.1978\n",
      "Epoch 82/100\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0284 - output_1_loss: 0.0283 - val_loss: 0.0731 - val_output_1_loss: 0.0731\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0099 - output_1_loss: 0.0097Epoch 83/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0099 - output_1_loss: 0.0097 - val_loss: 0.1954 - val_output_1_loss: 0.1949\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0279 - output_1_loss: 0.0278 - val_loss: 0.0724 - val_output_1_loss: 0.0724\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0275 - output_1_loss: 0.0274 - val_loss: 0.0716 - val_output_1_loss: 0.0716\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0080 - output_1_loss: 0.0077 - val_loss: 0.1938 - val_output_1_loss: 0.1933\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0270 - output_1_loss: 0.0269 - val_loss: 0.0710 - val_output_1_loss: 0.0709\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0176 - output_1_loss: 0.0174Epoch 86/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0176 - output_1_loss: 0.0174 - val_loss: 0.1917 - val_output_1_loss: 0.1912\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0266 - output_1_loss: 0.0266 - val_loss: 0.0707 - val_output_1_loss: 0.0706\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0264 - output_1_loss: 0.0264 - val_loss: 0.0702 - val_output_1_loss: 0.0701\n",
      "Epoch 63/100\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0263 - output_1_loss: 0.0262 - val_loss: 0.0700 - val_output_1_loss: 0.0699\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0124 - output_1_loss: 0.0122 - val_loss: 0.1898 - val_output_1_loss: 0.1893\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0147 - output_1_loss: 0.0145 - val_loss: 0.1876 - val_output_1_loss: 0.1871\n",
      "Epoch 65/100\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0265 - output_1_loss: 0.0264 - val_loss: 0.0692 - val_output_1_loss: 0.0691\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0215 - output_1_loss: 0.0213 - val_loss: 0.1847 - val_output_1_loss: 0.1842\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0254 - output_1_loss: 0.0253 - val_loss: 0.0682 - val_output_1_loss: 0.0681\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0099 - output_1_loss: 0.0096 - val_loss: 0.1812 - val_output_1_loss: 0.1807\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0277 - output_1_loss: 0.0276 - val_loss: 0.0675 - val_output_1_loss: 0.0675\n",
      "Epoch 67/100\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0274 - output_1_loss: 0.0273 - val_loss: 0.0671 - val_output_1_loss: 0.0670\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0104 - output_1_loss: 0.0101 - val_loss: 0.1779 - val_output_1_loss: 0.1775\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0270 - output_1_loss: 0.0270 - val_loss: 0.0667 - val_output_1_loss: 0.0667\n",
      "Epoch 68/100\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0102 - output_1_loss: 0.0099 - val_loss: 0.1758 - val_output_1_loss: 0.1753\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0268 - output_1_loss: 0.0268 - val_loss: 0.0665 - val_output_1_loss: 0.0665\n",
      "Epoch 69/100\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0266 - output_1_loss: 0.0266 - val_loss: 0.0662 - val_output_1_loss: 0.0661\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0100 - output_1_loss: 0.0097 - val_loss: 0.1735 - val_output_1_loss: 0.1730\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0260 - output_1_loss: 0.0259 - val_loss: 0.0658 - val_output_1_loss: 0.0657\n",
      "Epoch 70/100\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0256 - output_1_loss: 0.0255 - val_loss: 0.0655 - val_output_1_loss: 0.0654\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0106 - output_1_loss: 0.0104 - val_loss: 0.1710 - val_output_1_loss: 0.1705\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0253 - output_1_loss: 0.0252 - val_loss: 0.0652 - val_output_1_loss: 0.0651\n",
      "Epoch 99/100\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0251 - output_1_loss: 0.0250 - val_loss: 0.0651 - val_output_1_loss: 0.0650\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0102 - output_1_loss: 0.0100 - val_loss: 0.1683 - val_output_1_loss: 0.1678\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0245 - output_1_loss: 0.0245 - val_loss: 0.0651 - val_output_1_loss: 0.0650\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0077 - output_1_loss: 0.0075 - val_loss: 0.1660 - val_output_1_loss: 0.1655\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0069 - output_1_loss: 0.0066 - val_loss: 0.1637 - val_output_1_loss: 0.1632\n",
      "1/1 [==============================] - 1s 780ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:39:04,592]\u001b[0m Trial 97 finished with value: 0.03333333333333333 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 0, 'relaxation_factor': 1.7000000000000002, 'sparsity_coefficient': 2.6641562966067956e-05, 'bn_momentum': 0.9145239930829965}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 0.0075 - output_1_loss: 0.0072 - val_loss: 0.1613 - val_output_1_loss: 0.1608\n",
      "Epoch 1/100\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0075 - output_1_loss: 0.0072 - val_loss: 0.1592 - val_output_1_loss: 0.1587\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.0079 - output_1_loss: 0.0077 - val_loss: 0.1569 - val_output_1_loss: 0.1564\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0069 - output_1_loss: 0.0066 - val_loss: 0.1552 - val_output_1_loss: 0.1548\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.0067 - output_1_loss: 0.0064 - val_loss: 0.1542 - val_output_1_loss: 0.1538\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0064 - output_1_loss: 0.0061 - val_loss: 0.1534 - val_output_1_loss: 0.1529\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0059 - output_1_loss: 0.0056 - val_loss: 0.1528 - val_output_1_loss: 0.1523\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.0054 - output_1_loss: 0.0051 - val_loss: 0.1526 - val_output_1_loss: 0.1521\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.0051 - output_1_loss: 0.0048 - val_loss: 0.1519 - val_output_1_loss: 0.1514\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0048 - output_1_loss: 0.0045 - val_loss: 0.1514 - val_output_1_loss: 0.1509\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0048 - output_1_loss: 0.0045 - val_loss: 0.1510 - val_output_1_loss: 0.1506\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0043 - output_1_loss: 0.0041 - val_loss: 0.1504 - val_output_1_loss: 0.1499\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0042 - output_1_loss: 0.0039 - val_loss: 0.1496 - val_output_1_loss: 0.1491\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.0040 - output_1_loss: 0.0037 - val_loss: 0.1490 - val_output_1_loss: 0.1485\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0038 - output_1_loss: 0.0036 - val_loss: 0.1486 - val_output_1_loss: 0.1482\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.0036 - output_1_loss: 0.0034 - val_loss: 0.1485 - val_output_1_loss: 0.1480\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0034 - output_1_loss: 0.0031 - val_loss: 0.1483 - val_output_1_loss: 0.1478\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.0033 - output_1_loss: 0.0030 - val_loss: 0.1478 - val_output_1_loss: 0.1474\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0031 - output_1_loss: 0.0029 - val_loss: 0.1473 - val_output_1_loss: 0.1469\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0030 - output_1_loss: 0.0028 - val_loss: 0.1469 - val_output_1_loss: 0.1464\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.0030 - output_1_loss: 0.0027 - val_loss: 0.1465 - val_output_1_loss: 0.1461\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0029 - output_1_loss: 0.0026 - val_loss: 0.1463 - val_output_1_loss: 0.1458\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0028 - output_1_loss: 0.0025 - val_loss: 0.1462 - val_output_1_loss: 0.1457\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0028 - output_1_loss: 0.0025 - val_loss: 0.1461 - val_output_1_loss: 0.1456\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0028 - output_1_loss: 0.0025 - val_loss: 0.1464 - val_output_1_loss: 0.1459\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0031 - output_1_loss: 0.0029 - val_loss: 0.1461 - val_output_1_loss: 0.1457\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0042 - output_1_loss: 0.0039 - val_loss: 0.1469 - val_output_1_loss: 0.1464\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:39:14,765]\u001b[0m Trial 96 finished with value: 0.016666666666666666 and parameters: {'feature_dim': 128, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 1.3, 'sparsity_coefficient': 0.00014945287699849686, 'bn_momentum': 0.959585490081182}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 0.9941 - output_1_loss: 0.9940Epoch 1/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.9941 - output_1_loss: 0.9940 - val_loss: 0.6915 - val_output_1_loss: 0.6914\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9191 - output_1_loss: 0.9191 - val_loss: 0.6901 - val_output_1_loss: 0.6899\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.7972 - output_1_loss: 0.7971 - val_loss: 0.6888 - val_output_1_loss: 0.6886\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.7408 - output_1_loss: 0.7407 - val_loss: 0.6871 - val_output_1_loss: 0.6870\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6952 - output_1_loss: 0.6952 - val_loss: 0.6853 - val_output_1_loss: 0.6852\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6737 - output_1_loss: 0.6737 - val_loss: 0.6831 - val_output_1_loss: 0.6830\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.6836 - output_1_loss: 0.6835 - val_loss: 0.6817 - val_output_1_loss: 0.6816\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6666 - output_1_loss: 0.6665 - val_loss: 0.6802 - val_output_1_loss: 0.6801\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6267 - output_1_loss: 0.6266 - val_loss: 0.6782 - val_output_1_loss: 0.6781\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.5846 - output_1_loss: 0.5846 - val_loss: 0.6757 - val_output_1_loss: 0.6755\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5475 - output_1_loss: 0.5474 - val_loss: 0.6728 - val_output_1_loss: 0.6727\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.5125 - output_1_loss: 0.5125 - val_loss: 0.6697 - val_output_1_loss: 0.6696\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.4882 - output_1_loss: 0.4881 - val_loss: 0.6662 - val_output_1_loss: 0.6661\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4590 - output_1_loss: 0.4590 - val_loss: 0.6623 - val_output_1_loss: 0.6622\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4311 - output_1_loss: 0.4311 - val_loss: 0.6580 - val_output_1_loss: 0.6579\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.3970 - output_1_loss: 0.3970 - val_loss: 0.6533 - val_output_1_loss: 0.6532\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3836 - output_1_loss: 0.3835 - val_loss: 0.6484 - val_output_1_loss: 0.6483\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3485 - output_1_loss: 0.3484 - val_loss: 0.6424 - val_output_1_loss: 0.6423\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3267 - output_1_loss: 0.3266 - val_loss: 0.6358 - val_output_1_loss: 0.6357\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.3032 - output_1_loss: 0.3032 - val_loss: 0.6286 - val_output_1_loss: 0.6285\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2858 - output_1_loss: 0.2858 - val_loss: 0.6210 - val_output_1_loss: 0.6209\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2646 - output_1_loss: 0.2645 - val_loss: 0.6126 - val_output_1_loss: 0.6125\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.2467 - output_1_loss: 0.2467 - val_loss: 0.6037 - val_output_1_loss: 0.6036\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.2310 - output_1_loss: 0.2310 - val_loss: 0.5941 - val_output_1_loss: 0.5940\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.2144 - output_1_loss: 0.2143 - val_loss: 0.5838 - val_output_1_loss: 0.5837\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1996 - output_1_loss: 0.1995 - val_loss: 0.5729 - val_output_1_loss: 0.5728\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.1865 - output_1_loss: 0.1864 - val_loss: 0.5615 - val_output_1_loss: 0.5615\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1738 - output_1_loss: 0.1737 - val_loss: 0.5496 - val_output_1_loss: 0.5495\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.1639 - output_1_loss: 0.1639 - val_loss: 0.5373 - val_output_1_loss: 0.5373\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1548 - output_1_loss: 0.1548 - val_loss: 0.5248 - val_output_1_loss: 0.5247\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1451 - output_1_loss: 0.1450 - val_loss: 0.5120 - val_output_1_loss: 0.5119\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1364 - output_1_loss: 0.1364 - val_loss: 0.4991 - val_output_1_loss: 0.4990\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1293 - output_1_loss: 0.1292 - val_loss: 0.4861 - val_output_1_loss: 0.4860\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1230 - output_1_loss: 0.1229 - val_loss: 0.4731 - val_output_1_loss: 0.4730\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1174 - output_1_loss: 0.1173 - val_loss: 0.4602 - val_output_1_loss: 0.4601\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.1121 - output_1_loss: 0.1121 - val_loss: 0.4473 - val_output_1_loss: 0.4472\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1072 - output_1_loss: 0.1072 - val_loss: 0.4345 - val_output_1_loss: 0.4344\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1027 - output_1_loss: 0.1027 - val_loss: 0.4218 - val_output_1_loss: 0.4217\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0987 - output_1_loss: 0.0986 - val_loss: 0.4092 - val_output_1_loss: 0.4091\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0949 - output_1_loss: 0.0949 - val_loss: 0.3968 - val_output_1_loss: 0.3967\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0915 - output_1_loss: 0.0914 - val_loss: 0.3847 - val_output_1_loss: 0.3846\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0882 - output_1_loss: 0.0882 - val_loss: 0.3729 - val_output_1_loss: 0.3728\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0851 - output_1_loss: 0.0850 - val_loss: 0.3613 - val_output_1_loss: 0.3613\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0821 - output_1_loss: 0.0821 - val_loss: 0.3501 - val_output_1_loss: 0.3500\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0793 - output_1_loss: 0.0792 - val_loss: 0.3393 - val_output_1_loss: 0.3392\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0766 - output_1_loss: 0.0765 - val_loss: 0.3290 - val_output_1_loss: 0.3289\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0740 - output_1_loss: 0.0739 - val_loss: 0.3189 - val_output_1_loss: 0.3189\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0715 - output_1_loss: 0.0714 - val_loss: 0.3093 - val_output_1_loss: 0.3092\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.9201 - output_1_loss: 0.9199 - val_loss: 0.6812 - val_output_1_loss: 0.6809\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0692 - output_1_loss: 0.0691 - val_loss: 0.2999 - val_output_1_loss: 0.2999\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0670 - output_1_loss: 0.0669 - val_loss: 0.2908 - val_output_1_loss: 0.2907\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0649 - output_1_loss: 0.0648 - val_loss: 0.2818 - val_output_1_loss: 0.2817\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0628 - output_1_loss: 0.0628 - val_loss: 0.2731 - val_output_1_loss: 0.2731\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0609 - output_1_loss: 0.0609 - val_loss: 0.2649 - val_output_1_loss: 0.2649\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0590 - output_1_loss: 0.0590 - val_loss: 0.2570 - val_output_1_loss: 0.2569\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0573 - output_1_loss: 0.0573 - val_loss: 0.2493 - val_output_1_loss: 0.2493\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0556 - output_1_loss: 0.0555 - val_loss: 0.2419 - val_output_1_loss: 0.2418\n",
      "Epoch 57/100\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0538 - output_1_loss: 0.0538 - val_loss: 0.2346 - val_output_1_loss: 0.2346\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6863 - output_1_loss: 0.6862 - val_loss: 0.6676 - val_output_1_loss: 0.6673\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0523 - output_1_loss: 0.0522 - val_loss: 0.2276 - val_output_1_loss: 0.2275\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.6224 - output_1_loss: 0.6222 - val_loss: 0.6539 - val_output_1_loss: 0.6535\n",
      "Epoch 59/100\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0507 - output_1_loss: 0.0506 - val_loss: 0.2206 - val_output_1_loss: 0.2205\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2783 - output_1_loss: 0.2781 - val_loss: 0.6248 - val_output_1_loss: 0.6245\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0492 - output_1_loss: 0.0492 - val_loss: 0.2138 - val_output_1_loss: 0.2137\n",
      "Epoch 61/100\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0478 - output_1_loss: 0.0478 - val_loss: 0.2072 - val_output_1_loss: 0.2071\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.3273 - output_1_loss: 0.3272 - val_loss: 0.6066 - val_output_1_loss: 0.6063\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0465 - output_1_loss: 0.0464Epoch 6/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0465 - output_1_loss: 0.0464 - val_loss: 0.2008 - val_output_1_loss: 0.2007\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0762 - output_1_loss: 0.0761 - val_loss: 0.5461 - val_output_1_loss: 0.5458\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0452 - output_1_loss: 0.0452 - val_loss: 0.1946 - val_output_1_loss: 0.1945\n",
      "Epoch 64/100\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0439 - output_1_loss: 0.0439 - val_loss: 0.1884 - val_output_1_loss: 0.1884\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0752 - output_1_loss: 0.0750 - val_loss: 0.4795 - val_output_1_loss: 0.4792\n",
      "Epoch 8/100\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0428 - output_1_loss: 0.0427 - val_loss: 0.1825 - val_output_1_loss: 0.1825\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0591 - output_1_loss: 0.0589 - val_loss: 0.4173 - val_output_1_loss: 0.4171\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0416 - output_1_loss: 0.0416 - val_loss: 0.1769 - val_output_1_loss: 0.1768\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0545 - output_1_loss: 0.0543 - val_loss: 0.3614 - val_output_1_loss: 0.3612\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0406 - output_1_loss: 0.0405 - val_loss: 0.1715 - val_output_1_loss: 0.1715\n",
      "Epoch 68/100\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0395 - output_1_loss: 0.0395 - val_loss: 0.1664 - val_output_1_loss: 0.1664\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0483 - output_1_loss: 0.0481 - val_loss: 0.3130 - val_output_1_loss: 0.3128\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0385 - output_1_loss: 0.0384 - val_loss: 0.1615 - val_output_1_loss: 0.1614\n",
      "Epoch 11/100\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0375 - output_1_loss: 0.0374 - val_loss: 0.1567 - val_output_1_loss: 0.1566\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0445 - output_1_loss: 0.0443 - val_loss: 0.2718 - val_output_1_loss: 0.2716\n",
      "Epoch 12/100\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0365 - output_1_loss: 0.0364 - val_loss: 0.1534 - val_output_1_loss: 0.1534\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0398 - output_1_loss: 0.0396 - val_loss: 0.2373 - val_output_1_loss: 0.2371\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0350 - output_1_loss: 0.0349 - val_loss: 0.1549 - val_output_1_loss: 0.1549\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0353 - output_1_loss: 0.0351Epoch 73/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0343 - output_1_loss: 0.0343 - val_loss: 0.1535 - val_output_1_loss: 0.1535\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0353 - output_1_loss: 0.0351 - val_loss: 0.2089 - val_output_1_loss: 0.2087\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0390 - output_1_loss: 0.0390Epoch 14/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0390 - output_1_loss: 0.0390 - val_loss: 0.1455 - val_output_1_loss: 0.1454\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0308 - output_1_loss: 0.0307 - val_loss: 0.1851 - val_output_1_loss: 0.1849\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0287 - output_1_loss: 0.0285Epoch 75/100\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0287 - output_1_loss: 0.0285 - val_loss: 0.1653 - val_output_1_loss: 0.1651\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0327 - output_1_loss: 0.0326 - val_loss: 0.1349 - val_output_1_loss: 0.1348\n",
      "Epoch 76/100\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.0323 - output_1_loss: 0.0323 - val_loss: 0.1287 - val_output_1_loss: 0.1287\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0277 - output_1_loss: 0.0275 - val_loss: 0.1489 - val_output_1_loss: 0.1487\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0263 - output_1_loss: 0.0262Epoch 77/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0263 - output_1_loss: 0.0262 - val_loss: 0.1354 - val_output_1_loss: 0.1352\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0314 - output_1_loss: 0.0314 - val_loss: 0.1241 - val_output_1_loss: 0.1240\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0304 - output_1_loss: 0.0304Epoch 18/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0304 - output_1_loss: 0.0304 - val_loss: 0.1205 - val_output_1_loss: 0.1204\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0255 - output_1_loss: 0.0254 - val_loss: 0.1243 - val_output_1_loss: 0.1240\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0244 - output_1_loss: 0.0243Epoch 79/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0244 - output_1_loss: 0.0243 - val_loss: 0.1149 - val_output_1_loss: 0.1147\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0302 - output_1_loss: 0.0302 - val_loss: 0.1176 - val_output_1_loss: 0.1176\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0240 - output_1_loss: 0.0238 - val_loss: 0.1074 - val_output_1_loss: 0.1072\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0294 - output_1_loss: 0.0293 - val_loss: 0.1151 - val_output_1_loss: 0.1151\n",
      "Epoch 21/100\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0289 - output_1_loss: 0.0289 - val_loss: 0.1125 - val_output_1_loss: 0.1124\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0216 - output_1_loss: 0.0215 - val_loss: 0.1010 - val_output_1_loss: 0.1008\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0283 - output_1_loss: 0.0283 - val_loss: 0.1100 - val_output_1_loss: 0.1100\n",
      "Epoch 83/100\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0276 - output_1_loss: 0.0275 - val_loss: 0.1094 - val_output_1_loss: 0.1093\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0202 - output_1_loss: 0.0200 - val_loss: 0.0954 - val_output_1_loss: 0.0952\n",
      "Epoch 84/100\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0268 - output_1_loss: 0.0267 - val_loss: 0.1102 - val_output_1_loss: 0.1101\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0187 - output_1_loss: 0.0186 - val_loss: 0.0906 - val_output_1_loss: 0.0904\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0277 - output_1_loss: 0.0276 - val_loss: 0.1026 - val_output_1_loss: 0.1026\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0175 - output_1_loss: 0.0173 - val_loss: 0.0865 - val_output_1_loss: 0.0863\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0312 - output_1_loss: 0.0312 - val_loss: 0.0997 - val_output_1_loss: 0.0996\n",
      "Epoch 25/100\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0343 - output_1_loss: 0.0342 - val_loss: 0.0987 - val_output_1_loss: 0.0987\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.0159 - output_1_loss: 0.0157 - val_loss: 0.0831 - val_output_1_loss: 0.0829\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0142 - output_1_loss: 0.0141Epoch 88/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0142 - output_1_loss: 0.0141 - val_loss: 0.0801 - val_output_1_loss: 0.0799\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0302 - output_1_loss: 0.0302Epoch 27/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0302 - output_1_loss: 0.0302 - val_loss: 0.0954 - val_output_1_loss: 0.0954\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0124 - output_1_loss: 0.0123 - val_loss: 0.0775 - val_output_1_loss: 0.0773\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0291 - output_1_loss: 0.0291Epoch 28/100\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0291 - output_1_loss: 0.0291 - val_loss: 0.0922 - val_output_1_loss: 0.0922\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0105 - output_1_loss: 0.0104 - val_loss: 0.0753 - val_output_1_loss: 0.0751\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0288 - output_1_loss: 0.0288 - val_loss: 0.0896 - val_output_1_loss: 0.0896\n",
      "Epoch 29/100\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0280 - output_1_loss: 0.0280 - val_loss: 0.0884 - val_output_1_loss: 0.0884\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0083 - output_1_loss: 0.0081 - val_loss: 0.0733 - val_output_1_loss: 0.0731\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - output_1_loss: 0.0061Epoch 92/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0062 - output_1_loss: 0.0061 - val_loss: 0.0716 - val_output_1_loss: 0.0714\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0272 - output_1_loss: 0.0272 - val_loss: 0.0877 - val_output_1_loss: 0.0876\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0043 - output_1_loss: 0.0042 - val_loss: 0.0700 - val_output_1_loss: 0.0698\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0266 - output_1_loss: 0.0265 - val_loss: 0.0872 - val_output_1_loss: 0.0872\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0031 - output_1_loss: 0.0030 - val_loss: 0.0687 - val_output_1_loss: 0.0685\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0024 - output_1_loss: 0.0023Epoch 94/100\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0024 - output_1_loss: 0.0023 - val_loss: 0.0675 - val_output_1_loss: 0.0673\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0257 - output_1_loss: 0.0257 - val_loss: 0.0869 - val_output_1_loss: 0.0868\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0035 - output_1_loss: 0.0034 - val_loss: 0.0666 - val_output_1_loss: 0.0664\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0249 - output_1_loss: 0.0249 - val_loss: 0.0867 - val_output_1_loss: 0.0867\n",
      "Epoch 35/100\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0353 - output_1_loss: 0.0351 - val_loss: 0.0657 - val_output_1_loss: 0.0655\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0243 - output_1_loss: 0.0243 - val_loss: 0.0866 - val_output_1_loss: 0.0866\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0269 - output_1_loss: 0.0267 - val_loss: 0.0661 - val_output_1_loss: 0.0660\n",
      "Epoch 37/100\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0342 - output_1_loss: 0.0340 - val_loss: 0.0661 - val_output_1_loss: 0.0659\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0241 - output_1_loss: 0.0240 - val_loss: 0.0865 - val_output_1_loss: 0.0864\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0238 - output_1_loss: 0.0236 - val_loss: 0.0657 - val_output_1_loss: 0.0655\n",
      "Epoch 39/100\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0215 - output_1_loss: 0.0213 - val_loss: 0.0656 - val_output_1_loss: 0.0654\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0238 - output_1_loss: 0.0237 - val_loss: 0.0863 - val_output_1_loss: 0.0863\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0234 - output_1_loss: 0.0233 - val_loss: 0.0862 - val_output_1_loss: 0.0861\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0190 - output_1_loss: 0.0189Epoch 100/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0190 - output_1_loss: 0.0189 - val_loss: 0.0657 - val_output_1_loss: 0.0655\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0223 - output_1_loss: 0.0221 - val_loss: 0.0658 - val_output_1_loss: 0.0656\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0229 - output_1_loss: 0.0228 - val_loss: 0.0861 - val_output_1_loss: 0.0860\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0251 - output_1_loss: 0.0250 - val_loss: 0.0658 - val_output_1_loss: 0.0657\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0288 - output_1_loss: 0.0287 - val_loss: 0.0660 - val_output_1_loss: 0.0658\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0179 - output_1_loss: 0.0177 - val_loss: 0.0658 - val_output_1_loss: 0.0656\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:39:39,687]\u001b[0m Trial 98 finished with value: 0.011627906976744186 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 0, 'relaxation_factor': 1.4, 'sparsity_coefficient': 1.7018038783648865e-05, 'bn_momentum': 0.9268480632442077}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-28 04:39:39,946]\u001b[0m Trial 99 finished with value: 0.037037037037037035 and parameters: {'feature_dim': 512, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.6, 'sparsity_coefficient': 4.914270468796725e-05, 'bn_momentum': 0.9339691060033563}. Best is trial 9 with value: 1.0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "\n",
    "def Objective(trial):\n",
    "    feature_dim = trial.suggest_categorical(\"feature_dim\", [32, 64, 128, 256, 512])\n",
    "    n_step = trial.suggest_int(\"n_step\", 2, 9, step=1)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 0, 4, step=1)\n",
    "    relaxation_factor = trial.suggest_float(\"relaxation_factor\", 1., 3., step=0.1)\n",
    "    sparsity_coefficient = trial.suggest_float(\"sparsity_coefficient\", 0.00000001, 0.1, log=True)\n",
    "    bn_momentum = trial.suggest_float(\"bn_momentum\", 0.9, 0.9999)\n",
    "    tabnet_params = dict(num_features=train_X_transformed.shape[1],\n",
    "                         output_dim=feature_dim,\n",
    "                         feature_dim=feature_dim,\n",
    "                         n_step=n_step, \n",
    "                         relaxation_factor=relaxation_factor,\n",
    "                         sparsity_coefficient=sparsity_coefficient,\n",
    "                         n_shared = n_shared,\n",
    "                         bn_momentum = bn_momentum)\n",
    "    \n",
    "    \n",
    "    cbs = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "    )]\n",
    "    \n",
    "    tn = TabNet(**tabnet_params)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=10)\n",
    "    loss = [tf.keras.losses.CategoricalCrossentropy(from_logits=False)]\n",
    "    \n",
    "    tn.compile(optimizer, loss=loss)\n",
    "    tn.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=cbs, verbose=1)\n",
    "    \n",
    "    val_preds, _ =  tn.predict(val_ds)\n",
    "    pr_auc = average_precision_score(val_y, val_preds[:,1])\n",
    "    \n",
    "    return pr_auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, n_jobs=-1, n_trials=100, gc_after_trial=True, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f58a43e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f58a43e",
    "outputId": "1ba5164f-3071-4e37-f556-df5a86ec1c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8348 - output_1_loss: 0.8348 - val_loss: 0.6883 - val_output_1_loss: 0.6883\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7702 - output_1_loss: 0.7702 - val_loss: 0.6806 - val_output_1_loss: 0.6806\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7298 - output_1_loss: 0.7298 - val_loss: 0.6748 - val_output_1_loss: 0.6748\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6864 - output_1_loss: 0.6864 - val_loss: 0.6684 - val_output_1_loss: 0.6684\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5354 - output_1_loss: 0.5354 - val_loss: 0.6590 - val_output_1_loss: 0.6590\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4201 - output_1_loss: 0.4201 - val_loss: 0.6458 - val_output_1_loss: 0.6458\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3515 - output_1_loss: 0.3515 - val_loss: 0.6298 - val_output_1_loss: 0.6298\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3049 - output_1_loss: 0.3049 - val_loss: 0.6121 - val_output_1_loss: 0.6121\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2775 - output_1_loss: 0.2775 - val_loss: 0.5935 - val_output_1_loss: 0.5935\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2565 - output_1_loss: 0.2565 - val_loss: 0.5754 - val_output_1_loss: 0.5754\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2538 - output_1_loss: 0.2538 - val_loss: 0.5619 - val_output_1_loss: 0.5619\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1970 - output_1_loss: 0.1970 - val_loss: 0.5483 - val_output_1_loss: 0.5483\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1913 - output_1_loss: 0.1913 - val_loss: 0.5311 - val_output_1_loss: 0.5311\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1658 - output_1_loss: 0.1658 - val_loss: 0.5115 - val_output_1_loss: 0.5115\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1510 - output_1_loss: 0.1510 - val_loss: 0.4924 - val_output_1_loss: 0.4924\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1357 - output_1_loss: 0.1357 - val_loss: 0.4758 - val_output_1_loss: 0.4758\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1274 - output_1_loss: 0.1274 - val_loss: 0.4636 - val_output_1_loss: 0.4636\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1136 - output_1_loss: 0.1136 - val_loss: 0.4552 - val_output_1_loss: 0.4552\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0973 - output_1_loss: 0.0973 - val_loss: 0.4446 - val_output_1_loss: 0.4446\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1444 - output_1_loss: 0.1444 - val_loss: 0.4319 - val_output_1_loss: 0.4319\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0924 - output_1_loss: 0.0924 - val_loss: 0.4154 - val_output_1_loss: 0.4154\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0810 - output_1_loss: 0.0810 - val_loss: 0.3973 - val_output_1_loss: 0.3973\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0677 - output_1_loss: 0.0677 - val_loss: 0.3798 - val_output_1_loss: 0.3798\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0577 - output_1_loss: 0.0577 - val_loss: 0.3642 - val_output_1_loss: 0.3642\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0492 - output_1_loss: 0.0492 - val_loss: 0.3506 - val_output_1_loss: 0.3506\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0410 - output_1_loss: 0.0410 - val_loss: 0.3388 - val_output_1_loss: 0.3388\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0352 - output_1_loss: 0.0352 - val_loss: 0.3290 - val_output_1_loss: 0.3290\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0275 - output_1_loss: 0.0275 - val_loss: 0.3190 - val_output_1_loss: 0.3190\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0226 - output_1_loss: 0.0226 - val_loss: 0.3079 - val_output_1_loss: 0.3079\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0194 - output_1_loss: 0.0194 - val_loss: 0.2964 - val_output_1_loss: 0.2964\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0170 - output_1_loss: 0.0170 - val_loss: 0.2842 - val_output_1_loss: 0.2842\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0151 - output_1_loss: 0.0151 - val_loss: 0.2717 - val_output_1_loss: 0.2717\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0135 - output_1_loss: 0.0135 - val_loss: 0.2595 - val_output_1_loss: 0.2595\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0123 - output_1_loss: 0.0123 - val_loss: 0.2474 - val_output_1_loss: 0.2474\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0113 - output_1_loss: 0.0113 - val_loss: 0.2356 - val_output_1_loss: 0.2356\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0104 - output_1_loss: 0.0104 - val_loss: 0.2245 - val_output_1_loss: 0.2245\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0098 - output_1_loss: 0.0098 - val_loss: 0.2141 - val_output_1_loss: 0.2141\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0092 - output_1_loss: 0.0092 - val_loss: 0.2045 - val_output_1_loss: 0.2045\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0087 - output_1_loss: 0.0087 - val_loss: 0.1954 - val_output_1_loss: 0.1954\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0083 - output_1_loss: 0.0083 - val_loss: 0.1870 - val_output_1_loss: 0.1870\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0079 - output_1_loss: 0.0079 - val_loss: 0.1790 - val_output_1_loss: 0.1790\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0076 - output_1_loss: 0.0076 - val_loss: 0.1715 - val_output_1_loss: 0.1715\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0073 - output_1_loss: 0.0073 - val_loss: 0.1645 - val_output_1_loss: 0.1645\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0071 - output_1_loss: 0.0071 - val_loss: 0.1581 - val_output_1_loss: 0.1581\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0075 - output_1_loss: 0.0075 - val_loss: 0.1522 - val_output_1_loss: 0.1522\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - output_1_loss: 0.0071 - val_loss: 0.1473 - val_output_1_loss: 0.1473\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0112 - output_1_loss: 0.0112 - val_loss: 0.1430 - val_output_1_loss: 0.1430\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0121 - output_1_loss: 0.0121 - val_loss: 0.1388 - val_output_1_loss: 0.1388\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0119 - output_1_loss: 0.0119 - val_loss: 0.1348 - val_output_1_loss: 0.1348\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0140 - output_1_loss: 0.0140 - val_loss: 0.1311 - val_output_1_loss: 0.1311\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0164 - output_1_loss: 0.0164 - val_loss: 0.1268 - val_output_1_loss: 0.1268\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0225 - output_1_loss: 0.0225 - val_loss: 0.1233 - val_output_1_loss: 0.1233\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0453 - output_1_loss: 0.0453 - val_loss: 0.1203 - val_output_1_loss: 0.1203\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0162 - output_1_loss: 0.0162 - val_loss: 0.1180 - val_output_1_loss: 0.1180\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0143 - output_1_loss: 0.0143 - val_loss: 0.1160 - val_output_1_loss: 0.1160\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0164 - output_1_loss: 0.0164 - val_loss: 0.1141 - val_output_1_loss: 0.1141\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0096 - output_1_loss: 0.0096 - val_loss: 0.1127 - val_output_1_loss: 0.1127\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0095 - output_1_loss: 0.0095 - val_loss: 0.1125 - val_output_1_loss: 0.1125\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0094 - output_1_loss: 0.0094 - val_loss: 0.1180 - val_output_1_loss: 0.1180\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0112 - output_1_loss: 0.0112 - val_loss: 0.1251 - val_output_1_loss: 0.1251\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0090 - output_1_loss: 0.0090 - val_loss: 0.1314 - val_output_1_loss: 0.1314\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0079 - output_1_loss: 0.0079 - val_loss: 0.1149 - val_output_1_loss: 0.1149\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0084 - output_1_loss: 0.0084 - val_loss: 0.1132 - val_output_1_loss: 0.1132\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0084 - output_1_loss: 0.0084 - val_loss: 0.1125 - val_output_1_loss: 0.1125\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0257 - output_1_loss: 0.0257 - val_loss: 0.1115 - val_output_1_loss: 0.1115\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0073 - output_1_loss: 0.0073 - val_loss: 0.1098 - val_output_1_loss: 0.1098\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0075 - output_1_loss: 0.0075 - val_loss: 0.1074 - val_output_1_loss: 0.1074\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0100 - output_1_loss: 0.0100 - val_loss: 0.1053 - val_output_1_loss: 0.1053\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - output_1_loss: 0.0075 - val_loss: 0.1026 - val_output_1_loss: 0.1026\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0074 - output_1_loss: 0.0074 - val_loss: 0.1002 - val_output_1_loss: 0.1002\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0072 - output_1_loss: 0.0072 - val_loss: 0.0972 - val_output_1_loss: 0.0972\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - output_1_loss: 0.0071 - val_loss: 0.0939 - val_output_1_loss: 0.0939\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0070 - output_1_loss: 0.0070 - val_loss: 0.0927 - val_output_1_loss: 0.0927\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0069 - output_1_loss: 0.0069 - val_loss: 0.0919 - val_output_1_loss: 0.0919\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0121 - output_1_loss: 0.0121 - val_loss: 0.0924 - val_output_1_loss: 0.0924\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0101 - output_1_loss: 0.0101 - val_loss: 0.0915 - val_output_1_loss: 0.0915\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - output_1_loss: 0.0068 - val_loss: 0.0919 - val_output_1_loss: 0.0919\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0090 - output_1_loss: 0.0090 - val_loss: 0.0912 - val_output_1_loss: 0.0912\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0865 - output_1_loss: 0.0865 - val_loss: 0.1063 - val_output_1_loss: 0.1063\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0106 - output_1_loss: 0.0106 - val_loss: 0.1057 - val_output_1_loss: 0.1057\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0810 - output_1_loss: 0.0810 - val_loss: 0.1624 - val_output_1_loss: 0.1624\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2498 - output_1_loss: 0.2498 - val_loss: 0.1161 - val_output_1_loss: 0.1161\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1384 - output_1_loss: 0.1384 - val_loss: 0.1051 - val_output_1_loss: 0.1051\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0824 - output_1_loss: 0.0824 - val_loss: 0.1046 - val_output_1_loss: 0.1046\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0694 - output_1_loss: 0.0694 - val_loss: 0.1179 - val_output_1_loss: 0.1179\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0584 - output_1_loss: 0.0584 - val_loss: 0.1657 - val_output_1_loss: 0.1657\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0534 - output_1_loss: 0.0534 - val_loss: 0.1906 - val_output_1_loss: 0.1906\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0546 - output_1_loss: 0.0546 - val_loss: 0.2033 - val_output_1_loss: 0.2033\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0438 - output_1_loss: 0.0438 - val_loss: 0.2133 - val_output_1_loss: 0.2133\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0394 - output_1_loss: 0.0394 - val_loss: 0.2157 - val_output_1_loss: 0.2157\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0484 - output_1_loss: 0.0484 - val_loss: 0.1848 - val_output_1_loss: 0.1848\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0592 - output_1_loss: 0.0592 - val_loss: 0.1787 - val_output_1_loss: 0.1787\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0401 - output_1_loss: 0.0401 - val_loss: 0.1706 - val_output_1_loss: 0.1706\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0394 - output_1_loss: 0.0394 - val_loss: 0.1625 - val_output_1_loss: 0.1625\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0388 - output_1_loss: 0.0388 - val_loss: 0.1562 - val_output_1_loss: 0.1562\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0309 - output_1_loss: 0.0309 - val_loss: 0.1505 - val_output_1_loss: 0.1505\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0325 - output_1_loss: 0.0325 - val_loss: 0.1429 - val_output_1_loss: 0.1429\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0338 - output_1_loss: 0.0338 - val_loss: 0.1334 - val_output_1_loss: 0.1334\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0287 - output_1_loss: 0.0287 - val_loss: 0.1284 - val_output_1_loss: 0.1284\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0257 - output_1_loss: 0.0257 - val_loss: 0.1101 - val_output_1_loss: 0.1101\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0217 - output_1_loss: 0.0217 - val_loss: 0.1084 - val_output_1_loss: 0.1084\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0182 - output_1_loss: 0.0182 - val_loss: 0.1114 - val_output_1_loss: 0.1114\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0171 - output_1_loss: 0.0171 - val_loss: 0.1153 - val_output_1_loss: 0.1153\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0147 - output_1_loss: 0.0146 - val_loss: 0.1175 - val_output_1_loss: 0.1175\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0160 - output_1_loss: 0.0160 - val_loss: 0.1170 - val_output_1_loss: 0.1170\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0137 - output_1_loss: 0.0137 - val_loss: 0.1136 - val_output_1_loss: 0.1136\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0133 - output_1_loss: 0.0133 - val_loss: 0.1100 - val_output_1_loss: 0.1100\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0145 - output_1_loss: 0.0145 - val_loss: 0.1066 - val_output_1_loss: 0.1066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a8968b1d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabnet = TabNet(num_features=train_X_transformed.shape[1],\n",
    "                output_dim=128,\n",
    "                feature_dim=512,\n",
    "                n_step=2, \n",
    "                relaxation_factor=1.6,\n",
    "                sparsity_coefficient=4.914270468796725e-05,\n",
    "                n_shared=3,\n",
    "                bn_momentum=0.9339691060033563)\n",
    "\n",
    "cbs = [tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=30, restore_best_weights=True\n",
    ")]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=10)\n",
    "\n",
    "loss = [tf.keras.losses.CategoricalCrossentropy(from_logits=False)]\n",
    "\n",
    "tabnet.compile(optimizer, loss=loss)\n",
    "\n",
    "tabnet.fit(train_ds, epochs=1000, validation_data=val_ds, callbacks=cbs,\n",
    "           verbose=1, class_weight={0: 1, 1: 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fl5YSdg7tiyN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fl5YSdg7tiyN",
    "outputId": "95ad4a6e-c1b6-4d1c-98e9-b1a7bc57e011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 584ms/step\n",
      "Test ROC AUC 0.6011\n",
      "Test PR AUC 0.025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "val_preds, val_imps = tabnet.predict(val_ds)\n",
    "\n",
    "print('Test ROC AUC', np.round(roc_auc_score(val_y, val_preds[:, 1]), 4))\n",
    "print('Test PR AUC', np.round(average_precision_score(val_y, val_preds[:, 1]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R9FnMav8u9Ii",
   "metadata": {
    "id": "R9FnMav8u9Ii"
   },
   "source": [
    "## Test Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "WLgmlbLUu7qg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "WLgmlbLUu7qg",
    "outputId": "8364a89d-301c-4b11-b772-8786ead522d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cd0241a6-f277-4951-83b8-3876907f94ac\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>18403224</td>\n",
       "      <td>31.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10409</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>18403263</td>\n",
       "      <td>49.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4272</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>18403310</td>\n",
       "      <td>171.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4476</td>\n",
       "      <td>574.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>18403310</td>\n",
       "      <td>284.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10989</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>18403317</td>\n",
       "      <td>67.95</td>\n",
       "      <td>W</td>\n",
       "      <td>18018</td>\n",
       "      <td>452.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 422 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd0241a6-f277-4951-83b8-3876907f94ac')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cd0241a6-f277-4951-83b8-3876907f94ac button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cd0241a6-f277-4951-83b8-3876907f94ac');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   TransactionID  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
       "0        3663549       18403224           31.95         W  10409  111.0   \n",
       "1        3663550       18403263           49.00         W   4272  111.0   \n",
       "2        3663551       18403310          171.00         W   4476  574.0   \n",
       "3        3663552       18403310          284.95         W  10989  360.0   \n",
       "4        3663553       18403317           67.95         W  18018  452.0   \n",
       "\n",
       "   card3       card4  card5  card6  ...    id_32    id_33    id_34    id_35  \\\n",
       "0  150.0        visa  226.0  debit  ...  missing  missing  missing  missing   \n",
       "1  150.0        visa  226.0  debit  ...  missing  missing  missing  missing   \n",
       "2  150.0        visa  226.0  debit  ...  missing  missing  missing  missing   \n",
       "3  150.0        visa  166.0  debit  ...  missing  missing  missing  missing   \n",
       "4  150.0  mastercard  117.0  debit  ...  missing  missing  missing  missing   \n",
       "\n",
       "     id_36    id_37    id_38  DeviceType  DeviceInfo  hour  \n",
       "0  missing  missing  missing     missing     missing   0.0  \n",
       "1  missing  missing  missing     missing     missing   0.0  \n",
       "2  missing  missing  missing     missing     missing   0.0  \n",
       "3  missing  missing  missing     missing     missing   0.0  \n",
       "4  missing  missing  missing     missing     missing   0.0  \n",
       "\n",
       "[5 rows x 422 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "q-XdRtj_vBCo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-XdRtj_vBCo",
    "outputId": "eb4a9134-b28a-4b71-99ef-0b437e413640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 576ms/step\n"
     ]
    }
   ],
   "source": [
    "test_preds, test_imp = tabnet.predict(test_ds)\n",
    "\n",
    "submission_df  = pd.DataFrame({\"TransactionID\": test['TransactionID'].values,\n",
    "                              'isFraud': test_preds[:, 1]})\n",
    "\n",
    "submission_df.to_csv('tabnet_sumbission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
