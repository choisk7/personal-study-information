{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40abcd9d",
   "metadata": {
    "id": "b7c5785c",
    "papermill": {
     "duration": 0.008054,
     "end_time": "2022-11-09T06:09:49.378356",
     "exception": false,
     "start_time": "2022-11-09T06:09:49.370302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "출처: [https://www.kaggle.com/code/electro/deberta-layerwiselr-lastlayerreinit-tensorflow](https://www.kaggle.com/code/electro/deberta-layerwiselr-lastlayerreinit-tensorflow)\n",
    "\n",
    "# DeBERTa LLRD + LastLayerReinit with TensorFlow\n",
    "- MultilabelStratifiedKFold split of the data\n",
    "\n",
    "- HuggingFace DeBERTaV3 pre-trained model finetuning with Tensorflow\n",
    "\n",
    "- WeightedLayerPool + MeanPool TensorFlow implementation\n",
    "\n",
    "- Layer-wise learning rate decay\n",
    "\n",
    "- Last layer reinitialization or partially reinitialzation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb5483",
   "metadata": {
    "id": "871b0853",
    "papermill": {
     "duration": 0.00663,
     "end_time": "2022-11-09T06:09:49.391986",
     "exception": false,
     "start_time": "2022-11-09T06:09:49.385356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1333531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:49.407600Z",
     "iopub.status.busy": "2022-11-09T06:09:49.407046Z",
     "iopub.status.idle": "2022-11-09T06:09:55.507548Z",
     "shell.execute_reply": "2022-11-09T06:09:55.506608Z"
    },
    "id": "18103cc1",
    "outputId": "6d66d8af-7947-4653-d5f0-8f9dc1ba6c45",
    "papermill": {
     "duration": 6.111386,
     "end_time": "2022-11-09T06:09:55.510084",
     "exception": false,
     "start_time": "2022-11-09T06:09:49.398698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.6.4\n",
      "transformers version: 4.20.1\n"
     ]
    }
   ],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f'TF version: {tf.__version__}')\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import transformers\n",
    "print(f'transformers version: {transformers.__version__}')\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cceea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:55.527004Z",
     "iopub.status.busy": "2022-11-09T06:09:55.525313Z",
     "iopub.status.idle": "2022-11-09T06:09:55.531739Z",
     "shell.execute_reply": "2022-11-09T06:09:55.530857Z"
    },
    "id": "9f863ccb",
    "papermill": {
     "duration": 0.016359,
     "end_time": "2022-11-09T06:09:55.533679",
     "exception": false,
     "start_time": "2022-11-09T06:09:55.517320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f836324",
   "metadata": {
    "id": "07525a22",
    "papermill": {
     "duration": 0.006634,
     "end_time": "2022-11-09T06:09:55.547192",
     "exception": false,
     "start_time": "2022-11-09T06:09:55.540558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfeefc12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:55.563628Z",
     "iopub.status.busy": "2022-11-09T06:09:55.562800Z",
     "iopub.status.idle": "2022-11-09T06:09:55.780097Z",
     "shell.execute_reply": "2022-11-09T06:09:55.778402Z"
    },
    "id": "6c3b2aa3",
    "outputId": "49cb013b-1a66-4bee-b270-cc4db9fb07c2",
    "papermill": {
     "duration": 0.22723,
     "end_time": "2022-11-09T06:09:55.782491",
     "exception": false,
     "start_time": "2022-11-09T06:09:55.555261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------DataFrame Summary---------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3911 entries, 0 to 3910\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   text_id      3911 non-null   object \n",
      " 1   full_text    3911 non-null   object \n",
      " 2   cohesion     3911 non-null   float64\n",
      " 3   syntax       3911 non-null   float64\n",
      " 4   vocabulary   3911 non-null   float64\n",
      " 5   phraseology  3911 non-null   float64\n",
      " 6   grammar      3911 non-null   float64\n",
      " 7   conventions  3911 non-null   float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 244.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/feedback-prize-english-language-learning/train.csv\")\n",
    "df.head()\n",
    "print('\\n---------DataFrame Summary---------')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98313519",
   "metadata": {
    "id": "8943ce00",
    "papermill": {
     "duration": 0.006801,
     "end_time": "2022-11-09T06:09:55.797176",
     "exception": false,
     "start_time": "2022-11-09T06:09:55.790375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7881ea59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:55.812758Z",
     "iopub.status.busy": "2022-11-09T06:09:55.812460Z",
     "iopub.status.idle": "2022-11-09T06:09:55.964845Z",
     "shell.execute_reply": "2022-11-09T06:09:55.963578Z"
    },
    "id": "17ff1019",
    "outputId": "00ccc319-9475-41ae-ff72-ab7ce3aa4e26",
    "papermill": {
     "duration": 0.163645,
     "end_time": "2022-11-09T06:09:55.967985",
     "exception": false,
     "start_time": "2022-11-09T06:09:55.804340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    783\n",
       "0    782\n",
       "4    782\n",
       "3    782\n",
       "2    782\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_FOLD = 5\n",
    "TARGET_COLS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "skf = MultilabelStratifiedKFold(n_splits=N_FOLD, shuffle=True, random_state=42)\n",
    "\n",
    "for n, (train_index, val_index) in enumerate(skf.split(df, df[TARGET_COLS])):\n",
    "    df.loc[val_index, \"fold\"] = n\n",
    "\n",
    "df[\"fold\"] = df[\"fold\"].astype(int)\n",
    "df[\"fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb76dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:55.985360Z",
     "iopub.status.busy": "2022-11-09T06:09:55.985048Z",
     "iopub.status.idle": "2022-11-09T06:09:56.136161Z",
     "shell.execute_reply": "2022-11-09T06:09:56.135244Z"
    },
    "id": "abd81a09",
    "papermill": {
     "duration": 0.161935,
     "end_time": "2022-11-09T06:09:56.138335",
     "exception": false,
     "start_time": "2022-11-09T06:09:55.976400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"df_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c9244",
   "metadata": {
    "id": "261708d6",
    "papermill": {
     "duration": 0.006838,
     "end_time": "2022-11-09T06:09:56.152796",
     "exception": false,
     "start_time": "2022-11-09T06:09:56.145958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5990102e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:56.167901Z",
     "iopub.status.busy": "2022-11-09T06:09:56.167636Z",
     "iopub.status.idle": "2022-11-09T06:09:56.172969Z",
     "shell.execute_reply": "2022-11-09T06:09:56.172205Z"
    },
    "id": "a88440d3",
    "papermill": {
     "duration": 0.015175,
     "end_time": "2022-11-09T06:09:56.174964",
     "exception": false,
     "start_time": "2022-11-09T06:09:56.159789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 4\n",
    "DEBERTA_MODEL = \"../input/debertav3base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e7148",
   "metadata": {
    "id": "ae78fbc1",
    "papermill": {
     "duration": 0.006741,
     "end_time": "2022-11-09T06:09:56.188828",
     "exception": false,
     "start_time": "2022-11-09T06:09:56.182087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "regression task에서 dropout을 비활성화 시켜야 하는 이유: [discussion](https://www.kaggle.com/competitions/commonlitreadabilityprize/discussion/260729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aea9ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:56.203679Z",
     "iopub.status.busy": "2022-11-09T06:09:56.203425Z",
     "iopub.status.idle": "2022-11-09T06:09:57.717216Z",
     "shell.execute_reply": "2022-11-09T06:09:57.716131Z"
    },
    "id": "889cd9a5",
    "outputId": "514a8f12-829e-4fc3-e01e-9dced26b029e",
    "papermill": {
     "duration": 1.524279,
     "end_time": "2022-11-09T06:09:57.719991",
     "exception": false,
     "start_time": "2022-11-09T06:09:56.195712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(DEBERTA_MODEL)\n",
    "tokenizer.save_pretrained(\"./tokenizer\")\n",
    "\n",
    "cfg = transformers.AutoConfig.from_pretrained(DEBERTA_MODEL, output_hidden_states=True)\n",
    "cfg.hidden_dropout_prob = 0\n",
    "cfg.attention_probs_dropout_prob = 0\n",
    "cfg.save_pretrained(\"./tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da754e2a",
   "metadata": {
    "id": "ac7408eb",
    "papermill": {
     "duration": 0.007188,
     "end_time": "2022-11-09T06:09:57.734663",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.727475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Process Function\n",
    "HugggingFace DeBERTa 모델을 사용하려면 pre-training된 DeBERTa 모델이 요구하는 대로 input text를 토큰화해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95975ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:57.750250Z",
     "iopub.status.busy": "2022-11-09T06:09:57.749801Z",
     "iopub.status.idle": "2022-11-09T06:09:57.756889Z",
     "shell.execute_reply": "2022-11-09T06:09:57.756080Z"
    },
    "id": "8ba5319b",
    "papermill": {
     "duration": 0.017261,
     "end_time": "2022-11-09T06:09:57.758897",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.741636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deberta_encode(texts, tokenizer=tokenizer):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for text in texts.tolist():\n",
    "        token = tokenizer(text,\n",
    "                          max_length=MAX_LENGTH,\n",
    "                          return_attention_mask=True,\n",
    "                          return_tensors=\"np\",\n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\")\n",
    "        input_ids.append(token[\"input_ids\"][0])\n",
    "        attention_mask.append(token[\"attention_mask\"][0])\n",
    "        \n",
    "    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4526fc7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:57.774468Z",
     "iopub.status.busy": "2022-11-09T06:09:57.773701Z",
     "iopub.status.idle": "2022-11-09T06:09:57.778328Z",
     "shell.execute_reply": "2022-11-09T06:09:57.777380Z"
    },
    "id": "00079ae2",
    "papermill": {
     "duration": 0.014397,
     "end_time": "2022-11-09T06:09:57.780194",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.765797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(df):\n",
    "    inputs = deberta_encode(df[\"full_text\"])\n",
    "    targets = np.array(df[TARGET_COLS], dtype=\"float32\")\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dee3b3",
   "metadata": {
    "id": "475409e7",
    "papermill": {
     "duration": 0.006743,
     "end_time": "2022-11-09T06:09:57.793934",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.787191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3fddb",
   "metadata": {
    "id": "31668060",
    "papermill": {
     "duration": 0.006831,
     "end_time": "2022-11-09T06:09:57.807717",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.800886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MeanPool\n",
    "[CLS] token을 사용하는 대신 padding token을 masking하여 sequence axis를 따라 hidden state의 한 layer를 평균화하는 MeanPool method을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122e1d2",
   "metadata": {
    "id": "851463d4",
    "papermill": {
     "duration": 0.0068,
     "end_time": "2022-11-09T06:09:57.821630",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.814830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## WeightedLayerPool\n",
    "WeightedLayerPool은 training 가능한 weight set를 사용하여 transformer backbone에서 hidden state 세트를 평균화합니다. 여기서는 이것을 구현하기 위해 constraint가 있는 Dense layer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "136e04eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:57.837358Z",
     "iopub.status.busy": "2022-11-09T06:09:57.836599Z",
     "iopub.status.idle": "2022-11-09T06:09:57.842799Z",
     "shell.execute_reply": "2022-11-09T06:09:57.842014Z"
    },
    "id": "7d0251cd",
    "papermill": {
     "duration": 0.016025,
     "end_time": "2022-11-09T06:09:57.844685",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.828660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPool(tf.keras.layers.Layer):\n",
    "    def call(self, inputs, mask=None):\n",
    "        # inputs: (None, 512, 768)\n",
    "        \n",
    "        # (None, 512, 1)\n",
    "        broadcast_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
    "        \n",
    "        # (None, 768)\n",
    "        embedding_sum = tf.reduce_sum(inputs * broadcast_mask, axis=1)\n",
    "        \n",
    "        # (None, 1)\n",
    "        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n",
    "        \n",
    "        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n",
    "        return embedding_sum / mask_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9139d8a0",
   "metadata": {
    "id": "94aa5f5c",
    "papermill": {
     "duration": 0.006899,
     "end_time": "2022-11-09T06:09:57.858505",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.851606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "WeightedLayerPool weights constraints: sum(w)을 1로 만들기 위한 softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd2d4b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:57.873936Z",
     "iopub.status.busy": "2022-11-09T06:09:57.873202Z",
     "iopub.status.idle": "2022-11-09T06:09:57.878032Z",
     "shell.execute_reply": "2022-11-09T06:09:57.877266Z"
    },
    "id": "8b0f3993",
    "papermill": {
     "duration": 0.014461,
     "end_time": "2022-11-09T06:09:57.879939",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.865478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightsSumOne(tf.keras.constraints.Constraint):\n",
    "    def __call__(self, w):\n",
    "        return tf.nn.softmax(w, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be913d97",
   "metadata": {
    "id": "1195f818",
    "papermill": {
     "duration": 0.006783,
     "end_time": "2022-11-09T06:09:57.893795",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.887012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Design Choice\n",
    "final representation을 얻는 방법에는 여러 가지가 있지만 DeBERTa의 마지막 4개 layer hidden state를 선택하고, 그 중 MeanPool을 사용하여 sequence axis를 따라 정보를 수집한 다음, training 가능한 weight set와 함께 WeightedLayerPool을 사용하여 model의 depth axis를 따라 정보를 수집합니다. 마지막으로는 regression head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b311c38",
   "metadata": {
    "id": "463a73f8",
    "papermill": {
     "duration": 0.006869,
     "end_time": "2022-11-09T06:09:57.908167",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.901298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Last Layer Reinitialization\n",
    "마지막 transformer encoder block의 reinitialization: Dense kerenl을 위한 GlorotUniform, Dense bias를 위한 Zeros, LayerNorm beta를 위한 Zeros, LayerNorm gamma를 위한 Ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93afcd9b",
   "metadata": {
    "id": "2a2a7164",
    "papermill": {
     "duration": 0.006798,
     "end_time": "2022-11-09T06:09:57.921917",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.915119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Layer-wise Learning Rate Decay\n",
    "MultiOptimizer를 사용하여 LLRD를 구현합니다: transformer encoder와 embedding block의 경우 layer-wise decay가 0.9인 초기 learning rate 1e-5, 나머지 model의 경우 1e-4입니다. 모든 learning rate에는 decay rate이 0.3인 ExponentialDecay scheduler가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6e9f14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:57.937716Z",
     "iopub.status.busy": "2022-11-09T06:09:57.937186Z",
     "iopub.status.idle": "2022-11-09T06:09:57.953250Z",
     "shell.execute_reply": "2022-11-09T06:09:57.952332Z"
    },
    "id": "33444019",
    "papermill": {
     "duration": 0.026267,
     "end_time": "2022-11-09T06:09:57.955373",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.929106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_ids = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32,\n",
    "                                      name=\"input_ids\")\n",
    "    attention_masks = tf.keras.layers.Input(shape=(MAX_LENGTH,), dtype=tf.int32,\n",
    "                                            name=\"attention_masks\")\n",
    "    \n",
    "    deberta_model = transformers.TFAutoModel.from_pretrained(DEBERTA_MODEL,\n",
    "                                                             config=cfg)\n",
    "    \n",
    "    REINIT_LAYERS = 1\n",
    "    normal_initializer = tf.keras.initializers.GlorotUniform()\n",
    "    zeros_initializer = tf.keras.initializers.Zeros()\n",
    "    ones_initializer = tf.keras.initializers.Ones()\n",
    "    \n",
    "    for encoder_block in deberta_model.deberta.encoder.layer[-REINIT_LAYERS:]:\n",
    "        for layer in encoder_block.submodules:\n",
    "            if isinstance(layer, tf.keras.layers.Dense):\n",
    "                layer.kernel.assign(normal_initializer(shape=layer.kernel.shape,\n",
    "                                                       dtype=layer.kernel.dtype))\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.assign(zeros_initializer(shape=layer.bias.shape,\n",
    "                                                        dtype=layer.bias.dtype))\n",
    "            \n",
    "            elif isinstance(layer, tf.keras.layers.LayerNormalization):\n",
    "                layer.beta.assign(zeros_initializer(shape=layer.beta.shape,\n",
    "                                                    dtype=layer.beta.dtype))\n",
    "                layer.gamma.assign(ones_initializer(shape=layer.gamma.shape,\n",
    "                                                    dtype=layer.gamma.dtype))\n",
    "    \n",
    "    deberta_output = deberta_model.deberta(input_ids, attention_mask=attention_masks)\n",
    "    hidden_states = deberta_output.hidden_states # (None, 512, 768) 여러개\n",
    "    \n",
    "    # WeightedLayerPool + MeanPool of the last 4 hidden states\n",
    "    stack_meanpool = tf.stack([MeanPool()(hidden_s, mask=attention_masks)\n",
    "                               for hidden_s in hidden_states[-4:]],\n",
    "                              axis=2) # (None, 768, 4)\n",
    "    \n",
    "    weighted_layer_pool = layers.Dense(1, use_bias=False,\n",
    "                                      kernel_constraint=WeightsSumOne())(stack_meanpool)\n",
    "    \n",
    "    weighted_layer_pool = tf.squeeze(weighted_layer_pool, axis=-1)\n",
    "    \n",
    "    x = layers.Dense(6, activation=\"sigmoid\")(weighted_layer_pool)\n",
    "    output = layers.Rescaling(scale=4.0, offset=1.0)(x)\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n",
    "    \n",
    "    # Compile model with Layer-wise Learning Rate Decay\n",
    "    layer_list = [deberta_model.deberta.embeddings] + list(deberta_model.deberta.encoder.layer)\n",
    "    layer_list.reverse()\n",
    "    \n",
    "    INIT_LR = 1e-5\n",
    "    LLRDR = 0.9\n",
    "    LR_SCH_DECAY_STEPS = 1600 # 2 * len(train_df) // BATCH_SIZE\n",
    "    \n",
    "    lr_schedules = [tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=INIT_LR * LLRDR ** i,\n",
    "        decay_steps=LR_SCH_DECAY_STEPS,\n",
    "        decay_rate=0.3) for i in range(len(layer_list))]\n",
    "    \n",
    "    lr_schedule_head = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-4,\n",
    "        decay_steps=LR_SCH_DECAY_STEPS,\n",
    "        decay_rate=0.3\n",
    "    )\n",
    "    \n",
    "    optimizers = [tf.keras.optimizers.Adam(learning_rate=lr_sch) for lr_sch in lr_schedules]\n",
    "    \n",
    "    optimizers_and_layers = [(tf.keras.optimizers.Adam(learning_rate=lr_schedule_head),\n",
    "                              model.layers[-4:])] + list(zip(optimizers, layer_list))\n",
    "    \n",
    "    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"huber_loss\",\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9938bc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:09:57.971929Z",
     "iopub.status.busy": "2022-11-09T06:09:57.971198Z",
     "iopub.status.idle": "2022-11-09T06:10:24.416972Z",
     "shell.execute_reply": "2022-11-09T06:10:24.414393Z"
    },
    "id": "79e6387f",
    "outputId": "d11c6d46-0fc9-40b1-ec36-d0663bad8a4c",
    "papermill": {
     "duration": 26.457267,
     "end_time": "2022-11-09T06:10:24.419928",
     "exception": false,
     "start_time": "2022-11-09T06:09:57.962661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 06:09:59.493138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:09:59.494217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:09:59.494896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:09:59.495755: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 06:09:59.496083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:09:59.496771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:09:59.497428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:10:04.029922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:10:04.030780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:10:04.031467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-09 06:10:04.032050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15043 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-11-09 06:10:14.576277: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "deberta (TFDebertaV2MainLayer)  TFBaseModelOutput(la 183831552   input_ids[0][0]                  \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool (MeanPool)            (None, 768)          0           deberta[0][9]                    \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_1 (MeanPool)          (None, 768)          0           deberta[0][10]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_2 (MeanPool)          (None, 768)          0           deberta[0][11]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_3 (MeanPool)          (None, 768)          0           deberta[0][12]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack (TFOpLambda)           (None, 768, 4)       0           mean_pool[0][0]                  \n",
      "                                                                 mean_pool_1[0][0]                \n",
      "                                                                 mean_pool_2[0][0]                \n",
      "                                                                 mean_pool_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 768, 1)       4           tf.stack[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 768)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            4614        tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 6)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 183,836,170\n",
      "Trainable params: 183,836,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb331864",
   "metadata": {
    "id": "HHd0grJXtPlb",
    "papermill": {
     "duration": 0.007365,
     "end_time": "2022-11-09T06:10:24.435714",
     "exception": false,
     "start_time": "2022-11-09T06:10:24.428349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5 Folds Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb1faf59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T06:10:24.469761Z",
     "iopub.status.busy": "2022-11-09T06:10:24.469026Z",
     "iopub.status.idle": "2022-11-09T09:37:09.139636Z",
     "shell.execute_reply": "2022-11-09T09:37:09.138638Z"
    },
    "id": "60c07ce2",
    "outputId": "5deff487-9fea-4475-d7bf-8c72a41921d4",
    "papermill": {
     "duration": 12404.689593,
     "end_time": "2022-11-09T09:37:09.142485",
     "exception": false,
     "start_time": "2022-11-09T06:10:24.452892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------FOLD 0 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 06:10:43.814448: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 418s 478ms/step - loss: 0.1230 - root_mean_squared_error: 0.4997 - val_loss: 0.1047 - val_root_mean_squared_error: 0.4588\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10474, saving model to best_model_fold0.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 368s 470ms/step - loss: 0.1000 - root_mean_squared_error: 0.4485 - val_loss: 0.1070 - val_root_mean_squared_error: 0.4637\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.10474\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.0916 - root_mean_squared_error: 0.4289 - val_loss: 0.1011 - val_root_mean_squared_error: 0.4506\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10474 to 0.10110, saving model to best_model_fold0.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.0865 - root_mean_squared_error: 0.4164 - val_loss: 0.1025 - val_root_mean_squared_error: 0.4537\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10110\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 367s 468ms/step - loss: 0.0832 - root_mean_squared_error: 0.4084 - val_loss: 0.1021 - val_root_mean_squared_error: 0.4527\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10110\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 366s 468ms/step - loss: 0.0813 - root_mean_squared_error: 0.4037 - val_loss: 0.1026 - val_root_mean_squared_error: 0.4539\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10110\n",
      "Epoch 00006: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 1 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3128, 512) dtype: int32\n",
      "Training data attention_mask shape: (3128, 512) dtype: int32\n",
      "Training data targets shape: (3128, 6) dtype: float32\n",
      "Validation data input_ids shape: (783, 512) dtype: int32\n",
      "Validation data attention_mask shape: (783, 512) dtype: int32\n",
      "Validation data targets shape: (783, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 383s 447ms/step - loss: 0.1240 - root_mean_squared_error: 0.5017 - val_loss: 0.1072 - val_root_mean_squared_error: 0.4647\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10719, saving model to best_model_fold1.h5\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.0991 - root_mean_squared_error: 0.4463 - val_loss: 0.1061 - val_root_mean_squared_error: 0.4620\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10719 to 0.10606, saving model to best_model_fold1.h5\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.0901 - root_mean_squared_error: 0.4250 - val_loss: 0.1068 - val_root_mean_squared_error: 0.4638\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10606\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.0854 - root_mean_squared_error: 0.4138 - val_loss: 0.1054 - val_root_mean_squared_error: 0.4605\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10606 to 0.10541, saving model to best_model_fold1.h5\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.0820 - root_mean_squared_error: 0.4053 - val_loss: 0.1048 - val_root_mean_squared_error: 0.4591\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10541 to 0.10475, saving model to best_model_fold1.h5\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.0800 - root_mean_squared_error: 0.4003 - val_loss: 0.1058 - val_root_mean_squared_error: 0.4614\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10475\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.0790 - root_mean_squared_error: 0.3979 - val_loss: 0.1049 - val_root_mean_squared_error: 0.4595\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10475\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.0783 - root_mean_squared_error: 0.3962 - val_loss: 0.1049 - val_root_mean_squared_error: 0.4595\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10475\n",
      "Epoch 00008: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 2 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 415s 476ms/step - loss: 0.1229 - root_mean_squared_error: 0.4991 - val_loss: 0.1131 - val_root_mean_squared_error: 0.4780\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11313, saving model to best_model_fold2.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.0987 - root_mean_squared_error: 0.4453 - val_loss: 0.1061 - val_root_mean_squared_error: 0.4626\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11313 to 0.10613, saving model to best_model_fold2.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 367s 468ms/step - loss: 0.0906 - root_mean_squared_error: 0.4265 - val_loss: 0.1106 - val_root_mean_squared_error: 0.4731\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10613\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.0856 - root_mean_squared_error: 0.4143 - val_loss: 0.1070 - val_root_mean_squared_error: 0.4647\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.10613\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.0823 - root_mean_squared_error: 0.4061 - val_loss: 0.1072 - val_root_mean_squared_error: 0.4654\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10613\n",
      "Epoch 00005: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 3 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 414s 475ms/step - loss: 0.1214 - root_mean_squared_error: 0.4957 - val_loss: 0.1091 - val_root_mean_squared_error: 0.4684\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10907, saving model to best_model_fold3.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 366s 467ms/step - loss: 0.0982 - root_mean_squared_error: 0.4443 - val_loss: 0.1040 - val_root_mean_squared_error: 0.4571\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10907 to 0.10395, saving model to best_model_fold3.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 365s 467ms/step - loss: 0.0901 - root_mean_squared_error: 0.4251 - val_loss: 0.1034 - val_root_mean_squared_error: 0.4557\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10395 to 0.10337, saving model to best_model_fold3.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 366s 467ms/step - loss: 0.0849 - root_mean_squared_error: 0.4125 - val_loss: 0.1030 - val_root_mean_squared_error: 0.4550\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10337 to 0.10301, saving model to best_model_fold3.h5\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 366s 467ms/step - loss: 0.0818 - root_mean_squared_error: 0.4049 - val_loss: 0.1030 - val_root_mean_squared_error: 0.4550\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10301\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 367s 468ms/step - loss: 0.0799 - root_mean_squared_error: 0.4001 - val_loss: 0.1036 - val_root_mean_squared_error: 0.4563\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10301\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.0788 - root_mean_squared_error: 0.3973 - val_loss: 0.1033 - val_root_mean_squared_error: 0.4557\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10301\n",
      "Epoch 00007: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 4 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 419s 479ms/step - loss: 0.1217 - root_mean_squared_error: 0.4961 - val_loss: 0.1055 - val_root_mean_squared_error: 0.4612\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10550, saving model to best_model_fold4.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 368s 471ms/step - loss: 0.0989 - root_mean_squared_error: 0.4459 - val_loss: 0.1040 - val_root_mean_squared_error: 0.4576\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10550 to 0.10404, saving model to best_model_fold4.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.0913 - root_mean_squared_error: 0.4280 - val_loss: 0.1033 - val_root_mean_squared_error: 0.4558\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10404 to 0.10327, saving model to best_model_fold4.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 368s 470ms/step - loss: 0.0857 - root_mean_squared_error: 0.4145 - val_loss: 0.1016 - val_root_mean_squared_error: 0.4522\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10327 to 0.10158, saving model to best_model_fold4.h5\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.0827 - root_mean_squared_error: 0.4072 - val_loss: 0.1017 - val_root_mean_squared_error: 0.4524\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10158\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 368s 470ms/step - loss: 0.0807 - root_mean_squared_error: 0.4022 - val_loss: 0.1022 - val_root_mean_squared_error: 0.4535\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10158\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.0797 - root_mean_squared_error: 0.3997 - val_loss: 0.1016 - val_root_mean_squared_error: 0.4522\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10158\n",
      "Epoch 00007: early stopping\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "valid_rmses = []\n",
    "for fold in range(N_FOLD):\n",
    "    print(f'\\n-----------FOLD {fold} ------------')\n",
    "    train_df = df[df[\"fold\"] != fold].reset_index(drop=True)\n",
    "    valid_df = df[df[\"fold\"] == fold].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = get_dataset(train_df)\n",
    "    valid_dataset = get_dataset(valid_df)\n",
    "\n",
    "    print('Data prepared.')\n",
    "    print(f'Training data input_ids shape: {train_dataset[0][0].shape} dtype: {train_dataset[0][0].dtype}') \n",
    "    print(f'Training data attention_mask shape: {train_dataset[0][1].shape} dtype: {train_dataset[0][1].dtype}')\n",
    "    print(f'Training data targets shape: {train_dataset[1].shape} dtype: {train_dataset[1].dtype}')\n",
    "    print(f'Validation data input_ids shape: {valid_dataset[0][0].shape} dtype: {valid_dataset[0][0].dtype}')\n",
    "    print(f'Validation data attention_mask shape: {valid_dataset[0][1].shape} dtype: {valid_dataset[0][1].dtype}')\n",
    "    print(f'Validation data targets shape: {valid_dataset[1].shape} dtype: {valid_dataset[1].dtype}')\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = get_model()\n",
    "    print('Model prepared.')\n",
    "\n",
    "    print('Start training...')\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(f\"best_model_fold{fold}.h5\", monitor=\"val_loss\",\n",
    "                                                     mode=\"min\", save_best_only=True,\n",
    "                                                     verbose=1, save_weights_only=True),\n",
    "                 tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=1e-5, \n",
    "                                                  patience=3, verbose=1, mode=\"min\")]\n",
    "    history = model.fit(x=train_dataset[0], y=train_dataset[1],\n",
    "                        validation_data=valid_dataset,\n",
    "                        epochs=10, shuffle=True,\n",
    "                        batch_size=BATCH_SIZE, callbacks=callbacks)\n",
    "    valid_rmses.append(np.min(history.history[\"val_root_mean_squared_error\"]))\n",
    "\n",
    "    print('Training finished.')\n",
    "    del train_dataset, valid_dataset, train_df, valid_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247df44f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:37:12.164952Z",
     "iopub.status.busy": "2022-11-09T09:37:12.164579Z",
     "iopub.status.idle": "2022-11-09T09:37:12.223654Z",
     "shell.execute_reply": "2022-11-09T09:37:12.222138Z"
    },
    "id": "Gw53zKV_uuFR",
    "outputId": "0edba42c-e579-44ac-b5b1-13d46446caa0",
    "papermill": {
     "duration": 1.486277,
     "end_time": "2022-11-09T09:37:12.226388",
     "exception": false,
     "start_time": "2022-11-09T09:37:10.740111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Folds validation RMSE:\n",
      "[0.4505632519721985, 0.459128201007843, 0.46264517307281494, 0.45495015382766724, 0.45215508341789246]\n",
      "Local CV Average score: 0.45588837265968324\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(valid_rmses)} Folds validation RMSE:\\n{valid_rmses}')\n",
    "print(f'Local CV Average score: {np.mean(valid_rmses)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4b543",
   "metadata": {
    "id": "WS_Byq4doAMk",
    "papermill": {
     "duration": 1.424849,
     "end_time": "2022-11-09T09:37:15.060745",
     "exception": false,
     "start_time": "2022-11-09T09:37:13.635896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d059bd26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:37:17.824181Z",
     "iopub.status.busy": "2022-11-09T09:37:17.823795Z",
     "iopub.status.idle": "2022-11-09T09:37:17.853012Z",
     "shell.execute_reply": "2022-11-09T09:37:17.852026Z"
    },
    "id": "4eZF5hxYn9rU",
    "outputId": "41673b2d-cff5-4c86-c561-3ffab7488d4f",
    "papermill": {
     "duration": 1.45815,
     "end_time": "2022-11-09T09:37:17.855247",
     "exception": false,
     "start_time": "2022-11-09T09:37:16.397097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../input/feedback-prize-english-language-learning/test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7f217aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:37:20.855685Z",
     "iopub.status.busy": "2022-11-09T09:37:20.855320Z",
     "iopub.status.idle": "2022-11-09T09:37:20.872876Z",
     "shell.execute_reply": "2022-11-09T09:37:20.871991Z"
    },
    "id": "QW3wja7soF_K",
    "papermill": {
     "duration": 1.590304,
     "end_time": "2022-11-09T09:37:20.874880",
     "exception": false,
     "start_time": "2022-11-09T09:37:19.284576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = deberta_encode(test_df['full_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c3c49b",
   "metadata": {
    "id": "1epJVT46oYCD",
    "papermill": {
     "duration": 1.415918,
     "end_time": "2022-11-09T09:37:23.717367",
     "exception": false,
     "start_time": "2022-11-09T09:37:22.301449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5 Folds ensemble prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "719bda10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:37:26.599654Z",
     "iopub.status.busy": "2022-11-09T09:37:26.598971Z",
     "iopub.status.idle": "2022-11-09T09:39:34.616240Z",
     "shell.execute_reply": "2022-11-09T09:39:34.615224Z"
    },
    "id": "VUrr85J2oV75",
    "outputId": "9e2f32cc-ee02-43ba-c2cf-46c2cdb925c9",
    "papermill": {
     "duration": 129.535342,
     "end_time": "2022-11-09T09:39:34.619059",
     "exception": false,
     "start_time": "2022-11-09T09:37:25.083717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 inference...\n",
      "\n",
      "Fold 1 inference...\n",
      "\n",
      "Fold 2 inference...\n",
      "\n",
      "Fold 3 inference...\n",
      "\n",
      "Fold 4 inference...\n"
     ]
    }
   ],
   "source": [
    "fold_preds = []\n",
    "for fold in range(N_FOLD):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = get_model()\n",
    "    model.load_weights(f\"best_model_fold{fold}.h5\")\n",
    "    print(f'\\nFold {fold} inference...')\n",
    "    pred = model.predict(test_dataset, batch_size=BATCH_SIZE)\n",
    "    fold_preds.append(pred)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "400711f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:39:37.402643Z",
     "iopub.status.busy": "2022-11-09T09:39:37.402268Z",
     "iopub.status.idle": "2022-11-09T09:39:37.432443Z",
     "shell.execute_reply": "2022-11-09T09:39:37.431582Z"
    },
    "id": "r8WJDvJVpEAa",
    "papermill": {
     "duration": 1.477783,
     "end_time": "2022-11-09T09:39:37.434397",
     "exception": false,
     "start_time": "2022-11-09T09:39:35.956614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.mean(fold_preds, axis=0)\n",
    "preds = np.clip(preds, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f460d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:39:40.201285Z",
     "iopub.status.busy": "2022-11-09T09:39:40.200899Z",
     "iopub.status.idle": "2022-11-09T09:39:40.209376Z",
     "shell.execute_reply": "2022-11-09T09:39:40.208478Z"
    },
    "id": "Led2c-yPpWnJ",
    "papermill": {
     "duration": 1.364961,
     "end_time": "2022-11-09T09:39:40.211310",
     "exception": false,
     "start_time": "2022-11-09T09:39:38.846349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = pd.concat([test_df[[\"text_id\"]], pd.DataFrame(preds, columns=TARGET_COLS)], axis=1)\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3897b3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T09:39:43.126187Z",
     "iopub.status.busy": "2022-11-09T09:39:43.125762Z",
     "iopub.status.idle": "2022-11-09T09:39:43.139966Z",
     "shell.execute_reply": "2022-11-09T09:39:43.139092Z"
    },
    "id": "4XoA_lNopnKB",
    "outputId": "96e8dd35-1b82-46fa-d9ad-c5f5cc15c20c",
    "papermill": {
     "duration": 1.506604,
     "end_time": "2022-11-09T09:39:43.142377",
     "exception": false,
     "start_time": "2022-11-09T09:39:41.635773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.927250</td>\n",
       "      <td>2.759098</td>\n",
       "      <td>3.090907</td>\n",
       "      <td>2.983907</td>\n",
       "      <td>2.65453</td>\n",
       "      <td>2.625527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.697297</td>\n",
       "      <td>2.502063</td>\n",
       "      <td>2.743973</td>\n",
       "      <td>2.359509</td>\n",
       "      <td>2.12162</td>\n",
       "      <td>2.607434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.708724</td>\n",
       "      <td>3.460325</td>\n",
       "      <td>3.653716</td>\n",
       "      <td>3.513729</td>\n",
       "      <td>3.37132</td>\n",
       "      <td>3.262542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology  grammar  \\\n",
       "0  0000C359D63E  2.927250  2.759098    3.090907     2.983907  2.65453   \n",
       "1  000BAD50D026  2.697297  2.502063    2.743973     2.359509  2.12162   \n",
       "2  00367BB2546B  3.708724  3.460325    3.653716     3.513729  3.37132   \n",
       "\n",
       "   conventions  \n",
       "0     2.625527  \n",
       "1     2.607434  \n",
       "2     3.262542  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80a531",
   "metadata": {
    "id": "TarwPkuupn_J",
    "papermill": {
     "duration": 1.792498,
     "end_time": "2022-11-09T09:39:46.489223",
     "exception": false,
     "start_time": "2022-11-09T09:39:44.696725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12609.463856,
   "end_time": "2022-11-09T09:39:51.216345",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-09T06:09:41.752489",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
